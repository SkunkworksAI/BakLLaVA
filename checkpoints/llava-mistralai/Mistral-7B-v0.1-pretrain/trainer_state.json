{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 18606,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "learning_rate": 3.5778175313059034e-06,
      "loss": 7.4609,
      "step": 1
    },
    {
      "epoch": 0.0,
      "learning_rate": 7.155635062611807e-06,
      "loss": 7.5,
      "step": 2
    },
    {
      "epoch": 0.0,
      "learning_rate": 1.073345259391771e-05,
      "loss": 7.4609,
      "step": 3
    },
    {
      "epoch": 0.0,
      "learning_rate": 1.4311270125223614e-05,
      "loss": 7.5703,
      "step": 4
    },
    {
      "epoch": 0.0,
      "learning_rate": 1.7889087656529517e-05,
      "loss": 7.5391,
      "step": 5
    },
    {
      "epoch": 0.0,
      "learning_rate": 2.146690518783542e-05,
      "loss": 7.1328,
      "step": 6
    },
    {
      "epoch": 0.0,
      "learning_rate": 2.5044722719141324e-05,
      "loss": 7.1172,
      "step": 7
    },
    {
      "epoch": 0.0,
      "learning_rate": 2.8622540250447228e-05,
      "loss": 6.7812,
      "step": 8
    },
    {
      "epoch": 0.0,
      "learning_rate": 3.2200357781753134e-05,
      "loss": 6.4844,
      "step": 9
    },
    {
      "epoch": 0.0,
      "learning_rate": 3.5778175313059034e-05,
      "loss": 6.3516,
      "step": 10
    },
    {
      "epoch": 0.0,
      "learning_rate": 3.935599284436494e-05,
      "loss": 6.2266,
      "step": 11
    },
    {
      "epoch": 0.0,
      "learning_rate": 4.293381037567084e-05,
      "loss": 6.3047,
      "step": 12
    },
    {
      "epoch": 0.0,
      "learning_rate": 4.651162790697674e-05,
      "loss": 5.9688,
      "step": 13
    },
    {
      "epoch": 0.0,
      "learning_rate": 5.008944543828265e-05,
      "loss": 5.7188,
      "step": 14
    },
    {
      "epoch": 0.0,
      "learning_rate": 5.366726296958855e-05,
      "loss": 5.7578,
      "step": 15
    },
    {
      "epoch": 0.0,
      "learning_rate": 5.7245080500894455e-05,
      "loss": 5.7031,
      "step": 16
    },
    {
      "epoch": 0.0,
      "learning_rate": 6.082289803220036e-05,
      "loss": 5.6484,
      "step": 17
    },
    {
      "epoch": 0.0,
      "learning_rate": 6.440071556350627e-05,
      "loss": 5.6016,
      "step": 18
    },
    {
      "epoch": 0.0,
      "learning_rate": 6.797853309481217e-05,
      "loss": 5.4375,
      "step": 19
    },
    {
      "epoch": 0.0,
      "learning_rate": 7.155635062611807e-05,
      "loss": 5.3672,
      "step": 20
    },
    {
      "epoch": 0.0,
      "learning_rate": 7.513416815742398e-05,
      "loss": 5.6172,
      "step": 21
    },
    {
      "epoch": 0.0,
      "learning_rate": 7.871198568872988e-05,
      "loss": 5.375,
      "step": 22
    },
    {
      "epoch": 0.0,
      "learning_rate": 8.228980322003578e-05,
      "loss": 5.1016,
      "step": 23
    },
    {
      "epoch": 0.0,
      "learning_rate": 8.586762075134168e-05,
      "loss": 5.0938,
      "step": 24
    },
    {
      "epoch": 0.0,
      "learning_rate": 8.94454382826476e-05,
      "loss": 5.125,
      "step": 25
    },
    {
      "epoch": 0.0,
      "learning_rate": 9.302325581395348e-05,
      "loss": 4.9922,
      "step": 26
    },
    {
      "epoch": 0.0,
      "learning_rate": 9.660107334525938e-05,
      "loss": 5.0938,
      "step": 27
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.0001001788908765653,
      "loss": 4.8438,
      "step": 28
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.0001037567084078712,
      "loss": 5.0078,
      "step": 29
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.0001073345259391771,
      "loss": 5.0156,
      "step": 30
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.00011091234347048301,
      "loss": 4.7266,
      "step": 31
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.00011449016100178891,
      "loss": 4.8516,
      "step": 32
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.00011806797853309481,
      "loss": 4.7734,
      "step": 33
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.00012164579606440072,
      "loss": 4.7891,
      "step": 34
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.0001252236135957066,
      "loss": 4.6953,
      "step": 35
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.00012880143112701254,
      "loss": 4.5391,
      "step": 36
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.00013237924865831842,
      "loss": 4.6484,
      "step": 37
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.00013595706618962434,
      "loss": 4.5938,
      "step": 38
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.00013953488372093022,
      "loss": 4.5859,
      "step": 39
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.00014311270125223614,
      "loss": 4.4609,
      "step": 40
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.00014669051878354202,
      "loss": 4.4453,
      "step": 41
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.00015026833631484796,
      "loss": 4.5156,
      "step": 42
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.00015384615384615385,
      "loss": 4.3125,
      "step": 43
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.00015742397137745977,
      "loss": 4.3906,
      "step": 44
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.00016100178890876565,
      "loss": 4.1719,
      "step": 45
    },
    {
      "epoch": 0.0,
      "learning_rate": 0.00016457960644007157,
      "loss": 4.4062,
      "step": 46
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00016815742397137745,
      "loss": 4.0547,
      "step": 47
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00017173524150268337,
      "loss": 4.2188,
      "step": 48
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00017531305903398928,
      "loss": 4.1758,
      "step": 49
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0001788908765652952,
      "loss": 4.0977,
      "step": 50
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00018246869409660108,
      "loss": 4.3438,
      "step": 51
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00018604651162790697,
      "loss": 4.3281,
      "step": 52
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00018962432915921288,
      "loss": 4.0586,
      "step": 53
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00019320214669051877,
      "loss": 4.0859,
      "step": 54
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0001967799642218247,
      "loss": 4.1289,
      "step": 55
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0002003577817531306,
      "loss": 3.9844,
      "step": 56
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0002039355992844365,
      "loss": 4.0586,
      "step": 57
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0002075134168157424,
      "loss": 3.9414,
      "step": 58
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0002110912343470483,
      "loss": 3.8984,
      "step": 59
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0002146690518783542,
      "loss": 3.8047,
      "step": 60
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0002182468694096601,
      "loss": 3.8438,
      "step": 61
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00022182468694096602,
      "loss": 3.9258,
      "step": 62
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00022540250447227193,
      "loss": 3.8516,
      "step": 63
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00022898032200357782,
      "loss": 4.0352,
      "step": 64
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00023255813953488373,
      "loss": 4.0508,
      "step": 65
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00023613595706618962,
      "loss": 3.7617,
      "step": 66
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00023971377459749553,
      "loss": 3.8203,
      "step": 67
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00024329159212880145,
      "loss": 3.8164,
      "step": 68
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00024686940966010736,
      "loss": 3.7344,
      "step": 69
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0002504472271914132,
      "loss": 3.7227,
      "step": 70
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00025402504472271913,
      "loss": 3.7773,
      "step": 71
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0002576028622540251,
      "loss": 3.8516,
      "step": 72
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00026118067978533096,
      "loss": 3.668,
      "step": 73
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00026475849731663685,
      "loss": 3.5469,
      "step": 74
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00026833631484794273,
      "loss": 3.7422,
      "step": 75
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0002719141323792487,
      "loss": 3.9492,
      "step": 76
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00027549194991055456,
      "loss": 3.5781,
      "step": 77
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00027906976744186045,
      "loss": 3.8047,
      "step": 78
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0002826475849731664,
      "loss": 3.5195,
      "step": 79
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0002862254025044723,
      "loss": 3.5234,
      "step": 80
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0002898032200357782,
      "loss": 3.7305,
      "step": 81
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00029338103756708405,
      "loss": 3.6484,
      "step": 82
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00029695885509839,
      "loss": 3.8359,
      "step": 83
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00030053667262969593,
      "loss": 3.6016,
      "step": 84
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00030411449016100176,
      "loss": 3.6172,
      "step": 85
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0003076923076923077,
      "loss": 3.6211,
      "step": 86
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0003112701252236136,
      "loss": 3.7891,
      "step": 87
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00031484794275491953,
      "loss": 3.457,
      "step": 88
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00031842576028622536,
      "loss": 3.7422,
      "step": 89
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0003220035778175313,
      "loss": 3.4727,
      "step": 90
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00032558139534883724,
      "loss": 3.5938,
      "step": 91
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00032915921288014313,
      "loss": 3.6367,
      "step": 92
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.000332737030411449,
      "loss": 3.3672,
      "step": 93
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0003363148479427549,
      "loss": 3.5781,
      "step": 94
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00033989266547406084,
      "loss": 3.6719,
      "step": 95
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00034347048300536673,
      "loss": 3.5508,
      "step": 96
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0003470483005366726,
      "loss": 3.3828,
      "step": 97
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00035062611806797856,
      "loss": 3.457,
      "step": 98
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00035420393559928444,
      "loss": 3.5234,
      "step": 99
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0003577817531305904,
      "loss": 3.6211,
      "step": 100
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0003613595706618962,
      "loss": 3.4922,
      "step": 101
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00036493738819320216,
      "loss": 3.1445,
      "step": 102
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0003685152057245081,
      "loss": 3.6094,
      "step": 103
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00037209302325581393,
      "loss": 3.4258,
      "step": 104
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00037567084078711987,
      "loss": 3.5391,
      "step": 105
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00037924865831842576,
      "loss": 3.4023,
      "step": 106
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0003828264758497317,
      "loss": 3.543,
      "step": 107
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00038640429338103753,
      "loss": 3.3008,
      "step": 108
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00038998211091234347,
      "loss": 3.4453,
      "step": 109
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0003935599284436494,
      "loss": 3.582,
      "step": 110
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0003971377459749553,
      "loss": 3.4062,
      "step": 111
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0004007155635062612,
      "loss": 3.4336,
      "step": 112
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00040429338103756707,
      "loss": 3.4453,
      "step": 113
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.000407871198568873,
      "loss": 3.418,
      "step": 114
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0004114490161001789,
      "loss": 3.3555,
      "step": 115
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0004150268336314848,
      "loss": 3.2344,
      "step": 116
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0004186046511627907,
      "loss": 3.2852,
      "step": 117
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0004221824686940966,
      "loss": 3.3047,
      "step": 118
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0004257602862254025,
      "loss": 3.3008,
      "step": 119
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0004293381037567084,
      "loss": 3.3359,
      "step": 120
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0004329159212880143,
      "loss": 3.4297,
      "step": 121
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0004364937388193202,
      "loss": 3.2852,
      "step": 122
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0004400715563506261,
      "loss": 3.207,
      "step": 123
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00044364937388193204,
      "loss": 3.3086,
      "step": 124
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0004472271914132379,
      "loss": 3.3125,
      "step": 125
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00045080500894454387,
      "loss": 3.2539,
      "step": 126
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0004543828264758497,
      "loss": 3.1367,
      "step": 127
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00045796064400715564,
      "loss": 3.2852,
      "step": 128
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0004615384615384616,
      "loss": 3.0547,
      "step": 129
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00046511627906976747,
      "loss": 3.0938,
      "step": 130
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00046869409660107335,
      "loss": 3.1797,
      "step": 131
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00047227191413237924,
      "loss": 3.2266,
      "step": 132
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0004758497316636852,
      "loss": 3.0859,
      "step": 133
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00047942754919499107,
      "loss": 3.0352,
      "step": 134
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00048300536672629695,
      "loss": 3.2812,
      "step": 135
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0004865831842576029,
      "loss": 3.2305,
      "step": 136
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0004901610017889088,
      "loss": 3.0898,
      "step": 137
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0004937388193202147,
      "loss": 3.2734,
      "step": 138
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0004973166368515206,
      "loss": 2.9922,
      "step": 139
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005008944543828264,
      "loss": 3.0898,
      "step": 140
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005044722719141323,
      "loss": 3.1836,
      "step": 141
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005080500894454383,
      "loss": 3.0742,
      "step": 142
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005116279069767442,
      "loss": 3.0117,
      "step": 143
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005152057245080502,
      "loss": 3.1211,
      "step": 144
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.000518783542039356,
      "loss": 3.2383,
      "step": 145
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005223613595706619,
      "loss": 3.0781,
      "step": 146
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005259391771019679,
      "loss": 2.9805,
      "step": 147
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005295169946332737,
      "loss": 3.0664,
      "step": 148
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005330948121645796,
      "loss": 3.0078,
      "step": 149
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005366726296958855,
      "loss": 3.1055,
      "step": 150
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005402504472271914,
      "loss": 3.1016,
      "step": 151
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005438282647584974,
      "loss": 3.1289,
      "step": 152
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005474060822898033,
      "loss": 3.1445,
      "step": 153
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005509838998211091,
      "loss": 2.9922,
      "step": 154
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.000554561717352415,
      "loss": 2.9492,
      "step": 155
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005581395348837209,
      "loss": 3.0078,
      "step": 156
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005617173524150268,
      "loss": 3.0273,
      "step": 157
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005652951699463328,
      "loss": 3.082,
      "step": 158
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005688729874776386,
      "loss": 3.0898,
      "step": 159
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005724508050089446,
      "loss": 3.0234,
      "step": 160
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005760286225402505,
      "loss": 3.0,
      "step": 161
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005796064400715564,
      "loss": 2.9453,
      "step": 162
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005831842576028623,
      "loss": 3.1133,
      "step": 163
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005867620751341681,
      "loss": 3.1641,
      "step": 164
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.000590339892665474,
      "loss": 3.1875,
      "step": 165
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.00059391771019678,
      "loss": 3.0039,
      "step": 166
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0005974955277280859,
      "loss": 2.9453,
      "step": 167
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006010733452593919,
      "loss": 3.1836,
      "step": 168
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006046511627906977,
      "loss": 3.0234,
      "step": 169
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006082289803220035,
      "loss": 3.0664,
      "step": 170
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006118067978533095,
      "loss": 3.1484,
      "step": 171
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006153846153846154,
      "loss": 2.918,
      "step": 172
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006189624329159212,
      "loss": 2.8438,
      "step": 173
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006225402504472272,
      "loss": 2.8945,
      "step": 174
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006261180679785331,
      "loss": 3.082,
      "step": 175
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006296958855098391,
      "loss": 2.9766,
      "step": 176
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.000633273703041145,
      "loss": 3.0039,
      "step": 177
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006368515205724507,
      "loss": 2.9141,
      "step": 178
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006404293381037567,
      "loss": 2.957,
      "step": 179
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006440071556350626,
      "loss": 2.8945,
      "step": 180
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006475849731663685,
      "loss": 2.957,
      "step": 181
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006511627906976745,
      "loss": 2.9883,
      "step": 182
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006547406082289803,
      "loss": 2.8984,
      "step": 183
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006583184257602863,
      "loss": 3.043,
      "step": 184
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006618962432915922,
      "loss": 2.9062,
      "step": 185
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.000665474060822898,
      "loss": 2.9922,
      "step": 186
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.000669051878354204,
      "loss": 2.8672,
      "step": 187
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006726296958855098,
      "loss": 3.0156,
      "step": 188
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006762075134168157,
      "loss": 3.0312,
      "step": 189
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006797853309481217,
      "loss": 2.8398,
      "step": 190
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006833631484794276,
      "loss": 2.9141,
      "step": 191
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006869409660107335,
      "loss": 2.8281,
      "step": 192
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006905187835420393,
      "loss": 2.9805,
      "step": 193
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006940966010733452,
      "loss": 2.9609,
      "step": 194
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0006976744186046512,
      "loss": 3.0859,
      "step": 195
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007012522361359571,
      "loss": 2.7539,
      "step": 196
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.000704830053667263,
      "loss": 2.832,
      "step": 197
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007084078711985689,
      "loss": 2.9219,
      "step": 198
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007119856887298748,
      "loss": 2.8945,
      "step": 199
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007155635062611808,
      "loss": 2.9375,
      "step": 200
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007191413237924866,
      "loss": 2.8008,
      "step": 201
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007227191413237924,
      "loss": 2.7266,
      "step": 202
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007262969588550984,
      "loss": 2.8828,
      "step": 203
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007298747763864043,
      "loss": 2.7188,
      "step": 204
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007334525939177103,
      "loss": 2.7148,
      "step": 205
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007370304114490162,
      "loss": 2.9141,
      "step": 206
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.000740608228980322,
      "loss": 2.8438,
      "step": 207
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007441860465116279,
      "loss": 2.875,
      "step": 208
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007477638640429338,
      "loss": 3.0742,
      "step": 209
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007513416815742397,
      "loss": 3.0742,
      "step": 210
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007549194991055456,
      "loss": 2.6797,
      "step": 211
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007584973166368515,
      "loss": 2.8906,
      "step": 212
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007620751341681575,
      "loss": 2.8477,
      "step": 213
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007656529516994634,
      "loss": 2.7734,
      "step": 214
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007692307692307693,
      "loss": 2.7578,
      "step": 215
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007728085867620751,
      "loss": 2.957,
      "step": 216
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.000776386404293381,
      "loss": 2.8359,
      "step": 217
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007799642218246869,
      "loss": 2.9219,
      "step": 218
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007835420393559929,
      "loss": 2.8555,
      "step": 219
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007871198568872988,
      "loss": 2.7422,
      "step": 220
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007906976744186047,
      "loss": 2.8633,
      "step": 221
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007942754919499106,
      "loss": 2.8828,
      "step": 222
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0007978533094812164,
      "loss": 2.7461,
      "step": 223
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0008014311270125224,
      "loss": 2.7812,
      "step": 224
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0008050089445438283,
      "loss": 2.9141,
      "step": 225
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0008085867620751341,
      "loss": 2.7227,
      "step": 226
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0008121645796064401,
      "loss": 2.8125,
      "step": 227
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.000815742397137746,
      "loss": 3.0586,
      "step": 228
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.000819320214669052,
      "loss": 2.7578,
      "step": 229
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0008228980322003578,
      "loss": 2.8008,
      "step": 230
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0008264758497316636,
      "loss": 2.8242,
      "step": 231
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0008300536672629696,
      "loss": 2.668,
      "step": 232
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0008336314847942755,
      "loss": 2.8281,
      "step": 233
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0008372093023255815,
      "loss": 2.9141,
      "step": 234
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0008407871198568873,
      "loss": 2.9492,
      "step": 235
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0008443649373881932,
      "loss": 2.6562,
      "step": 236
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0008479427549194992,
      "loss": 2.7617,
      "step": 237
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.000851520572450805,
      "loss": 2.9375,
      "step": 238
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0008550983899821109,
      "loss": 2.75,
      "step": 239
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0008586762075134168,
      "loss": 2.8945,
      "step": 240
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0008622540250447227,
      "loss": 3.0312,
      "step": 241
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0008658318425760287,
      "loss": 2.7695,
      "step": 242
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0008694096601073346,
      "loss": 2.9766,
      "step": 243
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0008729874776386404,
      "loss": 2.8008,
      "step": 244
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0008765652951699464,
      "loss": 3.0352,
      "step": 245
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0008801431127012522,
      "loss": 2.8125,
      "step": 246
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0008837209302325581,
      "loss": 2.8008,
      "step": 247
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0008872987477638641,
      "loss": 2.8945,
      "step": 248
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0008908765652951699,
      "loss": 2.8711,
      "step": 249
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0008944543828264759,
      "loss": 2.8086,
      "step": 250
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0008980322003577818,
      "loss": 2.9805,
      "step": 251
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009016100178890877,
      "loss": 2.8438,
      "step": 252
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009051878354203937,
      "loss": 2.793,
      "step": 253
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009087656529516994,
      "loss": 2.707,
      "step": 254
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009123434704830053,
      "loss": 2.9258,
      "step": 255
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009159212880143113,
      "loss": 2.7852,
      "step": 256
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009194991055456172,
      "loss": 2.8711,
      "step": 257
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009230769230769232,
      "loss": 2.7812,
      "step": 258
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.000926654740608229,
      "loss": 2.7266,
      "step": 259
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009302325581395349,
      "loss": 2.8867,
      "step": 260
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009338103756708408,
      "loss": 2.7852,
      "step": 261
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009373881932021467,
      "loss": 2.7227,
      "step": 262
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009409660107334525,
      "loss": 2.9922,
      "step": 263
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009445438282647585,
      "loss": 2.6406,
      "step": 264
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009481216457960644,
      "loss": 2.6992,
      "step": 265
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009516994633273704,
      "loss": 2.8789,
      "step": 266
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009552772808586763,
      "loss": 2.7578,
      "step": 267
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009588550983899821,
      "loss": 2.7812,
      "step": 268
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.000962432915921288,
      "loss": 2.9219,
      "step": 269
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009660107334525939,
      "loss": 2.9609,
      "step": 270
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009695885509838999,
      "loss": 2.7383,
      "step": 271
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009731663685152058,
      "loss": 2.7305,
      "step": 272
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009767441860465116,
      "loss": 2.8203,
      "step": 273
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009803220035778176,
      "loss": 2.7734,
      "step": 274
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009838998211091235,
      "loss": 2.7031,
      "step": 275
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009874776386404294,
      "loss": 2.7773,
      "step": 276
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009910554561717354,
      "loss": 2.793,
      "step": 277
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009946332737030411,
      "loss": 2.8242,
      "step": 278
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.000998211091234347,
      "loss": 2.7812,
      "step": 279
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010017889087656528,
      "loss": 2.8555,
      "step": 280
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010053667262969587,
      "loss": 2.6953,
      "step": 281
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010089445438282647,
      "loss": 2.6719,
      "step": 282
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010125223613595706,
      "loss": 2.5781,
      "step": 283
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010161001788908765,
      "loss": 2.7969,
      "step": 284
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010196779964221825,
      "loss": 2.707,
      "step": 285
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010232558139534884,
      "loss": 2.8281,
      "step": 286
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010268336314847944,
      "loss": 2.7148,
      "step": 287
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010304114490161003,
      "loss": 2.7109,
      "step": 288
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.001033989266547406,
      "loss": 2.8359,
      "step": 289
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.001037567084078712,
      "loss": 2.6328,
      "step": 290
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.001041144901610018,
      "loss": 3.0547,
      "step": 291
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010447227191413238,
      "loss": 2.8086,
      "step": 292
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010483005366726298,
      "loss": 2.6641,
      "step": 293
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010518783542039357,
      "loss": 2.7422,
      "step": 294
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010554561717352415,
      "loss": 2.7539,
      "step": 295
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010590339892665474,
      "loss": 2.9336,
      "step": 296
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010626118067978533,
      "loss": 2.75,
      "step": 297
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010661896243291593,
      "loss": 2.7773,
      "step": 298
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.001069767441860465,
      "loss": 2.8281,
      "step": 299
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.001073345259391771,
      "loss": 2.7891,
      "step": 300
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010769230769230769,
      "loss": 2.8867,
      "step": 301
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010805008944543828,
      "loss": 2.9375,
      "step": 302
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010840787119856888,
      "loss": 2.6602,
      "step": 303
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010876565295169947,
      "loss": 2.7383,
      "step": 304
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010912343470483006,
      "loss": 2.6133,
      "step": 305
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010948121645796066,
      "loss": 2.8438,
      "step": 306
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0010983899821109125,
      "loss": 2.5625,
      "step": 307
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0011019677996422182,
      "loss": 2.8281,
      "step": 308
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0011055456171735242,
      "loss": 2.6328,
      "step": 309
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.00110912343470483,
      "loss": 2.8516,
      "step": 310
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0011127012522361359,
      "loss": 2.6523,
      "step": 311
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0011162790697674418,
      "loss": 2.6641,
      "step": 312
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0011198568872987477,
      "loss": 2.7305,
      "step": 313
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0011234347048300537,
      "loss": 2.7617,
      "step": 314
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0011270125223613596,
      "loss": 2.8164,
      "step": 315
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0011305903398926656,
      "loss": 2.7461,
      "step": 316
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0011341681574239715,
      "loss": 2.832,
      "step": 317
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0011377459749552772,
      "loss": 2.7461,
      "step": 318
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0011413237924865832,
      "loss": 2.8086,
      "step": 319
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.001144901610017889,
      "loss": 2.75,
      "step": 320
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.001148479427549195,
      "loss": 2.9297,
      "step": 321
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.001152057245080501,
      "loss": 2.7852,
      "step": 322
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.001155635062611807,
      "loss": 2.6992,
      "step": 323
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0011592128801431129,
      "loss": 2.7852,
      "step": 324
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0011627906976744186,
      "loss": 2.75,
      "step": 325
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0011663685152057245,
      "loss": 2.832,
      "step": 326
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0011699463327370303,
      "loss": 2.8477,
      "step": 327
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0011735241502683362,
      "loss": 2.8125,
      "step": 328
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0011771019677996421,
      "loss": 2.7109,
      "step": 329
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.001180679785330948,
      "loss": 2.8398,
      "step": 330
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.001184257602862254,
      "loss": 2.6406,
      "step": 331
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.00118783542039356,
      "loss": 2.8008,
      "step": 332
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.001191413237924866,
      "loss": 2.9297,
      "step": 333
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0011949910554561718,
      "loss": 2.668,
      "step": 334
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0011985688729874778,
      "loss": 2.5977,
      "step": 335
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012021466905187837,
      "loss": 2.8438,
      "step": 336
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012057245080500894,
      "loss": 2.7031,
      "step": 337
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012093023255813954,
      "loss": 2.5938,
      "step": 338
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012128801431127013,
      "loss": 2.6836,
      "step": 339
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.001216457960644007,
      "loss": 2.8867,
      "step": 340
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.001220035778175313,
      "loss": 2.6758,
      "step": 341
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.001223613595706619,
      "loss": 2.7773,
      "step": 342
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012271914132379249,
      "loss": 2.6797,
      "step": 343
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012307692307692308,
      "loss": 2.7891,
      "step": 344
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012343470483005368,
      "loss": 2.7617,
      "step": 345
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012379248658318425,
      "loss": 2.7344,
      "step": 346
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012415026833631484,
      "loss": 2.543,
      "step": 347
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012450805008944544,
      "loss": 2.793,
      "step": 348
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012486583184257603,
      "loss": 2.6094,
      "step": 349
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012522361359570662,
      "loss": 2.8047,
      "step": 350
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012558139534883722,
      "loss": 2.668,
      "step": 351
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012593917710196781,
      "loss": 2.7812,
      "step": 352
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.001262969588550984,
      "loss": 2.8008,
      "step": 353
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.00126654740608229,
      "loss": 2.8164,
      "step": 354
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.001270125223613596,
      "loss": 2.7188,
      "step": 355
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012737030411449014,
      "loss": 2.6523,
      "step": 356
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012772808586762074,
      "loss": 2.832,
      "step": 357
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012808586762075133,
      "loss": 2.793,
      "step": 358
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012844364937388193,
      "loss": 2.793,
      "step": 359
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012880143112701252,
      "loss": 2.8945,
      "step": 360
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0012915921288014312,
      "loss": 2.6602,
      "step": 361
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.001295169946332737,
      "loss": 2.8516,
      "step": 362
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.001298747763864043,
      "loss": 2.6211,
      "step": 363
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.001302325581395349,
      "loss": 2.8438,
      "step": 364
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013059033989266547,
      "loss": 2.5977,
      "step": 365
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013094812164579606,
      "loss": 2.7148,
      "step": 366
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013130590339892666,
      "loss": 2.582,
      "step": 367
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013166368515205725,
      "loss": 2.6992,
      "step": 368
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013202146690518785,
      "loss": 2.7148,
      "step": 369
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013237924865831844,
      "loss": 2.7656,
      "step": 370
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013273703041144901,
      "loss": 2.6562,
      "step": 371
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.001330948121645796,
      "loss": 2.7227,
      "step": 372
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.001334525939177102,
      "loss": 2.6992,
      "step": 373
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.001338103756708408,
      "loss": 2.6328,
      "step": 374
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013416815742397137,
      "loss": 2.6602,
      "step": 375
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013452593917710196,
      "loss": 2.7109,
      "step": 376
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013488372093023256,
      "loss": 2.7109,
      "step": 377
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013524150268336315,
      "loss": 2.5273,
      "step": 378
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013559928443649374,
      "loss": 2.668,
      "step": 379
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013595706618962434,
      "loss": 2.6211,
      "step": 380
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013631484794275493,
      "loss": 2.6133,
      "step": 381
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013667262969588553,
      "loss": 2.6562,
      "step": 382
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013703041144901612,
      "loss": 2.7539,
      "step": 383
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.001373881932021467,
      "loss": 2.8203,
      "step": 384
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013774597495527729,
      "loss": 2.6602,
      "step": 385
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013810375670840786,
      "loss": 2.7227,
      "step": 386
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013846153846153845,
      "loss": 2.6992,
      "step": 387
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013881932021466905,
      "loss": 2.7266,
      "step": 388
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013917710196779964,
      "loss": 2.6289,
      "step": 389
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013953488372093023,
      "loss": 2.7422,
      "step": 390
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0013989266547406083,
      "loss": 2.7305,
      "step": 391
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014025044722719142,
      "loss": 2.7578,
      "step": 392
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014060822898032202,
      "loss": 2.6172,
      "step": 393
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.001409660107334526,
      "loss": 2.7031,
      "step": 394
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014132379248658318,
      "loss": 2.75,
      "step": 395
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014168157423971378,
      "loss": 2.7148,
      "step": 396
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014203935599284437,
      "loss": 2.6406,
      "step": 397
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014239713774597497,
      "loss": 2.6797,
      "step": 398
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014275491949910556,
      "loss": 2.7305,
      "step": 399
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014311270125223615,
      "loss": 2.582,
      "step": 400
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014347048300536673,
      "loss": 2.7383,
      "step": 401
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014382826475849732,
      "loss": 2.5508,
      "step": 402
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.001441860465116279,
      "loss": 2.5625,
      "step": 403
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014454382826475849,
      "loss": 2.6797,
      "step": 404
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014490161001788908,
      "loss": 2.582,
      "step": 405
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014525939177101968,
      "loss": 2.6367,
      "step": 406
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014561717352415027,
      "loss": 2.7227,
      "step": 407
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014597495527728086,
      "loss": 2.6641,
      "step": 408
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014633273703041146,
      "loss": 2.4258,
      "step": 409
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014669051878354205,
      "loss": 2.5898,
      "step": 410
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014704830053667265,
      "loss": 2.7227,
      "step": 411
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014740608228980324,
      "loss": 2.7773,
      "step": 412
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014776386404293381,
      "loss": 2.6055,
      "step": 413
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.001481216457960644,
      "loss": 2.7383,
      "step": 414
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.00148479427549195,
      "loss": 2.6875,
      "step": 415
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014883720930232557,
      "loss": 2.5234,
      "step": 416
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014919499105545617,
      "loss": 2.6758,
      "step": 417
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0014955277280858676,
      "loss": 2.6484,
      "step": 418
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0014991055456171735,
      "loss": 2.5664,
      "step": 419
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015026833631484795,
      "loss": 2.6758,
      "step": 420
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015062611806797854,
      "loss": 2.6055,
      "step": 421
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015098389982110912,
      "loss": 2.7891,
      "step": 422
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.001513416815742397,
      "loss": 2.5273,
      "step": 423
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.001516994633273703,
      "loss": 2.6523,
      "step": 424
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.001520572450805009,
      "loss": 2.5664,
      "step": 425
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.001524150268336315,
      "loss": 2.6094,
      "step": 426
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015277280858676209,
      "loss": 2.6602,
      "step": 427
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015313059033989268,
      "loss": 2.8398,
      "step": 428
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015348837209302327,
      "loss": 2.6602,
      "step": 429
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015384615384615387,
      "loss": 2.6836,
      "step": 430
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015420393559928444,
      "loss": 2.5742,
      "step": 431
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015456171735241501,
      "loss": 2.832,
      "step": 432
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.001549194991055456,
      "loss": 2.8164,
      "step": 433
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.001552772808586762,
      "loss": 2.6992,
      "step": 434
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.001556350626118068,
      "loss": 2.582,
      "step": 435
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015599284436493739,
      "loss": 2.5977,
      "step": 436
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015635062611806798,
      "loss": 2.8828,
      "step": 437
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015670840787119858,
      "loss": 2.6758,
      "step": 438
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015706618962432917,
      "loss": 2.7734,
      "step": 439
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015742397137745977,
      "loss": 2.5703,
      "step": 440
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015778175313059034,
      "loss": 2.5859,
      "step": 441
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015813953488372093,
      "loss": 2.5703,
      "step": 442
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015849731663685153,
      "loss": 2.793,
      "step": 443
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015885509838998212,
      "loss": 2.6172,
      "step": 444
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015921288014311271,
      "loss": 2.6875,
      "step": 445
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015957066189624329,
      "loss": 2.5664,
      "step": 446
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0015992844364937388,
      "loss": 2.6562,
      "step": 447
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016028622540250447,
      "loss": 2.6641,
      "step": 448
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016064400715563507,
      "loss": 2.6328,
      "step": 449
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016100178890876566,
      "loss": 2.5977,
      "step": 450
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016135957066189623,
      "loss": 2.8906,
      "step": 451
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016171735241502683,
      "loss": 2.7266,
      "step": 452
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016207513416815742,
      "loss": 2.5703,
      "step": 453
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016243291592128802,
      "loss": 2.7148,
      "step": 454
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016279069767441861,
      "loss": 2.5508,
      "step": 455
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.001631484794275492,
      "loss": 2.6641,
      "step": 456
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.001635062611806798,
      "loss": 2.6992,
      "step": 457
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.001638640429338104,
      "loss": 2.6289,
      "step": 458
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016422182468694099,
      "loss": 2.6602,
      "step": 459
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016457960644007156,
      "loss": 2.625,
      "step": 460
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016493738819320213,
      "loss": 2.6484,
      "step": 461
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016529516994633273,
      "loss": 2.6836,
      "step": 462
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016565295169946332,
      "loss": 2.6914,
      "step": 463
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016601073345259391,
      "loss": 2.5703,
      "step": 464
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.001663685152057245,
      "loss": 2.6562,
      "step": 465
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.001667262969588551,
      "loss": 2.6602,
      "step": 466
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.001670840787119857,
      "loss": 2.832,
      "step": 467
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.001674418604651163,
      "loss": 2.6172,
      "step": 468
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016779964221824686,
      "loss": 2.832,
      "step": 469
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016815742397137746,
      "loss": 2.6133,
      "step": 470
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016851520572450805,
      "loss": 2.7617,
      "step": 471
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016887298747763865,
      "loss": 2.6602,
      "step": 472
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016923076923076924,
      "loss": 2.5039,
      "step": 473
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016958855098389983,
      "loss": 2.7734,
      "step": 474
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0016994633273703043,
      "loss": 2.6641,
      "step": 475
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00170304114490161,
      "loss": 2.5117,
      "step": 476
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.001706618962432916,
      "loss": 2.8867,
      "step": 477
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017101967799642219,
      "loss": 2.4648,
      "step": 478
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017137745974955276,
      "loss": 2.5586,
      "step": 479
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017173524150268335,
      "loss": 2.4609,
      "step": 480
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017209302325581395,
      "loss": 2.6055,
      "step": 481
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017245080500894454,
      "loss": 2.7266,
      "step": 482
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017280858676207514,
      "loss": 2.6055,
      "step": 483
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017316636851520573,
      "loss": 2.6055,
      "step": 484
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017352415026833632,
      "loss": 2.7148,
      "step": 485
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017388193202146692,
      "loss": 2.6836,
      "step": 486
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017423971377459751,
      "loss": 2.7305,
      "step": 487
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017459749552772809,
      "loss": 2.6523,
      "step": 488
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017495527728085868,
      "loss": 2.7578,
      "step": 489
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017531305903398927,
      "loss": 2.707,
      "step": 490
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017567084078711985,
      "loss": 2.7383,
      "step": 491
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017602862254025044,
      "loss": 2.5625,
      "step": 492
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017638640429338103,
      "loss": 2.4961,
      "step": 493
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017674418604651163,
      "loss": 2.6797,
      "step": 494
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017710196779964222,
      "loss": 2.707,
      "step": 495
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017745974955277282,
      "loss": 2.4922,
      "step": 496
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.001778175313059034,
      "loss": 2.7031,
      "step": 497
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017817531305903398,
      "loss": 3.0195,
      "step": 498
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017853309481216458,
      "loss": 2.5391,
      "step": 499
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017889087656529517,
      "loss": 2.5547,
      "step": 500
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017924865831842576,
      "loss": 2.625,
      "step": 501
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017960644007155636,
      "loss": 2.5781,
      "step": 502
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0017996422182468695,
      "loss": 2.7031,
      "step": 503
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0018032200357781755,
      "loss": 2.6641,
      "step": 504
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0018067978533094814,
      "loss": 2.5195,
      "step": 505
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0018103756708407874,
      "loss": 2.5625,
      "step": 506
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0018139534883720929,
      "loss": 2.5469,
      "step": 507
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0018175313059033988,
      "loss": 2.6719,
      "step": 508
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0018211091234347047,
      "loss": 2.75,
      "step": 509
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0018246869409660107,
      "loss": 2.4805,
      "step": 510
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0018282647584973166,
      "loss": 2.7148,
      "step": 511
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0018318425760286226,
      "loss": 2.7031,
      "step": 512
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0018354203935599285,
      "loss": 2.5859,
      "step": 513
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0018389982110912344,
      "loss": 2.5859,
      "step": 514
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0018425760286225404,
      "loss": 2.4766,
      "step": 515
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0018461538461538463,
      "loss": 2.4609,
      "step": 516
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001849731663685152,
      "loss": 2.6758,
      "step": 517
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001853309481216458,
      "loss": 2.6094,
      "step": 518
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001856887298747764,
      "loss": 2.6016,
      "step": 519
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0018604651162790699,
      "loss": 2.4805,
      "step": 520
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0018640429338103758,
      "loss": 2.5,
      "step": 521
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0018676207513416815,
      "loss": 2.7578,
      "step": 522
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0018711985688729875,
      "loss": 2.5,
      "step": 523
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0018747763864042934,
      "loss": 2.6016,
      "step": 524
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0018783542039355994,
      "loss": 2.6406,
      "step": 525
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001881932021466905,
      "loss": 2.4883,
      "step": 526
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001885509838998211,
      "loss": 2.6797,
      "step": 527
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001889087656529517,
      "loss": 2.5469,
      "step": 528
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001892665474060823,
      "loss": 2.6328,
      "step": 529
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0018962432915921288,
      "loss": 2.8359,
      "step": 530
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0018998211091234348,
      "loss": 2.5234,
      "step": 531
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019033989266547407,
      "loss": 2.7148,
      "step": 532
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019069767441860467,
      "loss": 2.5273,
      "step": 533
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019105545617173526,
      "loss": 2.625,
      "step": 534
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019141323792486585,
      "loss": 2.4453,
      "step": 535
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019177101967799643,
      "loss": 2.7617,
      "step": 536
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00192128801431127,
      "loss": 2.5859,
      "step": 537
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001924865831842576,
      "loss": 2.7578,
      "step": 538
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019284436493738819,
      "loss": 2.6914,
      "step": 539
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019320214669051878,
      "loss": 2.6211,
      "step": 540
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019355992844364938,
      "loss": 2.625,
      "step": 541
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019391771019677997,
      "loss": 2.582,
      "step": 542
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019427549194991056,
      "loss": 2.6523,
      "step": 543
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019463327370304116,
      "loss": 2.7578,
      "step": 544
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019499105545617173,
      "loss": 2.9062,
      "step": 545
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019534883720930232,
      "loss": 2.5273,
      "step": 546
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001957066189624329,
      "loss": 2.5586,
      "step": 547
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001960644007155635,
      "loss": 2.5742,
      "step": 548
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001964221824686941,
      "loss": 2.7148,
      "step": 549
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001967799642218247,
      "loss": 2.5664,
      "step": 550
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001971377459749553,
      "loss": 2.6719,
      "step": 551
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001974955277280859,
      "loss": 2.5703,
      "step": 552
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001978533094812165,
      "loss": 2.4961,
      "step": 553
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019821109123434708,
      "loss": 2.4414,
      "step": 554
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019856887298747763,
      "loss": 2.7031,
      "step": 555
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019892665474060822,
      "loss": 2.582,
      "step": 556
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001992844364937388,
      "loss": 2.6133,
      "step": 557
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001996422182468694,
      "loss": 2.5352,
      "step": 558
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.002,
      "loss": 2.5898,
      "step": 559
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999999848483575,
      "loss": 2.6875,
      "step": 560
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999999939393431,
      "loss": 2.5664,
      "step": 561
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999999863635221,
      "loss": 2.4961,
      "step": 562
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999999757573731,
      "loss": 2.7578,
      "step": 563
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999999621208963,
      "loss": 2.5,
      "step": 564
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999994545409215,
      "loss": 2.4961,
      "step": 565
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999999257569612,
      "loss": 2.8047,
      "step": 566
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999990302950405,
      "loss": 2.4883,
      "step": 567
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999998772717213,
      "loss": 2.4961,
      "step": 568
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999984848361385,
      "loss": 2.5664,
      "step": 569
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999981666518245,
      "loss": 2.5469,
      "step": 570
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999997818164282,
      "loss": 2.4922,
      "step": 571
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999974393735197,
      "loss": 2.6094,
      "step": 572
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999997030279551,
      "loss": 2.8242,
      "step": 573
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999965908823873,
      "loss": 2.5508,
      "step": 574
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999961211820422,
      "loss": 2.6133,
      "step": 575
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999956211785297,
      "loss": 2.4805,
      "step": 576
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999995090871865,
      "loss": 2.4922,
      "step": 577
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999945302620645,
      "loss": 2.5742,
      "step": 578
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999939393491447,
      "loss": 2.4648,
      "step": 579
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999993318133124,
      "loss": 2.5156,
      "step": 580
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999992666614021,
      "loss": 2.7266,
      "step": 581
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999991984791855,
      "loss": 2.6602,
      "step": 582
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999991272666647,
      "loss": 2.5,
      "step": 583
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999905302384192,
      "loss": 2.7148,
      "step": 584
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999897575071935,
      "loss": 2.5117,
      "step": 585
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999988954472993,
      "loss": 2.7148,
      "step": 586
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999881211358425,
      "loss": 2.4883,
      "step": 587
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999872574957673,
      "loss": 2.6016,
      "step": 588
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999863635527934,
      "loss": 2.7539,
      "step": 589
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999854393069477,
      "loss": 2.7695,
      "step": 590
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999984484758259,
      "loss": 2.7461,
      "step": 591
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999983499906755,
      "loss": 2.6875,
      "step": 592
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999982484752467,
      "loss": 2.5938,
      "step": 593
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999981439295424,
      "loss": 2.5508,
      "step": 594
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999980363535659,
      "loss": 2.7148,
      "step": 595
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999979257473205,
      "loss": 2.707,
      "step": 596
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999978121108094,
      "loss": 2.6797,
      "step": 597
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.001999976954440361,
      "loss": 2.5898,
      "step": 598
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999757574700417,
      "loss": 2.4805,
      "step": 599
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999745301971725,
      "loss": 2.5938,
      "step": 600
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00199997327262179,
      "loss": 2.5312,
      "step": 601
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999719847439332,
      "loss": 2.5352,
      "step": 602
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999706665636396,
      "loss": 2.6172,
      "step": 603
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0019999693180809508,
      "loss": 2.4922,
      "step": 604
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999679392959067,
      "loss": 2.7812,
      "step": 605
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999665302085495,
      "loss": 2.6172,
      "step": 606
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999650908189216,
      "loss": 2.5508,
      "step": 607
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999963621127067,
      "loss": 2.5977,
      "step": 608
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999621211330295,
      "loss": 2.6523,
      "step": 609
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999605908368554,
      "loss": 2.6055,
      "step": 610
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999590302385906,
      "loss": 2.4844,
      "step": 611
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999574393382825,
      "loss": 2.5859,
      "step": 612
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999558181359794,
      "loss": 2.8555,
      "step": 613
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999541666317305,
      "loss": 2.6484,
      "step": 614
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999524848255856,
      "loss": 2.5352,
      "step": 615
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999507727175955,
      "loss": 2.6719,
      "step": 616
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999490303078122,
      "loss": 2.6523,
      "step": 617
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999947257596289,
      "loss": 2.5742,
      "step": 618
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999454545830794,
      "loss": 2.6484,
      "step": 619
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999436212682375,
      "loss": 2.5781,
      "step": 620
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999417576518196,
      "loss": 2.4805,
      "step": 621
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999939863733882,
      "loss": 2.707,
      "step": 622
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999937939514481,
      "loss": 2.7344,
      "step": 623
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999935984993677,
      "loss": 2.6719,
      "step": 624
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999934000171527,
      "loss": 2.7031,
      "step": 625
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999319850480925,
      "loss": 2.6836,
      "step": 626
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999299396234343,
      "loss": 2.6719,
      "step": 627
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999278638976148,
      "loss": 2.543,
      "step": 628
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999257578706964,
      "loss": 2.6875,
      "step": 629
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999236215427424,
      "loss": 2.4805,
      "step": 630
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999214549138184,
      "loss": 2.7188,
      "step": 631
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00199991925798399,
      "loss": 2.5391,
      "step": 632
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999917030753323,
      "loss": 2.6445,
      "step": 633
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999914773221886,
      "loss": 2.5078,
      "step": 634
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999124853897466,
      "loss": 2.6367,
      "step": 635
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999101672569745,
      "loss": 2.6172,
      "step": 636
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999078188236395,
      "loss": 2.5059,
      "step": 637
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999054400898133,
      "loss": 2.6758,
      "step": 638
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019999030310555678,
      "loss": 2.6992,
      "step": 639
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999900591720976,
      "loss": 2.957,
      "step": 640
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019998981220861116,
      "loss": 2.4922,
      "step": 641
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019998956221510497,
      "loss": 2.6484,
      "step": 642
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999893091915866,
      "loss": 2.625,
      "step": 643
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019998905313806372,
      "loss": 2.6641,
      "step": 644
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019998879405454402,
      "loss": 2.4766,
      "step": 645
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999885319410355,
      "loss": 2.5391,
      "step": 646
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019998826679754602,
      "loss": 2.5547,
      "step": 647
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019998799862408355,
      "loss": 2.5391,
      "step": 648
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019998772742065634,
      "loss": 2.5195,
      "step": 649
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999874531872725,
      "loss": 2.5781,
      "step": 650
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019998717592394043,
      "loss": 2.6211,
      "step": 651
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999868956306685,
      "loss": 2.6797,
      "step": 652
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999866123074652,
      "loss": 2.5,
      "step": 653
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019998632595433904,
      "loss": 2.5469,
      "step": 654
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999860365712988,
      "loss": 2.6797,
      "step": 655
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019998574415835326,
      "loss": 2.6758,
      "step": 656
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999854487155112,
      "loss": 2.7695,
      "step": 657
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999851502427816,
      "loss": 2.4961,
      "step": 658
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999848487401735,
      "loss": 2.6328,
      "step": 659
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999845442076961,
      "loss": 2.8086,
      "step": 660
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019998423664535857,
      "loss": 2.4453,
      "step": 661
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019998392605317023,
      "loss": 2.7344,
      "step": 662
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999836124311405,
      "loss": 2.3984,
      "step": 663
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999832957792789,
      "loss": 2.4844,
      "step": 664
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00199982976097595,
      "loss": 2.707,
      "step": 665
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999826533860985,
      "loss": 2.668,
      "step": 666
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019998232764479916,
      "loss": 2.5859,
      "step": 667
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999819988737069,
      "loss": 2.5703,
      "step": 668
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019998166707283164,
      "loss": 2.6641,
      "step": 669
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019998133224218345,
      "loss": 2.543,
      "step": 670
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999809943817725,
      "loss": 2.6172,
      "step": 671
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019998065349160895,
      "loss": 2.6016,
      "step": 672
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999803095717032,
      "loss": 2.4688,
      "step": 673
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019997996262206565,
      "loss": 2.6172,
      "step": 674
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019997961264270683,
      "loss": 2.7539,
      "step": 675
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019997925963363733,
      "loss": 2.5391,
      "step": 676
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019997890359486786,
      "loss": 2.6953,
      "step": 677
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999785445264092,
      "loss": 2.7656,
      "step": 678
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019997818242827223,
      "loss": 2.4492,
      "step": 679
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999778173004679,
      "loss": 2.5703,
      "step": 680
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999774491430073,
      "loss": 2.7656,
      "step": 681
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999770779559016,
      "loss": 2.4766,
      "step": 682
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019997670373916206,
      "loss": 2.8555,
      "step": 683
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999763264927999,
      "loss": 2.6914,
      "step": 684
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019997594621682675,
      "loss": 2.6406,
      "step": 685
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019997556291125396,
      "loss": 2.7383,
      "step": 686
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019997517657609322,
      "loss": 2.6367,
      "step": 687
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019997478721135624,
      "loss": 2.8008,
      "step": 688
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019997439481705486,
      "loss": 2.7852,
      "step": 689
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019997399939320083,
      "loss": 2.668,
      "step": 690
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999736009398063,
      "loss": 2.4766,
      "step": 691
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999731994568832,
      "loss": 2.457,
      "step": 692
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999727949444438,
      "loss": 2.6055,
      "step": 693
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019997238740250035,
      "loss": 2.6133,
      "step": 694
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019997197683106513,
      "loss": 2.6172,
      "step": 695
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0019997156323015063,
      "loss": 2.5352,
      "step": 696
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.001999711465997694,
      "loss": 2.5547,
      "step": 697
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00199970726939934,
      "loss": 2.6641,
      "step": 698
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019997030425065723,
      "loss": 2.625,
      "step": 699
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019996987853195185,
      "loss": 2.5391,
      "step": 700
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019996944978383072,
      "loss": 2.5625,
      "step": 701
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999690180063069,
      "loss": 2.6211,
      "step": 702
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999685831993935,
      "loss": 2.5273,
      "step": 703
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999681453631036,
      "loss": 2.6797,
      "step": 704
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019996770449745055,
      "loss": 2.5938,
      "step": 705
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019996726060244768,
      "loss": 2.418,
      "step": 706
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019996681367810843,
      "loss": 2.6875,
      "step": 707
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999663637244464,
      "loss": 2.5742,
      "step": 708
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999659107414751,
      "loss": 2.5938,
      "step": 709
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019996545472920836,
      "loss": 2.6094,
      "step": 710
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019996499568766,
      "loss": 2.3945,
      "step": 711
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999645336168439,
      "loss": 2.5312,
      "step": 712
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019996406851677403,
      "loss": 2.4336,
      "step": 713
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019996360038746458,
      "loss": 2.5469,
      "step": 714
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019996312922892965,
      "loss": 2.5156,
      "step": 715
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999626550411835,
      "loss": 2.5742,
      "step": 716
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999621778242406,
      "loss": 2.5938,
      "step": 717
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019996169757811534,
      "loss": 2.4844,
      "step": 718
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999612143028223,
      "loss": 2.3906,
      "step": 719
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019996072799837606,
      "loss": 2.5352,
      "step": 720
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019996023866479147,
      "loss": 2.6602,
      "step": 721
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019995974630208327,
      "loss": 2.5664,
      "step": 722
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019995925091026642,
      "loss": 2.6914,
      "step": 723
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019995875248935593,
      "loss": 2.6172,
      "step": 724
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999582510393669,
      "loss": 2.4766,
      "step": 725
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999577465603145,
      "loss": 2.6211,
      "step": 726
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00199957239052214,
      "loss": 2.8008,
      "step": 727
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019995672851508086,
      "loss": 2.6328,
      "step": 728
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999562149489305,
      "loss": 2.5625,
      "step": 729
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999556983537785,
      "loss": 2.6836,
      "step": 730
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019995517872964047,
      "loss": 2.6055,
      "step": 731
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019995465607653222,
      "loss": 2.7188,
      "step": 732
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999541303944696,
      "loss": 2.625,
      "step": 733
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019995360168346844,
      "loss": 2.5078,
      "step": 734
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999530699435448,
      "loss": 2.7617,
      "step": 735
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019995253517471486,
      "loss": 2.5742,
      "step": 736
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019995199737699474,
      "loss": 2.3828,
      "step": 737
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999514565504008,
      "loss": 2.668,
      "step": 738
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019995091269494943,
      "loss": 2.5469,
      "step": 739
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019995036581065707,
      "loss": 2.5195,
      "step": 740
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019994981589754033,
      "loss": 2.5703,
      "step": 741
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999492629556158,
      "loss": 2.6562,
      "step": 742
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999487069849003,
      "loss": 2.6914,
      "step": 743
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999481479854107,
      "loss": 2.582,
      "step": 744
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999475859571639,
      "loss": 2.6797,
      "step": 745
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019994702090017687,
      "loss": 2.5703,
      "step": 746
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019994645281446685,
      "loss": 2.5742,
      "step": 747
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00199945881700051,
      "loss": 2.7344,
      "step": 748
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019994530755694665,
      "loss": 2.7578,
      "step": 749
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019994473038517117,
      "loss": 2.4531,
      "step": 750
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019994415018474206,
      "loss": 2.5234,
      "step": 751
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999435669556769,
      "loss": 2.6406,
      "step": 752
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999429806979934,
      "loss": 2.5039,
      "step": 753
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999423914117092,
      "loss": 2.6406,
      "step": 754
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999417990968423,
      "loss": 2.6484,
      "step": 755
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999412037534106,
      "loss": 2.6055,
      "step": 756
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019994060538143215,
      "loss": 2.6758,
      "step": 757
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019994000398092506,
      "loss": 2.5547,
      "step": 758
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019993939955190755,
      "loss": 2.5703,
      "step": 759
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00199938792094398,
      "loss": 2.6602,
      "step": 760
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999381816084147,
      "loss": 2.5273,
      "step": 761
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019993756809397628,
      "loss": 2.582,
      "step": 762
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019993695155110123,
      "loss": 2.3008,
      "step": 763
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999363319798083,
      "loss": 2.6055,
      "step": 764
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019993570938011624,
      "loss": 2.7773,
      "step": 765
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999350837520439,
      "loss": 2.6055,
      "step": 766
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019993445509561025,
      "loss": 2.5703,
      "step": 767
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019993382341083436,
      "loss": 2.4961,
      "step": 768
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019993318869773536,
      "loss": 2.4492,
      "step": 769
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999325509563325,
      "loss": 2.293,
      "step": 770
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019993191018664504,
      "loss": 2.4414,
      "step": 771
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019993126638869247,
      "loss": 2.5938,
      "step": 772
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019993061956249426,
      "loss": 2.5312,
      "step": 773
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019992996970807004,
      "loss": 2.6406,
      "step": 774
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999293168254395,
      "loss": 2.6133,
      "step": 775
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019992866091462233,
      "loss": 2.6367,
      "step": 776
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019992800197563857,
      "loss": 2.5625,
      "step": 777
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019992734000850807,
      "loss": 2.5,
      "step": 778
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019992667501325095,
      "loss": 2.6094,
      "step": 779
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019992600698988732,
      "loss": 2.3555,
      "step": 780
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019992533593843746,
      "loss": 2.5742,
      "step": 781
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999246618589217,
      "loss": 2.625,
      "step": 782
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999239847513604,
      "loss": 2.5391,
      "step": 783
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019992330461577417,
      "loss": 2.6602,
      "step": 784
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.001999226214521835,
      "loss": 2.4609,
      "step": 785
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019992193526060928,
      "loss": 2.5391,
      "step": 786
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019992124604107215,
      "loss": 2.4609,
      "step": 787
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019992055379359306,
      "loss": 2.5508,
      "step": 788
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019991985851819296,
      "loss": 2.4805,
      "step": 789
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0019991916021489292,
      "loss": 2.4922,
      "step": 790
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001999184588837141,
      "loss": 2.6211,
      "step": 791
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001999177545246778,
      "loss": 2.5508,
      "step": 792
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001999170471378053,
      "loss": 2.5234,
      "step": 793
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019991633672311808,
      "loss": 2.6641,
      "step": 794
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001999156232806376,
      "loss": 2.5156,
      "step": 795
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001999149068103856,
      "loss": 2.3574,
      "step": 796
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001999141873123837,
      "loss": 2.625,
      "step": 797
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001999134647866537,
      "loss": 2.5703,
      "step": 798
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019991273923321757,
      "loss": 2.5469,
      "step": 799
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019991201065209722,
      "loss": 2.4023,
      "step": 800
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019991127904331473,
      "loss": 2.375,
      "step": 801
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019991054440689233,
      "loss": 2.5469,
      "step": 802
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019990980674285223,
      "loss": 2.5625,
      "step": 803
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019990906605121678,
      "loss": 2.7148,
      "step": 804
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019990832233200847,
      "loss": 2.3809,
      "step": 805
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019990757558524985,
      "loss": 2.6445,
      "step": 806
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001999068258109635,
      "loss": 2.6914,
      "step": 807
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001999060730091721,
      "loss": 2.4922,
      "step": 808
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019990531717989854,
      "loss": 2.6758,
      "step": 809
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001999045583231657,
      "loss": 2.4805,
      "step": 810
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019990379643899663,
      "loss": 2.5234,
      "step": 811
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001999030315274143,
      "loss": 2.4688,
      "step": 812
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019990226358844194,
      "loss": 2.5664,
      "step": 813
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019990149262210286,
      "loss": 2.7227,
      "step": 814
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001999007186284204,
      "loss": 2.4688,
      "step": 815
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019989994160741803,
      "loss": 2.5664,
      "step": 816
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019989916155911925,
      "loss": 2.4336,
      "step": 817
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998983784835477,
      "loss": 2.4805,
      "step": 818
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019989759238072716,
      "loss": 2.5234,
      "step": 819
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998968032506815,
      "loss": 2.5234,
      "step": 820
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019989601109343443,
      "loss": 2.6602,
      "step": 821
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998952159090102,
      "loss": 2.4766,
      "step": 822
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998944176974327,
      "loss": 2.5312,
      "step": 823
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019989361645872624,
      "loss": 2.5781,
      "step": 824
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019989281219291504,
      "loss": 2.4805,
      "step": 825
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019989200490002357,
      "loss": 2.5156,
      "step": 826
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998911945800762,
      "loss": 2.4258,
      "step": 827
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998903812330975,
      "loss": 2.457,
      "step": 828
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019988956485911214,
      "loss": 2.5781,
      "step": 829
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019988874545814484,
      "loss": 2.582,
      "step": 830
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019988792303022042,
      "loss": 2.4961,
      "step": 831
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019988709757536387,
      "loss": 2.7148,
      "step": 832
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998862690936001,
      "loss": 2.7344,
      "step": 833
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998854375849543,
      "loss": 2.4766,
      "step": 834
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998846030494516,
      "loss": 2.4531,
      "step": 835
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998837654871173,
      "loss": 2.4844,
      "step": 836
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019988292489797692,
      "loss": 2.5195,
      "step": 837
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019988208128205575,
      "loss": 2.5352,
      "step": 838
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019988123463937943,
      "loss": 2.4648,
      "step": 839
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998803849699736,
      "loss": 2.7266,
      "step": 840
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019987953227386403,
      "loss": 2.3438,
      "step": 841
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019987867655107652,
      "loss": 2.6328,
      "step": 842
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019987781780163704,
      "loss": 2.4883,
      "step": 843
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019987695602557165,
      "loss": 2.5938,
      "step": 844
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019987609122290636,
      "loss": 2.6328,
      "step": 845
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998752233936674,
      "loss": 2.5586,
      "step": 846
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998743525378812,
      "loss": 2.5195,
      "step": 847
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00199873478655574,
      "loss": 2.4844,
      "step": 848
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998726017467723,
      "loss": 2.4727,
      "step": 849
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019987172181150275,
      "loss": 2.75,
      "step": 850
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019987083884979192,
      "loss": 2.5156,
      "step": 851
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019986995286166665,
      "loss": 2.6836,
      "step": 852
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998690638471538,
      "loss": 2.5898,
      "step": 853
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998681718062802,
      "loss": 2.3906,
      "step": 854
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019986727673907295,
      "loss": 2.5273,
      "step": 855
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998663786455592,
      "loss": 2.6367,
      "step": 856
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019986547752576613,
      "loss": 2.4102,
      "step": 857
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019986457337972103,
      "loss": 2.5742,
      "step": 858
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019986366620745135,
      "loss": 2.6172,
      "step": 859
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998627560089845,
      "loss": 2.4883,
      "step": 860
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019986184278434817,
      "loss": 2.6055,
      "step": 861
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019986092653356997,
      "loss": 2.5234,
      "step": 862
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019986000725667765,
      "loss": 2.4414,
      "step": 863
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998590849536991,
      "loss": 2.4961,
      "step": 864
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998581596246622,
      "loss": 2.6328,
      "step": 865
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019985723126959513,
      "loss": 2.582,
      "step": 866
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998562998885259,
      "loss": 2.3203,
      "step": 867
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998553654814828,
      "loss": 2.293,
      "step": 868
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998544280484941,
      "loss": 2.5859,
      "step": 869
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019985348758958825,
      "loss": 2.4023,
      "step": 870
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019985254410479366,
      "loss": 2.3359,
      "step": 871
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998515975941391,
      "loss": 2.6172,
      "step": 872
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019985064805765305,
      "loss": 2.5508,
      "step": 873
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019984969549536437,
      "loss": 2.4531,
      "step": 874
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019984873990730196,
      "loss": 2.7109,
      "step": 875
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998477812934948,
      "loss": 2.4492,
      "step": 876
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998468196539718,
      "loss": 2.3516,
      "step": 877
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998458549887622,
      "loss": 2.6797,
      "step": 878
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019984488729789525,
      "loss": 2.6562,
      "step": 879
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.001998439165814002,
      "loss": 2.7109,
      "step": 880
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019984294283930657,
      "loss": 2.625,
      "step": 881
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019984196607164377,
      "loss": 2.457,
      "step": 882
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0019984098627844143,
      "loss": 2.5938,
      "step": 883
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001998400034597293,
      "loss": 2.5,
      "step": 884
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019983901761553703,
      "loss": 2.6172,
      "step": 885
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001998380287458946,
      "loss": 2.6211,
      "step": 886
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00199837036850832,
      "loss": 2.7266,
      "step": 887
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019983604193037916,
      "loss": 2.5312,
      "step": 888
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019983504398456637,
      "loss": 2.5117,
      "step": 889
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019983404301342376,
      "loss": 2.3945,
      "step": 890
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019983303901698174,
      "loss": 2.5469,
      "step": 891
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001998320319952707,
      "loss": 2.457,
      "step": 892
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001998310219483212,
      "loss": 2.6836,
      "step": 893
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019983000887616375,
      "loss": 2.6211,
      "step": 894
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019982899277882914,
      "loss": 2.5508,
      "step": 895
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001998279736563481,
      "loss": 2.5312,
      "step": 896
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001998269515087516,
      "loss": 2.668,
      "step": 897
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001998259263360705,
      "loss": 2.5039,
      "step": 898
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019982489813833593,
      "loss": 2.5703,
      "step": 899
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019982386691557905,
      "loss": 2.4805,
      "step": 900
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001998228326678311,
      "loss": 2.6367,
      "step": 901
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019982179539512345,
      "loss": 2.7031,
      "step": 902
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019982075509748748,
      "loss": 2.6289,
      "step": 903
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019981971177495473,
      "loss": 2.5,
      "step": 904
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019981866542755685,
      "loss": 2.4258,
      "step": 905
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019981761605532547,
      "loss": 2.5078,
      "step": 906
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001998165636582925,
      "loss": 2.5352,
      "step": 907
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001998155082364897,
      "loss": 2.8047,
      "step": 908
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001998144497899492,
      "loss": 2.5117,
      "step": 909
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00199813388318703,
      "loss": 2.3477,
      "step": 910
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001998123238227832,
      "loss": 2.5156,
      "step": 911
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001998112563022222,
      "loss": 2.5234,
      "step": 912
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019981018575705224,
      "loss": 2.3867,
      "step": 913
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019980911218730577,
      "loss": 2.5781,
      "step": 914
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019980803559301536,
      "loss": 2.7539,
      "step": 915
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001998069559742136,
      "loss": 2.6328,
      "step": 916
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019980587333093326,
      "loss": 2.7344,
      "step": 917
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019980478766320714,
      "loss": 2.5352,
      "step": 918
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001998036989710681,
      "loss": 2.4727,
      "step": 919
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019980260725454913,
      "loss": 2.582,
      "step": 920
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001998015125136833,
      "loss": 2.5352,
      "step": 921
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019980041474850383,
      "loss": 2.5703,
      "step": 922
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00199799313959044,
      "loss": 2.6641,
      "step": 923
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001997982101453371,
      "loss": 2.457,
      "step": 924
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001997971033074166,
      "loss": 2.5938,
      "step": 925
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019979599344531612,
      "loss": 2.6367,
      "step": 926
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019979488055906916,
      "loss": 2.7578,
      "step": 927
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019979376464870956,
      "loss": 2.543,
      "step": 928
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019979264571427105,
      "loss": 2.5547,
      "step": 929
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001997915237557876,
      "loss": 2.4648,
      "step": 930
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001997903987732932,
      "loss": 2.5195,
      "step": 931
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001997892707668219,
      "loss": 2.5,
      "step": 932
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001997881397364079,
      "loss": 2.5156,
      "step": 933
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001997870056820855,
      "loss": 2.4844,
      "step": 934
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00199785868603889,
      "loss": 2.5742,
      "step": 935
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019978472850185297,
      "loss": 2.582,
      "step": 936
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019978358537601185,
      "loss": 2.4805,
      "step": 937
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019978243922640034,
      "loss": 2.5977,
      "step": 938
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019978129005305315,
      "loss": 2.6562,
      "step": 939
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019978013785600514,
      "loss": 2.5391,
      "step": 940
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019977898263529117,
      "loss": 2.4062,
      "step": 941
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019977782439094625,
      "loss": 2.6094,
      "step": 942
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001997766631230055,
      "loss": 2.5273,
      "step": 943
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019977549883150414,
      "loss": 2.6602,
      "step": 944
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001997743315164774,
      "loss": 2.5254,
      "step": 945
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001997731611779607,
      "loss": 2.4336,
      "step": 946
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019977198781598944,
      "loss": 2.5742,
      "step": 947
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019977081143059926,
      "loss": 2.5508,
      "step": 948
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001997696320218257,
      "loss": 2.6758,
      "step": 949
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019976844958970465,
      "loss": 2.582,
      "step": 950
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019976726413427183,
      "loss": 2.6016,
      "step": 951
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019976607565556316,
      "loss": 2.5078,
      "step": 952
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001997648841536147,
      "loss": 2.4805,
      "step": 953
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019976368962846256,
      "loss": 2.7812,
      "step": 954
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001997624920801429,
      "loss": 2.2539,
      "step": 955
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00199761291508692,
      "loss": 2.668,
      "step": 956
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001997600879141463,
      "loss": 2.3516,
      "step": 957
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019975888129654226,
      "loss": 2.6016,
      "step": 958
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019975767165591645,
      "loss": 2.5742,
      "step": 959
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019975645899230547,
      "loss": 2.5273,
      "step": 960
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019975524330574606,
      "loss": 2.5195,
      "step": 961
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001997540245962752,
      "loss": 2.5391,
      "step": 962
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019975280286392964,
      "loss": 2.5117,
      "step": 963
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019975157810874647,
      "loss": 2.7383,
      "step": 964
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001997503503307629,
      "loss": 2.4297,
      "step": 965
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00199749119530016,
      "loss": 2.625,
      "step": 966
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019974788570654312,
      "loss": 2.4023,
      "step": 967
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001997466488603817,
      "loss": 2.6016,
      "step": 968
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.001997454089915691,
      "loss": 2.5195,
      "step": 969
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019974416610014298,
      "loss": 2.5117,
      "step": 970
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00199742920186141,
      "loss": 2.5625,
      "step": 971
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019974167124960094,
      "loss": 2.5312,
      "step": 972
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019974041929056055,
      "loss": 2.5391,
      "step": 973
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019973916430905785,
      "loss": 2.5742,
      "step": 974
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019973790630513086,
      "loss": 2.3594,
      "step": 975
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0019973664527881767,
      "loss": 2.8477,
      "step": 976
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019973538123015653,
      "loss": 2.6055,
      "step": 977
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001997341141591857,
      "loss": 2.3945,
      "step": 978
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001997328440659436,
      "loss": 2.4922,
      "step": 979
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019973157095046876,
      "loss": 2.4102,
      "step": 980
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001997302948127997,
      "loss": 2.5195,
      "step": 981
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001997290156529751,
      "loss": 2.4922,
      "step": 982
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019972773347103376,
      "loss": 2.6484,
      "step": 983
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001997264482670145,
      "loss": 2.5234,
      "step": 984
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019972516004095626,
      "loss": 2.373,
      "step": 985
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001997238687928981,
      "loss": 2.4609,
      "step": 986
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019972257452287915,
      "loss": 2.4375,
      "step": 987
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001997212772309386,
      "loss": 2.4492,
      "step": 988
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001997199769171158,
      "loss": 2.6445,
      "step": 989
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019971867358145015,
      "loss": 2.5508,
      "step": 990
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019971736722398117,
      "loss": 2.6055,
      "step": 991
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019971605784474835,
      "loss": 2.6016,
      "step": 992
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019971474544379143,
      "loss": 2.3984,
      "step": 993
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019971343002115017,
      "loss": 2.457,
      "step": 994
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001997121115768645,
      "loss": 2.7461,
      "step": 995
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019971079011097425,
      "loss": 2.8125,
      "step": 996
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019970946562351956,
      "loss": 2.3887,
      "step": 997
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019970813811454055,
      "loss": 2.5352,
      "step": 998
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001997068075840774,
      "loss": 2.4961,
      "step": 999
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001997054740321705,
      "loss": 2.5,
      "step": 1000
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019970413745886016,
      "loss": 2.707,
      "step": 1001
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00199702797864187,
      "loss": 2.5703,
      "step": 1002
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019970145524819158,
      "loss": 2.5781,
      "step": 1003
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019970010961091454,
      "loss": 2.5078,
      "step": 1004
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019969876095239664,
      "loss": 2.5,
      "step": 1005
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019969740927267884,
      "loss": 2.6016,
      "step": 1006
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00199696054571802,
      "loss": 2.5078,
      "step": 1007
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996946968498073,
      "loss": 2.3789,
      "step": 1008
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019969333610673577,
      "loss": 2.4609,
      "step": 1009
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996919723426287,
      "loss": 2.668,
      "step": 1010
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019969060555752737,
      "loss": 2.6016,
      "step": 1011
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019968923575147323,
      "loss": 2.6016,
      "step": 1012
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996878629245078,
      "loss": 2.4805,
      "step": 1013
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019968648707667266,
      "loss": 2.5664,
      "step": 1014
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019968510820800953,
      "loss": 2.6289,
      "step": 1015
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019968372631856014,
      "loss": 2.5547,
      "step": 1016
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019968234140836645,
      "loss": 2.5508,
      "step": 1017
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019968095347747033,
      "loss": 2.6328,
      "step": 1018
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019967956252591387,
      "loss": 2.5664,
      "step": 1019
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996781685537393,
      "loss": 2.5078,
      "step": 1020
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019967677156098877,
      "loss": 2.5664,
      "step": 1021
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996753715477046,
      "loss": 2.6719,
      "step": 1022
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019967396851392934,
      "loss": 2.5273,
      "step": 1023
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019967256245970537,
      "loss": 2.4727,
      "step": 1024
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996711533850754,
      "loss": 2.4531,
      "step": 1025
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00199669741290082,
      "loss": 2.5781,
      "step": 1026
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996683261747681,
      "loss": 2.6016,
      "step": 1027
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019966690803917653,
      "loss": 2.543,
      "step": 1028
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996654868833502,
      "loss": 2.5156,
      "step": 1029
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996640627073323,
      "loss": 2.8359,
      "step": 1030
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019966263551116593,
      "loss": 2.4141,
      "step": 1031
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996612052948943,
      "loss": 2.6055,
      "step": 1032
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996597720585608,
      "loss": 2.668,
      "step": 1033
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996583358022088,
      "loss": 2.3789,
      "step": 1034
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996568965258819,
      "loss": 2.5195,
      "step": 1035
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019965545422962368,
      "loss": 2.5,
      "step": 1036
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019965400891347783,
      "loss": 2.6836,
      "step": 1037
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996525605774882,
      "loss": 2.5977,
      "step": 1038
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996511092216986,
      "loss": 2.3984,
      "step": 1039
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996496548461531,
      "loss": 2.418,
      "step": 1040
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019964819745089566,
      "loss": 2.7578,
      "step": 1041
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996467370359706,
      "loss": 2.3672,
      "step": 1042
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00199645273601422,
      "loss": 2.5273,
      "step": 1043
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019964380714729436,
      "loss": 2.625,
      "step": 1044
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019964233767363203,
      "loss": 2.7891,
      "step": 1045
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019964086518047958,
      "loss": 2.5273,
      "step": 1046
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996393896678816,
      "loss": 2.5312,
      "step": 1047
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996379111358828,
      "loss": 2.6133,
      "step": 1048
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00199636429584528,
      "loss": 2.6328,
      "step": 1049
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019963494501386214,
      "loss": 2.5898,
      "step": 1050
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019963345742393017,
      "loss": 2.5742,
      "step": 1051
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996319668147771,
      "loss": 2.5469,
      "step": 1052
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996304731864482,
      "loss": 2.5547,
      "step": 1053
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996289765389887,
      "loss": 2.3672,
      "step": 1054
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019962747687244393,
      "loss": 2.6797,
      "step": 1055
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019962597418685937,
      "loss": 2.6055,
      "step": 1056
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996244684822805,
      "loss": 2.5742,
      "step": 1057
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019962295975875306,
      "loss": 2.6445,
      "step": 1058
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019962144801632265,
      "loss": 2.5312,
      "step": 1059
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019961993325503516,
      "loss": 2.5703,
      "step": 1060
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996184154749364,
      "loss": 2.4844,
      "step": 1061
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019961689467607245,
      "loss": 2.5234,
      "step": 1062
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996153708584894,
      "loss": 2.4766,
      "step": 1063
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019961384402223336,
      "loss": 2.5352,
      "step": 1064
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019961231416735065,
      "loss": 2.5078,
      "step": 1065
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996107812938876,
      "loss": 2.7227,
      "step": 1066
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019960924540189068,
      "loss": 2.5703,
      "step": 1067
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0019960770649140643,
      "loss": 2.6484,
      "step": 1068
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.001996061645624815,
      "loss": 2.5391,
      "step": 1069
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019960461961516258,
      "loss": 2.4922,
      "step": 1070
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001996030716494965,
      "loss": 2.6172,
      "step": 1071
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019960152066553017,
      "loss": 2.6484,
      "step": 1072
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995999666633106,
      "loss": 2.5547,
      "step": 1073
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019959840964288485,
      "loss": 2.7383,
      "step": 1074
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019959684960430013,
      "loss": 2.4766,
      "step": 1075
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019959528654760377,
      "loss": 2.6289,
      "step": 1076
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019959372047284297,
      "loss": 2.6523,
      "step": 1077
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995921513800654,
      "loss": 2.5156,
      "step": 1078
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019959057926931846,
      "loss": 2.3516,
      "step": 1079
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995890041406498,
      "loss": 2.5742,
      "step": 1080
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995874259941072,
      "loss": 2.4922,
      "step": 1081
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995858448297385,
      "loss": 2.5195,
      "step": 1082
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019958426064759153,
      "loss": 2.4766,
      "step": 1083
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995826734477144,
      "loss": 2.416,
      "step": 1084
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019958108323015512,
      "loss": 2.5273,
      "step": 1085
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019957948999496196,
      "loss": 2.4219,
      "step": 1086
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995778937421831,
      "loss": 2.5938,
      "step": 1087
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019957629447186695,
      "loss": 2.7344,
      "step": 1088
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019957469218406204,
      "loss": 2.5078,
      "step": 1089
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019957308687881684,
      "loss": 2.4375,
      "step": 1090
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019957147855618005,
      "loss": 2.6445,
      "step": 1091
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019956986721620038,
      "loss": 2.5312,
      "step": 1092
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019956825285892665,
      "loss": 2.625,
      "step": 1093
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019956663548440783,
      "loss": 2.5625,
      "step": 1094
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995650150926929,
      "loss": 2.5352,
      "step": 1095
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995633916838309,
      "loss": 2.4961,
      "step": 1096
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019956176525787114,
      "loss": 2.4219,
      "step": 1097
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019956013581486284,
      "loss": 2.5781,
      "step": 1098
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019955850335485535,
      "loss": 2.6133,
      "step": 1099
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019955686787789823,
      "loss": 2.5234,
      "step": 1100
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019955522938404097,
      "loss": 2.3789,
      "step": 1101
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019955358787333323,
      "loss": 2.5703,
      "step": 1102
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995519433458248,
      "loss": 2.5742,
      "step": 1103
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019955029580156543,
      "loss": 2.4297,
      "step": 1104
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995486452406051,
      "loss": 2.4492,
      "step": 1105
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019954699166299383,
      "loss": 2.5703,
      "step": 1106
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019954533506878172,
      "loss": 2.4961,
      "step": 1107
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019954367545801897,
      "loss": 2.4648,
      "step": 1108
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995420128307559,
      "loss": 2.4453,
      "step": 1109
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019954034718704283,
      "loss": 2.6055,
      "step": 1110
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019953867852693027,
      "loss": 2.3828,
      "step": 1111
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019953700685046882,
      "loss": 2.5898,
      "step": 1112
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019953533215770905,
      "loss": 2.6914,
      "step": 1113
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995336544487018,
      "loss": 2.5156,
      "step": 1114
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019953197372349785,
      "loss": 2.4219,
      "step": 1115
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019953028998214817,
      "loss": 2.457,
      "step": 1116
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019952860322470373,
      "loss": 2.5859,
      "step": 1117
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995269134512157,
      "loss": 2.6289,
      "step": 1118
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995252206617353,
      "loss": 2.6172,
      "step": 1119
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019952352485631377,
      "loss": 2.418,
      "step": 1120
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995218260350025,
      "loss": 2.4766,
      "step": 1121
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.00199520124197853,
      "loss": 2.3477,
      "step": 1122
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019951841934491682,
      "loss": 2.4336,
      "step": 1123
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995167114762457,
      "loss": 2.6602,
      "step": 1124
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019951500059189123,
      "loss": 2.7031,
      "step": 1125
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995132866919054,
      "loss": 2.5039,
      "step": 1126
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019951156977634013,
      "loss": 2.6445,
      "step": 1127
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995098498452474,
      "loss": 2.6992,
      "step": 1128
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019950812689867935,
      "loss": 2.5312,
      "step": 1129
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995064009366882,
      "loss": 2.5039,
      "step": 1130
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995046719593262,
      "loss": 2.5117,
      "step": 1131
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995029399666458,
      "loss": 2.5156,
      "step": 1132
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001995012049586995,
      "loss": 2.4609,
      "step": 1133
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019949946693553983,
      "loss": 2.7812,
      "step": 1134
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019949772589721946,
      "loss": 2.6328,
      "step": 1135
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019949598184379118,
      "loss": 2.457,
      "step": 1136
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019949423477530785,
      "loss": 2.5273,
      "step": 1137
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019949248469182234,
      "loss": 2.6133,
      "step": 1138
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019949073159338773,
      "loss": 2.3867,
      "step": 1139
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019948897548005716,
      "loss": 2.6133,
      "step": 1140
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019948721635188386,
      "loss": 2.5859,
      "step": 1141
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019948545420892107,
      "loss": 2.5039,
      "step": 1142
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019948368905122224,
      "loss": 2.5312,
      "step": 1143
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019948192087884085,
      "loss": 2.7891,
      "step": 1144
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019948014969183047,
      "loss": 2.5273,
      "step": 1145
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019947837549024483,
      "loss": 2.6016,
      "step": 1146
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019947659827413756,
      "loss": 2.5039,
      "step": 1147
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019947481804356263,
      "loss": 2.7031,
      "step": 1148
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019947303479857397,
      "loss": 2.3477,
      "step": 1149
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019947124853922564,
      "loss": 2.5273,
      "step": 1150
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001994694592655717,
      "loss": 2.4043,
      "step": 1151
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019946766697766637,
      "loss": 2.3867,
      "step": 1152
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019946587167556404,
      "loss": 2.5273,
      "step": 1153
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019946407335931907,
      "loss": 2.6836,
      "step": 1154
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019946227202898596,
      "loss": 2.625,
      "step": 1155
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001994604676846193,
      "loss": 2.6055,
      "step": 1156
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019945866032627375,
      "loss": 2.4375,
      "step": 1157
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001994568499540041,
      "loss": 2.5703,
      "step": 1158
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019945503656786517,
      "loss": 2.5781,
      "step": 1159
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019945322016791194,
      "loss": 2.4023,
      "step": 1160
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019945140075419946,
      "loss": 2.5078,
      "step": 1161
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.001994495783267829,
      "loss": 2.4141,
      "step": 1162
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001994477528857174,
      "loss": 2.543,
      "step": 1163
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019944592443105836,
      "loss": 2.5117,
      "step": 1164
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019944409296286107,
      "loss": 2.3633,
      "step": 1165
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019944225848118114,
      "loss": 2.5078,
      "step": 1166
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019944042098607416,
      "loss": 2.4883,
      "step": 1167
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019943858047759577,
      "loss": 2.3633,
      "step": 1168
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001994367369558018,
      "loss": 2.4961,
      "step": 1169
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00199434890420748,
      "loss": 2.3066,
      "step": 1170
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019943304087249045,
      "loss": 2.4805,
      "step": 1171
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001994311883110851,
      "loss": 2.5391,
      "step": 1172
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001994293327365881,
      "loss": 2.6094,
      "step": 1173
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019942747414905576,
      "loss": 2.6172,
      "step": 1174
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001994256125485444,
      "loss": 2.6602,
      "step": 1175
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001994237479351103,
      "loss": 2.6094,
      "step": 1176
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001994218803088101,
      "loss": 2.4102,
      "step": 1177
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001994200096697003,
      "loss": 2.6836,
      "step": 1178
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019941813601783765,
      "loss": 2.5664,
      "step": 1179
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019941625935327896,
      "loss": 2.5,
      "step": 1180
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00199414379676081,
      "loss": 2.6289,
      "step": 1181
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001994124969863008,
      "loss": 2.3984,
      "step": 1182
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001994106112839954,
      "loss": 2.5391,
      "step": 1183
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019940872256922187,
      "loss": 2.5508,
      "step": 1184
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019940683084203755,
      "loss": 2.4609,
      "step": 1185
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001994049361024997,
      "loss": 2.3809,
      "step": 1186
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001994030383506658,
      "loss": 2.5625,
      "step": 1187
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001994011375865933,
      "loss": 2.4961,
      "step": 1188
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993992338103398,
      "loss": 2.5586,
      "step": 1189
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00199397327021963,
      "loss": 2.5742,
      "step": 1190
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019939541722152074,
      "loss": 2.5234,
      "step": 1191
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993935044090708,
      "loss": 2.6055,
      "step": 1192
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993915885846712,
      "loss": 2.6953,
      "step": 1193
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019938966974838,
      "loss": 2.5195,
      "step": 1194
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993877479002553,
      "loss": 2.5352,
      "step": 1195
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993858230403554,
      "loss": 2.5938,
      "step": 1196
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993838951687386,
      "loss": 2.5508,
      "step": 1197
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019938196428546328,
      "loss": 2.5703,
      "step": 1198
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019938003039058805,
      "loss": 2.3438,
      "step": 1199
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993780934841714,
      "loss": 2.6484,
      "step": 1200
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993761535662721,
      "loss": 2.5859,
      "step": 1201
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019937421063694893,
      "loss": 2.457,
      "step": 1202
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993722646962607,
      "loss": 2.3789,
      "step": 1203
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993703157442665,
      "loss": 2.5977,
      "step": 1204
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993683637810253,
      "loss": 2.5391,
      "step": 1205
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019936640880659625,
      "loss": 2.4258,
      "step": 1206
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993644508210386,
      "loss": 2.5,
      "step": 1207
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019936248982441174,
      "loss": 2.6914,
      "step": 1208
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00199360525816775,
      "loss": 2.4688,
      "step": 1209
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00199358558798188,
      "loss": 2.3984,
      "step": 1210
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019935658876871027,
      "loss": 2.5664,
      "step": 1211
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019935461572840154,
      "loss": 2.3984,
      "step": 1212
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019935263967732157,
      "loss": 2.5234,
      "step": 1213
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993506606155303,
      "loss": 2.3789,
      "step": 1214
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993486785430876,
      "loss": 2.4648,
      "step": 1215
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993466934600537,
      "loss": 2.4883,
      "step": 1216
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019934470536648857,
      "loss": 2.582,
      "step": 1217
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019934271426245258,
      "loss": 2.5078,
      "step": 1218
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00199340720148006,
      "loss": 2.3867,
      "step": 1219
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993387230232093,
      "loss": 2.6367,
      "step": 1220
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019933672288812297,
      "loss": 2.418,
      "step": 1221
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019933471974280764,
      "loss": 2.6172,
      "step": 1222
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00199332713587324,
      "loss": 2.5703,
      "step": 1223
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993307044217329,
      "loss": 2.3711,
      "step": 1224
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019932869224609513,
      "loss": 2.7109,
      "step": 1225
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019932667706047172,
      "loss": 2.4297,
      "step": 1226
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993246588649237,
      "loss": 2.4336,
      "step": 1227
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993226376595123,
      "loss": 2.5117,
      "step": 1228
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019932061344429867,
      "loss": 2.543,
      "step": 1229
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019931858621934423,
      "loss": 2.6133,
      "step": 1230
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993165559847104,
      "loss": 2.5547,
      "step": 1231
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993145227404587,
      "loss": 2.5742,
      "step": 1232
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019931248648665067,
      "loss": 2.4609,
      "step": 1233
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993104472233481,
      "loss": 2.5039,
      "step": 1234
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993084049506128,
      "loss": 2.3984,
      "step": 1235
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019930635966850657,
      "loss": 2.6094,
      "step": 1236
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019930431137709145,
      "loss": 2.3203,
      "step": 1237
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001993022600764295,
      "loss": 2.4688,
      "step": 1238
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019930020576658294,
      "loss": 2.5664,
      "step": 1239
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019929814844761393,
      "loss": 2.6094,
      "step": 1240
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001992960881195848,
      "loss": 2.5312,
      "step": 1241
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019929402478255807,
      "loss": 2.4043,
      "step": 1242
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019929195843659624,
      "loss": 2.5859,
      "step": 1243
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019928988908176188,
      "loss": 2.5078,
      "step": 1244
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019928781671811773,
      "loss": 2.6211,
      "step": 1245
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019928574134572665,
      "loss": 2.4609,
      "step": 1246
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001992836629646514,
      "loss": 2.418,
      "step": 1247
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001992815815749551,
      "loss": 2.4141,
      "step": 1248
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001992794971767007,
      "loss": 2.3789,
      "step": 1249
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019927740976995144,
      "loss": 2.4336,
      "step": 1250
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019927531935477055,
      "loss": 2.5391,
      "step": 1251
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001992732259312214,
      "loss": 2.5938,
      "step": 1252
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0019927112949936743,
      "loss": 2.3164,
      "step": 1253
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001992690300592721,
      "loss": 2.4414,
      "step": 1254
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.001992669276109991,
      "loss": 2.4531,
      "step": 1255
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019926482215461214,
      "loss": 2.6914,
      "step": 1256
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019926271369017498,
      "loss": 2.5859,
      "step": 1257
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019926060221775155,
      "loss": 2.4297,
      "step": 1258
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019925848773740583,
      "loss": 2.3594,
      "step": 1259
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019925637024920183,
      "loss": 2.5859,
      "step": 1260
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019925424975320385,
      "loss": 2.4258,
      "step": 1261
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.00199252126249476,
      "loss": 2.4688,
      "step": 1262
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019924999973808277,
      "loss": 2.5508,
      "step": 1263
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019924787021908846,
      "loss": 2.4648,
      "step": 1264
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019924573769255776,
      "loss": 2.4922,
      "step": 1265
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019924360215855513,
      "loss": 2.4453,
      "step": 1266
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019924146361714537,
      "loss": 2.6758,
      "step": 1267
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001992393220683933,
      "loss": 2.4551,
      "step": 1268
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019923717751236377,
      "loss": 2.4102,
      "step": 1269
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001992350299491218,
      "loss": 2.4492,
      "step": 1270
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019923287937873243,
      "loss": 2.6406,
      "step": 1271
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019923072580126087,
      "loss": 2.2344,
      "step": 1272
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019922856921677236,
      "loss": 2.3008,
      "step": 1273
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019922640962533227,
      "loss": 2.4922,
      "step": 1274
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.00199224247027006,
      "loss": 2.5039,
      "step": 1275
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019922208142185913,
      "loss": 2.3164,
      "step": 1276
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019921991280995727,
      "loss": 2.457,
      "step": 1277
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019921774119136615,
      "loss": 2.4531,
      "step": 1278
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019921556656615153,
      "loss": 2.5,
      "step": 1279
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001992133889343793,
      "loss": 2.3789,
      "step": 1280
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019921120829611556,
      "loss": 2.4961,
      "step": 1281
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001992090246514263,
      "loss": 2.5312,
      "step": 1282
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001992068380003777,
      "loss": 2.4688,
      "step": 1283
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019920464834303603,
      "loss": 2.5898,
      "step": 1284
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019920245567946766,
      "loss": 2.5742,
      "step": 1285
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019920026000973903,
      "loss": 2.6016,
      "step": 1286
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019919806133391663,
      "loss": 2.4727,
      "step": 1287
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019919585965206717,
      "loss": 2.5664,
      "step": 1288
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001991936549642573,
      "loss": 2.3516,
      "step": 1289
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019919144727055384,
      "loss": 2.375,
      "step": 1290
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001991892365710237,
      "loss": 2.5039,
      "step": 1291
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019918702286573393,
      "loss": 2.5703,
      "step": 1292
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019918480615475154,
      "loss": 2.5078,
      "step": 1293
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019918258643814367,
      "loss": 2.7812,
      "step": 1294
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019918036371597767,
      "loss": 2.3652,
      "step": 1295
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019917813798832084,
      "loss": 2.4531,
      "step": 1296
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019917590925524068,
      "loss": 2.3984,
      "step": 1297
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019917367751680465,
      "loss": 2.4961,
      "step": 1298
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019917144277308047,
      "loss": 2.4414,
      "step": 1299
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019916920502413577,
      "loss": 2.6367,
      "step": 1300
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019916696427003844,
      "loss": 2.3672,
      "step": 1301
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019916472051085634,
      "loss": 2.4336,
      "step": 1302
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001991624737466575,
      "loss": 2.2773,
      "step": 1303
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019916022397750994,
      "loss": 2.5469,
      "step": 1304
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019915797120348185,
      "loss": 2.4492,
      "step": 1305
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019915571542464157,
      "loss": 2.3438,
      "step": 1306
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001991534566410574,
      "loss": 2.4297,
      "step": 1307
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019915119485279776,
      "loss": 2.5781,
      "step": 1308
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019914893005993123,
      "loss": 2.4102,
      "step": 1309
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019914666226252646,
      "loss": 2.582,
      "step": 1310
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001991443914606521,
      "loss": 2.5977,
      "step": 1311
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019914211765437702,
      "loss": 2.5977,
      "step": 1312
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019913984084377013,
      "loss": 2.5352,
      "step": 1313
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019913756102890043,
      "loss": 2.5586,
      "step": 1314
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019913527820983696,
      "loss": 2.3984,
      "step": 1315
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001991329923866489,
      "loss": 2.5391,
      "step": 1316
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001991307035594056,
      "loss": 2.668,
      "step": 1317
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019912841172817627,
      "loss": 2.5469,
      "step": 1318
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001991261168930305,
      "loss": 2.4648,
      "step": 1319
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019912381905403775,
      "loss": 2.4766,
      "step": 1320
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001991215182112677,
      "loss": 2.5117,
      "step": 1321
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019911921436479006,
      "loss": 2.4961,
      "step": 1322
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001991169075146746,
      "loss": 2.5039,
      "step": 1323
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001991145976609913,
      "loss": 2.5156,
      "step": 1324
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001991122848038101,
      "loss": 2.3789,
      "step": 1325
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001991099689432011,
      "loss": 2.4023,
      "step": 1326
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001991076500792345,
      "loss": 2.582,
      "step": 1327
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001991053282119806,
      "loss": 2.5039,
      "step": 1328
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001991030033415096,
      "loss": 2.5,
      "step": 1329
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019910067546789214,
      "loss": 2.6953,
      "step": 1330
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001990983445911987,
      "loss": 2.5352,
      "step": 1331
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019909601071149987,
      "loss": 2.5,
      "step": 1332
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019909367382886637,
      "loss": 2.5977,
      "step": 1333
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019909133394336908,
      "loss": 2.6016,
      "step": 1334
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001990889910550789,
      "loss": 2.6055,
      "step": 1335
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001990866451640668,
      "loss": 2.4727,
      "step": 1336
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019908429627040385,
      "loss": 2.5,
      "step": 1337
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019908194437416125,
      "loss": 2.5234,
      "step": 1338
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001990795894754103,
      "loss": 2.5273,
      "step": 1339
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019907723157422228,
      "loss": 2.7969,
      "step": 1340
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019907487067066867,
      "loss": 2.6836,
      "step": 1341
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019907250676482113,
      "loss": 2.4883,
      "step": 1342
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019907013985675116,
      "loss": 2.4453,
      "step": 1343
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019906776994653053,
      "loss": 2.4023,
      "step": 1344
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.00199065397034231,
      "loss": 2.3516,
      "step": 1345
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0019906302111992458,
      "loss": 2.4883,
      "step": 1346
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.001990606422036832,
      "loss": 2.4961,
      "step": 1347
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.00199058260285579,
      "loss": 2.4961,
      "step": 1348
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001990558753656841,
      "loss": 2.4727,
      "step": 1349
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019905348744407077,
      "loss": 2.4648,
      "step": 1350
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019905109652081144,
      "loss": 2.4453,
      "step": 1351
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001990487025959785,
      "loss": 2.5078,
      "step": 1352
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019904630566964453,
      "loss": 2.5781,
      "step": 1353
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019904390574188215,
      "loss": 2.6406,
      "step": 1354
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019904150281276406,
      "loss": 2.3906,
      "step": 1355
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019903909688236314,
      "loss": 2.5664,
      "step": 1356
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019903668795075223,
      "loss": 2.4844,
      "step": 1357
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001990342760180044,
      "loss": 2.5898,
      "step": 1358
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001990318610841926,
      "loss": 2.6562,
      "step": 1359
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001990294431493902,
      "loss": 2.3984,
      "step": 1360
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019902702221367037,
      "loss": 2.7031,
      "step": 1361
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019902459827710645,
      "loss": 2.4922,
      "step": 1362
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019902217133977193,
      "loss": 2.5547,
      "step": 1363
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019901974140174037,
      "loss": 2.6016,
      "step": 1364
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001990173084630854,
      "loss": 2.2578,
      "step": 1365
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019901487252388067,
      "loss": 2.4492,
      "step": 1366
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001990124335842001,
      "loss": 2.7188,
      "step": 1367
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001990099916441176,
      "loss": 2.4922,
      "step": 1368
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019900754670370705,
      "loss": 2.4375,
      "step": 1369
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001990050987630426,
      "loss": 2.5625,
      "step": 1370
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019900264782219852,
      "loss": 2.2812,
      "step": 1371
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019900019388124895,
      "loss": 2.4531,
      "step": 1372
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019899773694026833,
      "loss": 2.418,
      "step": 1373
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001989952769993311,
      "loss": 2.5273,
      "step": 1374
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019899281405851175,
      "loss": 2.6875,
      "step": 1375
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.00198990348117885,
      "loss": 2.5312,
      "step": 1376
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019898787917752556,
      "loss": 2.6797,
      "step": 1377
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019898540723750817,
      "loss": 2.5898,
      "step": 1378
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019898293229790786,
      "loss": 2.4844,
      "step": 1379
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001989804543587995,
      "loss": 2.5,
      "step": 1380
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019897797342025825,
      "loss": 2.6719,
      "step": 1381
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001989754894823593,
      "loss": 2.4453,
      "step": 1382
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001989730025451779,
      "loss": 2.4727,
      "step": 1383
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001989705126087894,
      "loss": 2.2852,
      "step": 1384
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001989680196732693,
      "loss": 2.5938,
      "step": 1385
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001989655237386931,
      "loss": 2.6406,
      "step": 1386
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001989630248051364,
      "loss": 2.418,
      "step": 1387
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019896052287267504,
      "loss": 2.4141,
      "step": 1388
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019895801794138474,
      "loss": 2.5078,
      "step": 1389
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019895551001134146,
      "loss": 2.5547,
      "step": 1390
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019895299908262117,
      "loss": 2.3789,
      "step": 1391
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019895048515529996,
      "loss": 2.5391,
      "step": 1392
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.00198947968229454,
      "loss": 2.5234,
      "step": 1393
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001989454483051596,
      "loss": 2.6211,
      "step": 1394
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019894292538249307,
      "loss": 2.3945,
      "step": 1395
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001989403994615309,
      "loss": 2.6016,
      "step": 1396
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019893787054234965,
      "loss": 2.4141,
      "step": 1397
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019893533862502593,
      "loss": 2.5195,
      "step": 1398
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001989328037096365,
      "loss": 2.582,
      "step": 1399
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019893026579625808,
      "loss": 2.4336,
      "step": 1400
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019892772488496763,
      "loss": 2.3203,
      "step": 1401
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001989251809758422,
      "loss": 2.5586,
      "step": 1402
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019892263406895883,
      "loss": 2.3633,
      "step": 1403
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001989200841643947,
      "loss": 2.5703,
      "step": 1404
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019891753126222707,
      "loss": 2.4727,
      "step": 1405
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001989149753625333,
      "loss": 2.5703,
      "step": 1406
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001989124164653909,
      "loss": 2.5898,
      "step": 1407
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019890985457087737,
      "loss": 2.3438,
      "step": 1408
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001989072896790703,
      "loss": 2.4844,
      "step": 1409
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019890472179004753,
      "loss": 2.5703,
      "step": 1410
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019890215090388676,
      "loss": 2.4492,
      "step": 1411
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.00198899577020666,
      "loss": 2.6797,
      "step": 1412
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019889700014046312,
      "loss": 2.418,
      "step": 1413
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001988944202633563,
      "loss": 2.418,
      "step": 1414
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019889183738942373,
      "loss": 2.3379,
      "step": 1415
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001988892515187436,
      "loss": 2.4883,
      "step": 1416
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019888666265139433,
      "loss": 2.5742,
      "step": 1417
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019888407078745437,
      "loss": 2.5703,
      "step": 1418
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019888147592700225,
      "loss": 2.4883,
      "step": 1419
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001988788780701166,
      "loss": 2.7422,
      "step": 1420
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019887627721687615,
      "loss": 2.4609,
      "step": 1421
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019887367336735968,
      "loss": 2.4297,
      "step": 1422
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019887106652164616,
      "loss": 2.3945,
      "step": 1423
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019886845667981454,
      "loss": 2.3047,
      "step": 1424
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001988658438419439,
      "loss": 2.4492,
      "step": 1425
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019886322800811347,
      "loss": 2.3711,
      "step": 1426
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001988606091784025,
      "loss": 2.75,
      "step": 1427
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019885798735289027,
      "loss": 2.6328,
      "step": 1428
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019885536253165634,
      "loss": 2.7109,
      "step": 1429
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019885273471478017,
      "loss": 2.4297,
      "step": 1430
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019885010390234144,
      "loss": 2.5938,
      "step": 1431
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001988474700944199,
      "loss": 2.4141,
      "step": 1432
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019884483329109526,
      "loss": 2.6055,
      "step": 1433
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001988421934924475,
      "loss": 2.248,
      "step": 1434
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001988395506985566,
      "loss": 2.4414,
      "step": 1435
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001988369049095027,
      "loss": 2.5273,
      "step": 1436
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019883425612536587,
      "loss": 2.5078,
      "step": 1437
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001988316043462264,
      "loss": 2.3828,
      "step": 1438
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001988289495721647,
      "loss": 2.5,
      "step": 1439
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019882629180326124,
      "loss": 2.543,
      "step": 1440
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0019882363103959646,
      "loss": 2.5117,
      "step": 1441
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019882096728125105,
      "loss": 2.5391,
      "step": 1442
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019881830052830575,
      "loss": 2.6094,
      "step": 1443
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001988156307808413,
      "loss": 2.4297,
      "step": 1444
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019881295803893867,
      "loss": 2.4922,
      "step": 1445
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019881028230267885,
      "loss": 2.543,
      "step": 1446
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001988076035721429,
      "loss": 2.4414,
      "step": 1447
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00198804921847412,
      "loss": 2.5078,
      "step": 1448
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001988022371285674,
      "loss": 2.543,
      "step": 1449
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019879954941569044,
      "loss": 2.4141,
      "step": 1450
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001987968587088626,
      "loss": 2.4844,
      "step": 1451
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019879416500816543,
      "loss": 2.5703,
      "step": 1452
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019879146831368053,
      "loss": 2.5898,
      "step": 1453
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019878876862548965,
      "loss": 2.3359,
      "step": 1454
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001987860659436746,
      "loss": 2.4766,
      "step": 1455
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001987833602683172,
      "loss": 2.4648,
      "step": 1456
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019878065159949954,
      "loss": 2.3945,
      "step": 1457
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019877793993730362,
      "loss": 2.2852,
      "step": 1458
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019877522528181173,
      "loss": 2.4258,
      "step": 1459
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00198772507633106,
      "loss": 2.5703,
      "step": 1460
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019876978699126884,
      "loss": 2.5312,
      "step": 1461
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001987670633563827,
      "loss": 2.5273,
      "step": 1462
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001987643367285301,
      "loss": 2.4609,
      "step": 1463
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001987616071077937,
      "loss": 2.4766,
      "step": 1464
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019875887449425614,
      "loss": 2.5664,
      "step": 1465
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019875613888800034,
      "loss": 2.5117,
      "step": 1466
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001987534002891091,
      "loss": 2.3242,
      "step": 1467
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019875065869766548,
      "loss": 2.5,
      "step": 1468
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019874791411375247,
      "loss": 2.457,
      "step": 1469
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019874516653745336,
      "loss": 2.5156,
      "step": 1470
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001987424159688513,
      "loss": 2.6797,
      "step": 1471
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019873966240802968,
      "loss": 2.3984,
      "step": 1472
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019873690585507195,
      "loss": 2.6836,
      "step": 1473
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001987341463100617,
      "loss": 2.4688,
      "step": 1474
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001987313837730824,
      "loss": 2.3086,
      "step": 1475
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019872861824421794,
      "loss": 2.5742,
      "step": 1476
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00198725849723552,
      "loss": 2.7109,
      "step": 1477
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019872307821116853,
      "loss": 2.4805,
      "step": 1478
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001987203037071515,
      "loss": 2.4805,
      "step": 1479
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00198717526211585,
      "loss": 2.4102,
      "step": 1480
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001987147457245532,
      "loss": 2.5938,
      "step": 1481
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001987119622461403,
      "loss": 2.3672,
      "step": 1482
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019870917577643073,
      "loss": 2.5625,
      "step": 1483
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001987063863155089,
      "loss": 2.5234,
      "step": 1484
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001987035938634593,
      "loss": 2.5508,
      "step": 1485
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001987007984203666,
      "loss": 2.7031,
      "step": 1486
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019869799998631548,
      "loss": 2.4805,
      "step": 1487
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019869519856139076,
      "loss": 2.3984,
      "step": 1488
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019869239414567735,
      "loss": 2.3516,
      "step": 1489
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001986895867392602,
      "loss": 2.5117,
      "step": 1490
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001986867763422244,
      "loss": 2.5469,
      "step": 1491
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019868396295465505,
      "loss": 2.4531,
      "step": 1492
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019868114657663758,
      "loss": 2.4336,
      "step": 1493
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019867832720825715,
      "loss": 2.4883,
      "step": 1494
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019867550484959926,
      "loss": 2.4492,
      "step": 1495
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019867267950074946,
      "loss": 2.457,
      "step": 1496
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019866985116179336,
      "loss": 2.3867,
      "step": 1497
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019866701983281662,
      "loss": 2.5859,
      "step": 1498
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001986641855139051,
      "loss": 2.4609,
      "step": 1499
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001986613482051447,
      "loss": 2.3906,
      "step": 1500
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001986585079066213,
      "loss": 2.4492,
      "step": 1501
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019865566461842107,
      "loss": 2.4883,
      "step": 1502
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019865281834063014,
      "loss": 2.5664,
      "step": 1503
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019864996907333478,
      "loss": 2.5664,
      "step": 1504
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001986471168166213,
      "loss": 2.5469,
      "step": 1505
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001986442615705761,
      "loss": 2.5586,
      "step": 1506
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001986414033352858,
      "loss": 2.5547,
      "step": 1507
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019863854211083693,
      "loss": 2.5195,
      "step": 1508
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019863567789731623,
      "loss": 2.4453,
      "step": 1509
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019863281069481048,
      "loss": 2.3359,
      "step": 1510
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019862994050340657,
      "loss": 2.3711,
      "step": 1511
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001986270673231915,
      "loss": 2.4961,
      "step": 1512
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019862419115425235,
      "loss": 2.6367,
      "step": 1513
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001986213119966762,
      "loss": 2.5039,
      "step": 1514
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019861842985055035,
      "loss": 2.4922,
      "step": 1515
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019861554471596217,
      "loss": 2.5898,
      "step": 1516
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00198612656592999,
      "loss": 2.4688,
      "step": 1517
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019860976548174846,
      "loss": 2.5078,
      "step": 1518
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001986068713822981,
      "loss": 2.6641,
      "step": 1519
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001986039742947356,
      "loss": 2.4648,
      "step": 1520
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019860107421914882,
      "loss": 2.6602,
      "step": 1521
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019859817115562557,
      "loss": 2.3633,
      "step": 1522
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001985952651042539,
      "loss": 2.5352,
      "step": 1523
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001985923560651218,
      "loss": 2.4766,
      "step": 1524
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019858944403831746,
      "loss": 2.6133,
      "step": 1525
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001985865290239291,
      "loss": 2.4844,
      "step": 1526
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019858361102204508,
      "loss": 2.3242,
      "step": 1527
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019858069003275383,
      "loss": 2.3359,
      "step": 1528
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019857776605614386,
      "loss": 2.5312,
      "step": 1529
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019857483909230377,
      "loss": 2.2715,
      "step": 1530
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019857190914132224,
      "loss": 2.4414,
      "step": 1531
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001985689762032881,
      "loss": 2.582,
      "step": 1532
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.001985660402782902,
      "loss": 2.2539,
      "step": 1533
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0019856310136641747,
      "loss": 2.4961,
      "step": 1534
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00198560159467759,
      "loss": 2.4922,
      "step": 1535
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00198557214582404,
      "loss": 2.5859,
      "step": 1536
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019855426671044163,
      "loss": 2.5781,
      "step": 1537
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019855131585196123,
      "loss": 2.4297,
      "step": 1538
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001985483620070523,
      "loss": 2.582,
      "step": 1539
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001985454051758042,
      "loss": 2.4375,
      "step": 1540
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001985424453583067,
      "loss": 2.6055,
      "step": 1541
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019853948255464937,
      "loss": 2.3164,
      "step": 1542
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019853651676492202,
      "loss": 2.543,
      "step": 1543
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019853354798921455,
      "loss": 2.5703,
      "step": 1544
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019853057622761694,
      "loss": 2.2539,
      "step": 1545
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001985276014802192,
      "loss": 2.3047,
      "step": 1546
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001985246237471115,
      "loss": 2.5859,
      "step": 1547
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019852164302838404,
      "loss": 2.5938,
      "step": 1548
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001985186593241272,
      "loss": 2.4453,
      "step": 1549
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019851567263443138,
      "loss": 2.5547,
      "step": 1550
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019851268295938704,
      "loss": 2.4805,
      "step": 1551
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001985096902990848,
      "loss": 2.5508,
      "step": 1552
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001985066946536154,
      "loss": 2.5508,
      "step": 1553
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019850369602306952,
      "loss": 2.3281,
      "step": 1554
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019850069440753813,
      "loss": 2.4336,
      "step": 1555
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001984976898071121,
      "loss": 2.5078,
      "step": 1556
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001984946822218826,
      "loss": 2.6641,
      "step": 1557
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001984916716519406,
      "loss": 2.5352,
      "step": 1558
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019848865809737747,
      "loss": 2.5391,
      "step": 1559
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001984856415582845,
      "loss": 2.4961,
      "step": 1560
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001984826220347531,
      "loss": 2.2422,
      "step": 1561
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001984795995268747,
      "loss": 2.2852,
      "step": 1562
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019847657403474096,
      "loss": 2.6172,
      "step": 1563
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019847354555844357,
      "loss": 2.6289,
      "step": 1564
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019847051409807425,
      "loss": 2.5898,
      "step": 1565
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019846747965372494,
      "loss": 2.4766,
      "step": 1566
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019846444222548754,
      "loss": 2.4297,
      "step": 1567
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019846140181345407,
      "loss": 2.4805,
      "step": 1568
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019845835841771674,
      "loss": 2.3516,
      "step": 1569
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001984553120383677,
      "loss": 2.4414,
      "step": 1570
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019845226267549932,
      "loss": 2.4648,
      "step": 1571
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00198449210329204,
      "loss": 2.4258,
      "step": 1572
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019844615499957415,
      "loss": 2.3398,
      "step": 1573
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001984430966867025,
      "loss": 2.5039,
      "step": 1574
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019844003539068165,
      "loss": 2.418,
      "step": 1575
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001984369711116043,
      "loss": 2.5117,
      "step": 1576
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019843390384956345,
      "loss": 2.5859,
      "step": 1577
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019843083360465193,
      "loss": 2.3867,
      "step": 1578
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019842776037696285,
      "loss": 2.6211,
      "step": 1579
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001984246841665893,
      "loss": 2.4961,
      "step": 1580
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019842160497362455,
      "loss": 2.5352,
      "step": 1581
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019841852279816182,
      "loss": 2.4258,
      "step": 1582
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001984154376402946,
      "loss": 2.5586,
      "step": 1583
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019841234950011637,
      "loss": 2.5625,
      "step": 1584
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001984092583777206,
      "loss": 2.6914,
      "step": 1585
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019840616427320113,
      "loss": 2.6523,
      "step": 1586
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001984030671866516,
      "loss": 2.5391,
      "step": 1587
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019839996711816586,
      "loss": 2.457,
      "step": 1588
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019839686406783797,
      "loss": 2.5742,
      "step": 1589
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001983937580357618,
      "loss": 2.5938,
      "step": 1590
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019839064902203163,
      "loss": 2.4922,
      "step": 1591
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019838753702674156,
      "loss": 2.5469,
      "step": 1592
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019838442204998595,
      "loss": 2.5703,
      "step": 1593
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019838130409185915,
      "loss": 2.5781,
      "step": 1594
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001983781831524557,
      "loss": 2.6406,
      "step": 1595
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019837505923187017,
      "loss": 2.5,
      "step": 1596
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019837193233019717,
      "loss": 2.6797,
      "step": 1597
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001983688024475315,
      "loss": 2.4023,
      "step": 1598
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019836566958396796,
      "loss": 2.3125,
      "step": 1599
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001983625337396016,
      "loss": 2.4023,
      "step": 1600
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019835939491452724,
      "loss": 2.4453,
      "step": 1601
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019835625310884023,
      "loss": 2.4492,
      "step": 1602
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001983531083226356,
      "loss": 2.5117,
      "step": 1603
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019834996055600874,
      "loss": 2.418,
      "step": 1604
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001983468098090551,
      "loss": 2.457,
      "step": 1605
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019834365608186995,
      "loss": 2.4766,
      "step": 1606
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019834049937454902,
      "loss": 2.5586,
      "step": 1607
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001983373396871879,
      "loss": 2.457,
      "step": 1608
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019833417701988244,
      "loss": 2.4141,
      "step": 1609
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019833101137272835,
      "loss": 2.5508,
      "step": 1610
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019832784274582166,
      "loss": 2.3789,
      "step": 1611
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001983246711392583,
      "loss": 2.5938,
      "step": 1612
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019832149655313446,
      "loss": 2.4961,
      "step": 1613
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001983183189875463,
      "loss": 2.4844,
      "step": 1614
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001983151384425901,
      "loss": 2.5,
      "step": 1615
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001983119549183623,
      "loss": 2.4492,
      "step": 1616
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001983087684149593,
      "loss": 2.5898,
      "step": 1617
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001983055789324777,
      "loss": 2.2422,
      "step": 1618
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001983023864710141,
      "loss": 2.3164,
      "step": 1619
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019829919103066533,
      "loss": 2.4414,
      "step": 1620
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001982959926115282,
      "loss": 2.418,
      "step": 1621
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019829279121369955,
      "loss": 2.6406,
      "step": 1622
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001982895868372765,
      "loss": 2.5664,
      "step": 1623
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019828637948235608,
      "loss": 2.3047,
      "step": 1624
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019828316914903554,
      "loss": 2.5977,
      "step": 1625
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019827995583741207,
      "loss": 2.4062,
      "step": 1626
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0019827673954758316,
      "loss": 2.4961,
      "step": 1627
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.001982735202796462,
      "loss": 2.5156,
      "step": 1628
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019827029803369876,
      "loss": 2.1562,
      "step": 1629
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001982670728098385,
      "loss": 2.6016,
      "step": 1630
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001982638446081632,
      "loss": 2.5273,
      "step": 1631
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019826061342877056,
      "loss": 2.6914,
      "step": 1632
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001982573792717586,
      "loss": 2.625,
      "step": 1633
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019825414213722526,
      "loss": 2.5703,
      "step": 1634
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001982509020252687,
      "loss": 2.5195,
      "step": 1635
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019824765893598707,
      "loss": 2.2266,
      "step": 1636
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019824441286947865,
      "loss": 2.5078,
      "step": 1637
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001982411638258418,
      "loss": 2.3945,
      "step": 1638
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019823791180517496,
      "loss": 2.6406,
      "step": 1639
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019823465680757673,
      "loss": 2.457,
      "step": 1640
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001982313988331457,
      "loss": 2.5195,
      "step": 1641
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001982281378819806,
      "loss": 2.7969,
      "step": 1642
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019822487395418026,
      "loss": 2.373,
      "step": 1643
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019822160704984363,
      "loss": 2.5195,
      "step": 1644
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019821833716906967,
      "loss": 2.4492,
      "step": 1645
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019821506431195743,
      "loss": 2.7344,
      "step": 1646
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001982117884786061,
      "loss": 2.5742,
      "step": 1647
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019820850966911505,
      "loss": 2.4375,
      "step": 1648
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001982052278835835,
      "loss": 2.416,
      "step": 1649
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00198201943122111,
      "loss": 2.4648,
      "step": 1650
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00198198655384797,
      "loss": 2.4375,
      "step": 1651
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001981953646717412,
      "loss": 2.6328,
      "step": 1652
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001981920709830433,
      "loss": 2.4961,
      "step": 1653
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001981887743188031,
      "loss": 2.5391,
      "step": 1654
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001981854746791205,
      "loss": 2.5,
      "step": 1655
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019818217206409553,
      "loss": 2.6094,
      "step": 1656
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001981788664738282,
      "loss": 2.6445,
      "step": 1657
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019817555790841873,
      "loss": 2.5859,
      "step": 1658
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001981722463679674,
      "loss": 2.2852,
      "step": 1659
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001981689318525745,
      "loss": 2.6797,
      "step": 1660
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001981656143623405,
      "loss": 2.5039,
      "step": 1661
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001981622938973659,
      "loss": 2.3867,
      "step": 1662
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001981589704577514,
      "loss": 2.4141,
      "step": 1663
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019815564404359765,
      "loss": 2.5352,
      "step": 1664
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019815231465500544,
      "loss": 2.4492,
      "step": 1665
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001981489822920757,
      "loss": 2.4141,
      "step": 1666
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001981456469549094,
      "loss": 2.4297,
      "step": 1667
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001981423086436076,
      "loss": 2.2539,
      "step": 1668
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019813896735827144,
      "loss": 2.4492,
      "step": 1669
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019813562309900228,
      "loss": 2.6445,
      "step": 1670
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001981322758659013,
      "loss": 2.5742,
      "step": 1671
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019812892565907007,
      "loss": 2.5586,
      "step": 1672
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019812557247861004,
      "loss": 2.6289,
      "step": 1673
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001981222163246228,
      "loss": 2.4844,
      "step": 1674
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019811885719721017,
      "loss": 2.4062,
      "step": 1675
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001981154950964738,
      "loss": 2.4414,
      "step": 1676
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019811213002251566,
      "loss": 2.4062,
      "step": 1677
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001981087619754377,
      "loss": 2.4023,
      "step": 1678
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00198105390955342,
      "loss": 2.582,
      "step": 1679
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019810201696233067,
      "loss": 2.6367,
      "step": 1680
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00198098639996506,
      "loss": 2.5039,
      "step": 1681
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001980952600579703,
      "loss": 2.4258,
      "step": 1682
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00198091877146826,
      "loss": 2.7305,
      "step": 1683
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019808849126317562,
      "loss": 2.4766,
      "step": 1684
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001980851024071217,
      "loss": 2.4766,
      "step": 1685
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019808171057876705,
      "loss": 2.4844,
      "step": 1686
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019807831577821435,
      "loss": 2.2344,
      "step": 1687
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001980749180055665,
      "loss": 2.5117,
      "step": 1688
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001980715172609265,
      "loss": 2.6836,
      "step": 1689
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001980681135443974,
      "loss": 2.4844,
      "step": 1690
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001980647068560823,
      "loss": 2.4062,
      "step": 1691
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019806129719608444,
      "loss": 2.2891,
      "step": 1692
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019805788456450724,
      "loss": 2.4336,
      "step": 1693
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019805446896145394,
      "loss": 2.6445,
      "step": 1694
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001980510503870282,
      "loss": 2.582,
      "step": 1695
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019804762884133354,
      "loss": 2.6328,
      "step": 1696
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001980442043244736,
      "loss": 2.4375,
      "step": 1697
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001980407768365523,
      "loss": 2.6523,
      "step": 1698
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001980373463776734,
      "loss": 2.4883,
      "step": 1699
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019803391294794083,
      "loss": 2.4609,
      "step": 1700
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019803047654745874,
      "loss": 2.3906,
      "step": 1701
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019802703717633112,
      "loss": 2.543,
      "step": 1702
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019802359483466233,
      "loss": 2.5469,
      "step": 1703
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001980201495225566,
      "loss": 2.4141,
      "step": 1704
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001980167012401184,
      "loss": 2.543,
      "step": 1705
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019801324998745214,
      "loss": 2.3867,
      "step": 1706
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001980097957646625,
      "loss": 2.5312,
      "step": 1707
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019800633857185402,
      "loss": 2.5586,
      "step": 1708
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001980028784091316,
      "loss": 2.5273,
      "step": 1709
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001979994152766001,
      "loss": 2.4258,
      "step": 1710
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001979959491743643,
      "loss": 2.4863,
      "step": 1711
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019799248010252944,
      "loss": 2.4883,
      "step": 1712
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019798900806120047,
      "loss": 2.3867,
      "step": 1713
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001979855330504827,
      "loss": 2.6523,
      "step": 1714
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019798205507048144,
      "loss": 2.582,
      "step": 1715
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019797857412130206,
      "loss": 2.4453,
      "step": 1716
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019797509020305004,
      "loss": 2.4531,
      "step": 1717
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019797160331583093,
      "loss": 2.293,
      "step": 1718
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019796811345975046,
      "loss": 2.4531,
      "step": 1719
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.001979646206349143,
      "loss": 2.4258,
      "step": 1720
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0019796112484142835,
      "loss": 2.4531,
      "step": 1721
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019795762607939856,
      "loss": 2.4062,
      "step": 1722
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001979541243489309,
      "loss": 2.4141,
      "step": 1723
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019795061965013155,
      "loss": 2.5625,
      "step": 1724
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019794711198310665,
      "loss": 2.4727,
      "step": 1725
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001979436013479625,
      "loss": 2.5742,
      "step": 1726
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019794008774480553,
      "loss": 2.5469,
      "step": 1727
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001979365711737422,
      "loss": 2.375,
      "step": 1728
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019793305163487906,
      "loss": 2.6172,
      "step": 1729
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001979295291283227,
      "loss": 2.5,
      "step": 1730
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019792600365418,
      "loss": 2.4492,
      "step": 1731
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001979224752125577,
      "loss": 2.5938,
      "step": 1732
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019791894380356274,
      "loss": 2.3594,
      "step": 1733
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001979154094273021,
      "loss": 2.3398,
      "step": 1734
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00197911872083883,
      "loss": 2.5938,
      "step": 1735
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001979083317734125,
      "loss": 2.5078,
      "step": 1736
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019790478849599793,
      "loss": 2.3047,
      "step": 1737
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001979012422517467,
      "loss": 2.4727,
      "step": 1738
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019789769304076623,
      "loss": 2.4102,
      "step": 1739
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001978941408631641,
      "loss": 2.6133,
      "step": 1740
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001978905857190479,
      "loss": 2.5547,
      "step": 1741
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019788702760852542,
      "loss": 2.5352,
      "step": 1742
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001978834665317045,
      "loss": 2.3789,
      "step": 1743
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019787990248869296,
      "loss": 2.4961,
      "step": 1744
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019787633547959887,
      "loss": 2.4844,
      "step": 1745
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019787276550453036,
      "loss": 2.6289,
      "step": 1746
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001978691925635955,
      "loss": 2.3398,
      "step": 1747
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019786561665690264,
      "loss": 2.209,
      "step": 1748
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019786203778456015,
      "loss": 2.2422,
      "step": 1749
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019785845594667644,
      "loss": 2.6523,
      "step": 1750
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019785487114336005,
      "loss": 2.2852,
      "step": 1751
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019785128337471967,
      "loss": 2.2422,
      "step": 1752
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019784769264086393,
      "loss": 2.3945,
      "step": 1753
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019784409894190173,
      "loss": 2.3789,
      "step": 1754
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019784050227794193,
      "loss": 2.6406,
      "step": 1755
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001978369026490935,
      "loss": 2.3633,
      "step": 1756
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001978333000554656,
      "loss": 2.6367,
      "step": 1757
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019782969449716726,
      "loss": 2.5312,
      "step": 1758
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019782608597430787,
      "loss": 2.5312,
      "step": 1759
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019782247448699676,
      "loss": 2.582,
      "step": 1760
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019781886003534333,
      "loss": 2.5508,
      "step": 1761
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001978152426194571,
      "loss": 2.457,
      "step": 1762
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001978116222394477,
      "loss": 2.5977,
      "step": 1763
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001978079988954249,
      "loss": 2.4297,
      "step": 1764
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019780437258749843,
      "loss": 2.4922,
      "step": 1765
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001978007433157782,
      "loss": 2.4961,
      "step": 1766
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019779711108037423,
      "loss": 2.5195,
      "step": 1767
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001977934758813965,
      "loss": 2.6055,
      "step": 1768
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019778983771895522,
      "loss": 2.6172,
      "step": 1769
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019778619659316064,
      "loss": 2.4023,
      "step": 1770
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019778255250412313,
      "loss": 2.332,
      "step": 1771
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019777890545195306,
      "loss": 2.4297,
      "step": 1772
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019777525543676097,
      "loss": 2.3203,
      "step": 1773
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019777160245865746,
      "loss": 2.3281,
      "step": 1774
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019776794651775323,
      "loss": 2.375,
      "step": 1775
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019776428761415906,
      "loss": 2.4258,
      "step": 1776
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001977606257479859,
      "loss": 2.5898,
      "step": 1777
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001977569609193446,
      "loss": 2.6016,
      "step": 1778
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001977532931283463,
      "loss": 2.3398,
      "step": 1779
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019774962237510208,
      "loss": 2.5977,
      "step": 1780
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019774594865972325,
      "loss": 2.3828,
      "step": 1781
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019774227198232105,
      "loss": 2.4531,
      "step": 1782
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00197738592343007,
      "loss": 2.543,
      "step": 1783
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001977349097418925,
      "loss": 2.2773,
      "step": 1784
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019773122417908926,
      "loss": 2.6562,
      "step": 1785
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019772753565470884,
      "loss": 2.3828,
      "step": 1786
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001977238441688631,
      "loss": 2.3184,
      "step": 1787
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019772014972166386,
      "loss": 2.4883,
      "step": 1788
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001977164523132231,
      "loss": 2.6172,
      "step": 1789
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001977127519436529,
      "loss": 2.4141,
      "step": 1790
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019770904861306526,
      "loss": 2.4727,
      "step": 1791
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019770534232157254,
      "loss": 2.457,
      "step": 1792
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019770163306928705,
      "loss": 2.4922,
      "step": 1793
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019769792085632108,
      "loss": 2.5586,
      "step": 1794
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001976942056827872,
      "loss": 2.3672,
      "step": 1795
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019769048754879797,
      "loss": 2.3906,
      "step": 1796
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019768676645446613,
      "loss": 2.5469,
      "step": 1797
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001976830423999043,
      "loss": 2.293,
      "step": 1798
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001976793153852255,
      "loss": 2.457,
      "step": 1799
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019767558541054255,
      "loss": 2.4414,
      "step": 1800
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019767185247596846,
      "loss": 2.4883,
      "step": 1801
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019766811658161647,
      "loss": 2.5,
      "step": 1802
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001976643777275997,
      "loss": 2.5547,
      "step": 1803
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019766063591403153,
      "loss": 2.5312,
      "step": 1804
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019765689114102526,
      "loss": 2.5,
      "step": 1805
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019765314340869436,
      "loss": 2.5664,
      "step": 1806
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001976493927171525,
      "loss": 2.3008,
      "step": 1807
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019764563906651323,
      "loss": 2.6211,
      "step": 1808
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019764188245689042,
      "loss": 2.457,
      "step": 1809
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.001976381228883978,
      "loss": 2.4531,
      "step": 1810
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019763436036114935,
      "loss": 2.4297,
      "step": 1811
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00197630594875259,
      "loss": 2.3789,
      "step": 1812
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00197626826430841,
      "loss": 2.3438,
      "step": 1813
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0019762305502800948,
      "loss": 2.5898,
      "step": 1814
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019761928066687868,
      "loss": 2.5273,
      "step": 1815
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00197615503347563,
      "loss": 2.4102,
      "step": 1816
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019761172307017696,
      "loss": 2.5664,
      "step": 1817
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019760793983483508,
      "loss": 2.418,
      "step": 1818
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00197604153641652,
      "loss": 2.4414,
      "step": 1819
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019760036449074244,
      "loss": 2.4453,
      "step": 1820
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019759657238222123,
      "loss": 2.5586,
      "step": 1821
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001975927773162033,
      "loss": 2.4727,
      "step": 1822
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019758897929280364,
      "loss": 2.3867,
      "step": 1823
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019758517831213736,
      "loss": 2.4453,
      "step": 1824
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001975813743743196,
      "loss": 2.4531,
      "step": 1825
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019757756747946567,
      "loss": 2.3672,
      "step": 1826
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001975737576276909,
      "loss": 2.4727,
      "step": 1827
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001975699448191108,
      "loss": 2.5352,
      "step": 1828
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019756612905384085,
      "loss": 2.3945,
      "step": 1829
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019756231033199673,
      "loss": 2.3125,
      "step": 1830
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019755848865369414,
      "loss": 2.3203,
      "step": 1831
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019755466401904886,
      "loss": 2.5352,
      "step": 1832
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001975508364281768,
      "loss": 2.6523,
      "step": 1833
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019754700588119397,
      "loss": 2.5664,
      "step": 1834
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019754317237821646,
      "loss": 2.5586,
      "step": 1835
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001975393359193604,
      "loss": 2.4961,
      "step": 1836
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019753549650474204,
      "loss": 2.6641,
      "step": 1837
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001975316541344778,
      "loss": 2.4375,
      "step": 1838
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00197527808808684,
      "loss": 2.332,
      "step": 1839
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019752396052747727,
      "loss": 2.4492,
      "step": 1840
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019752010929097417,
      "loss": 2.3711,
      "step": 1841
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001975162550992915,
      "loss": 2.4648,
      "step": 1842
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001975123979525459,
      "loss": 2.4531,
      "step": 1843
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019750853785085436,
      "loss": 2.2695,
      "step": 1844
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001975046747943338,
      "loss": 2.4805,
      "step": 1845
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019750080878310136,
      "loss": 2.4258,
      "step": 1846
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001974969398172741,
      "loss": 2.4648,
      "step": 1847
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001974930678969693,
      "loss": 2.6914,
      "step": 1848
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019748919302230434,
      "loss": 2.3867,
      "step": 1849
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019748531519339653,
      "loss": 2.4922,
      "step": 1850
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019748143441036354,
      "loss": 2.4688,
      "step": 1851
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001974775506733228,
      "loss": 2.6133,
      "step": 1852
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001974736639823921,
      "loss": 2.4531,
      "step": 1853
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001974697743376892,
      "loss": 2.3867,
      "step": 1854
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00197465881739332,
      "loss": 2.5469,
      "step": 1855
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001974619861874384,
      "loss": 2.5625,
      "step": 1856
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019745808768212646,
      "loss": 2.582,
      "step": 1857
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019745418622351438,
      "loss": 2.3906,
      "step": 1858
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001974502818117203,
      "loss": 2.5,
      "step": 1859
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019744637444686257,
      "loss": 2.582,
      "step": 1860
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019744246412905964,
      "loss": 2.4492,
      "step": 1861
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001974385508584299,
      "loss": 2.4766,
      "step": 1862
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019743463463509207,
      "loss": 2.4805,
      "step": 1863
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001974307154591647,
      "loss": 2.4062,
      "step": 1864
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019742679333076664,
      "loss": 2.4219,
      "step": 1865
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019742286825001672,
      "loss": 2.625,
      "step": 1866
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001974189402170339,
      "loss": 2.3398,
      "step": 1867
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019741500923193714,
      "loss": 2.5156,
      "step": 1868
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019741107529484565,
      "loss": 2.5703,
      "step": 1869
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019740713840587856,
      "loss": 2.4961,
      "step": 1870
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019740319856515524,
      "loss": 2.582,
      "step": 1871
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019739925577279506,
      "loss": 2.6602,
      "step": 1872
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019739531002891746,
      "loss": 2.4219,
      "step": 1873
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019739136133364206,
      "loss": 2.4102,
      "step": 1874
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001973874096870885,
      "loss": 2.5781,
      "step": 1875
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019738345508937653,
      "loss": 2.6055,
      "step": 1876
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019737949754062597,
      "loss": 2.4297,
      "step": 1877
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001973755370409568,
      "loss": 2.3828,
      "step": 1878
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019737157359048896,
      "loss": 2.3008,
      "step": 1879
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001973676071893426,
      "loss": 2.6367,
      "step": 1880
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001973636378376379,
      "loss": 2.6641,
      "step": 1881
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019735966553549515,
      "loss": 2.5234,
      "step": 1882
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019735569028303474,
      "loss": 2.5312,
      "step": 1883
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019735171208037712,
      "loss": 2.4297,
      "step": 1884
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019734773092764286,
      "loss": 2.6562,
      "step": 1885
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019734374682495257,
      "loss": 2.3555,
      "step": 1886
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00197339759772427,
      "loss": 2.3086,
      "step": 1887
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001973357697701869,
      "loss": 2.6562,
      "step": 1888
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019733177681835333,
      "loss": 2.3711,
      "step": 1889
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001973277809170472,
      "loss": 2.4062,
      "step": 1890
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001973237820663896,
      "loss": 2.4648,
      "step": 1891
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019731978026650164,
      "loss": 2.6094,
      "step": 1892
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019731577551750476,
      "loss": 2.5664,
      "step": 1893
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019731176781952017,
      "loss": 2.4922,
      "step": 1894
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019730775717266935,
      "loss": 2.5195,
      "step": 1895
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001973037435770739,
      "loss": 2.6055,
      "step": 1896
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019729972703285536,
      "loss": 2.4102,
      "step": 1897
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019729570754013544,
      "loss": 2.5352,
      "step": 1898
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019729168509903606,
      "loss": 2.6719,
      "step": 1899
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00197287659709679,
      "loss": 2.5273,
      "step": 1900
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001972836313721863,
      "loss": 2.4141,
      "step": 1901
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019727960008668,
      "loss": 2.5469,
      "step": 1902
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001972755658532823,
      "loss": 2.4336,
      "step": 1903
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019727152867211536,
      "loss": 2.4219,
      "step": 1904
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001972674885433016,
      "loss": 2.5039,
      "step": 1905
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.001972634454669635,
      "loss": 2.3906,
      "step": 1906
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0019725939944322344,
      "loss": 2.3242,
      "step": 1907
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019725535047220412,
      "loss": 2.4004,
      "step": 1908
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001972512985540282,
      "loss": 2.418,
      "step": 1909
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019724724368881848,
      "loss": 2.4531,
      "step": 1910
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019724318587669787,
      "loss": 2.3789,
      "step": 1911
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019723912511778927,
      "loss": 2.4844,
      "step": 1912
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019723506141221575,
      "loss": 2.4883,
      "step": 1913
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019723099476010053,
      "loss": 2.4688,
      "step": 1914
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019722692516156676,
      "loss": 2.2969,
      "step": 1915
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001972228526167378,
      "loss": 2.3633,
      "step": 1916
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.00197218777125737,
      "loss": 2.5117,
      "step": 1917
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019721469868868792,
      "loss": 2.3652,
      "step": 1918
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019721061730571415,
      "loss": 2.4492,
      "step": 1919
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001972065329769394,
      "loss": 2.3672,
      "step": 1920
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019720244570248734,
      "loss": 2.3008,
      "step": 1921
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001971983554824819,
      "loss": 2.5156,
      "step": 1922
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.00197194262317047,
      "loss": 2.4844,
      "step": 1923
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001971901662063067,
      "loss": 2.5586,
      "step": 1924
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001971860671503851,
      "loss": 2.5547,
      "step": 1925
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019718196514940645,
      "loss": 2.5312,
      "step": 1926
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019717786020349505,
      "loss": 2.2227,
      "step": 1927
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019717375231277524,
      "loss": 2.3164,
      "step": 1928
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001971696414773715,
      "loss": 2.4062,
      "step": 1929
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019716552769740853,
      "loss": 2.543,
      "step": 1930
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019716141097301083,
      "loss": 2.4609,
      "step": 1931
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019715729130430322,
      "loss": 2.4453,
      "step": 1932
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019715316869141058,
      "loss": 2.5391,
      "step": 1933
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001971490431344578,
      "loss": 2.3477,
      "step": 1934
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001971449146335699,
      "loss": 2.5234,
      "step": 1935
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019714078318887195,
      "loss": 2.4492,
      "step": 1936
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019713664880048917,
      "loss": 2.8398,
      "step": 1937
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001971325114685469,
      "loss": 2.3281,
      "step": 1938
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019712837119317045,
      "loss": 2.4219,
      "step": 1939
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001971242279744853,
      "loss": 2.5352,
      "step": 1940
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.00197120081812617,
      "loss": 2.5586,
      "step": 1941
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019711593270769125,
      "loss": 2.2188,
      "step": 1942
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001971117806598337,
      "loss": 2.5195,
      "step": 1943
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019710762566917017,
      "loss": 2.3477,
      "step": 1944
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019710346773582662,
      "loss": 2.4453,
      "step": 1945
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019709930685992906,
      "loss": 2.457,
      "step": 1946
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001970951430416035,
      "loss": 2.418,
      "step": 1947
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019709097628097623,
      "loss": 2.3438,
      "step": 1948
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001970868065781734,
      "loss": 2.5586,
      "step": 1949
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019708263393332145,
      "loss": 2.5586,
      "step": 1950
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001970784583465468,
      "loss": 2.7227,
      "step": 1951
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019707427981797594,
      "loss": 2.4258,
      "step": 1952
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019707009834773557,
      "loss": 2.2969,
      "step": 1953
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001970659139359523,
      "loss": 2.3047,
      "step": 1954
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019706172658275306,
      "loss": 2.3945,
      "step": 1955
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019705753628826467,
      "loss": 2.543,
      "step": 1956
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019705334305261412,
      "loss": 2.4805,
      "step": 1957
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019704914687592844,
      "loss": 2.3633,
      "step": 1958
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019704494775833483,
      "loss": 2.5,
      "step": 1959
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019704074569996052,
      "loss": 2.3945,
      "step": 1960
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019703654070093285,
      "loss": 2.3672,
      "step": 1961
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019703233276137933,
      "loss": 2.3281,
      "step": 1962
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001970281218814273,
      "loss": 2.4844,
      "step": 1963
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019702390806120447,
      "loss": 2.4922,
      "step": 1964
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019701969130083855,
      "loss": 2.7148,
      "step": 1965
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001970154716004573,
      "loss": 2.5977,
      "step": 1966
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019701124896018855,
      "loss": 2.4062,
      "step": 1967
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001970070233801603,
      "loss": 2.6758,
      "step": 1968
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019700279486050062,
      "loss": 2.5469,
      "step": 1969
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001969985634013376,
      "loss": 2.5742,
      "step": 1970
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001969943290027995,
      "loss": 2.4219,
      "step": 1971
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001969900916650146,
      "loss": 2.5508,
      "step": 1972
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019698585138811136,
      "loss": 2.4883,
      "step": 1973
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001969816081722182,
      "loss": 2.5586,
      "step": 1974
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001969773620174638,
      "loss": 2.3477,
      "step": 1975
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019697311292397675,
      "loss": 2.4453,
      "step": 1976
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019696886089188587,
      "loss": 2.5508,
      "step": 1977
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019696460592131993,
      "loss": 2.4414,
      "step": 1978
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019696034801240793,
      "loss": 2.4023,
      "step": 1979
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001969560871652789,
      "loss": 2.5938,
      "step": 1980
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.00196951823380062,
      "loss": 2.5625,
      "step": 1981
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001969475566568863,
      "loss": 2.5039,
      "step": 1982
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001969432869958812,
      "loss": 2.4688,
      "step": 1983
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019693901439717604,
      "loss": 2.4648,
      "step": 1984
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019693473886090037,
      "loss": 2.5117,
      "step": 1985
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001969304603871837,
      "loss": 2.5156,
      "step": 1986
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019692617897615564,
      "loss": 2.5859,
      "step": 1987
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.00196921894627946,
      "loss": 2.4141,
      "step": 1988
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001969176073426846,
      "loss": 2.4414,
      "step": 1989
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001969133171205013,
      "loss": 2.4219,
      "step": 1990
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001969090239615262,
      "loss": 2.5273,
      "step": 1991
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001969047278658893,
      "loss": 2.5586,
      "step": 1992
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001969004288337208,
      "loss": 2.2676,
      "step": 1993
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001968961268651511,
      "loss": 2.6016,
      "step": 1994
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001968918219603104,
      "loss": 2.5781,
      "step": 1995
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001968875141193293,
      "loss": 2.3164,
      "step": 1996
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001968832033423382,
      "loss": 2.4297,
      "step": 1997
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001968788896294678,
      "loss": 2.2539,
      "step": 1998
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.001968745729808488,
      "loss": 2.3008,
      "step": 1999
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0019687025339661206,
      "loss": 2.668,
      "step": 2000
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019686593087688844,
      "loss": 2.3652,
      "step": 2001
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001968616054218089,
      "loss": 2.4805,
      "step": 2002
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001968572770315046,
      "loss": 2.4023,
      "step": 2003
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001968529457061066,
      "loss": 2.4766,
      "step": 2004
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019684861144574624,
      "loss": 2.5664,
      "step": 2005
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001968442742505548,
      "loss": 2.5586,
      "step": 2006
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001968399341206637,
      "loss": 2.5273,
      "step": 2007
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019683559105620452,
      "loss": 2.5469,
      "step": 2008
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019683124505730887,
      "loss": 2.4766,
      "step": 2009
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001968268961241084,
      "loss": 2.3359,
      "step": 2010
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001968225442567349,
      "loss": 2.5273,
      "step": 2011
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001968181894553203,
      "loss": 2.5547,
      "step": 2012
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019681383171999654,
      "loss": 2.625,
      "step": 2013
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019680947105089565,
      "loss": 2.3711,
      "step": 2014
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001968051074481498,
      "loss": 2.4297,
      "step": 2015
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001968007409118912,
      "loss": 2.5781,
      "step": 2016
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019679637144225212,
      "loss": 2.2891,
      "step": 2017
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001967919990393651,
      "loss": 2.4453,
      "step": 2018
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019678762370336253,
      "loss": 2.5195,
      "step": 2019
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.00196783245434377,
      "loss": 2.4844,
      "step": 2020
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001967788642325413,
      "loss": 2.5508,
      "step": 2021
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001967744800979881,
      "loss": 2.4922,
      "step": 2022
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001967700930308502,
      "loss": 2.5273,
      "step": 2023
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001967657030312607,
      "loss": 2.375,
      "step": 2024
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019676131009935247,
      "loss": 2.4961,
      "step": 2025
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019675691423525874,
      "loss": 2.5586,
      "step": 2026
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019675251543911265,
      "loss": 2.4609,
      "step": 2027
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019674811371104754,
      "loss": 2.5664,
      "step": 2028
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001967437090511968,
      "loss": 2.3047,
      "step": 2029
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019673930145969387,
      "loss": 2.4219,
      "step": 2030
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019673489093667237,
      "loss": 2.5,
      "step": 2031
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019673047748226587,
      "loss": 2.4961,
      "step": 2032
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001967260610966082,
      "loss": 2.4297,
      "step": 2033
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019672164177983315,
      "loss": 2.5273,
      "step": 2034
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019671721953207462,
      "loss": 2.4609,
      "step": 2035
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019671279435346666,
      "loss": 2.4609,
      "step": 2036
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019670836624414334,
      "loss": 2.4336,
      "step": 2037
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019670393520423886,
      "loss": 2.4961,
      "step": 2038
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019669950123388747,
      "loss": 2.4258,
      "step": 2039
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001966950643332236,
      "loss": 2.5195,
      "step": 2040
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001966906245023816,
      "loss": 2.2227,
      "step": 2041
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019668618174149607,
      "loss": 2.3555,
      "step": 2042
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019668173605070166,
      "loss": 2.2188,
      "step": 2043
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001966772874301331,
      "loss": 2.4258,
      "step": 2044
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001966728358799251,
      "loss": 2.4727,
      "step": 2045
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019666838140021264,
      "loss": 2.4688,
      "step": 2046
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001966639239911307,
      "loss": 2.6328,
      "step": 2047
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019665946365281435,
      "loss": 2.3672,
      "step": 2048
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001966550003853987,
      "loss": 2.3359,
      "step": 2049
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001966505341890191,
      "loss": 2.5352,
      "step": 2050
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001966460650638108,
      "loss": 2.4336,
      "step": 2051
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001966415930099093,
      "loss": 2.5156,
      "step": 2052
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019663711802745004,
      "loss": 2.6172,
      "step": 2053
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019663264011656866,
      "loss": 2.543,
      "step": 2054
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001966281592774009,
      "loss": 2.5664,
      "step": 2055
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001966236755100825,
      "loss": 2.3945,
      "step": 2056
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019661918881474934,
      "loss": 2.5469,
      "step": 2057
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001966146991915374,
      "loss": 2.5742,
      "step": 2058
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001966102066405827,
      "loss": 2.4258,
      "step": 2059
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019660571116202137,
      "loss": 2.3535,
      "step": 2060
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001966012127559897,
      "loss": 2.6875,
      "step": 2061
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001965967114226239,
      "loss": 2.4336,
      "step": 2062
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001965922071620605,
      "loss": 2.5859,
      "step": 2063
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019658769997443594,
      "loss": 2.4414,
      "step": 2064
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001965831898598868,
      "loss": 2.2617,
      "step": 2065
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001965786768185497,
      "loss": 2.4805,
      "step": 2066
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019657416085056153,
      "loss": 2.3672,
      "step": 2067
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.00196569641956059,
      "loss": 2.582,
      "step": 2068
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019656512013517913,
      "loss": 2.3594,
      "step": 2069
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019656059538805887,
      "loss": 2.4375,
      "step": 2070
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019655606771483546,
      "loss": 2.4883,
      "step": 2071
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.00196551537115646,
      "loss": 2.5391,
      "step": 2072
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001965470035906278,
      "loss": 2.6094,
      "step": 2073
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019654246713991827,
      "loss": 2.5508,
      "step": 2074
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019653792776365485,
      "loss": 2.5195,
      "step": 2075
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019653338546197514,
      "loss": 2.4727,
      "step": 2076
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001965288402350167,
      "loss": 2.6016,
      "step": 2077
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019652429208291736,
      "loss": 2.7031,
      "step": 2078
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001965197410058149,
      "loss": 2.4219,
      "step": 2079
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019651518700384723,
      "loss": 2.4453,
      "step": 2080
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001965106300771524,
      "loss": 2.4805,
      "step": 2081
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019650607022586837,
      "loss": 2.5117,
      "step": 2082
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001965015074501335,
      "loss": 2.4961,
      "step": 2083
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019649694175008594,
      "loss": 2.6523,
      "step": 2084
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019649237312586404,
      "loss": 2.5469,
      "step": 2085
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001964878015776063,
      "loss": 2.5938,
      "step": 2086
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019648322710545123,
      "loss": 2.6094,
      "step": 2087
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019647864970953745,
      "loss": 2.5234,
      "step": 2088
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019647406939000364,
      "loss": 2.5273,
      "step": 2089
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019646948614698866,
      "loss": 2.5117,
      "step": 2090
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0019646489998063135,
      "loss": 2.4336,
      "step": 2091
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001964603108910707,
      "loss": 2.5312,
      "step": 2092
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.001964557188784458,
      "loss": 2.4414,
      "step": 2093
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019645112394289575,
      "loss": 2.1719,
      "step": 2094
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019644652608455985,
      "loss": 2.3594,
      "step": 2095
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001964419253035774,
      "loss": 2.5938,
      "step": 2096
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001964373216000878,
      "loss": 2.5547,
      "step": 2097
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019643271497423054,
      "loss": 2.3203,
      "step": 2098
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019642810542614534,
      "loss": 2.5898,
      "step": 2099
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019642349295597174,
      "loss": 2.3906,
      "step": 2100
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001964188775638496,
      "loss": 2.6406,
      "step": 2101
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001964142592499187,
      "loss": 2.3828,
      "step": 2102
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001964096380143191,
      "loss": 2.4375,
      "step": 2103
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019640501385719076,
      "loss": 2.4375,
      "step": 2104
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019640038677867385,
      "loss": 2.582,
      "step": 2105
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019639575677890854,
      "loss": 2.4297,
      "step": 2106
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019639112385803513,
      "loss": 2.4531,
      "step": 2107
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001963864880161941,
      "loss": 2.6133,
      "step": 2108
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019638184925352587,
      "loss": 2.418,
      "step": 2109
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019637720757017096,
      "loss": 2.4375,
      "step": 2110
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019637256296627013,
      "loss": 2.4961,
      "step": 2111
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00196367915441964,
      "loss": 2.3477,
      "step": 2112
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019636326499739357,
      "loss": 2.5586,
      "step": 2113
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019635861163269965,
      "loss": 2.5312,
      "step": 2114
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019635395534802324,
      "loss": 2.4961,
      "step": 2115
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001963492961435055,
      "loss": 2.5234,
      "step": 2116
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001963446340192876,
      "loss": 2.5039,
      "step": 2117
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019633996897551083,
      "loss": 2.5312,
      "step": 2118
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001963353010123165,
      "loss": 2.4805,
      "step": 2119
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019633063012984616,
      "loss": 2.293,
      "step": 2120
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019632595632824127,
      "loss": 2.4102,
      "step": 2121
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001963212796076435,
      "loss": 2.2207,
      "step": 2122
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001963165999681946,
      "loss": 2.2695,
      "step": 2123
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019631191741003623,
      "loss": 2.5,
      "step": 2124
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001963072319333105,
      "loss": 2.5977,
      "step": 2125
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019630254353815925,
      "loss": 2.4883,
      "step": 2126
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001962978522247246,
      "loss": 2.2402,
      "step": 2127
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001962931579931487,
      "loss": 2.4258,
      "step": 2128
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019628846084357382,
      "loss": 2.4531,
      "step": 2129
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019628376077614226,
      "loss": 2.5,
      "step": 2130
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019627905779099654,
      "loss": 2.5117,
      "step": 2131
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019627435188827903,
      "loss": 2.293,
      "step": 2132
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019626964306813247,
      "loss": 2.3848,
      "step": 2133
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001962649313306995,
      "loss": 2.6289,
      "step": 2134
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019626021667612284,
      "loss": 2.25,
      "step": 2135
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019625549910454545,
      "loss": 2.3594,
      "step": 2136
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001962507786161103,
      "loss": 2.3438,
      "step": 2137
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019624605521096033,
      "loss": 2.6328,
      "step": 2138
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019624132888923875,
      "loss": 2.3594,
      "step": 2139
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001962365996510888,
      "loss": 2.582,
      "step": 2140
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019623186749665377,
      "loss": 2.5352,
      "step": 2141
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00196227132426077,
      "loss": 2.4258,
      "step": 2142
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001962223944395021,
      "loss": 2.4727,
      "step": 2143
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001962176535370725,
      "loss": 2.4648,
      "step": 2144
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00196212909718932,
      "loss": 2.6406,
      "step": 2145
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019620816298522425,
      "loss": 2.5039,
      "step": 2146
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019620341333609313,
      "loss": 2.6211,
      "step": 2147
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001961986607716826,
      "loss": 2.3906,
      "step": 2148
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019619390529213667,
      "loss": 2.4336,
      "step": 2149
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019618914689759942,
      "loss": 2.457,
      "step": 2150
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019618438558821503,
      "loss": 2.5312,
      "step": 2151
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019617962136412783,
      "loss": 2.5352,
      "step": 2152
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019617485422548215,
      "loss": 2.4492,
      "step": 2153
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001961700841724225,
      "loss": 2.6836,
      "step": 2154
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001961653112050934,
      "loss": 2.6719,
      "step": 2155
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001961605353236395,
      "loss": 2.4727,
      "step": 2156
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019615575652820547,
      "loss": 2.4688,
      "step": 2157
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019615097481893618,
      "loss": 2.3438,
      "step": 2158
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001961461901959765,
      "loss": 2.3164,
      "step": 2159
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019614140265947146,
      "loss": 2.4531,
      "step": 2160
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019613661220956612,
      "loss": 2.3203,
      "step": 2161
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001961318188464056,
      "loss": 2.6328,
      "step": 2162
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019612702257013523,
      "loss": 2.4219,
      "step": 2163
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019612222338090033,
      "loss": 2.4297,
      "step": 2164
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019611742127884626,
      "loss": 2.3359,
      "step": 2165
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019611261626411866,
      "loss": 2.3281,
      "step": 2166
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019610780833686304,
      "loss": 2.5078,
      "step": 2167
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019610299749722514,
      "loss": 2.5391,
      "step": 2168
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019609818374535072,
      "loss": 2.4336,
      "step": 2169
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001960933670813857,
      "loss": 2.457,
      "step": 2170
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019608854750547597,
      "loss": 2.6406,
      "step": 2171
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019608372501776767,
      "loss": 2.4961,
      "step": 2172
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001960788996184068,
      "loss": 2.5898,
      "step": 2173
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019607407130753977,
      "loss": 2.4531,
      "step": 2174
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019606924008531276,
      "loss": 2.6328,
      "step": 2175
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019606440595187217,
      "loss": 2.5156,
      "step": 2176
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019605956890736457,
      "loss": 2.5352,
      "step": 2177
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019605472895193646,
      "loss": 2.4961,
      "step": 2178
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019604988608573457,
      "loss": 2.293,
      "step": 2179
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019604504030890564,
      "loss": 2.4648,
      "step": 2180
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019604019162159647,
      "loss": 2.4336,
      "step": 2181
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00196035340023954,
      "loss": 2.4082,
      "step": 2182
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001960304855161253,
      "loss": 2.3516,
      "step": 2183
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019602562809825745,
      "loss": 2.3203,
      "step": 2184
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.001960207677704976,
      "loss": 2.4336,
      "step": 2185
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0019601590453299316,
      "loss": 2.4219,
      "step": 2186
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019601103838589136,
      "loss": 2.3359,
      "step": 2187
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001960061693293397,
      "loss": 2.4961,
      "step": 2188
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019600129736348578,
      "loss": 2.3125,
      "step": 2189
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001959964224884772,
      "loss": 2.3789,
      "step": 2190
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001959915447044617,
      "loss": 2.5898,
      "step": 2191
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019598666401158702,
      "loss": 2.4219,
      "step": 2192
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019598178041000123,
      "loss": 2.5039,
      "step": 2193
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001959768938998521,
      "loss": 2.5117,
      "step": 2194
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001959720044812879,
      "loss": 2.4648,
      "step": 2195
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001959671121544567,
      "loss": 2.5,
      "step": 2196
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019596221691950675,
      "loss": 2.3828,
      "step": 2197
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001959573187765864,
      "loss": 2.582,
      "step": 2198
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019595241772584412,
      "loss": 2.3789,
      "step": 2199
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019594751376742835,
      "loss": 2.4492,
      "step": 2200
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001959426069014878,
      "loss": 2.5938,
      "step": 2201
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001959376971281711,
      "loss": 2.5117,
      "step": 2202
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00195932784447627,
      "loss": 2.5117,
      "step": 2203
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019592786886000442,
      "loss": 2.3672,
      "step": 2204
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019592295036545233,
      "loss": 2.5703,
      "step": 2205
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019591802896411978,
      "loss": 2.5156,
      "step": 2206
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019591310465615582,
      "loss": 2.3633,
      "step": 2207
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019590817744170974,
      "loss": 2.4219,
      "step": 2208
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001959032473209309,
      "loss": 2.3105,
      "step": 2209
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019589831429396858,
      "loss": 2.3359,
      "step": 2210
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019589337836097235,
      "loss": 2.4922,
      "step": 2211
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019588843952209178,
      "loss": 2.6797,
      "step": 2212
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019588349777747652,
      "loss": 2.5039,
      "step": 2213
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001958785531272763,
      "loss": 2.4023,
      "step": 2214
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019587360557164098,
      "loss": 2.3203,
      "step": 2215
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001958686551107205,
      "loss": 2.375,
      "step": 2216
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019586370174466483,
      "loss": 2.4883,
      "step": 2217
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001958587454736241,
      "loss": 2.2891,
      "step": 2218
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019585378629774853,
      "loss": 2.4453,
      "step": 2219
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019584882421718837,
      "loss": 2.375,
      "step": 2220
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00195843859232094,
      "loss": 2.3516,
      "step": 2221
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019583889134261586,
      "loss": 2.3633,
      "step": 2222
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001958339205489045,
      "loss": 2.3906,
      "step": 2223
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001958289468511105,
      "loss": 2.4922,
      "step": 2224
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001958239702493847,
      "loss": 2.4727,
      "step": 2225
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001958189907438778,
      "loss": 2.457,
      "step": 2226
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019581400833474072,
      "loss": 2.4531,
      "step": 2227
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019580902302212453,
      "loss": 2.5039,
      "step": 2228
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019580403480618015,
      "loss": 2.4336,
      "step": 2229
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001957990436870589,
      "loss": 2.457,
      "step": 2230
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019579404966491186,
      "loss": 2.6016,
      "step": 2231
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001957890527398905,
      "loss": 2.6172,
      "step": 2232
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019578405291214617,
      "loss": 2.4609,
      "step": 2233
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019577905018183044,
      "loss": 2.5586,
      "step": 2234
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019577404454909483,
      "loss": 2.3789,
      "step": 2235
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001957690360140911,
      "loss": 2.3242,
      "step": 2236
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019576402457697093,
      "loss": 2.2266,
      "step": 2237
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019575901023788636,
      "loss": 2.543,
      "step": 2238
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019575399299698914,
      "loss": 2.3867,
      "step": 2239
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019574897285443145,
      "loss": 2.3984,
      "step": 2240
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001957439498103653,
      "loss": 2.5352,
      "step": 2241
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019573892386494304,
      "loss": 2.4922,
      "step": 2242
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019573389501831686,
      "loss": 2.4766,
      "step": 2243
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019572886327063922,
      "loss": 2.457,
      "step": 2244
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001957238286220626,
      "loss": 2.3906,
      "step": 2245
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019571879107273945,
      "loss": 2.625,
      "step": 2246
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001957137506228226,
      "loss": 2.4648,
      "step": 2247
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019570870727246463,
      "loss": 2.4844,
      "step": 2248
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001957036610218185,
      "loss": 2.4961,
      "step": 2249
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019569861187103705,
      "loss": 2.3633,
      "step": 2250
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019569355982027334,
      "loss": 2.5117,
      "step": 2251
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019568850486968038,
      "loss": 2.4844,
      "step": 2252
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019568344701941143,
      "loss": 2.3867,
      "step": 2253
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001956783862696197,
      "loss": 2.2852,
      "step": 2254
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019567332262045863,
      "loss": 2.4688,
      "step": 2255
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001956682560720816,
      "loss": 2.6172,
      "step": 2256
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019566318662464217,
      "loss": 2.4688,
      "step": 2257
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019565811427829393,
      "loss": 2.5625,
      "step": 2258
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019565303903319063,
      "loss": 2.3164,
      "step": 2259
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00195647960889486,
      "loss": 2.3594,
      "step": 2260
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00195642879847334,
      "loss": 2.457,
      "step": 2261
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001956377959068886,
      "loss": 2.4492,
      "step": 2262
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019563270906830382,
      "loss": 2.4766,
      "step": 2263
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001956276193317338,
      "loss": 2.4531,
      "step": 2264
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019562252669733282,
      "loss": 2.3125,
      "step": 2265
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019561743116525516,
      "loss": 2.5781,
      "step": 2266
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019561233273565526,
      "loss": 2.5273,
      "step": 2267
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001956072314086876,
      "loss": 2.4102,
      "step": 2268
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001956021271845068,
      "loss": 2.3672,
      "step": 2269
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019559702006326746,
      "loss": 2.4375,
      "step": 2270
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001955919100451244,
      "loss": 2.5781,
      "step": 2271
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001955867971302325,
      "loss": 2.2012,
      "step": 2272
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019558168131874666,
      "loss": 2.625,
      "step": 2273
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001955765626108219,
      "loss": 2.3359,
      "step": 2274
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019557144100661333,
      "loss": 2.3926,
      "step": 2275
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001955663165062762,
      "loss": 2.3438,
      "step": 2276
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001955611891099657,
      "loss": 2.7188,
      "step": 2277
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019555605881783735,
      "loss": 2.6523,
      "step": 2278
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0019555092563004646,
      "loss": 2.4258,
      "step": 2279
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001955457895467487,
      "loss": 2.4414,
      "step": 2280
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019554065056809965,
      "loss": 2.4023,
      "step": 2281
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019553550869425506,
      "loss": 2.3711,
      "step": 2282
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019553036392537075,
      "loss": 2.6328,
      "step": 2283
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001955252162616026,
      "loss": 2.418,
      "step": 2284
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001955200657031066,
      "loss": 2.4727,
      "step": 2285
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001955149122500389,
      "loss": 2.4922,
      "step": 2286
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019550975590255557,
      "loss": 2.3555,
      "step": 2287
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001955045966608129,
      "loss": 2.5312,
      "step": 2288
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019549943452496724,
      "loss": 2.5039,
      "step": 2289
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019549426949517505,
      "loss": 2.5781,
      "step": 2290
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019548910157159275,
      "loss": 2.3672,
      "step": 2291
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019548393075437707,
      "loss": 2.5273,
      "step": 2292
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001954787570436846,
      "loss": 2.5078,
      "step": 2293
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001954735804396722,
      "loss": 2.5273,
      "step": 2294
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001954684009424967,
      "loss": 2.5625,
      "step": 2295
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019546321855231498,
      "loss": 2.4961,
      "step": 2296
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019545803326928425,
      "loss": 2.3867,
      "step": 2297
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001954528450935615,
      "loss": 2.418,
      "step": 2298
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019544765402530404,
      "loss": 2.3047,
      "step": 2299
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001954424600646691,
      "loss": 2.3984,
      "step": 2300
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001954372632118141,
      "loss": 2.5117,
      "step": 2301
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019543206346689657,
      "loss": 2.5625,
      "step": 2302
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00195426860830074,
      "loss": 2.4609,
      "step": 2303
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019542165530150413,
      "loss": 2.4141,
      "step": 2304
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019541644688134464,
      "loss": 2.4219,
      "step": 2305
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001954112355697534,
      "loss": 2.5,
      "step": 2306
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019540602136688826,
      "loss": 2.3281,
      "step": 2307
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019540080427290735,
      "loss": 2.4141,
      "step": 2308
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019539558428796865,
      "loss": 2.4492,
      "step": 2309
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001953903614122304,
      "loss": 2.3633,
      "step": 2310
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001953851356458509,
      "loss": 2.4609,
      "step": 2311
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019537990698898842,
      "loss": 2.4141,
      "step": 2312
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001953746754418015,
      "loss": 2.4805,
      "step": 2313
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001953694410044486,
      "loss": 2.5078,
      "step": 2314
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019536420367708834,
      "loss": 2.4062,
      "step": 2315
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001953589634598795,
      "loss": 2.5352,
      "step": 2316
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001953537203529808,
      "loss": 2.3711,
      "step": 2317
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001953484743565512,
      "loss": 2.4453,
      "step": 2318
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019534322547074953,
      "loss": 2.5898,
      "step": 2319
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00195337973695735,
      "loss": 2.6016,
      "step": 2320
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019533271903166673,
      "loss": 2.3438,
      "step": 2321
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001953274614787039,
      "loss": 2.582,
      "step": 2322
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019532220103700582,
      "loss": 2.3281,
      "step": 2323
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00195316937706732,
      "loss": 2.4922,
      "step": 2324
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019531167148804185,
      "loss": 2.5703,
      "step": 2325
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019530640238109495,
      "loss": 2.6875,
      "step": 2326
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019530113038605103,
      "loss": 2.5508,
      "step": 2327
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019529585550306977,
      "loss": 2.4961,
      "step": 2328
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019529057773231106,
      "loss": 2.293,
      "step": 2329
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019528529707393484,
      "loss": 2.4688,
      "step": 2330
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019528001352810116,
      "loss": 2.418,
      "step": 2331
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019527472709497005,
      "loss": 2.5625,
      "step": 2332
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001952694377747018,
      "loss": 2.2734,
      "step": 2333
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001952641455674566,
      "loss": 2.4141,
      "step": 2334
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019525885047339488,
      "loss": 2.3555,
      "step": 2335
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019525355249267707,
      "loss": 2.3945,
      "step": 2336
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001952482516254637,
      "loss": 2.4961,
      "step": 2337
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001952429478719155,
      "loss": 2.5312,
      "step": 2338
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001952376412321931,
      "loss": 2.4531,
      "step": 2339
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019523233170645733,
      "loss": 2.5352,
      "step": 2340
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019522701929486908,
      "loss": 2.5273,
      "step": 2341
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019522170399758937,
      "loss": 2.4102,
      "step": 2342
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001952163858147792,
      "loss": 2.582,
      "step": 2343
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019521106474659979,
      "loss": 2.3398,
      "step": 2344
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019520574079321242,
      "loss": 2.4453,
      "step": 2345
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019520041395477833,
      "loss": 2.5938,
      "step": 2346
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019519508423145894,
      "loss": 2.293,
      "step": 2347
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019518975162341585,
      "loss": 2.418,
      "step": 2348
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019518441613081059,
      "loss": 2.7305,
      "step": 2349
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019517907775380486,
      "loss": 2.5234,
      "step": 2350
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019517373649256045,
      "loss": 2.4883,
      "step": 2351
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019516839234723917,
      "loss": 2.332,
      "step": 2352
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019516304531800302,
      "loss": 2.6016,
      "step": 2353
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019515769540501397,
      "loss": 2.4297,
      "step": 2354
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001951523426084342,
      "loss": 2.3242,
      "step": 2355
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019514698692842587,
      "loss": 2.5469,
      "step": 2356
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001951416283651513,
      "loss": 2.5625,
      "step": 2357
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019513626691877288,
      "loss": 2.4414,
      "step": 2358
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019513090258945307,
      "loss": 2.4453,
      "step": 2359
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001951255353773544,
      "loss": 2.4609,
      "step": 2360
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019512016528263959,
      "loss": 2.4492,
      "step": 2361
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019511479230547126,
      "loss": 2.3945,
      "step": 2362
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019510941644601233,
      "loss": 2.4453,
      "step": 2363
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019510403770442565,
      "loss": 2.3164,
      "step": 2364
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019509865608087424,
      "loss": 2.4844,
      "step": 2365
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019509327157552115,
      "loss": 2.375,
      "step": 2366
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019508788418852957,
      "loss": 2.4062,
      "step": 2367
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019508249392006277,
      "loss": 2.2383,
      "step": 2368
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019507710077028408,
      "loss": 2.3672,
      "step": 2369
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001950717047393569,
      "loss": 2.5273,
      "step": 2370
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.001950663058274448,
      "loss": 2.5195,
      "step": 2371
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0019506090403471133,
      "loss": 2.1973,
      "step": 2372
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019505549936132023,
      "loss": 2.4062,
      "step": 2373
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019505009180743524,
      "loss": 2.4141,
      "step": 2374
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001950446813732203,
      "loss": 2.4727,
      "step": 2375
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019503926805883927,
      "loss": 2.3594,
      "step": 2376
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019503385186445624,
      "loss": 2.5078,
      "step": 2377
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019502843279023533,
      "loss": 2.5352,
      "step": 2378
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019502301083634075,
      "loss": 2.6719,
      "step": 2379
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001950175860029368,
      "loss": 2.5039,
      "step": 2380
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001950121582901879,
      "loss": 2.3945,
      "step": 2381
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019500672769825849,
      "loss": 2.4531,
      "step": 2382
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019500129422731316,
      "loss": 2.5195,
      "step": 2383
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019499585787751657,
      "loss": 2.5781,
      "step": 2384
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019499041864903342,
      "loss": 2.457,
      "step": 2385
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019498497654202858,
      "loss": 2.625,
      "step": 2386
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019497953155666692,
      "loss": 2.4805,
      "step": 2387
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019497408369311348,
      "loss": 2.5078,
      "step": 2388
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019496863295153332,
      "loss": 2.5195,
      "step": 2389
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019496317933209162,
      "loss": 2.4453,
      "step": 2390
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019495772283495368,
      "loss": 2.5703,
      "step": 2391
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019495226346028481,
      "loss": 2.3926,
      "step": 2392
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019494680120825043,
      "loss": 2.4688,
      "step": 2393
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001949413360790161,
      "loss": 2.5352,
      "step": 2394
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019493586807274746,
      "loss": 2.707,
      "step": 2395
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019493039718961015,
      "loss": 2.2637,
      "step": 2396
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019492492342976996,
      "loss": 2.5508,
      "step": 2397
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001949194467933928,
      "loss": 2.3906,
      "step": 2398
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001949139672806446,
      "loss": 2.3203,
      "step": 2399
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019490848489169144,
      "loss": 2.668,
      "step": 2400
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019490299962669942,
      "loss": 2.4453,
      "step": 2401
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019489751148583476,
      "loss": 2.6094,
      "step": 2402
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019489202046926377,
      "loss": 2.5234,
      "step": 2403
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019488652657715288,
      "loss": 2.5195,
      "step": 2404
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019488102980966856,
      "loss": 2.5117,
      "step": 2405
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019487553016697735,
      "loss": 2.7617,
      "step": 2406
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019487002764924594,
      "loss": 2.8086,
      "step": 2407
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019486452225664103,
      "loss": 2.3125,
      "step": 2408
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019485901398932953,
      "loss": 2.5078,
      "step": 2409
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001948535028474783,
      "loss": 2.4492,
      "step": 2410
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019484798883125435,
      "loss": 2.4844,
      "step": 2411
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019484247194082478,
      "loss": 2.4492,
      "step": 2412
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019483695217635676,
      "loss": 2.5469,
      "step": 2413
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019483142953801759,
      "loss": 2.418,
      "step": 2414
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019482590402597458,
      "loss": 2.6211,
      "step": 2415
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019482037564039522,
      "loss": 2.2578,
      "step": 2416
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019481484438144698,
      "loss": 2.5039,
      "step": 2417
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019480931024929752,
      "loss": 2.3008,
      "step": 2418
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019480377324411454,
      "loss": 2.4258,
      "step": 2419
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001947982333660658,
      "loss": 2.3164,
      "step": 2420
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019479269061531922,
      "loss": 2.3809,
      "step": 2421
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001947871449920427,
      "loss": 2.5547,
      "step": 2422
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019478159649640437,
      "loss": 2.3613,
      "step": 2423
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001947760451285723,
      "loss": 2.5117,
      "step": 2424
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019477049088871474,
      "loss": 2.4492,
      "step": 2425
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019476493377700002,
      "loss": 2.3281,
      "step": 2426
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019475937379359652,
      "loss": 2.4922,
      "step": 2427
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001947538109386727,
      "loss": 2.4766,
      "step": 2428
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001947482452123972,
      "loss": 2.3828,
      "step": 2429
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019474267661493863,
      "loss": 2.2422,
      "step": 2430
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019473710514646574,
      "loss": 2.3125,
      "step": 2431
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019473153080714735,
      "loss": 2.4453,
      "step": 2432
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019472595359715243,
      "loss": 2.4141,
      "step": 2433
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019472037351664995,
      "loss": 2.4453,
      "step": 2434
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019471479056580902,
      "loss": 2.4766,
      "step": 2435
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019470920474479881,
      "loss": 2.3359,
      "step": 2436
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019470361605378858,
      "loss": 2.4688,
      "step": 2437
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019469802449294774,
      "loss": 2.5742,
      "step": 2438
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019469243006244566,
      "loss": 2.5195,
      "step": 2439
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001946868327624519,
      "loss": 2.3867,
      "step": 2440
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019468123259313611,
      "loss": 2.5195,
      "step": 2441
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019467562955466794,
      "loss": 2.4766,
      "step": 2442
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001946700236472172,
      "loss": 2.3555,
      "step": 2443
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019466441487095377,
      "loss": 2.7109,
      "step": 2444
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019465880322604764,
      "loss": 2.5547,
      "step": 2445
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001946531887126688,
      "loss": 2.3945,
      "step": 2446
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019464757133098743,
      "loss": 2.5586,
      "step": 2447
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019464195108117378,
      "loss": 2.4102,
      "step": 2448
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019463632796339811,
      "loss": 2.5078,
      "step": 2449
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019463070197783083,
      "loss": 2.3398,
      "step": 2450
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019462507312464244,
      "loss": 2.4531,
      "step": 2451
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019461944140400354,
      "loss": 2.3945,
      "step": 2452
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019461380681608472,
      "loss": 2.4531,
      "step": 2453
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001946081693610568,
      "loss": 2.4961,
      "step": 2454
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019460252903909054,
      "loss": 2.3945,
      "step": 2455
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019459688585035694,
      "loss": 2.582,
      "step": 2456
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019459123979502693,
      "loss": 2.582,
      "step": 2457
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019458559087327165,
      "loss": 2.3789,
      "step": 2458
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019457993908526228,
      "loss": 2.4688,
      "step": 2459
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019457428443117007,
      "loss": 2.543,
      "step": 2460
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001945686269111664,
      "loss": 2.4844,
      "step": 2461
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019456296652542266,
      "loss": 2.4531,
      "step": 2462
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019455730327411045,
      "loss": 2.2617,
      "step": 2463
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019455163715740133,
      "loss": 2.4727,
      "step": 2464
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0019454596817546702,
      "loss": 2.4062,
      "step": 2465
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019454029632847934,
      "loss": 2.7461,
      "step": 2466
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019453462161661008,
      "loss": 2.5586,
      "step": 2467
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001945289440400313,
      "loss": 2.3457,
      "step": 2468
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019452326359891497,
      "loss": 2.4062,
      "step": 2469
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001945175802934333,
      "loss": 2.3281,
      "step": 2470
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019451189412375844,
      "loss": 2.5781,
      "step": 2471
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019450620509006277,
      "loss": 2.4023,
      "step": 2472
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001945005131925186,
      "loss": 2.5039,
      "step": 2473
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001944948184312985,
      "loss": 2.5547,
      "step": 2474
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019448912080657502,
      "loss": 2.582,
      "step": 2475
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019448342031852077,
      "loss": 2.3164,
      "step": 2476
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019447771696730854,
      "loss": 2.2891,
      "step": 2477
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019447201075311114,
      "loss": 2.5664,
      "step": 2478
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019446630167610148,
      "loss": 2.5781,
      "step": 2479
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001944605897364526,
      "loss": 2.4531,
      "step": 2480
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019445487493433755,
      "loss": 2.3906,
      "step": 2481
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019444915726992953,
      "loss": 2.3828,
      "step": 2482
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019444343674340178,
      "loss": 2.3828,
      "step": 2483
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019443771335492768,
      "loss": 2.2695,
      "step": 2484
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019443198710468066,
      "loss": 2.3789,
      "step": 2485
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019442625799283425,
      "loss": 2.3477,
      "step": 2486
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00194420526019562,
      "loss": 2.5938,
      "step": 2487
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019441479118503771,
      "loss": 2.7188,
      "step": 2488
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019440905348943511,
      "loss": 2.5078,
      "step": 2489
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019440331293292805,
      "loss": 2.4375,
      "step": 2490
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019439756951569053,
      "loss": 2.3945,
      "step": 2491
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019439182323789655,
      "loss": 2.1367,
      "step": 2492
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001943860740997203,
      "loss": 2.457,
      "step": 2493
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019438032210133593,
      "loss": 2.3906,
      "step": 2494
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001943745672429178,
      "loss": 2.5469,
      "step": 2495
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019436880952464028,
      "loss": 2.3789,
      "step": 2496
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019436304894667785,
      "loss": 2.4648,
      "step": 2497
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019435728550920505,
      "loss": 2.4531,
      "step": 2498
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019435151921239659,
      "loss": 2.2578,
      "step": 2499
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019434575005642715,
      "loss": 2.5938,
      "step": 2500
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019433997804147159,
      "loss": 2.4395,
      "step": 2501
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019433420316770477,
      "loss": 2.5859,
      "step": 2502
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019432842543530176,
      "loss": 2.5352,
      "step": 2503
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001943226448444376,
      "loss": 2.4141,
      "step": 2504
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019431686139528745,
      "loss": 2.4688,
      "step": 2505
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001943110750880266,
      "loss": 2.6484,
      "step": 2506
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001943052859228304,
      "loss": 2.6562,
      "step": 2507
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019429949389987424,
      "loss": 2.3945,
      "step": 2508
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019429369901933368,
      "loss": 2.418,
      "step": 2509
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019428790128138427,
      "loss": 2.4102,
      "step": 2510
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019428210068620176,
      "loss": 2.6289,
      "step": 2511
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019427629723396188,
      "loss": 2.3789,
      "step": 2512
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019427049092484053,
      "loss": 2.4336,
      "step": 2513
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019426468175901363,
      "loss": 2.3086,
      "step": 2514
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019425886973665726,
      "loss": 2.5195,
      "step": 2515
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019425305485794749,
      "loss": 2.4648,
      "step": 2516
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019424723712306053,
      "loss": 2.418,
      "step": 2517
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019424141653217276,
      "loss": 2.4414,
      "step": 2518
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019423559308546045,
      "loss": 2.4453,
      "step": 2519
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019422976678310016,
      "loss": 2.3828,
      "step": 2520
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001942239376252684,
      "loss": 2.2188,
      "step": 2521
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019421810561214181,
      "loss": 2.5234,
      "step": 2522
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019421227074389715,
      "loss": 2.2539,
      "step": 2523
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019420643302071122,
      "loss": 2.6133,
      "step": 2524
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001942005924427609,
      "loss": 2.5195,
      "step": 2525
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001941947490102232,
      "loss": 2.4062,
      "step": 2526
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019418890272327519,
      "loss": 2.6016,
      "step": 2527
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019418305358209404,
      "loss": 2.2969,
      "step": 2528
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019417720158685702,
      "loss": 2.5312,
      "step": 2529
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019417134673774142,
      "loss": 2.4023,
      "step": 2530
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019416548903492465,
      "loss": 2.5,
      "step": 2531
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019415962847858426,
      "loss": 2.4297,
      "step": 2532
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019415376506889785,
      "loss": 2.4609,
      "step": 2533
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001941478988060431,
      "loss": 2.6172,
      "step": 2534
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001941420296901977,
      "loss": 2.5234,
      "step": 2535
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001941361577215396,
      "loss": 2.4453,
      "step": 2536
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001941302829002467,
      "loss": 2.4531,
      "step": 2537
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00194124405226497,
      "loss": 2.5742,
      "step": 2538
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019411852470046869,
      "loss": 2.4766,
      "step": 2539
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019411264132233987,
      "loss": 2.4844,
      "step": 2540
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001941067550922889,
      "loss": 2.5586,
      "step": 2541
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019410086601049413,
      "loss": 2.4766,
      "step": 2542
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00194094974077134,
      "loss": 2.543,
      "step": 2543
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019408907929238711,
      "loss": 2.5273,
      "step": 2544
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00194083181656432,
      "loss": 2.3047,
      "step": 2545
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019407728116944748,
      "loss": 2.3594,
      "step": 2546
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019407137783161229,
      "loss": 2.4062,
      "step": 2547
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019406547164310536,
      "loss": 2.5742,
      "step": 2548
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019405956260410565,
      "loss": 2.6328,
      "step": 2549
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019405365071479223,
      "loss": 2.4766,
      "step": 2550
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019404773597534424,
      "loss": 2.4492,
      "step": 2551
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019404181838594092,
      "loss": 2.6016,
      "step": 2552
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001940358979467616,
      "loss": 2.4102,
      "step": 2553
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019402997465798567,
      "loss": 2.4062,
      "step": 2554
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019402404851979265,
      "loss": 2.3242,
      "step": 2555
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019401811953236208,
      "loss": 2.6133,
      "step": 2556
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0019401218769587367,
      "loss": 2.6016,
      "step": 2557
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.001940062530105072,
      "loss": 2.4375,
      "step": 2558
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019400031547644244,
      "loss": 2.3438,
      "step": 2559
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019399437509385936,
      "loss": 2.4141,
      "step": 2560
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019398843186293794,
      "loss": 2.4961,
      "step": 2561
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001939824857838583,
      "loss": 2.2617,
      "step": 2562
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019397653685680064,
      "loss": 2.5117,
      "step": 2563
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019397058508194521,
      "loss": 2.5312,
      "step": 2564
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001939646304594724,
      "loss": 2.5234,
      "step": 2565
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001939586729895626,
      "loss": 2.5938,
      "step": 2566
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019395271267239637,
      "loss": 2.4531,
      "step": 2567
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019394674950815433,
      "loss": 2.5703,
      "step": 2568
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019394078349701722,
      "loss": 2.5859,
      "step": 2569
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019393481463916575,
      "loss": 2.4023,
      "step": 2570
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019392884293478088,
      "loss": 2.4023,
      "step": 2571
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019392286838404349,
      "loss": 2.4453,
      "step": 2572
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019391689098713467,
      "loss": 2.3086,
      "step": 2573
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019391091074423559,
      "loss": 2.3594,
      "step": 2574
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001939049276555274,
      "loss": 2.3203,
      "step": 2575
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019389894172119147,
      "loss": 2.5234,
      "step": 2576
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019389295294140916,
      "loss": 2.3867,
      "step": 2577
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019388696131636195,
      "loss": 2.4141,
      "step": 2578
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001938809668462314,
      "loss": 2.5859,
      "step": 2579
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019387496953119918,
      "loss": 2.4453,
      "step": 2580
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019386896937144704,
      "loss": 2.3203,
      "step": 2581
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019386296636715677,
      "loss": 2.3008,
      "step": 2582
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001938569605185103,
      "loss": 2.3516,
      "step": 2583
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019385095182568963,
      "loss": 2.4141,
      "step": 2584
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019384494028887682,
      "loss": 2.3477,
      "step": 2585
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019383892590825408,
      "loss": 2.2539,
      "step": 2586
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019383290868400362,
      "loss": 2.5586,
      "step": 2587
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001938268886163078,
      "loss": 2.3359,
      "step": 2588
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019382086570534907,
      "loss": 2.4141,
      "step": 2589
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001938148399513099,
      "loss": 2.3984,
      "step": 2590
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019380881135437297,
      "loss": 2.3203,
      "step": 2591
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019380277991472086,
      "loss": 2.543,
      "step": 2592
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019379674563253643,
      "loss": 2.3555,
      "step": 2593
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019379070850800246,
      "loss": 2.4102,
      "step": 2594
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019378466854130198,
      "loss": 2.5078,
      "step": 2595
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019377862573261796,
      "loss": 2.4023,
      "step": 2596
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019377258008213352,
      "loss": 2.4297,
      "step": 2597
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019376653159003188,
      "loss": 2.4336,
      "step": 2598
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019376048025649636,
      "loss": 2.418,
      "step": 2599
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019375442608171028,
      "loss": 2.5703,
      "step": 2600
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019374836906585714,
      "loss": 2.5586,
      "step": 2601
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019374230920912044,
      "loss": 2.3945,
      "step": 2602
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019373624651168387,
      "loss": 2.4844,
      "step": 2603
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019373018097373113,
      "loss": 2.4609,
      "step": 2604
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00193724112595446,
      "loss": 2.4336,
      "step": 2605
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001937180413770124,
      "loss": 2.4648,
      "step": 2606
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001937119673186143,
      "loss": 2.6094,
      "step": 2607
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019370589042043578,
      "loss": 2.3867,
      "step": 2608
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019369981068266097,
      "loss": 2.5781,
      "step": 2609
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001936937281054741,
      "loss": 2.5039,
      "step": 2610
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019368764268905953,
      "loss": 2.5352,
      "step": 2611
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001936815544336016,
      "loss": 2.3906,
      "step": 2612
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019367546333928485,
      "loss": 2.5273,
      "step": 2613
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019366936940629388,
      "loss": 2.5234,
      "step": 2614
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001936632726348133,
      "loss": 2.3828,
      "step": 2615
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019365717302502793,
      "loss": 2.5742,
      "step": 2616
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019365107057712253,
      "loss": 2.3574,
      "step": 2617
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019364496529128208,
      "loss": 2.3984,
      "step": 2618
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001936388571676916,
      "loss": 2.4727,
      "step": 2619
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019363274620653613,
      "loss": 2.2344,
      "step": 2620
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001936266324080009,
      "loss": 2.4922,
      "step": 2621
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019362051577227115,
      "loss": 2.5234,
      "step": 2622
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019361439629953226,
      "loss": 2.5312,
      "step": 2623
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019360827398996966,
      "loss": 2.4492,
      "step": 2624
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019360214884376887,
      "loss": 2.3203,
      "step": 2625
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001935960208611155,
      "loss": 2.4844,
      "step": 2626
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019358989004219524,
      "loss": 2.5898,
      "step": 2627
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019358375638719393,
      "loss": 2.3359,
      "step": 2628
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019357761989629734,
      "loss": 2.3828,
      "step": 2629
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001935714805696915,
      "loss": 2.5625,
      "step": 2630
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019356533840756245,
      "loss": 2.5312,
      "step": 2631
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019355919341009632,
      "loss": 2.5703,
      "step": 2632
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019355304557747927,
      "loss": 2.5664,
      "step": 2633
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019354689490989766,
      "loss": 2.3398,
      "step": 2634
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001935407414075378,
      "loss": 2.2773,
      "step": 2635
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019353458507058627,
      "loss": 2.5078,
      "step": 2636
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019352842589922955,
      "loss": 2.5781,
      "step": 2637
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019352226389365431,
      "loss": 2.4922,
      "step": 2638
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019351609905404726,
      "loss": 2.4492,
      "step": 2639
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001935099313805952,
      "loss": 2.4609,
      "step": 2640
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019350376087348508,
      "loss": 2.4492,
      "step": 2641
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019349758753290389,
      "loss": 2.3516,
      "step": 2642
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019349141135903865,
      "loss": 2.582,
      "step": 2643
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019348523235207657,
      "loss": 2.4219,
      "step": 2644
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019347905051220482,
      "loss": 2.5117,
      "step": 2645
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019347286583961082,
      "loss": 2.3242,
      "step": 2646
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019346667833448192,
      "loss": 2.4492,
      "step": 2647
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019346048799700566,
      "loss": 2.4102,
      "step": 2648
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001934542948273696,
      "loss": 2.4609,
      "step": 2649
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019344809882576146,
      "loss": 2.3867,
      "step": 2650
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0019344189999236892,
      "loss": 2.3594,
      "step": 2651
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019343569832737991,
      "loss": 2.5312,
      "step": 2652
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019342949383098229,
      "loss": 2.4766,
      "step": 2653
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019342328650336414,
      "loss": 2.3867,
      "step": 2654
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019341707634471352,
      "loss": 2.5781,
      "step": 2655
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019341086335521863,
      "loss": 2.4414,
      "step": 2656
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019340464753506775,
      "loss": 2.4102,
      "step": 2657
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001933984288844492,
      "loss": 2.4688,
      "step": 2658
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019339220740355147,
      "loss": 2.4961,
      "step": 2659
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001933859830925631,
      "loss": 2.4453,
      "step": 2660
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001933797559516727,
      "loss": 2.3359,
      "step": 2661
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019337352598106892,
      "loss": 2.4297,
      "step": 2662
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001933672931809406,
      "loss": 2.4648,
      "step": 2663
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019336105755147664,
      "loss": 2.4922,
      "step": 2664
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019335481909286592,
      "loss": 2.625,
      "step": 2665
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019334857780529753,
      "loss": 2.2969,
      "step": 2666
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019334233368896061,
      "loss": 2.5742,
      "step": 2667
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001933360867440444,
      "loss": 2.3828,
      "step": 2668
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019332983697073812,
      "loss": 2.4688,
      "step": 2669
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019332358436923124,
      "loss": 2.4062,
      "step": 2670
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019331732893971317,
      "loss": 2.4531,
      "step": 2671
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019331107068237352,
      "loss": 2.5938,
      "step": 2672
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019330480959740192,
      "loss": 2.457,
      "step": 2673
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019329854568498812,
      "loss": 2.5469,
      "step": 2674
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001932922789453219,
      "loss": 2.4805,
      "step": 2675
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019328600937859317,
      "loss": 2.4805,
      "step": 2676
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019327973698499196,
      "loss": 2.3496,
      "step": 2677
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001932734617647083,
      "loss": 2.2969,
      "step": 2678
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019326718371793236,
      "loss": 2.5156,
      "step": 2679
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019326090284485437,
      "loss": 2.4023,
      "step": 2680
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001932546191456647,
      "loss": 2.6406,
      "step": 2681
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019324833262055377,
      "loss": 2.5742,
      "step": 2682
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019324204326971201,
      "loss": 2.4961,
      "step": 2683
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019323575109333007,
      "loss": 2.5195,
      "step": 2684
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019322945609159864,
      "loss": 2.3164,
      "step": 2685
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019322315826470842,
      "loss": 2.4961,
      "step": 2686
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019321685761285031,
      "loss": 2.5273,
      "step": 2687
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019321055413621519,
      "loss": 2.582,
      "step": 2688
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019320424783499412,
      "loss": 2.5273,
      "step": 2689
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019319793870937816,
      "loss": 2.4062,
      "step": 2690
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019319162675955851,
      "loss": 2.4219,
      "step": 2691
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019318531198572648,
      "loss": 2.4336,
      "step": 2692
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019317899438807337,
      "loss": 2.4727,
      "step": 2693
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001931726739667907,
      "loss": 2.7109,
      "step": 2694
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019316635072206994,
      "loss": 2.248,
      "step": 2695
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001931600246541027,
      "loss": 2.418,
      "step": 2696
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001931536957630807,
      "loss": 2.6094,
      "step": 2697
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019314736404919576,
      "loss": 2.418,
      "step": 2698
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019314102951263968,
      "loss": 2.6211,
      "step": 2699
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019313469215360448,
      "loss": 2.2422,
      "step": 2700
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019312835197228219,
      "loss": 2.375,
      "step": 2701
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019312200896886486,
      "loss": 2.5117,
      "step": 2702
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019311566314354485,
      "loss": 2.5273,
      "step": 2703
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019310931449651432,
      "loss": 2.6094,
      "step": 2704
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019310296302796576,
      "loss": 2.2812,
      "step": 2705
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019309660873809155,
      "loss": 2.373,
      "step": 2706
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019309025162708433,
      "loss": 2.6406,
      "step": 2707
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019308389169513669,
      "loss": 2.3789,
      "step": 2708
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019307752894244135,
      "loss": 2.5547,
      "step": 2709
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019307116336919118,
      "loss": 2.375,
      "step": 2710
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00193064794975579,
      "loss": 2.6445,
      "step": 2711
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019305842376179786,
      "loss": 2.5078,
      "step": 2712
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019305204972804078,
      "loss": 2.4961,
      "step": 2713
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019304567287450095,
      "loss": 2.3516,
      "step": 2714
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001930392932013716,
      "loss": 2.5352,
      "step": 2715
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019303291070884602,
      "loss": 2.3594,
      "step": 2716
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019302652539711768,
      "loss": 2.4102,
      "step": 2717
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019302013726638,
      "loss": 2.5039,
      "step": 2718
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019301374631682667,
      "loss": 2.3438,
      "step": 2719
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019300735254865126,
      "loss": 2.293,
      "step": 2720
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019300095596204755,
      "loss": 2.4375,
      "step": 2721
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019299455655720941,
      "loss": 2.5156,
      "step": 2722
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019298815433433072,
      "loss": 2.5352,
      "step": 2723
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001929817492936055,
      "loss": 2.3164,
      "step": 2724
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019297534143522786,
      "loss": 2.3125,
      "step": 2725
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019296893075939198,
      "loss": 2.5938,
      "step": 2726
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019296251726629208,
      "loss": 2.4219,
      "step": 2727
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019295610095612257,
      "loss": 2.4258,
      "step": 2728
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019294968182907784,
      "loss": 2.4609,
      "step": 2729
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019294325988535243,
      "loss": 2.4219,
      "step": 2730
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019293683512514096,
      "loss": 2.5,
      "step": 2731
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019293040754863808,
      "loss": 2.6641,
      "step": 2732
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019292397715603862,
      "loss": 2.3047,
      "step": 2733
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019291754394753743,
      "loss": 2.5234,
      "step": 2734
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001929111079233294,
      "loss": 2.4648,
      "step": 2735
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019290466908360962,
      "loss": 2.4473,
      "step": 2736
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001928982274285732,
      "loss": 2.2383,
      "step": 2737
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019289178295841532,
      "loss": 2.4375,
      "step": 2738
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001928853356733313,
      "loss": 2.4766,
      "step": 2739
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019287888557351649,
      "loss": 2.4453,
      "step": 2740
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019287243265916634,
      "loss": 2.5156,
      "step": 2741
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019286597693047645,
      "loss": 2.3008,
      "step": 2742
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001928595183876424,
      "loss": 2.4297,
      "step": 2743
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0019285305703085989,
      "loss": 2.332,
      "step": 2744
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019284659286032478,
      "loss": 2.5117,
      "step": 2745
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019284012587623292,
      "loss": 2.5117,
      "step": 2746
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019283365607878028,
      "loss": 2.6211,
      "step": 2747
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001928271834681629,
      "loss": 2.5859,
      "step": 2748
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019282070804457695,
      "loss": 2.418,
      "step": 2749
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019281422980821868,
      "loss": 2.4297,
      "step": 2750
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019280774875928433,
      "loss": 2.4219,
      "step": 2751
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019280126489797035,
      "loss": 2.4297,
      "step": 2752
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019279477822447323,
      "loss": 2.4258,
      "step": 2753
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019278828873898948,
      "loss": 2.6133,
      "step": 2754
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001927817964417158,
      "loss": 2.5195,
      "step": 2755
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019277530133284893,
      "loss": 2.4531,
      "step": 2756
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019276880341258568,
      "loss": 2.4961,
      "step": 2757
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019276230268112293,
      "loss": 2.457,
      "step": 2758
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019275579913865775,
      "loss": 2.4648,
      "step": 2759
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019274929278538713,
      "loss": 2.5273,
      "step": 2760
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001927427836215083,
      "loss": 2.668,
      "step": 2761
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019273627164721847,
      "loss": 2.6016,
      "step": 2762
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00192729756862715,
      "loss": 2.5508,
      "step": 2763
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019272323926819528,
      "loss": 2.4766,
      "step": 2764
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019271671886385683,
      "loss": 2.2305,
      "step": 2765
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019271019564989728,
      "loss": 2.4258,
      "step": 2766
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019270366962651421,
      "loss": 2.4766,
      "step": 2767
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001926971407939055,
      "loss": 2.4727,
      "step": 2768
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019269060915226889,
      "loss": 2.6484,
      "step": 2769
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019268407470180236,
      "loss": 2.418,
      "step": 2770
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001926775374427039,
      "loss": 2.4219,
      "step": 2771
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019267099737517164,
      "loss": 2.4727,
      "step": 2772
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019266445449940377,
      "loss": 2.3457,
      "step": 2773
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019265790881559854,
      "loss": 2.4062,
      "step": 2774
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019265136032395429,
      "loss": 2.5508,
      "step": 2775
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019264480902466948,
      "loss": 2.5781,
      "step": 2776
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019263825491794267,
      "loss": 2.7383,
      "step": 2777
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001926316980039724,
      "loss": 2.582,
      "step": 2778
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019262513828295742,
      "loss": 2.4141,
      "step": 2779
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019261857575509648,
      "loss": 2.3477,
      "step": 2780
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001926120104205885,
      "loss": 2.3359,
      "step": 2781
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019260544227963235,
      "loss": 2.5508,
      "step": 2782
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001925988713324271,
      "loss": 2.3242,
      "step": 2783
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001925922975791719,
      "loss": 2.3633,
      "step": 2784
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019258572102006594,
      "loss": 2.2656,
      "step": 2785
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001925791416553085,
      "loss": 2.4258,
      "step": 2786
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019257255948509897,
      "loss": 2.4219,
      "step": 2787
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019256597450963678,
      "loss": 2.293,
      "step": 2788
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019255938672912154,
      "loss": 2.3711,
      "step": 2789
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019255279614375281,
      "loss": 2.4023,
      "step": 2790
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019254620275373036,
      "loss": 2.3672,
      "step": 2791
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019253960655925397,
      "loss": 2.457,
      "step": 2792
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001925330075605235,
      "loss": 2.3281,
      "step": 2793
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019252640575773896,
      "loss": 2.4883,
      "step": 2794
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019251980115110039,
      "loss": 2.4727,
      "step": 2795
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019251319374080796,
      "loss": 2.3516,
      "step": 2796
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019250658352706186,
      "loss": 2.4414,
      "step": 2797
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019249997051006239,
      "loss": 2.3945,
      "step": 2798
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019249335469000996,
      "loss": 2.3906,
      "step": 2799
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019248673606710512,
      "loss": 2.418,
      "step": 2800
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019248011464154833,
      "loss": 2.5078,
      "step": 2801
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001924734904135403,
      "loss": 2.6133,
      "step": 2802
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019246686338328174,
      "loss": 2.543,
      "step": 2803
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019246023355097349,
      "loss": 2.6016,
      "step": 2804
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019245360091681648,
      "loss": 2.2891,
      "step": 2805
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019244696548101161,
      "loss": 2.4062,
      "step": 2806
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019244032724376006,
      "loss": 2.5742,
      "step": 2807
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019243368620526294,
      "loss": 2.6406,
      "step": 2808
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019242704236572148,
      "loss": 2.5352,
      "step": 2809
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019242039572533705,
      "loss": 2.4062,
      "step": 2810
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019241374628431104,
      "loss": 2.3867,
      "step": 2811
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019240709404284497,
      "loss": 2.5586,
      "step": 2812
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001924004390011404,
      "loss": 2.6328,
      "step": 2813
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019239378115939898,
      "loss": 2.418,
      "step": 2814
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019238712051782255,
      "loss": 2.2734,
      "step": 2815
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019238045707661287,
      "loss": 2.3281,
      "step": 2816
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019237379083597186,
      "loss": 2.7852,
      "step": 2817
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001923671217961016,
      "loss": 2.2031,
      "step": 2818
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019236044995720413,
      "loss": 2.4375,
      "step": 2819
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019235377531948163,
      "loss": 2.5391,
      "step": 2820
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019234709788313637,
      "loss": 2.332,
      "step": 2821
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001923404176483707,
      "loss": 2.543,
      "step": 2822
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019233373461538708,
      "loss": 2.4297,
      "step": 2823
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019232704878438798,
      "loss": 2.4453,
      "step": 2824
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019232036015557603,
      "loss": 2.5195,
      "step": 2825
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019231366872915392,
      "loss": 2.3555,
      "step": 2826
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001923069745053244,
      "loss": 2.4961,
      "step": 2827
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019230027748429036,
      "loss": 2.5547,
      "step": 2828
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001922935776662547,
      "loss": 2.4492,
      "step": 2829
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001922868750514205,
      "loss": 2.3828,
      "step": 2830
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019228016963999083,
      "loss": 2.5117,
      "step": 2831
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019227346143216887,
      "loss": 2.6562,
      "step": 2832
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019226675042815795,
      "loss": 2.582,
      "step": 2833
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001922600366281614,
      "loss": 2.3867,
      "step": 2834
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019225332003238271,
      "loss": 2.3555,
      "step": 2835
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019224660064102537,
      "loss": 2.4629,
      "step": 2836
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0019223987845429305,
      "loss": 2.375,
      "step": 2837
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019223315347238938,
      "loss": 2.4648,
      "step": 2838
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001922264256955182,
      "loss": 2.8359,
      "step": 2839
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001922196951238834,
      "loss": 2.5156,
      "step": 2840
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019221296175768888,
      "loss": 2.3516,
      "step": 2841
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019220622559713873,
      "loss": 2.5039,
      "step": 2842
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019219948664243706,
      "loss": 2.2773,
      "step": 2843
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019219274489378812,
      "loss": 2.4648,
      "step": 2844
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019218600035139613,
      "loss": 2.1816,
      "step": 2845
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019217925301546553,
      "loss": 2.3359,
      "step": 2846
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019217250288620078,
      "loss": 2.5039,
      "step": 2847
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001921657499638064,
      "loss": 2.3613,
      "step": 2848
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019215899424848708,
      "loss": 2.5469,
      "step": 2849
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019215223574044749,
      "loss": 2.4453,
      "step": 2850
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019214547443989248,
      "loss": 2.5,
      "step": 2851
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019213871034702691,
      "loss": 2.3789,
      "step": 2852
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019213194346205573,
      "loss": 2.5156,
      "step": 2853
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019212517378518403,
      "loss": 2.4141,
      "step": 2854
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019211840131661698,
      "loss": 2.4922,
      "step": 2855
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019211162605655976,
      "loss": 2.4141,
      "step": 2856
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019210484800521771,
      "loss": 2.5039,
      "step": 2857
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019209806716279619,
      "loss": 2.457,
      "step": 2858
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019209128352950073,
      "loss": 2.3809,
      "step": 2859
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019208449710553688,
      "loss": 2.4766,
      "step": 2860
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001920777078911103,
      "loss": 2.4375,
      "step": 2861
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001920709158864267,
      "loss": 2.3633,
      "step": 2862
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001920641210916919,
      "loss": 2.5117,
      "step": 2863
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019205732350711182,
      "loss": 2.5039,
      "step": 2864
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019205052313289249,
      "loss": 2.3945,
      "step": 2865
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019204371996923988,
      "loss": 2.4844,
      "step": 2866
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019203691401636026,
      "loss": 2.7305,
      "step": 2867
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019203010527445979,
      "loss": 2.4375,
      "step": 2868
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019202329374374482,
      "loss": 2.5586,
      "step": 2869
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001920164794244218,
      "loss": 2.3672,
      "step": 2870
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019200966231669718,
      "loss": 2.4102,
      "step": 2871
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019200284242077757,
      "loss": 2.2734,
      "step": 2872
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019199601973686961,
      "loss": 2.3086,
      "step": 2873
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019198919426518008,
      "loss": 2.4531,
      "step": 2874
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019198236600591577,
      "loss": 2.5391,
      "step": 2875
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019197553495928364,
      "loss": 2.375,
      "step": 2876
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001919687011254907,
      "loss": 2.3008,
      "step": 2877
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019196186450474398,
      "loss": 2.25,
      "step": 2878
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001919550250972507,
      "loss": 2.5977,
      "step": 2879
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001919481829032181,
      "loss": 2.4844,
      "step": 2880
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019194133792285353,
      "loss": 2.6055,
      "step": 2881
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019193449015636444,
      "loss": 2.2656,
      "step": 2882
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019192763960395828,
      "loss": 2.5352,
      "step": 2883
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019192078626584267,
      "loss": 2.5391,
      "step": 2884
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019191393014222529,
      "loss": 2.2617,
      "step": 2885
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019190707123331392,
      "loss": 2.5469,
      "step": 2886
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001919002095393164,
      "loss": 2.3633,
      "step": 2887
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019189334506044067,
      "loss": 2.5977,
      "step": 2888
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019188647779689472,
      "loss": 2.3984,
      "step": 2889
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019187960774888664,
      "loss": 2.2812,
      "step": 2890
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019187273491662468,
      "loss": 2.4766,
      "step": 2891
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019186585930031704,
      "loss": 2.3711,
      "step": 2892
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019185898090017211,
      "loss": 2.4922,
      "step": 2893
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001918520997163983,
      "loss": 2.5664,
      "step": 2894
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019184521574920415,
      "loss": 2.3086,
      "step": 2895
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001918383289987983,
      "loss": 2.6133,
      "step": 2896
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001918314394653894,
      "loss": 2.3906,
      "step": 2897
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019182454714918623,
      "loss": 2.582,
      "step": 2898
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019181765205039765,
      "loss": 2.3633,
      "step": 2899
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019181075416923263,
      "loss": 2.4062,
      "step": 2900
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019180385350590014,
      "loss": 2.5664,
      "step": 2901
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019179695006060937,
      "loss": 2.5078,
      "step": 2902
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019179004383356943,
      "loss": 2.4414,
      "step": 2903
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001917831348249897,
      "loss": 2.5156,
      "step": 2904
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019177622303507946,
      "loss": 2.457,
      "step": 2905
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019176930846404824,
      "loss": 2.4805,
      "step": 2906
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001917623911121055,
      "loss": 2.5859,
      "step": 2907
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019175547097946086,
      "loss": 2.5234,
      "step": 2908
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001917485480663241,
      "loss": 2.3535,
      "step": 2909
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019174162237290493,
      "loss": 2.5039,
      "step": 2910
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019173469389941326,
      "loss": 2.3555,
      "step": 2911
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.00191727762646059,
      "loss": 2.6328,
      "step": 2912
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019172082861305224,
      "loss": 2.4648,
      "step": 2913
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019171389180060313,
      "loss": 2.5781,
      "step": 2914
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019170695220892178,
      "loss": 2.4336,
      "step": 2915
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019170000983821855,
      "loss": 2.3008,
      "step": 2916
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019169306468870381,
      "loss": 2.4375,
      "step": 2917
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019168611676058803,
      "loss": 2.668,
      "step": 2918
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019167916605408173,
      "loss": 2.418,
      "step": 2919
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019167221256939555,
      "loss": 2.3984,
      "step": 2920
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019166525630674022,
      "loss": 2.4688,
      "step": 2921
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001916582972663265,
      "loss": 2.5234,
      "step": 2922
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019165133544836528,
      "loss": 2.2207,
      "step": 2923
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019164437085306756,
      "loss": 2.3906,
      "step": 2924
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019163740348064437,
      "loss": 2.4023,
      "step": 2925
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019163043333130685,
      "loss": 2.5273,
      "step": 2926
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001916234604052662,
      "loss": 2.3672,
      "step": 2927
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019161648470273373,
      "loss": 2.5391,
      "step": 2928
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0019160950622392084,
      "loss": 2.6133,
      "step": 2929
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.00191602524969039,
      "loss": 2.4414,
      "step": 2930
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019159554093829971,
      "loss": 2.3789,
      "step": 2931
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019158855413191473,
      "loss": 2.457,
      "step": 2932
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019158156455009565,
      "loss": 2.2695,
      "step": 2933
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019157457219305437,
      "loss": 2.4492,
      "step": 2934
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019156757706100271,
      "loss": 2.418,
      "step": 2935
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019156057915415271,
      "loss": 2.5039,
      "step": 2936
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.001915535784727164,
      "loss": 2.4316,
      "step": 2937
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019154657501690591,
      "loss": 2.2773,
      "step": 2938
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019153956878693351,
      "loss": 2.4883,
      "step": 2939
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019153255978301147,
      "loss": 2.5977,
      "step": 2940
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.001915255480053522,
      "loss": 2.625,
      "step": 2941
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.001915185334541682,
      "loss": 2.3945,
      "step": 2942
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00191511516129672,
      "loss": 2.4219,
      "step": 2943
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019150449603207624,
      "loss": 2.332,
      "step": 2944
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019149747316159372,
      "loss": 2.3633,
      "step": 2945
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.001914904475184372,
      "loss": 2.5781,
      "step": 2946
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019148341910281957,
      "loss": 2.2969,
      "step": 2947
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019147638791495386,
      "loss": 2.5508,
      "step": 2948
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019146935395505309,
      "loss": 2.3867,
      "step": 2949
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019146231722333045,
      "loss": 2.418,
      "step": 2950
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019145527771999916,
      "loss": 2.2383,
      "step": 2951
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019144823544527255,
      "loss": 2.4609,
      "step": 2952
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00191441190399364,
      "loss": 2.6133,
      "step": 2953
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019143414258248703,
      "loss": 2.4336,
      "step": 2954
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019142709199485518,
      "loss": 2.4297,
      "step": 2955
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019142003863668214,
      "loss": 2.2344,
      "step": 2956
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019141298250818161,
      "loss": 2.3477,
      "step": 2957
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019140592360956746,
      "loss": 2.3203,
      "step": 2958
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019139886194105356,
      "loss": 2.5625,
      "step": 2959
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.001913917975028539,
      "loss": 2.6055,
      "step": 2960
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.001913847302951826,
      "loss": 2.3633,
      "step": 2961
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019137766031825376,
      "loss": 2.5508,
      "step": 2962
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019137058757228167,
      "loss": 2.4648,
      "step": 2963
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019136351205748066,
      "loss": 2.4727,
      "step": 2964
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019135643377406512,
      "loss": 2.5586,
      "step": 2965
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.001913493527222495,
      "loss": 2.5234,
      "step": 2966
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019134226890224848,
      "loss": 2.418,
      "step": 2967
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019133518231427664,
      "loss": 2.3203,
      "step": 2968
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019132809295854879,
      "loss": 2.3281,
      "step": 2969
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.001913210008352797,
      "loss": 2.3438,
      "step": 2970
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019131390594468432,
      "loss": 2.5781,
      "step": 2971
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019130680828697763,
      "loss": 2.5469,
      "step": 2972
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019129970786237473,
      "loss": 2.3828,
      "step": 2973
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.001912926046710908,
      "loss": 2.4727,
      "step": 2974
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019128549871334105,
      "loss": 2.332,
      "step": 2975
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019127838998934084,
      "loss": 2.4688,
      "step": 2976
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019127127849930558,
      "loss": 2.5078,
      "step": 2977
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019126416424345076,
      "loss": 2.3906,
      "step": 2978
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00191257047221992,
      "loss": 2.6406,
      "step": 2979
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019124992743514496,
      "loss": 2.3711,
      "step": 2980
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019124280488312534,
      "loss": 2.6172,
      "step": 2981
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019123567956614903,
      "loss": 2.5625,
      "step": 2982
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019122855148443194,
      "loss": 2.3477,
      "step": 2983
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019122142063819005,
      "loss": 2.5156,
      "step": 2984
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019121428702763951,
      "loss": 2.3906,
      "step": 2985
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019120715065299642,
      "loss": 2.3555,
      "step": 2986
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.001912000115144771,
      "loss": 2.4961,
      "step": 2987
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019119286961229785,
      "loss": 2.375,
      "step": 2988
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019118572494667507,
      "loss": 2.4531,
      "step": 2989
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019117857751782532,
      "loss": 2.4609,
      "step": 2990
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019117142732596516,
      "loss": 2.418,
      "step": 2991
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019116427437131124,
      "loss": 2.418,
      "step": 2992
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.001911571186540804,
      "loss": 2.5977,
      "step": 2993
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.001911499601744894,
      "loss": 2.5078,
      "step": 2994
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019114279893275522,
      "loss": 2.457,
      "step": 2995
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019113563492909483,
      "loss": 2.2988,
      "step": 2996
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019112846816372537,
      "loss": 2.4648,
      "step": 2997
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019112129863686391,
      "loss": 2.4102,
      "step": 2998
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019111412634872785,
      "loss": 2.4766,
      "step": 2999
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019110695129953446,
      "loss": 2.6328,
      "step": 3000
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019109977348950116,
      "loss": 2.4648,
      "step": 3001
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019109259291884549,
      "loss": 2.5391,
      "step": 3002
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019108540958778502,
      "loss": 2.4766,
      "step": 3003
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019107822349653746,
      "loss": 2.6094,
      "step": 3004
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019107103464532055,
      "loss": 2.2773,
      "step": 3005
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019106384303435213,
      "loss": 2.4648,
      "step": 3006
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019105664866385012,
      "loss": 2.5078,
      "step": 3007
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.001910494515340326,
      "loss": 2.457,
      "step": 3008
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019104225164511756,
      "loss": 2.7344,
      "step": 3009
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019103504899732329,
      "loss": 2.4102,
      "step": 3010
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019102784359086799,
      "loss": 2.4844,
      "step": 3011
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019102063542597,
      "loss": 2.4219,
      "step": 3012
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019101342450284777,
      "loss": 2.5547,
      "step": 3013
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019100621082171984,
      "loss": 2.5078,
      "step": 3014
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019099899438280478,
      "loss": 2.4141,
      "step": 3015
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019099177518632127,
      "loss": 2.4922,
      "step": 3016
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019098455323248809,
      "loss": 2.4023,
      "step": 3017
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019097732852152408,
      "loss": 2.5156,
      "step": 3018
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019097010105364814,
      "loss": 2.5898,
      "step": 3019
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019096287082907932,
      "loss": 2.4141,
      "step": 3020
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019095563784803675,
      "loss": 2.6211,
      "step": 3021
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.001909484021107396,
      "loss": 2.5469,
      "step": 3022
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0019094116361740709,
      "loss": 2.4375,
      "step": 3023
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001909339223682586,
      "loss": 2.3633,
      "step": 3024
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019092667836351355,
      "loss": 2.4316,
      "step": 3025
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019091943160339147,
      "loss": 2.6289,
      "step": 3026
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019091218208811195,
      "loss": 2.4297,
      "step": 3027
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019090492981789471,
      "loss": 2.1797,
      "step": 3028
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019089767479295947,
      "loss": 2.4883,
      "step": 3029
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019089041701352612,
      "loss": 2.6367,
      "step": 3030
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019088315647981457,
      "loss": 2.3516,
      "step": 3031
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019087589319204486,
      "loss": 2.3555,
      "step": 3032
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019086862715043706,
      "loss": 2.2891,
      "step": 3033
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019086135835521137,
      "loss": 2.5938,
      "step": 3034
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019085408680658805,
      "loss": 2.5625,
      "step": 3035
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019084681250478748,
      "loss": 2.707,
      "step": 3036
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019083953545003009,
      "loss": 2.7773,
      "step": 3037
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019083225564253635,
      "loss": 2.4297,
      "step": 3038
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001908249730825269,
      "loss": 2.5078,
      "step": 3039
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019081768777022244,
      "loss": 2.6289,
      "step": 3040
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019081039970584373,
      "loss": 2.5156,
      "step": 3041
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001908031088896116,
      "loss": 2.5625,
      "step": 3042
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00190795815321747,
      "loss": 2.5273,
      "step": 3043
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019078851900247093,
      "loss": 2.4102,
      "step": 3044
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019078121993200455,
      "loss": 2.5156,
      "step": 3045
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00190773918110569,
      "loss": 2.3789,
      "step": 3046
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001907666135383855,
      "loss": 2.5234,
      "step": 3047
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019075930621567552,
      "loss": 2.7852,
      "step": 3048
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019075199614266042,
      "loss": 2.4922,
      "step": 3049
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019074468331956175,
      "loss": 2.4375,
      "step": 3050
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019073736774660106,
      "loss": 2.4141,
      "step": 3051
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001907300494240001,
      "loss": 2.5273,
      "step": 3052
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019072272835198062,
      "loss": 2.418,
      "step": 3053
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019071540453076442,
      "loss": 2.5469,
      "step": 3054
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019070807796057352,
      "loss": 2.793,
      "step": 3055
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019070074864162988,
      "loss": 2.6406,
      "step": 3056
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019069341657415562,
      "loss": 2.4375,
      "step": 3057
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019068608175837295,
      "loss": 2.5195,
      "step": 3058
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019067874419450407,
      "loss": 2.4844,
      "step": 3059
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019067140388277142,
      "loss": 2.5352,
      "step": 3060
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019066406082339738,
      "loss": 2.5508,
      "step": 3061
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019065671501660448,
      "loss": 2.4062,
      "step": 3062
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019064936646261536,
      "loss": 2.3125,
      "step": 3063
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019064201516165262,
      "loss": 2.5234,
      "step": 3064
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001906346611139391,
      "loss": 2.5625,
      "step": 3065
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019062730431969764,
      "loss": 2.4062,
      "step": 3066
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019061994477915115,
      "loss": 2.5,
      "step": 3067
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019061258249252267,
      "loss": 2.6875,
      "step": 3068
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001906052174600353,
      "loss": 2.5,
      "step": 3069
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001905978496819122,
      "loss": 2.5898,
      "step": 3070
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019059047915837666,
      "loss": 2.4219,
      "step": 3071
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019058310588965207,
      "loss": 2.5391,
      "step": 3072
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019057572987596179,
      "loss": 2.543,
      "step": 3073
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019056835111752937,
      "loss": 2.5586,
      "step": 3074
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019056096961457842,
      "loss": 2.5312,
      "step": 3075
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019055358536733261,
      "loss": 2.2383,
      "step": 3076
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019054619837601573,
      "loss": 2.4883,
      "step": 3077
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019053880864085158,
      "loss": 2.2656,
      "step": 3078
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019053141616206415,
      "loss": 2.5273,
      "step": 3079
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019052402093987742,
      "loss": 2.4766,
      "step": 3080
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001905166229745155,
      "loss": 2.4258,
      "step": 3081
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001905092222662026,
      "loss": 2.3633,
      "step": 3082
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019050181881516291,
      "loss": 2.3867,
      "step": 3083
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019049441262162087,
      "loss": 2.4141,
      "step": 3084
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019048700368580085,
      "loss": 2.6484,
      "step": 3085
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019047959200792742,
      "loss": 2.3555,
      "step": 3086
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001904721775882251,
      "loss": 2.543,
      "step": 3087
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019046476042691865,
      "loss": 2.3516,
      "step": 3088
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019045734052423279,
      "loss": 2.4766,
      "step": 3089
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019044991788039235,
      "loss": 2.4805,
      "step": 3090
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001904424924956223,
      "loss": 2.5312,
      "step": 3091
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019043506437014766,
      "loss": 2.625,
      "step": 3092
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001904276335041935,
      "loss": 2.2695,
      "step": 3093
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019042019989798501,
      "loss": 2.3164,
      "step": 3094
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019041276355174742,
      "loss": 2.5156,
      "step": 3095
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019040532446570613,
      "loss": 2.4375,
      "step": 3096
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019039788264008655,
      "loss": 2.3086,
      "step": 3097
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019039043807511419,
      "loss": 2.418,
      "step": 3098
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001903829907710146,
      "loss": 2.5859,
      "step": 3099
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019037554072801352,
      "loss": 2.5039,
      "step": 3100
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019036808794633672,
      "loss": 2.2969,
      "step": 3101
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019036063242620998,
      "loss": 2.4922,
      "step": 3102
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019035317416785929,
      "loss": 2.6992,
      "step": 3103
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001903457131715106,
      "loss": 2.4336,
      "step": 3104
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019033824943739007,
      "loss": 2.3984,
      "step": 3105
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001903307829657238,
      "loss": 2.5859,
      "step": 3106
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019032331375673807,
      "loss": 2.4023,
      "step": 3107
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019031584181065928,
      "loss": 2.4414,
      "step": 3108
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001903083671277138,
      "loss": 2.5625,
      "step": 3109
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019030088970812815,
      "loss": 2.4883,
      "step": 3110
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019029340955212892,
      "loss": 2.3164,
      "step": 3111
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019028592665994277,
      "loss": 2.5508,
      "step": 3112
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001902784410317965,
      "loss": 2.4961,
      "step": 3113
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001902709526679169,
      "loss": 2.4102,
      "step": 3114
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019026346156853094,
      "loss": 2.7188,
      "step": 3115
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0019025596773386555,
      "loss": 2.332,
      "step": 3116
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.001902484711641479,
      "loss": 2.5352,
      "step": 3117
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019024097185960512,
      "loss": 2.5977,
      "step": 3118
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019023346982046446,
      "loss": 2.375,
      "step": 3119
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019022596504695325,
      "loss": 2.543,
      "step": 3120
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019021845753929895,
      "loss": 2.5234,
      "step": 3121
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.00190210947297729,
      "loss": 2.4258,
      "step": 3122
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019020343432247105,
      "loss": 2.3086,
      "step": 3123
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019019591861375274,
      "loss": 2.2773,
      "step": 3124
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.001901884001718018,
      "loss": 2.7344,
      "step": 3125
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.001901808789968461,
      "loss": 2.3945,
      "step": 3126
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019017335508911353,
      "loss": 2.5312,
      "step": 3127
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019016582844883212,
      "loss": 2.3555,
      "step": 3128
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.001901582990762299,
      "loss": 2.4453,
      "step": 3129
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019015076697153509,
      "loss": 2.3359,
      "step": 3130
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.001901432321349759,
      "loss": 2.5039,
      "step": 3131
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019013569456678065,
      "loss": 2.4375,
      "step": 3132
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019012815426717783,
      "loss": 2.3516,
      "step": 3133
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019012061123639583,
      "loss": 2.5547,
      "step": 3134
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019011306547466332,
      "loss": 2.4766,
      "step": 3135
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019010551698220891,
      "loss": 2.4609,
      "step": 3136
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019009796575926133,
      "loss": 2.4961,
      "step": 3137
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019009041180604947,
      "loss": 2.625,
      "step": 3138
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019008285512280216,
      "loss": 2.3867,
      "step": 3139
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.001900752957097485,
      "loss": 2.3594,
      "step": 3140
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019006773356711744,
      "loss": 2.3438,
      "step": 3141
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019006016869513823,
      "loss": 2.3438,
      "step": 3142
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019005260109404005,
      "loss": 2.4688,
      "step": 3143
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019004503076405226,
      "loss": 2.4766,
      "step": 3144
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019003745770540428,
      "loss": 2.4844,
      "step": 3145
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019002988191832554,
      "loss": 2.4492,
      "step": 3146
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019002230340304568,
      "loss": 2.3672,
      "step": 3147
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019001472215979432,
      "loss": 2.4531,
      "step": 3148
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0019000713818880118,
      "loss": 2.4531,
      "step": 3149
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018999955149029608,
      "loss": 2.4961,
      "step": 3150
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018999196206450897,
      "loss": 2.3594,
      "step": 3151
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018998436991166981,
      "loss": 2.6562,
      "step": 3152
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018997677503200863,
      "loss": 2.418,
      "step": 3153
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018996917742575563,
      "loss": 2.457,
      "step": 3154
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018996157709314102,
      "loss": 2.4492,
      "step": 3155
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018995397403439509,
      "loss": 2.5586,
      "step": 3156
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018994636824974831,
      "loss": 2.5039,
      "step": 3157
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018993875973943109,
      "loss": 2.5469,
      "step": 3158
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.00189931148503674,
      "loss": 2.5742,
      "step": 3159
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018992353454270773,
      "loss": 2.3867,
      "step": 3160
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018991591785676302,
      "loss": 2.5156,
      "step": 3161
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018990829844607057,
      "loss": 2.5625,
      "step": 3162
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018990067631086136,
      "loss": 2.2891,
      "step": 3163
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018989305145136637,
      "loss": 2.3516,
      "step": 3164
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018988542386781666,
      "loss": 2.4961,
      "step": 3165
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.001898777935604433,
      "loss": 2.668,
      "step": 3166
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018987016052947761,
      "loss": 2.5625,
      "step": 3167
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018986252477515082,
      "loss": 2.6055,
      "step": 3168
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018985488629769437,
      "loss": 2.4219,
      "step": 3169
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018984724509733969,
      "loss": 2.4727,
      "step": 3170
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018983960117431836,
      "loss": 2.4648,
      "step": 3171
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.00189831954528862,
      "loss": 2.4727,
      "step": 3172
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018982430516120234,
      "loss": 2.4727,
      "step": 3173
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018981665307157118,
      "loss": 2.6367,
      "step": 3174
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018980899826020043,
      "loss": 2.3828,
      "step": 3175
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018980134072732198,
      "loss": 2.2695,
      "step": 3176
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018979368047316795,
      "loss": 2.5547,
      "step": 3177
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018978601749797045,
      "loss": 2.4922,
      "step": 3178
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.001897783518019617,
      "loss": 2.3477,
      "step": 3179
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018977068338537394,
      "loss": 2.4609,
      "step": 3180
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018976301224843963,
      "loss": 2.4844,
      "step": 3181
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.001897553383913912,
      "loss": 2.168,
      "step": 3182
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018974766181446114,
      "loss": 2.457,
      "step": 3183
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018973998251788219,
      "loss": 2.4844,
      "step": 3184
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018973230050188695,
      "loss": 2.5117,
      "step": 3185
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018972461576670825,
      "loss": 2.2773,
      "step": 3186
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018971692831257897,
      "loss": 2.418,
      "step": 3187
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018970923813973206,
      "loss": 2.4609,
      "step": 3188
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018970154524840055,
      "loss": 2.4258,
      "step": 3189
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.001896938496388176,
      "loss": 2.4336,
      "step": 3190
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018968615131121633,
      "loss": 2.4648,
      "step": 3191
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018967845026583012,
      "loss": 2.5469,
      "step": 3192
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018967074650289226,
      "loss": 2.4961,
      "step": 3193
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018966304002263623,
      "loss": 2.5664,
      "step": 3194
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018965533082529555,
      "loss": 2.4688,
      "step": 3195
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018964761891110387,
      "loss": 2.5078,
      "step": 3196
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018963990428029487,
      "loss": 2.3789,
      "step": 3197
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.001896321869331023,
      "loss": 2.3867,
      "step": 3198
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018962446686976004,
      "loss": 2.5742,
      "step": 3199
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018961674409050206,
      "loss": 2.4453,
      "step": 3200
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018960901859556235,
      "loss": 2.4609,
      "step": 3201
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018960129038517503,
      "loss": 2.4219,
      "step": 3202
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018959355945957425,
      "loss": 2.5898,
      "step": 3203
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018958582581899434,
      "loss": 2.1758,
      "step": 3204
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018957808946366967,
      "loss": 2.4102,
      "step": 3205
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018957035039383458,
      "loss": 2.6289,
      "step": 3206
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.001895626086097237,
      "loss": 2.6289,
      "step": 3207
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018955486411157158,
      "loss": 2.3242,
      "step": 3208
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0018954711689961289,
      "loss": 2.4961,
      "step": 3209
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018953936697408242,
      "loss": 2.3242,
      "step": 3210
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018953161433521502,
      "loss": 2.3555,
      "step": 3211
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001895238589832456,
      "loss": 2.5938,
      "step": 3212
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018951610091840919,
      "loss": 2.3555,
      "step": 3213
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018950834014094086,
      "loss": 2.5352,
      "step": 3214
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018950057665107582,
      "loss": 2.4492,
      "step": 3215
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018949281044904934,
      "loss": 2.5273,
      "step": 3216
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001894850415350967,
      "loss": 2.4336,
      "step": 3217
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018947726990945339,
      "loss": 2.457,
      "step": 3218
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018946949557235484,
      "loss": 2.5742,
      "step": 3219
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018946171852403672,
      "loss": 2.457,
      "step": 3220
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018945393876473467,
      "loss": 2.5391,
      "step": 3221
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001894461562946844,
      "loss": 2.2578,
      "step": 3222
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001894383711141218,
      "loss": 2.3633,
      "step": 3223
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018943058322328278,
      "loss": 2.5977,
      "step": 3224
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001894227926224033,
      "loss": 2.3555,
      "step": 3225
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001894149993117195,
      "loss": 2.4375,
      "step": 3226
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001894072032914675,
      "loss": 2.3438,
      "step": 3227
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018939940456188353,
      "loss": 2.625,
      "step": 3228
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018939160312320396,
      "loss": 2.4922,
      "step": 3229
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018938379897566518,
      "loss": 2.5469,
      "step": 3230
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001893759921195037,
      "loss": 2.3711,
      "step": 3231
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018936818255495605,
      "loss": 2.3164,
      "step": 3232
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018936037028225892,
      "loss": 2.4922,
      "step": 3233
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018935255530164903,
      "loss": 2.2539,
      "step": 3234
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018934473761336324,
      "loss": 2.4531,
      "step": 3235
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018933691721763836,
      "loss": 2.3828,
      "step": 3236
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018932909411471148,
      "loss": 2.4766,
      "step": 3237
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018932126830481961,
      "loss": 2.3867,
      "step": 3238
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018931343978819994,
      "loss": 2.3047,
      "step": 3239
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018930560856508963,
      "loss": 2.4082,
      "step": 3240
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018929777463572602,
      "loss": 2.2227,
      "step": 3241
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001892899380003465,
      "loss": 2.4258,
      "step": 3242
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001892820986591886,
      "loss": 2.3711,
      "step": 3243
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018927425661248983,
      "loss": 2.5195,
      "step": 3244
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018926641186048782,
      "loss": 2.457,
      "step": 3245
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001892585644034203,
      "loss": 2.4062,
      "step": 3246
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001892507142415251,
      "loss": 2.4922,
      "step": 3247
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018924286137504006,
      "loss": 2.6484,
      "step": 3248
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001892350058042032,
      "loss": 2.3633,
      "step": 3249
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018922714752925254,
      "loss": 2.3477,
      "step": 3250
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018921928655042622,
      "loss": 2.3867,
      "step": 3251
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018921142286796244,
      "loss": 2.5312,
      "step": 3252
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018920355648209951,
      "loss": 2.3867,
      "step": 3253
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001891956873930758,
      "loss": 2.5039,
      "step": 3254
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018918781560112977,
      "loss": 2.4961,
      "step": 3255
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018917994110649997,
      "loss": 2.332,
      "step": 3256
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00189172063909425,
      "loss": 2.5117,
      "step": 3257
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018916418401014358,
      "loss": 2.4141,
      "step": 3258
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001891563014088945,
      "loss": 2.418,
      "step": 3259
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018914841610591661,
      "loss": 2.4844,
      "step": 3260
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018914052810144893,
      "loss": 2.3867,
      "step": 3261
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001891326373957304,
      "loss": 2.3984,
      "step": 3262
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018912474398900018,
      "loss": 2.5312,
      "step": 3263
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018911684788149744,
      "loss": 2.1973,
      "step": 3264
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018910894907346151,
      "loss": 2.4219,
      "step": 3265
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018910104756513172,
      "loss": 2.6055,
      "step": 3266
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018909314335674744,
      "loss": 2.4414,
      "step": 3267
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018908523644854834,
      "loss": 2.3242,
      "step": 3268
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018907732684077393,
      "loss": 2.6094,
      "step": 3269
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001890694145336639,
      "loss": 2.582,
      "step": 3270
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018906149952745803,
      "loss": 2.6445,
      "step": 3271
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018905358182239617,
      "loss": 2.3711,
      "step": 3272
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018904566141871829,
      "loss": 2.4258,
      "step": 3273
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018903773831666438,
      "loss": 2.293,
      "step": 3274
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018902981251647448,
      "loss": 2.5039,
      "step": 3275
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018902188401838883,
      "loss": 2.5039,
      "step": 3276
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018901395282264768,
      "loss": 2.2383,
      "step": 3277
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018900601892949136,
      "loss": 2.4141,
      "step": 3278
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001889980823391603,
      "loss": 2.1602,
      "step": 3279
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018899014305189502,
      "loss": 2.625,
      "step": 3280
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018898220106793606,
      "loss": 2.418,
      "step": 3281
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018897425638752414,
      "loss": 2.418,
      "step": 3282
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018896630901089999,
      "loss": 2.4453,
      "step": 3283
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018895835893830441,
      "loss": 2.4805,
      "step": 3284
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018895040616997837,
      "loss": 2.3438,
      "step": 3285
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018894245070616284,
      "loss": 2.2363,
      "step": 3286
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018893449254709887,
      "loss": 2.3477,
      "step": 3287
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018892653169302767,
      "loss": 2.6094,
      "step": 3288
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018891856814419047,
      "loss": 2.5938,
      "step": 3289
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018891060190082852,
      "loss": 2.3867,
      "step": 3290
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018890263296318331,
      "loss": 2.3867,
      "step": 3291
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001888946613314963,
      "loss": 2.4492,
      "step": 3292
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018888668700600905,
      "loss": 2.3398,
      "step": 3293
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018887870998696317,
      "loss": 2.5078,
      "step": 3294
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018887073027460044,
      "loss": 2.3594,
      "step": 3295
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018886274786916268,
      "loss": 2.5117,
      "step": 3296
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018885476277089176,
      "loss": 2.375,
      "step": 3297
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018884677498002965,
      "loss": 2.3555,
      "step": 3298
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018883878449681842,
      "loss": 2.4648,
      "step": 3299
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018883079132150018,
      "loss": 2.5195,
      "step": 3300
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001888227954543172,
      "loss": 2.5234,
      "step": 3301
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0018881479689551173,
      "loss": 2.5117,
      "step": 3302
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018880679564532619,
      "loss": 2.3594,
      "step": 3303
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018879879170400303,
      "loss": 2.3906,
      "step": 3304
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018879078507178478,
      "loss": 2.4023,
      "step": 3305
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.001887827757489141,
      "loss": 2.3359,
      "step": 3306
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018877476373563365,
      "loss": 2.3789,
      "step": 3307
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018876674903218627,
      "loss": 2.3516,
      "step": 3308
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018875873163881481,
      "loss": 2.5977,
      "step": 3309
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018875071155576224,
      "loss": 2.4492,
      "step": 3310
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018874268878327155,
      "loss": 2.3828,
      "step": 3311
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018873466332158591,
      "loss": 2.4805,
      "step": 3312
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.001887266351709485,
      "loss": 2.4453,
      "step": 3313
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018871860433160258,
      "loss": 2.3984,
      "step": 3314
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018871057080379152,
      "loss": 2.4297,
      "step": 3315
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.001887025345877588,
      "loss": 2.418,
      "step": 3316
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018869449568374788,
      "loss": 2.5547,
      "step": 3317
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.001886864540920024,
      "loss": 2.4844,
      "step": 3318
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018867840981276604,
      "loss": 2.4805,
      "step": 3319
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018867036284628256,
      "loss": 2.3652,
      "step": 3320
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018866231319279586,
      "loss": 2.3125,
      "step": 3321
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.001886542608525498,
      "loss": 2.3516,
      "step": 3322
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018864620582578842,
      "loss": 2.4297,
      "step": 3323
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018863814811275583,
      "loss": 2.4648,
      "step": 3324
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.001886300877136962,
      "loss": 2.4121,
      "step": 3325
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018862202462885378,
      "loss": 2.3203,
      "step": 3326
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.001886139588584729,
      "loss": 2.4141,
      "step": 3327
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018860589040279798,
      "loss": 2.5078,
      "step": 3328
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018859781926207353,
      "loss": 2.2148,
      "step": 3329
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018858974543654412,
      "loss": 2.3867,
      "step": 3330
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018858166892645445,
      "loss": 2.5508,
      "step": 3331
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018857358973204921,
      "loss": 2.4727,
      "step": 3332
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.001885655078535733,
      "loss": 2.3633,
      "step": 3333
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018855742329127155,
      "loss": 2.5156,
      "step": 3334
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018854933604538896,
      "loss": 2.4336,
      "step": 3335
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018854124611617062,
      "loss": 2.5742,
      "step": 3336
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018853315350386172,
      "loss": 2.5938,
      "step": 3337
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018852505820870743,
      "loss": 2.582,
      "step": 3338
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018851696023095312,
      "loss": 2.4355,
      "step": 3339
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.001885088595708441,
      "loss": 2.6367,
      "step": 3340
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018850075622862592,
      "loss": 2.6719,
      "step": 3341
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018849265020454413,
      "loss": 2.3789,
      "step": 3342
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018848454149884436,
      "loss": 2.3125,
      "step": 3343
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018847643011177231,
      "loss": 2.6016,
      "step": 3344
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018846831604357379,
      "loss": 2.4375,
      "step": 3345
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018846019929449475,
      "loss": 2.3438,
      "step": 3346
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018845207986478104,
      "loss": 2.5352,
      "step": 3347
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018844395775467876,
      "loss": 2.3594,
      "step": 3348
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018843583296443407,
      "loss": 2.4492,
      "step": 3349
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018842770549429315,
      "loss": 2.4648,
      "step": 3350
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018841957534450225,
      "loss": 2.5273,
      "step": 3351
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.001884114425153078,
      "loss": 2.4297,
      "step": 3352
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018840330700695624,
      "loss": 2.4023,
      "step": 3353
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018839516881969404,
      "loss": 2.4258,
      "step": 3354
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018838702795376792,
      "loss": 2.2188,
      "step": 3355
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018837888440942448,
      "loss": 2.2227,
      "step": 3356
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018837073818691054,
      "loss": 2.5195,
      "step": 3357
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00188362589286473,
      "loss": 2.4727,
      "step": 3358
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.001883544377083587,
      "loss": 2.2891,
      "step": 3359
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018834628345281474,
      "loss": 2.4375,
      "step": 3360
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018833812652008814,
      "loss": 2.4531,
      "step": 3361
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018832996691042618,
      "loss": 2.5039,
      "step": 3362
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018832180462407604,
      "loss": 2.3008,
      "step": 3363
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018831363966128514,
      "loss": 2.4414,
      "step": 3364
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018830547202230083,
      "loss": 2.5742,
      "step": 3365
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018829730170737066,
      "loss": 2.5078,
      "step": 3366
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018828912871674223,
      "loss": 2.4492,
      "step": 3367
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018828095305066315,
      "loss": 2.2891,
      "step": 3368
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018827277470938122,
      "loss": 2.416,
      "step": 3369
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018826459369314429,
      "loss": 2.6406,
      "step": 3370
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.001882564100022002,
      "loss": 2.2773,
      "step": 3371
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00188248223636797,
      "loss": 2.6016,
      "step": 3372
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018824003459718274,
      "loss": 2.2695,
      "step": 3373
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018823184288360557,
      "loss": 2.3047,
      "step": 3374
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018822364849631374,
      "loss": 2.4961,
      "step": 3375
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018821545143555558,
      "loss": 2.4375,
      "step": 3376
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018820725170157946,
      "loss": 2.4609,
      "step": 3377
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018819904929463385,
      "loss": 2.4883,
      "step": 3378
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018819084421496735,
      "loss": 2.5664,
      "step": 3379
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018818263646282858,
      "loss": 2.5039,
      "step": 3380
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018817442603846627,
      "loss": 2.4375,
      "step": 3381
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.001881662129421292,
      "loss": 2.4453,
      "step": 3382
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018815799717406625,
      "loss": 2.334,
      "step": 3383
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018814977873452645,
      "loss": 2.3672,
      "step": 3384
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018814155762375876,
      "loss": 2.4023,
      "step": 3385
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018813333384201237,
      "loss": 2.4805,
      "step": 3386
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018812510738953645,
      "loss": 2.375,
      "step": 3387
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.001881168782665803,
      "loss": 2.4688,
      "step": 3388
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018810864647339329,
      "loss": 2.3613,
      "step": 3389
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.001881004120102249,
      "loss": 2.4648,
      "step": 3390
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.001880921748773246,
      "loss": 2.457,
      "step": 3391
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018808393507494206,
      "loss": 2.5977,
      "step": 3392
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018807569260332693,
      "loss": 2.1211,
      "step": 3393
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018806744746272899,
      "loss": 2.3242,
      "step": 3394
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0018805919965339815,
      "loss": 2.332,
      "step": 3395
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018805094917558427,
      "loss": 2.5273,
      "step": 3396
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018804269602953742,
      "loss": 2.5391,
      "step": 3397
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018803444021550763,
      "loss": 2.3672,
      "step": 3398
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018802618173374519,
      "loss": 2.4688,
      "step": 3399
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018801792058450026,
      "loss": 2.6484,
      "step": 3400
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018800965676802322,
      "loss": 2.4688,
      "step": 3401
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018800139028456446,
      "loss": 2.4688,
      "step": 3402
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018799312113437453,
      "loss": 2.4922,
      "step": 3403
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018798484931770402,
      "loss": 2.4141,
      "step": 3404
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001879765748348035,
      "loss": 2.625,
      "step": 3405
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001879682976859238,
      "loss": 2.4336,
      "step": 3406
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018796001787131573,
      "loss": 2.4805,
      "step": 3407
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001879517353912302,
      "loss": 2.6094,
      "step": 3408
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018794345024591816,
      "loss": 2.5898,
      "step": 3409
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001879351624356307,
      "loss": 2.3359,
      "step": 3410
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018792687196061897,
      "loss": 2.6484,
      "step": 3411
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018791857882113421,
      "loss": 2.6484,
      "step": 3412
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018791028301742769,
      "loss": 2.6328,
      "step": 3413
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018790198454975084,
      "loss": 2.375,
      "step": 3414
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018789368341835515,
      "loss": 2.4062,
      "step": 3415
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001878853796234921,
      "loss": 2.6211,
      "step": 3416
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018787707316541336,
      "loss": 2.3945,
      "step": 3417
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018786876404437065,
      "loss": 2.293,
      "step": 3418
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018786045226061576,
      "loss": 2.3828,
      "step": 3419
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018785213781440057,
      "loss": 2.6172,
      "step": 3420
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018784382070597702,
      "loss": 2.4258,
      "step": 3421
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018783550093559717,
      "loss": 2.4258,
      "step": 3422
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001878271785035131,
      "loss": 2.6016,
      "step": 3423
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018781885340997699,
      "loss": 2.4766,
      "step": 3424
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018781052565524118,
      "loss": 2.4922,
      "step": 3425
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018780219523955805,
      "loss": 2.4961,
      "step": 3426
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018779386216317992,
      "loss": 2.4883,
      "step": 3427
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018778552642635944,
      "loss": 2.3711,
      "step": 3428
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018777718802934912,
      "loss": 2.4219,
      "step": 3429
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018776884697240166,
      "loss": 2.5352,
      "step": 3430
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018776050325576986,
      "loss": 2.4727,
      "step": 3431
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018775215687970653,
      "loss": 2.4844,
      "step": 3432
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018774380784446457,
      "loss": 2.4922,
      "step": 3433
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018773545615029703,
      "loss": 2.5508,
      "step": 3434
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018772710179745698,
      "loss": 2.6562,
      "step": 3435
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018771874478619758,
      "loss": 2.4648,
      "step": 3436
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018771038511677205,
      "loss": 2.3164,
      "step": 3437
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018770202278943376,
      "loss": 2.3828,
      "step": 3438
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001876936578044361,
      "loss": 2.3164,
      "step": 3439
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018768529016203253,
      "loss": 2.5234,
      "step": 3440
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018767691986247663,
      "loss": 2.5664,
      "step": 3441
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018766854690602211,
      "loss": 2.5391,
      "step": 3442
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001876601712929226,
      "loss": 2.6055,
      "step": 3443
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018765179302343196,
      "loss": 2.3984,
      "step": 3444
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018764341209780407,
      "loss": 2.2617,
      "step": 3445
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001876350285162929,
      "loss": 2.3711,
      "step": 3446
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018762664227915252,
      "loss": 2.5312,
      "step": 3447
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018761825338663703,
      "loss": 2.293,
      "step": 3448
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018760986183900066,
      "loss": 2.4258,
      "step": 3449
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018760146763649767,
      "loss": 2.4805,
      "step": 3450
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001875930707793825,
      "loss": 2.5039,
      "step": 3451
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001875846712679095,
      "loss": 2.3906,
      "step": 3452
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018757626910233332,
      "loss": 2.4609,
      "step": 3453
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018756786428290849,
      "loss": 2.4727,
      "step": 3454
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018755945680988973,
      "loss": 2.582,
      "step": 3455
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001875510466835318,
      "loss": 2.4961,
      "step": 3456
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001875426339040896,
      "loss": 2.4297,
      "step": 3457
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018753421847181797,
      "loss": 2.6289,
      "step": 3458
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018752580038697204,
      "loss": 2.4258,
      "step": 3459
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018751737964980684,
      "loss": 2.3828,
      "step": 3460
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018750895626057755,
      "loss": 2.3516,
      "step": 3461
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018750053021953945,
      "loss": 2.5977,
      "step": 3462
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018749210152694787,
      "loss": 2.5,
      "step": 3463
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018748367018305819,
      "loss": 2.5117,
      "step": 3464
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018747523618812597,
      "loss": 2.4414,
      "step": 3465
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018746679954240674,
      "loss": 2.4648,
      "step": 3466
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018745836024615615,
      "loss": 2.3594,
      "step": 3467
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018744991829962997,
      "loss": 2.293,
      "step": 3468
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018744147370308402,
      "loss": 2.3555,
      "step": 3469
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018743302645677419,
      "loss": 2.6797,
      "step": 3470
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018742457656095643,
      "loss": 2.4492,
      "step": 3471
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018741612401588685,
      "loss": 2.5039,
      "step": 3472
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018740766882182158,
      "loss": 2.3828,
      "step": 3473
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001873992109790168,
      "loss": 2.5977,
      "step": 3474
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018739075048772884,
      "loss": 2.4551,
      "step": 3475
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001873822873482141,
      "loss": 2.4453,
      "step": 3476
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018737382156072903,
      "loss": 2.4531,
      "step": 3477
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018736535312553011,
      "loss": 2.4492,
      "step": 3478
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018735688204287407,
      "loss": 2.4258,
      "step": 3479
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018734840831301752,
      "loss": 2.7383,
      "step": 3480
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018733993193621725,
      "loss": 2.2227,
      "step": 3481
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018733145291273017,
      "loss": 2.3281,
      "step": 3482
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018732297124281322,
      "loss": 2.5703,
      "step": 3483
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018731448692672337,
      "loss": 2.4492,
      "step": 3484
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001873059999647178,
      "loss": 2.2422,
      "step": 3485
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001872975103570536,
      "loss": 2.6172,
      "step": 3486
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001872890181039881,
      "loss": 2.3438,
      "step": 3487
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0018728052320577864,
      "loss": 2.5273,
      "step": 3488
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001872720256626826,
      "loss": 2.5508,
      "step": 3489
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018726352547495753,
      "loss": 2.3906,
      "step": 3490
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018725502264286098,
      "loss": 2.1016,
      "step": 3491
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018724651716665063,
      "loss": 2.3281,
      "step": 3492
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018723800904658422,
      "loss": 2.4531,
      "step": 3493
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018722949828291959,
      "loss": 2.3477,
      "step": 3494
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018722098487591462,
      "loss": 2.4453,
      "step": 3495
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001872124688258273,
      "loss": 2.5234,
      "step": 3496
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018720395013291568,
      "loss": 2.3164,
      "step": 3497
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018719542879743797,
      "loss": 2.6289,
      "step": 3498
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018718690481965231,
      "loss": 2.3086,
      "step": 3499
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018717837819981708,
      "loss": 2.6133,
      "step": 3500
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018716984893819059,
      "loss": 2.4844,
      "step": 3501
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018716131703503133,
      "loss": 2.375,
      "step": 3502
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018715278249059788,
      "loss": 2.3906,
      "step": 3503
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018714424530514883,
      "loss": 2.4844,
      "step": 3504
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018713570547894292,
      "loss": 2.4336,
      "step": 3505
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018712716301223886,
      "loss": 2.4922,
      "step": 3506
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018711861790529562,
      "loss": 2.3906,
      "step": 3507
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018711007015837207,
      "loss": 2.5156,
      "step": 3508
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018710151977172724,
      "loss": 2.3516,
      "step": 3509
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018709296674562026,
      "loss": 2.4766,
      "step": 3510
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018708441108031032,
      "loss": 2.3594,
      "step": 3511
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018707585277605663,
      "loss": 2.3535,
      "step": 3512
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018706729183311861,
      "loss": 2.5859,
      "step": 3513
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001870587282517556,
      "loss": 2.3711,
      "step": 3514
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001870501620322272,
      "loss": 2.4062,
      "step": 3515
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018704159317479295,
      "loss": 2.2852,
      "step": 3516
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018703302167971249,
      "loss": 2.4414,
      "step": 3517
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018702444754724558,
      "loss": 2.1367,
      "step": 3518
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018701587077765206,
      "loss": 2.3438,
      "step": 3519
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018700729137119182,
      "loss": 2.4492,
      "step": 3520
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018699870932812486,
      "loss": 2.8477,
      "step": 3521
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018699012464871122,
      "loss": 2.5273,
      "step": 3522
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018698153733321106,
      "loss": 2.3867,
      "step": 3523
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001869729473818846,
      "loss": 2.3984,
      "step": 3524
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018696435479499214,
      "loss": 2.4375,
      "step": 3525
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001869557595727941,
      "loss": 2.4258,
      "step": 3526
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001869471617155509,
      "loss": 2.5742,
      "step": 3527
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001869385612235231,
      "loss": 2.4297,
      "step": 3528
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018692995809697127,
      "loss": 2.5312,
      "step": 3529
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001869213523361562,
      "loss": 2.4492,
      "step": 3530
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018691274394133863,
      "loss": 2.5156,
      "step": 3531
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018690413291277941,
      "loss": 2.5586,
      "step": 3532
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018689551925073953,
      "loss": 2.6094,
      "step": 3533
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018688690295547996,
      "loss": 2.375,
      "step": 3534
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018687828402726185,
      "loss": 2.2891,
      "step": 3535
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001868696624663463,
      "loss": 2.4453,
      "step": 3536
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018686103827299468,
      "loss": 2.4375,
      "step": 3537
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018685241144746824,
      "loss": 2.3887,
      "step": 3538
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018684378199002847,
      "loss": 2.5,
      "step": 3539
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018683514990093684,
      "loss": 2.3281,
      "step": 3540
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018682651518045492,
      "loss": 2.8516,
      "step": 3541
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018681787782884437,
      "loss": 2.4414,
      "step": 3542
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018680923784636697,
      "loss": 2.25,
      "step": 3543
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001868005952332845,
      "loss": 2.5508,
      "step": 3544
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018679194998985887,
      "loss": 2.5742,
      "step": 3545
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018678330211635203,
      "loss": 2.4375,
      "step": 3546
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018677465161302611,
      "loss": 2.457,
      "step": 3547
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001867659984801432,
      "loss": 2.3711,
      "step": 3548
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018675734271796553,
      "loss": 2.2656,
      "step": 3549
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018674868432675539,
      "loss": 2.2715,
      "step": 3550
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018674002330677513,
      "loss": 2.5469,
      "step": 3551
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018673135965828727,
      "loss": 2.5273,
      "step": 3552
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018672269338155432,
      "loss": 2.3633,
      "step": 3553
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001867140244768389,
      "loss": 2.2734,
      "step": 3554
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018670535294440368,
      "loss": 2.3594,
      "step": 3555
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018669667878451147,
      "loss": 2.5547,
      "step": 3556
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018668800199742508,
      "loss": 2.5,
      "step": 3557
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001866793225834075,
      "loss": 2.6367,
      "step": 3558
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001866706405427217,
      "loss": 2.2344,
      "step": 3559
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018666195587563085,
      "loss": 2.4492,
      "step": 3560
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018665326858239802,
      "loss": 2.5391,
      "step": 3561
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018664457866328652,
      "loss": 2.5508,
      "step": 3562
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018663588611855966,
      "loss": 2.5039,
      "step": 3563
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018662719094848092,
      "loss": 2.4961,
      "step": 3564
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001866184931533137,
      "loss": 2.4141,
      "step": 3565
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018660979273332162,
      "loss": 2.3711,
      "step": 3566
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001866010896887683,
      "loss": 2.3906,
      "step": 3567
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018659238401991752,
      "loss": 2.5391,
      "step": 3568
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018658367572703307,
      "loss": 2.4062,
      "step": 3569
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018657496481037884,
      "loss": 2.5352,
      "step": 3570
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018656625127021877,
      "loss": 2.4336,
      "step": 3571
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018655753510681695,
      "loss": 2.3125,
      "step": 3572
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001865488163204375,
      "loss": 2.5938,
      "step": 3573
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018654009491134457,
      "loss": 2.6094,
      "step": 3574
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018653137087980257,
      "loss": 2.4453,
      "step": 3575
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018652264422607573,
      "loss": 2.4531,
      "step": 3576
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001865139149504286,
      "loss": 2.3789,
      "step": 3577
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018650518305312566,
      "loss": 2.4609,
      "step": 3578
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018649644853443149,
      "loss": 2.3203,
      "step": 3579
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0018648771139461082,
      "loss": 2.4414,
      "step": 3580
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001864789716339284,
      "loss": 2.4258,
      "step": 3581
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018647022925264909,
      "loss": 2.2148,
      "step": 3582
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018646148425103778,
      "loss": 2.5312,
      "step": 3583
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018645273662935948,
      "loss": 2.457,
      "step": 3584
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001864439863878793,
      "loss": 2.4375,
      "step": 3585
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018643523352686235,
      "loss": 2.4453,
      "step": 3586
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018642647804657394,
      "loss": 2.3594,
      "step": 3587
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018641771994727932,
      "loss": 2.4492,
      "step": 3588
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018640895922924395,
      "loss": 2.5508,
      "step": 3589
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018640019589273322,
      "loss": 2.2969,
      "step": 3590
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001863914299380128,
      "loss": 2.3906,
      "step": 3591
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018638266136534827,
      "loss": 2.3262,
      "step": 3592
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018637389017500535,
      "loss": 2.7812,
      "step": 3593
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001863651163672498,
      "loss": 2.3672,
      "step": 3594
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018635633994234758,
      "loss": 2.4277,
      "step": 3595
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018634756090056455,
      "loss": 2.2812,
      "step": 3596
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018633877924216682,
      "loss": 2.4609,
      "step": 3597
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018632999496742046,
      "loss": 2.3945,
      "step": 3598
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018632120807659167,
      "loss": 2.3945,
      "step": 3599
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018631241856994674,
      "loss": 2.3945,
      "step": 3600
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00186303626447752,
      "loss": 2.2832,
      "step": 3601
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001862948317102739,
      "loss": 2.3359,
      "step": 3602
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018628603435777893,
      "loss": 2.3672,
      "step": 3603
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018627723439053369,
      "loss": 2.4297,
      "step": 3604
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018626843180880482,
      "loss": 2.3555,
      "step": 3605
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018625962661285912,
      "loss": 2.4219,
      "step": 3606
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018625081880296334,
      "loss": 2.3906,
      "step": 3607
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001862420083793845,
      "loss": 2.6641,
      "step": 3608
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018623319534238948,
      "loss": 2.6523,
      "step": 3609
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018622437969224538,
      "loss": 2.2695,
      "step": 3610
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018621556142921936,
      "loss": 2.5977,
      "step": 3611
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001862067405535786,
      "loss": 2.1953,
      "step": 3612
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018619791706559045,
      "loss": 2.4297,
      "step": 3613
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018618909096552226,
      "loss": 2.4023,
      "step": 3614
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001861802622536415,
      "loss": 2.4414,
      "step": 3615
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018617143093021574,
      "loss": 2.4375,
      "step": 3616
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018616259699551253,
      "loss": 2.4102,
      "step": 3617
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018615376044979958,
      "loss": 2.5156,
      "step": 3618
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018614492129334472,
      "loss": 2.4258,
      "step": 3619
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001861360795264158,
      "loss": 2.5469,
      "step": 3620
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018612723514928068,
      "loss": 2.4805,
      "step": 3621
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018611838816220748,
      "loss": 2.3711,
      "step": 3622
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001861095385654642,
      "loss": 2.2695,
      "step": 3623
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018610068635931906,
      "loss": 2.3906,
      "step": 3624
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001860918315440403,
      "loss": 2.332,
      "step": 3625
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018608297411989623,
      "loss": 2.3281,
      "step": 3626
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018607411408715529,
      "loss": 2.5469,
      "step": 3627
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018606525144608595,
      "loss": 2.4531,
      "step": 3628
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018605638619695677,
      "loss": 2.4375,
      "step": 3629
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018604751834003644,
      "loss": 2.3633,
      "step": 3630
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018603864787559363,
      "loss": 2.4219,
      "step": 3631
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001860297748038972,
      "loss": 2.4492,
      "step": 3632
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018602089912521601,
      "loss": 2.4219,
      "step": 3633
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018601202083981896,
      "loss": 2.3984,
      "step": 3634
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018600313994797518,
      "loss": 2.3828,
      "step": 3635
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018599425644995377,
      "loss": 2.3281,
      "step": 3636
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018598537034602387,
      "loss": 2.5781,
      "step": 3637
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001859764816364548,
      "loss": 2.4219,
      "step": 3638
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018596759032151599,
      "loss": 2.5234,
      "step": 3639
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018595869640147674,
      "loss": 2.3711,
      "step": 3640
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018594979987660665,
      "loss": 2.3262,
      "step": 3641
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001859409007471753,
      "loss": 2.3789,
      "step": 3642
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018593199901345238,
      "loss": 2.3008,
      "step": 3643
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018592309467570759,
      "loss": 2.6055,
      "step": 3644
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001859141877342108,
      "loss": 2.4961,
      "step": 3645
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001859052781892319,
      "loss": 2.3711,
      "step": 3646
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001858963660410409,
      "loss": 2.4492,
      "step": 3647
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018588745128990784,
      "loss": 2.4492,
      "step": 3648
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001858785339361029,
      "loss": 2.3359,
      "step": 3649
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018586961397989627,
      "loss": 2.3516,
      "step": 3650
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018586069142155829,
      "loss": 2.3633,
      "step": 3651
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018585176626135932,
      "loss": 2.2852,
      "step": 3652
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001858428384995698,
      "loss": 2.3359,
      "step": 3653
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018583390813646033,
      "loss": 2.5156,
      "step": 3654
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018582497517230148,
      "loss": 2.5352,
      "step": 3655
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018581603960736398,
      "loss": 2.3086,
      "step": 3656
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018580710144191857,
      "loss": 2.5625,
      "step": 3657
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018579816067623614,
      "loss": 2.2617,
      "step": 3658
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001857892173105876,
      "loss": 2.3945,
      "step": 3659
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018578027134524397,
      "loss": 2.2617,
      "step": 3660
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018577132278047635,
      "loss": 2.3398,
      "step": 3661
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018576237161655592,
      "loss": 2.3984,
      "step": 3662
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001857534178537539,
      "loss": 2.2578,
      "step": 3663
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018574446149234164,
      "loss": 2.4258,
      "step": 3664
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018573550253259054,
      "loss": 2.3242,
      "step": 3665
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001857265409747721,
      "loss": 2.4727,
      "step": 3666
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018571757681915787,
      "loss": 2.4609,
      "step": 3667
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001857086100660195,
      "loss": 2.5977,
      "step": 3668
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001856996407156287,
      "loss": 2.5039,
      "step": 3669
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018569066876825727,
      "loss": 2.3555,
      "step": 3670
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018568169422417712,
      "loss": 2.4141,
      "step": 3671
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0018567271708366017,
      "loss": 2.5156,
      "step": 3672
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001856637373469785,
      "loss": 2.4766,
      "step": 3673
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.001856547550144042,
      "loss": 2.5039,
      "step": 3674
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018564577008620942,
      "loss": 2.5117,
      "step": 3675
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.001856367825626665,
      "loss": 2.4062,
      "step": 3676
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018562779244404774,
      "loss": 2.5039,
      "step": 3677
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018561879973062565,
      "loss": 2.4414,
      "step": 3678
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018560980442267265,
      "loss": 2.2559,
      "step": 3679
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018560080652046138,
      "loss": 2.3398,
      "step": 3680
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.001855918060242645,
      "loss": 2.3555,
      "step": 3681
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018558280293435475,
      "loss": 2.5234,
      "step": 3682
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.001855737972510049,
      "loss": 2.4023,
      "step": 3683
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018556478897448793,
      "loss": 2.5781,
      "step": 3684
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.001855557781050768,
      "loss": 2.6016,
      "step": 3685
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018554676464304456,
      "loss": 2.3789,
      "step": 3686
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018553774858866433,
      "loss": 2.5234,
      "step": 3687
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018552872994220934,
      "loss": 2.5,
      "step": 3688
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018551970870395288,
      "loss": 2.3945,
      "step": 3689
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018551068487416835,
      "loss": 2.2578,
      "step": 3690
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018550165845312918,
      "loss": 2.4883,
      "step": 3691
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018549262944110893,
      "loss": 2.4492,
      "step": 3692
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018548359783838115,
      "loss": 2.5234,
      "step": 3693
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018547456364521953,
      "loss": 2.4961,
      "step": 3694
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018546552686189788,
      "loss": 2.2598,
      "step": 3695
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018545648748869007,
      "loss": 2.4531,
      "step": 3696
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018544744552586995,
      "loss": 2.5156,
      "step": 3697
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018543840097371153,
      "loss": 2.4648,
      "step": 3698
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018542935383248894,
      "loss": 2.4766,
      "step": 3699
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018542030410247632,
      "loss": 2.3125,
      "step": 3700
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018541125178394788,
      "loss": 2.1836,
      "step": 3701
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018540219687717793,
      "loss": 2.3945,
      "step": 3702
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018539313938244094,
      "loss": 2.3633,
      "step": 3703
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018538407930001127,
      "loss": 2.7344,
      "step": 3704
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018537501663016354,
      "loss": 2.2852,
      "step": 3705
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018536595137317237,
      "loss": 2.4414,
      "step": 3706
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.001853568835293125,
      "loss": 2.1562,
      "step": 3707
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018534781309885863,
      "loss": 2.6875,
      "step": 3708
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.001853387400820857,
      "loss": 2.3008,
      "step": 3709
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.001853296644792686,
      "loss": 2.4531,
      "step": 3710
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018532058629068238,
      "loss": 2.5664,
      "step": 3711
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018531150551660215,
      "loss": 2.2617,
      "step": 3712
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018530242215730305,
      "loss": 2.5039,
      "step": 3713
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018529333621306037,
      "loss": 2.4453,
      "step": 3714
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018528424768414942,
      "loss": 2.4336,
      "step": 3715
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018527515657084563,
      "loss": 2.4258,
      "step": 3716
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.001852660628734245,
      "loss": 2.2656,
      "step": 3717
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018525696659216157,
      "loss": 2.3906,
      "step": 3718
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.001852478677273325,
      "loss": 2.1953,
      "step": 3719
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018523876627921298,
      "loss": 2.4414,
      "step": 3720
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.001852296622480789,
      "loss": 2.3594,
      "step": 3721
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018522055563420605,
      "loss": 2.4648,
      "step": 3722
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018521144643787047,
      "loss": 2.4258,
      "step": 3723
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018520233465934813,
      "loss": 2.4336,
      "step": 3724
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018519322029891519,
      "loss": 2.5156,
      "step": 3725
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018518410335684782,
      "loss": 2.5391,
      "step": 3726
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018517498383342232,
      "loss": 2.5039,
      "step": 3727
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00185165861728915,
      "loss": 2.4688,
      "step": 3728
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018515673704360234,
      "loss": 2.4062,
      "step": 3729
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018514760977776082,
      "loss": 2.4531,
      "step": 3730
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018513847993166703,
      "loss": 2.3984,
      "step": 3731
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018512934750559765,
      "loss": 2.3242,
      "step": 3732
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018512021249982938,
      "loss": 2.6133,
      "step": 3733
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018511107491463905,
      "loss": 2.5117,
      "step": 3734
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.001851019347503036,
      "loss": 2.4688,
      "step": 3735
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018509279200710003,
      "loss": 2.3125,
      "step": 3736
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018508364668530528,
      "loss": 2.4453,
      "step": 3737
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018507449878519657,
      "loss": 2.5312,
      "step": 3738
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018506534830705112,
      "loss": 2.5156,
      "step": 3739
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018505619525114615,
      "loss": 2.3945,
      "step": 3740
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.001850470396177591,
      "loss": 2.5391,
      "step": 3741
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018503788140716737,
      "loss": 2.3594,
      "step": 3742
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018502872061964852,
      "loss": 2.3711,
      "step": 3743
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.001850195572554801,
      "loss": 2.4922,
      "step": 3744
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018501039131493986,
      "loss": 2.3477,
      "step": 3745
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018500122279830552,
      "loss": 2.4531,
      "step": 3746
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018499205170585489,
      "loss": 2.3828,
      "step": 3747
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018498287803786592,
      "loss": 2.168,
      "step": 3748
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018497370179461662,
      "loss": 2.4531,
      "step": 3749
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00184964522976385,
      "loss": 2.6133,
      "step": 3750
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018495534158344924,
      "loss": 2.3594,
      "step": 3751
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018494615761608757,
      "loss": 2.4727,
      "step": 3752
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.001849369710745783,
      "loss": 2.4062,
      "step": 3753
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.001849277819591998,
      "loss": 2.2891,
      "step": 3754
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018491859027023056,
      "loss": 2.5156,
      "step": 3755
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018490939600794905,
      "loss": 2.3398,
      "step": 3756
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018490019917263396,
      "loss": 2.4414,
      "step": 3757
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018489099976456394,
      "loss": 2.4844,
      "step": 3758
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.001848817977840178,
      "loss": 2.6406,
      "step": 3759
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018487259323127433,
      "loss": 2.3047,
      "step": 3760
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018486338610661252,
      "loss": 2.293,
      "step": 3761
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018485417641031135,
      "loss": 2.2891,
      "step": 3762
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.001848449641426499,
      "loss": 2.4062,
      "step": 3763
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018483574930390735,
      "loss": 2.4805,
      "step": 3764
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018482653189436289,
      "loss": 2.2695,
      "step": 3765
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018481731191429592,
      "loss": 2.5391,
      "step": 3766
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0018480808936398576,
      "loss": 2.2676,
      "step": 3767
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001847988642437119,
      "loss": 2.4062,
      "step": 3768
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018478963655375394,
      "loss": 2.2539,
      "step": 3769
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018478040629439146,
      "loss": 2.375,
      "step": 3770
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018477117346590419,
      "loss": 2.4492,
      "step": 3771
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001847619380685719,
      "loss": 2.3008,
      "step": 3772
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018475270010267447,
      "loss": 2.5234,
      "step": 3773
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001847434595684918,
      "loss": 2.3867,
      "step": 3774
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018473421646630398,
      "loss": 2.3047,
      "step": 3775
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018472497079639104,
      "loss": 2.4336,
      "step": 3776
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018471572255903319,
      "loss": 2.3945,
      "step": 3777
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018470647175451065,
      "loss": 2.4648,
      "step": 3778
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001846972183831038,
      "loss": 2.5391,
      "step": 3779
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00184687962445093,
      "loss": 2.6445,
      "step": 3780
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018467870394075876,
      "loss": 2.4219,
      "step": 3781
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018466944287038162,
      "loss": 2.457,
      "step": 3782
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018466017923424228,
      "loss": 2.3867,
      "step": 3783
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001846509130326214,
      "loss": 2.4531,
      "step": 3784
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018464164426579977,
      "loss": 2.4727,
      "step": 3785
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001846323729340583,
      "loss": 2.3594,
      "step": 3786
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018462309903767794,
      "loss": 2.4648,
      "step": 3787
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018461382257693969,
      "loss": 2.3359,
      "step": 3788
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018460454355212468,
      "loss": 2.457,
      "step": 3789
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001845952619635141,
      "loss": 2.4727,
      "step": 3790
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001845859778113892,
      "loss": 2.5547,
      "step": 3791
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018457669109603132,
      "loss": 2.4766,
      "step": 3792
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001845674018177219,
      "loss": 2.4336,
      "step": 3793
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001845581099767424,
      "loss": 2.6328,
      "step": 3794
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001845488155733744,
      "loss": 2.4297,
      "step": 3795
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018453951860789956,
      "loss": 2.5859,
      "step": 3796
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018453021908059963,
      "loss": 2.4688,
      "step": 3797
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001845209169917564,
      "loss": 2.5742,
      "step": 3798
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018451161234165172,
      "loss": 2.7617,
      "step": 3799
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001845023051305676,
      "loss": 2.4102,
      "step": 3800
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018449299535878607,
      "loss": 2.3164,
      "step": 3801
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018448368302658924,
      "loss": 2.5625,
      "step": 3802
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018447436813425928,
      "loss": 2.4648,
      "step": 3803
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001844650506820785,
      "loss": 2.3516,
      "step": 3804
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018445573067032922,
      "loss": 2.4883,
      "step": 3805
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001844464080992939,
      "loss": 2.3359,
      "step": 3806
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018443708296925498,
      "loss": 2.5039,
      "step": 3807
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018442775528049512,
      "loss": 2.4258,
      "step": 3808
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018441842503329694,
      "loss": 2.2617,
      "step": 3809
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001844090922279432,
      "loss": 2.4102,
      "step": 3810
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018439975686471667,
      "loss": 2.4062,
      "step": 3811
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001843904189439003,
      "loss": 2.4961,
      "step": 3812
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00184381078465777,
      "loss": 2.5586,
      "step": 3813
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018437173543062986,
      "loss": 2.5938,
      "step": 3814
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018436238983874198,
      "loss": 2.3359,
      "step": 3815
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001843530416903966,
      "loss": 2.5508,
      "step": 3816
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018434369098587694,
      "loss": 2.3945,
      "step": 3817
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001843343377254664,
      "loss": 2.3281,
      "step": 3818
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018432498190944842,
      "loss": 2.4336,
      "step": 3819
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001843156235381065,
      "loss": 2.4258,
      "step": 3820
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001843062626117242,
      "loss": 2.3047,
      "step": 3821
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018429689913058522,
      "loss": 2.3359,
      "step": 3822
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001842875330949733,
      "loss": 2.5312,
      "step": 3823
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018427816450517227,
      "loss": 2.3438,
      "step": 3824
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00184268793361466,
      "loss": 2.3594,
      "step": 3825
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001842594196641385,
      "loss": 2.4375,
      "step": 3826
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018425004341347383,
      "loss": 2.6055,
      "step": 3827
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018424066460975604,
      "loss": 2.4961,
      "step": 3828
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018423128325326945,
      "loss": 2.1543,
      "step": 3829
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018422189934429825,
      "loss": 2.3828,
      "step": 3830
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018421251288312688,
      "loss": 2.4727,
      "step": 3831
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018420312387003972,
      "loss": 2.457,
      "step": 3832
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018419373230532134,
      "loss": 2.373,
      "step": 3833
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018418433818925633,
      "loss": 2.4883,
      "step": 3834
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001841749415221293,
      "loss": 2.4336,
      "step": 3835
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018416554230422507,
      "loss": 2.5625,
      "step": 3836
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018415614053582843,
      "loss": 2.3047,
      "step": 3837
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001841467362172243,
      "loss": 2.418,
      "step": 3838
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018413732934869764,
      "loss": 2.3086,
      "step": 3839
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018412791993053354,
      "loss": 2.4102,
      "step": 3840
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018411850796301713,
      "loss": 2.5469,
      "step": 3841
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.001841090934464336,
      "loss": 2.5156,
      "step": 3842
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018409967638106826,
      "loss": 2.168,
      "step": 3843
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018409025676720647,
      "loss": 2.4492,
      "step": 3844
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018408083460513369,
      "loss": 2.4688,
      "step": 3845
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018407140989513543,
      "loss": 2.4805,
      "step": 3846
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018406198263749727,
      "loss": 2.3867,
      "step": 3847
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018405255283250495,
      "loss": 2.3398,
      "step": 3848
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018404312048044416,
      "loss": 2.5898,
      "step": 3849
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018403368558160074,
      "loss": 2.2129,
      "step": 3850
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018402424813626062,
      "loss": 2.332,
      "step": 3851
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018401480814470982,
      "loss": 2.5156,
      "step": 3852
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018400536560723429,
      "loss": 2.5781,
      "step": 3853
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018399592052412029,
      "loss": 2.4297,
      "step": 3854
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018398647289565395,
      "loss": 2.4141,
      "step": 3855
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018397702272212161,
      "loss": 2.4258,
      "step": 3856
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018396757000380965,
      "loss": 2.5,
      "step": 3857
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018395811474100452,
      "loss": 2.3828,
      "step": 3858
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018394865693399272,
      "loss": 2.5234,
      "step": 3859
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0018393919658306083,
      "loss": 2.3867,
      "step": 3860
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018392973368849556,
      "loss": 2.3867,
      "step": 3861
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.001839202682505837,
      "loss": 2.4766,
      "step": 3862
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018391080026961201,
      "loss": 2.4492,
      "step": 3863
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.001839013297458675,
      "loss": 2.4141,
      "step": 3864
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018389185667963704,
      "loss": 2.4727,
      "step": 3865
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018388238107120776,
      "loss": 2.543,
      "step": 3866
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018387290292086684,
      "loss": 2.4961,
      "step": 3867
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.001838634222289014,
      "loss": 2.2422,
      "step": 3868
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018385393899559882,
      "loss": 2.3672,
      "step": 3869
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018384445322124643,
      "loss": 2.4258,
      "step": 3870
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018383496490613173,
      "loss": 2.3477,
      "step": 3871
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018382547405054218,
      "loss": 2.5547,
      "step": 3872
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018381598065476542,
      "loss": 2.5273,
      "step": 3873
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018380648471908912,
      "loss": 2.5273,
      "step": 3874
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018379698624380106,
      "loss": 2.293,
      "step": 3875
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018378748522918905,
      "loss": 2.2715,
      "step": 3876
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018377798167554102,
      "loss": 2.5391,
      "step": 3877
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018376847558314493,
      "loss": 2.3574,
      "step": 3878
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018375896695228887,
      "loss": 2.5078,
      "step": 3879
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018374945578326098,
      "loss": 2.4648,
      "step": 3880
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018373994207634952,
      "loss": 2.2773,
      "step": 3881
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.001837304258318427,
      "loss": 2.707,
      "step": 3882
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018372090705002894,
      "loss": 2.5859,
      "step": 3883
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018371138573119673,
      "loss": 2.3594,
      "step": 3884
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018370186187563451,
      "loss": 2.3516,
      "step": 3885
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018369233548363093,
      "loss": 2.3516,
      "step": 3886
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018368280655547472,
      "loss": 2.3242,
      "step": 3887
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018367327509145456,
      "loss": 2.3477,
      "step": 3888
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018366374109185931,
      "loss": 2.3359,
      "step": 3889
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018365420455697787,
      "loss": 2.4844,
      "step": 3890
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018364466548709925,
      "loss": 2.457,
      "step": 3891
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018363512388251256,
      "loss": 2.4453,
      "step": 3892
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018362557974350682,
      "loss": 2.4414,
      "step": 3893
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018361603307037136,
      "loss": 2.4648,
      "step": 3894
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018360648386339543,
      "loss": 2.4609,
      "step": 3895
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.001835969321228684,
      "loss": 2.3164,
      "step": 3896
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018358737784907975,
      "loss": 2.543,
      "step": 3897
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018357782104231894,
      "loss": 2.4062,
      "step": 3898
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018356826170287564,
      "loss": 2.4219,
      "step": 3899
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.001835586998310395,
      "loss": 2.4648,
      "step": 3900
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.001835491354271003,
      "loss": 2.4805,
      "step": 3901
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018353956849134782,
      "loss": 2.3711,
      "step": 3902
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018352999902407205,
      "loss": 2.4766,
      "step": 3903
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018352042702556289,
      "loss": 2.3555,
      "step": 3904
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018351085249611043,
      "loss": 2.4102,
      "step": 3905
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018350127543600486,
      "loss": 2.4258,
      "step": 3906
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018349169584553633,
      "loss": 2.4766,
      "step": 3907
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.001834821137249952,
      "loss": 2.3984,
      "step": 3908
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018347252907467177,
      "loss": 2.3613,
      "step": 3909
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018346294189485652,
      "loss": 2.3594,
      "step": 3910
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018345335218583995,
      "loss": 2.3555,
      "step": 3911
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.001834437599479127,
      "loss": 2.4961,
      "step": 3912
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018343416518136547,
      "loss": 2.4102,
      "step": 3913
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018342456788648894,
      "loss": 2.3359,
      "step": 3914
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018341496806357394,
      "loss": 2.5586,
      "step": 3915
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018340536571291141,
      "loss": 2.3359,
      "step": 3916
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018339576083479235,
      "loss": 2.6172,
      "step": 3917
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018338615342950782,
      "loss": 2.5469,
      "step": 3918
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018337654349734889,
      "loss": 2.4766,
      "step": 3919
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018336693103860684,
      "loss": 2.375,
      "step": 3920
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.001833573160535729,
      "loss": 2.3906,
      "step": 3921
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.001833476985425385,
      "loss": 2.25,
      "step": 3922
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018333807850579506,
      "loss": 2.5039,
      "step": 3923
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018332845594363407,
      "loss": 2.5781,
      "step": 3924
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018331883085634718,
      "loss": 2.418,
      "step": 3925
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00183309203244226,
      "loss": 2.4609,
      "step": 3926
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.001832995731075623,
      "loss": 2.4062,
      "step": 3927
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018328994044664792,
      "loss": 2.3828,
      "step": 3928
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018328030526177477,
      "loss": 2.4141,
      "step": 3929
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.001832706675532348,
      "loss": 2.5664,
      "step": 3930
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.001832610273213201,
      "loss": 2.4609,
      "step": 3931
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018325138456632272,
      "loss": 2.4219,
      "step": 3932
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018324173928853495,
      "loss": 2.4102,
      "step": 3933
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018323209148824904,
      "loss": 2.4297,
      "step": 3934
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018322244116575738,
      "loss": 2.4062,
      "step": 3935
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018321278832135236,
      "loss": 2.2695,
      "step": 3936
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018320313295532653,
      "loss": 2.5469,
      "step": 3937
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018319347506797247,
      "loss": 2.7305,
      "step": 3938
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018318381465958283,
      "loss": 2.4102,
      "step": 3939
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018317415173045033,
      "loss": 2.3359,
      "step": 3940
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018316448628086786,
      "loss": 2.4297,
      "step": 3941
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018315481831112828,
      "loss": 2.3516,
      "step": 3942
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018314514782152454,
      "loss": 2.4297,
      "step": 3943
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.001831354748123497,
      "loss": 2.4492,
      "step": 3944
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018312579928389692,
      "loss": 2.3242,
      "step": 3945
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018311612123645933,
      "loss": 2.5469,
      "step": 3946
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018310644067033026,
      "loss": 2.4297,
      "step": 3947
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018309675758580307,
      "loss": 2.4219,
      "step": 3948
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018308707198317117,
      "loss": 2.4023,
      "step": 3949
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018307738386272804,
      "loss": 2.4258,
      "step": 3950
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018306769322476728,
      "loss": 2.2891,
      "step": 3951
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0018305800006958256,
      "loss": 2.5078,
      "step": 3952
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.001830483043974676,
      "loss": 2.2422,
      "step": 3953
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018303860620871625,
      "loss": 2.5898,
      "step": 3954
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018302890550362235,
      "loss": 2.3516,
      "step": 3955
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018301920228247987,
      "loss": 2.3672,
      "step": 3956
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018300949654558286,
      "loss": 2.457,
      "step": 3957
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018299978829322545,
      "loss": 2.4727,
      "step": 3958
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.001829900775257018,
      "loss": 2.4375,
      "step": 3959
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.001829803642433062,
      "loss": 2.2266,
      "step": 3960
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00182970648446333,
      "loss": 2.2305,
      "step": 3961
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.001829609301350766,
      "loss": 2.5586,
      "step": 3962
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.001829512093098315,
      "loss": 2.3867,
      "step": 3963
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018294148597089227,
      "loss": 2.207,
      "step": 3964
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018293176011855358,
      "loss": 2.2402,
      "step": 3965
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018292203175311016,
      "loss": 2.4805,
      "step": 3966
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018291230087485678,
      "loss": 2.4102,
      "step": 3967
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018290256748408834,
      "loss": 2.418,
      "step": 3968
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018289283158109976,
      "loss": 2.2969,
      "step": 3969
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018288309316618612,
      "loss": 2.4688,
      "step": 3970
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.001828733522396425,
      "loss": 2.4805,
      "step": 3971
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018286360880176407,
      "loss": 2.3594,
      "step": 3972
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018285386285284613,
      "loss": 2.7852,
      "step": 3973
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018284411439318396,
      "loss": 2.4453,
      "step": 3974
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00182834363423073,
      "loss": 2.375,
      "step": 3975
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018282460994280875,
      "loss": 2.5078,
      "step": 3976
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018281485395268673,
      "loss": 2.2852,
      "step": 3977
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018280509545300263,
      "loss": 2.3906,
      "step": 3978
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018279533444405212,
      "loss": 2.3516,
      "step": 3979
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018278557092613102,
      "loss": 2.4297,
      "step": 3980
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.001827758048995352,
      "loss": 2.3281,
      "step": 3981
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018276603636456054,
      "loss": 2.3906,
      "step": 3982
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018275626532150314,
      "loss": 2.7656,
      "step": 3983
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018274649177065908,
      "loss": 2.4531,
      "step": 3984
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018273671571232449,
      "loss": 2.2969,
      "step": 3985
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018272693714679565,
      "loss": 2.5586,
      "step": 3986
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018271715607436885,
      "loss": 2.6797,
      "step": 3987
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018270737249534053,
      "loss": 2.4297,
      "step": 3988
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018269758641000717,
      "loss": 2.3906,
      "step": 3989
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018268779781866525,
      "loss": 2.3594,
      "step": 3990
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018267800672161145,
      "loss": 2.3477,
      "step": 3991
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018266821311914247,
      "loss": 2.5312,
      "step": 3992
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.001826584170115551,
      "loss": 2.207,
      "step": 3993
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018264861839914618,
      "loss": 2.4141,
      "step": 3994
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018263881728221262,
      "loss": 2.5547,
      "step": 3995
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018262901366105143,
      "loss": 2.4609,
      "step": 3996
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018261920753595974,
      "loss": 2.2891,
      "step": 3997
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018260939890723466,
      "loss": 2.5898,
      "step": 3998
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018259958777517343,
      "loss": 2.5352,
      "step": 3999
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018258977414007337,
      "loss": 2.4883,
      "step": 4000
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018257995800223183,
      "loss": 2.3672,
      "step": 4001
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018257013936194633,
      "loss": 2.6055,
      "step": 4002
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.001825603182195144,
      "loss": 2.5156,
      "step": 4003
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.001825504945752336,
      "loss": 2.5,
      "step": 4004
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.001825406684294017,
      "loss": 2.4453,
      "step": 4005
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018253083978231636,
      "loss": 2.6094,
      "step": 4006
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.001825210086342755,
      "loss": 2.4141,
      "step": 4007
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018251117498557703,
      "loss": 2.3652,
      "step": 4008
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.001825013388365189,
      "loss": 2.291,
      "step": 4009
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018249150018739922,
      "loss": 2.4297,
      "step": 4010
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.001824816590385161,
      "loss": 2.3184,
      "step": 4011
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.001824718153901678,
      "loss": 2.418,
      "step": 4012
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018246196924265256,
      "loss": 2.3047,
      "step": 4013
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018245212059626878,
      "loss": 2.5547,
      "step": 4014
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018244226945131493,
      "loss": 2.4961,
      "step": 4015
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.001824324158080895,
      "loss": 2.4219,
      "step": 4016
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018242255966689107,
      "loss": 2.3516,
      "step": 4017
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018241270102801836,
      "loss": 2.375,
      "step": 4018
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.001824028398917701,
      "loss": 2.3281,
      "step": 4019
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018239297625844513,
      "loss": 2.4336,
      "step": 4020
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018238311012834232,
      "loss": 2.457,
      "step": 4021
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018237324150176067,
      "loss": 2.4141,
      "step": 4022
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018236337037899918,
      "loss": 2.2852,
      "step": 4023
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018235349676035705,
      "loss": 2.4297,
      "step": 4024
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018234362064613345,
      "loss": 2.4688,
      "step": 4025
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.001823337420366277,
      "loss": 2.6602,
      "step": 4026
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018232386093213907,
      "loss": 2.4492,
      "step": 4027
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018231397733296704,
      "loss": 2.2207,
      "step": 4028
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018230409123941112,
      "loss": 2.2012,
      "step": 4029
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018229420265177087,
      "loss": 2.4648,
      "step": 4030
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018228431157034596,
      "loss": 2.6055,
      "step": 4031
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018227441799543614,
      "loss": 2.5898,
      "step": 4032
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018226452192734118,
      "loss": 2.5898,
      "step": 4033
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00182254623366361,
      "loss": 2.6523,
      "step": 4034
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018224472231279552,
      "loss": 2.4297,
      "step": 4035
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018223481876694478,
      "loss": 2.6641,
      "step": 4036
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018222491272910895,
      "loss": 2.4375,
      "step": 4037
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018221500419958816,
      "loss": 2.3438,
      "step": 4038
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018220509317868267,
      "loss": 2.4414,
      "step": 4039
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018219517966669284,
      "loss": 2.4141,
      "step": 4040
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018218526366391905,
      "loss": 2.5625,
      "step": 4041
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018217534517066182,
      "loss": 2.5195,
      "step": 4042
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018216542418722172,
      "loss": 2.4648,
      "step": 4043
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018215550071389935,
      "loss": 2.3711,
      "step": 4044
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018214557475099541,
      "loss": 2.3613,
      "step": 4045
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0018213564629881078,
      "loss": 2.2344,
      "step": 4046
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018212571535764627,
      "loss": 2.5625,
      "step": 4047
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.001821157819278028,
      "loss": 2.3242,
      "step": 4048
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018210584600958138,
      "loss": 2.5938,
      "step": 4049
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018209590760328313,
      "loss": 2.5781,
      "step": 4050
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018208596670920923,
      "loss": 2.25,
      "step": 4051
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018207602332766088,
      "loss": 2.4727,
      "step": 4052
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018206607745893941,
      "loss": 2.4531,
      "step": 4053
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018205612910334628,
      "loss": 2.4336,
      "step": 4054
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018204617826118286,
      "loss": 2.3945,
      "step": 4055
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018203622493275073,
      "loss": 2.2969,
      "step": 4056
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.001820262691183515,
      "loss": 2.3789,
      "step": 4057
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.001820163108182869,
      "loss": 2.4297,
      "step": 4058
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018200635003285865,
      "loss": 2.457,
      "step": 4059
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018199638676236864,
      "loss": 2.5234,
      "step": 4060
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018198642100711877,
      "loss": 2.4609,
      "step": 4061
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018197645276741103,
      "loss": 2.5664,
      "step": 4062
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018196648204354747,
      "loss": 2.4414,
      "step": 4063
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018195650883583029,
      "loss": 2.4062,
      "step": 4064
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.001819465331445617,
      "loss": 2.4414,
      "step": 4065
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018193655497004393,
      "loss": 2.4375,
      "step": 4066
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.001819265743125794,
      "loss": 2.5938,
      "step": 4067
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.001819165911724706,
      "loss": 2.375,
      "step": 4068
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018190660555001995,
      "loss": 2.4766,
      "step": 4069
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018189661744553015,
      "loss": 2.4961,
      "step": 4070
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.001818866268593038,
      "loss": 2.332,
      "step": 4071
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018187663379164367,
      "loss": 2.3281,
      "step": 4072
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018186663824285262,
      "loss": 2.332,
      "step": 4073
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018185664021323348,
      "loss": 2.4023,
      "step": 4074
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018184663970308929,
      "loss": 2.2617,
      "step": 4075
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018183663671272304,
      "loss": 2.418,
      "step": 4076
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018182663124243787,
      "loss": 2.5273,
      "step": 4077
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018181662329253704,
      "loss": 2.4102,
      "step": 4078
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018180661286332372,
      "loss": 2.5312,
      "step": 4079
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.001817965999551013,
      "loss": 2.4336,
      "step": 4080
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018178658456817326,
      "loss": 2.4023,
      "step": 4081
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018177656670284304,
      "loss": 2.5938,
      "step": 4082
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018176654635941425,
      "loss": 2.3672,
      "step": 4083
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018175652353819049,
      "loss": 2.4805,
      "step": 4084
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018174649823947551,
      "loss": 2.4102,
      "step": 4085
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018173647046357314,
      "loss": 2.5039,
      "step": 4086
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018172644021078718,
      "loss": 2.5469,
      "step": 4087
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018171640748142167,
      "loss": 2.3281,
      "step": 4088
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018170637227578057,
      "loss": 2.3945,
      "step": 4089
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00181696334594168,
      "loss": 2.3672,
      "step": 4090
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018168629443688813,
      "loss": 2.4258,
      "step": 4091
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018167625180424522,
      "loss": 2.543,
      "step": 4092
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018166620669654362,
      "loss": 2.5195,
      "step": 4093
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018165615911408767,
      "loss": 2.3242,
      "step": 4094
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018164610905718186,
      "loss": 2.4883,
      "step": 4095
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018163605652613075,
      "loss": 2.3555,
      "step": 4096
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00181626001521239,
      "loss": 2.3984,
      "step": 4097
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018161594404281127,
      "loss": 2.4336,
      "step": 4098
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018160588409115235,
      "loss": 2.3164,
      "step": 4099
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018159582166656705,
      "loss": 2.5781,
      "step": 4100
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018158575676936036,
      "loss": 2.6094,
      "step": 4101
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018157568939983723,
      "loss": 2.4062,
      "step": 4102
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018156561955830275,
      "loss": 2.1973,
      "step": 4103
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018155554724506207,
      "loss": 2.5312,
      "step": 4104
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.001815454724604204,
      "loss": 2.5078,
      "step": 4105
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.001815353952046831,
      "loss": 2.6172,
      "step": 4106
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018152531547815545,
      "loss": 2.4297,
      "step": 4107
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018151523328114299,
      "loss": 2.4844,
      "step": 4108
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018150514861395117,
      "loss": 2.5312,
      "step": 4109
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.001814950614768856,
      "loss": 2.3867,
      "step": 4110
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00181484971870252,
      "loss": 2.6445,
      "step": 4111
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018147487979435608,
      "loss": 2.5195,
      "step": 4112
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018146478524950368,
      "loss": 2.5273,
      "step": 4113
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018145468823600069,
      "loss": 2.3711,
      "step": 4114
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018144458875415305,
      "loss": 2.457,
      "step": 4115
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018143448680426688,
      "loss": 2.4648,
      "step": 4116
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018142438238664827,
      "loss": 2.4219,
      "step": 4117
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018141427550160338,
      "loss": 2.7031,
      "step": 4118
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018140416614943853,
      "loss": 2.3633,
      "step": 4119
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018139405433046005,
      "loss": 2.5469,
      "step": 4120
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018138394004497433,
      "loss": 2.3984,
      "step": 4121
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018137382329328792,
      "loss": 2.4844,
      "step": 4122
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018136370407570736,
      "loss": 2.6367,
      "step": 4123
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018135358239253932,
      "loss": 2.4766,
      "step": 4124
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018134345824409048,
      "loss": 2.2656,
      "step": 4125
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.001813333316306677,
      "loss": 2.6406,
      "step": 4126
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018132320255257778,
      "loss": 2.3398,
      "step": 4127
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018131307101012766,
      "loss": 2.4961,
      "step": 4128
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018130293700362441,
      "loss": 2.4766,
      "step": 4129
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018129280053337511,
      "loss": 2.5273,
      "step": 4130
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018128266159968694,
      "loss": 2.4062,
      "step": 4131
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.001812725202028671,
      "loss": 2.3125,
      "step": 4132
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018126237634322293,
      "loss": 2.3828,
      "step": 4133
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018125223002106185,
      "loss": 2.4961,
      "step": 4134
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018124208123669128,
      "loss": 2.4336,
      "step": 4135
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018123192999041882,
      "loss": 2.3906,
      "step": 4136
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00181221776282552,
      "loss": 2.2461,
      "step": 4137
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.001812116201133986,
      "loss": 2.3086,
      "step": 4138
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0018120146148326633,
      "loss": 2.4023,
      "step": 4139
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018119130039246307,
      "loss": 2.3027,
      "step": 4140
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018118113684129666,
      "loss": 2.5312,
      "step": 4141
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018117097083007517,
      "loss": 2.2812,
      "step": 4142
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001811608023591066,
      "loss": 2.5508,
      "step": 4143
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018115063142869917,
      "loss": 2.4141,
      "step": 4144
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018114045803916102,
      "loss": 2.4531,
      "step": 4145
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018113028219080049,
      "loss": 2.2617,
      "step": 4146
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018112010388392585,
      "loss": 2.7969,
      "step": 4147
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018110992311884564,
      "loss": 2.4219,
      "step": 4148
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001810997398958683,
      "loss": 2.4492,
      "step": 4149
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018108955421530246,
      "loss": 2.3867,
      "step": 4150
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018107936607745679,
      "loss": 2.3867,
      "step": 4151
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018106917548263996,
      "loss": 2.4414,
      "step": 4152
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018105898243116084,
      "loss": 2.4219,
      "step": 4153
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001810487869233283,
      "loss": 2.6172,
      "step": 4154
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018103858895945125,
      "loss": 2.2422,
      "step": 4155
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018102838853983876,
      "loss": 2.4375,
      "step": 4156
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018101818566479998,
      "loss": 2.3672,
      "step": 4157
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00181007980334644,
      "loss": 2.3477,
      "step": 4158
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018099777254968012,
      "loss": 2.6016,
      "step": 4159
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001809875623102177,
      "loss": 2.4258,
      "step": 4160
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018097734961656608,
      "loss": 2.375,
      "step": 4161
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018096713446903482,
      "loss": 2.3672,
      "step": 4162
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018095691686793338,
      "loss": 2.3672,
      "step": 4163
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018094669681357144,
      "loss": 2.3398,
      "step": 4164
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001809364743062587,
      "loss": 2.4727,
      "step": 4165
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018092624934630494,
      "loss": 2.4102,
      "step": 4166
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018091602193401996,
      "loss": 2.4766,
      "step": 4167
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018090579206971374,
      "loss": 2.2695,
      "step": 4168
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018089555975369627,
      "loss": 2.4531,
      "step": 4169
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018088532498627761,
      "loss": 2.252,
      "step": 4170
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018087508776776788,
      "loss": 2.4219,
      "step": 4171
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018086484809847739,
      "loss": 2.4492,
      "step": 4172
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018085460597871636,
      "loss": 2.4805,
      "step": 4173
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018084436140879514,
      "loss": 2.457,
      "step": 4174
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018083411438902424,
      "loss": 2.3398,
      "step": 4175
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018082386491971411,
      "loss": 2.6094,
      "step": 4176
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018081361300117545,
      "loss": 2.2031,
      "step": 4177
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018080335863371881,
      "loss": 2.375,
      "step": 4178
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018079310181765501,
      "loss": 2.2461,
      "step": 4179
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001807828425532948,
      "loss": 2.3496,
      "step": 4180
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001807725808409491,
      "loss": 2.3633,
      "step": 4181
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001807623166809289,
      "loss": 2.375,
      "step": 4182
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018075205007354524,
      "loss": 2.2031,
      "step": 4183
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018074178101910917,
      "loss": 2.4492,
      "step": 4184
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018073150951793192,
      "loss": 2.1465,
      "step": 4185
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018072123557032476,
      "loss": 2.3477,
      "step": 4186
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00180710959176599,
      "loss": 2.5078,
      "step": 4187
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018070068033706607,
      "loss": 2.625,
      "step": 4188
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018069039905203742,
      "loss": 2.3516,
      "step": 4189
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018068011532182463,
      "loss": 2.5,
      "step": 4190
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018066982914673932,
      "loss": 2.7109,
      "step": 4191
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001806595405270932,
      "loss": 2.5234,
      "step": 4192
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018064924946319808,
      "loss": 2.5352,
      "step": 4193
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018063895595536576,
      "loss": 2.582,
      "step": 4194
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018062866000390818,
      "loss": 2.3867,
      "step": 4195
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001806183616091374,
      "loss": 2.3711,
      "step": 4196
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018060806077136538,
      "loss": 2.4375,
      "step": 4197
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018059775749090438,
      "loss": 2.3867,
      "step": 4198
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018058745176806658,
      "loss": 2.3125,
      "step": 4199
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018057714360316427,
      "loss": 2.6328,
      "step": 4200
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018056683299650983,
      "loss": 2.457,
      "step": 4201
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001805565199484157,
      "loss": 2.3125,
      "step": 4202
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001805462044591944,
      "loss": 2.6797,
      "step": 4203
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001805358865291585,
      "loss": 2.4922,
      "step": 4204
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018052556615862074,
      "loss": 2.4336,
      "step": 4205
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001805152433478938,
      "loss": 2.4414,
      "step": 4206
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001805049180972905,
      "loss": 2.5039,
      "step": 4207
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018049459040712374,
      "loss": 2.3711,
      "step": 4208
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018048426027770649,
      "loss": 2.5312,
      "step": 4209
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018047392770935177,
      "loss": 2.5,
      "step": 4210
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018046359270237268,
      "loss": 2.3203,
      "step": 4211
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018045325525708248,
      "loss": 2.418,
      "step": 4212
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018044291537379431,
      "loss": 2.375,
      "step": 4213
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018043257305282161,
      "loss": 2.2812,
      "step": 4214
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018042222829447773,
      "loss": 2.4414,
      "step": 4215
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018041188109907615,
      "loss": 2.4883,
      "step": 4216
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018040153146693045,
      "loss": 2.5059,
      "step": 4217
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018039117939835422,
      "loss": 2.5156,
      "step": 4218
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018038082489366118,
      "loss": 2.75,
      "step": 4219
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018037046795316514,
      "loss": 2.3945,
      "step": 4220
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018036010857717991,
      "loss": 2.4102,
      "step": 4221
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001803497467660194,
      "loss": 2.3633,
      "step": 4222
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018033938251999766,
      "loss": 2.5078,
      "step": 4223
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018032901583942872,
      "loss": 2.3398,
      "step": 4224
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018031864672462673,
      "loss": 2.543,
      "step": 4225
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001803082751759059,
      "loss": 2.6133,
      "step": 4226
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018029790119358056,
      "loss": 2.4883,
      "step": 4227
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018028752477796503,
      "loss": 2.5859,
      "step": 4228
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018027714592937377,
      "loss": 2.4023,
      "step": 4229
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018026676464812132,
      "loss": 2.5586,
      "step": 4230
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018025638093452222,
      "loss": 2.4727,
      "step": 4231
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0018024599478889116,
      "loss": 2.5039,
      "step": 4232
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0018023560621154284,
      "loss": 2.5508,
      "step": 4233
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0018022521520279211,
      "loss": 2.5742,
      "step": 4234
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0018021482176295385,
      "loss": 2.3594,
      "step": 4235
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0018020442589234298,
      "loss": 2.5117,
      "step": 4236
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0018019402759127457,
      "loss": 2.3555,
      "step": 4237
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0018018362686006368,
      "loss": 2.5742,
      "step": 4238
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0018017322369902554,
      "loss": 2.3594,
      "step": 4239
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0018016281810847533,
      "loss": 2.4492,
      "step": 4240
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0018015241008872843,
      "loss": 2.543,
      "step": 4241
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0018014199964010021,
      "loss": 2.5039,
      "step": 4242
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0018013158676290614,
      "loss": 2.5312,
      "step": 4243
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.001801211714574618,
      "loss": 2.5664,
      "step": 4244
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0018011075372408277,
      "loss": 2.1992,
      "step": 4245
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0018010033356308478,
      "loss": 2.5,
      "step": 4246
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.001800899109747835,
      "loss": 2.4883,
      "step": 4247
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.001800794859594949,
      "loss": 2.5547,
      "step": 4248
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.001800690585175348,
      "loss": 2.3984,
      "step": 4249
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0018005862864921922,
      "loss": 2.5508,
      "step": 4250
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0018004819635486422,
      "loss": 2.3398,
      "step": 4251
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0018003776163478594,
      "loss": 2.207,
      "step": 4252
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0018002732448930056,
      "loss": 2.3008,
      "step": 4253
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.001800168849187244,
      "loss": 2.4727,
      "step": 4254
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0018000644292337374,
      "loss": 2.5352,
      "step": 4255
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017999599850356508,
      "loss": 2.2578,
      "step": 4256
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017998555165961488,
      "loss": 2.3359,
      "step": 4257
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017997510239183975,
      "loss": 2.252,
      "step": 4258
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.001799646507005563,
      "loss": 2.5508,
      "step": 4259
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017995419658608123,
      "loss": 2.4219,
      "step": 4260
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017994374004873142,
      "loss": 2.3086,
      "step": 4261
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017993328108882368,
      "loss": 2.4492,
      "step": 4262
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017992281970667494,
      "loss": 2.5078,
      "step": 4263
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017991235590260224,
      "loss": 2.4688,
      "step": 4264
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017990188967692267,
      "loss": 2.4766,
      "step": 4265
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017989142102995336,
      "loss": 2.5156,
      "step": 4266
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017988094996201159,
      "loss": 2.3438,
      "step": 4267
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017987047647341462,
      "loss": 2.4062,
      "step": 4268
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017986000056447985,
      "loss": 2.543,
      "step": 4269
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017984952223552475,
      "loss": 2.5234,
      "step": 4270
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017983904148686683,
      "loss": 2.2422,
      "step": 4271
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017982855831882372,
      "loss": 2.2578,
      "step": 4272
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017981807273171305,
      "loss": 2.3633,
      "step": 4273
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017980758472585258,
      "loss": 2.5781,
      "step": 4274
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017979709430156015,
      "loss": 2.5078,
      "step": 4275
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017978660145915365,
      "loss": 2.4961,
      "step": 4276
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017977610619895105,
      "loss": 2.4141,
      "step": 4277
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017976560852127036,
      "loss": 2.373,
      "step": 4278
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017975510842642972,
      "loss": 2.3906,
      "step": 4279
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017974460591474732,
      "loss": 2.3164,
      "step": 4280
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.001797341009865414,
      "loss": 2.3906,
      "step": 4281
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017972359364213032,
      "loss": 2.5039,
      "step": 4282
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017971308388183252,
      "loss": 2.1914,
      "step": 4283
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017970257170596639,
      "loss": 2.3555,
      "step": 4284
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017969205711485055,
      "loss": 2.4023,
      "step": 4285
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017968154010880358,
      "loss": 2.4023,
      "step": 4286
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017967102068814423,
      "loss": 2.4062,
      "step": 4287
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017966049885319122,
      "loss": 2.5547,
      "step": 4288
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017964997460426344,
      "loss": 2.3516,
      "step": 4289
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017963944794167981,
      "loss": 2.3008,
      "step": 4290
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.001796289188657593,
      "loss": 2.5117,
      "step": 4291
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017961838737682097,
      "loss": 2.5312,
      "step": 4292
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017960785347518398,
      "loss": 2.5547,
      "step": 4293
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017959731716116751,
      "loss": 2.3867,
      "step": 4294
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017958677843509091,
      "loss": 2.4805,
      "step": 4295
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017957623729727347,
      "loss": 2.4922,
      "step": 4296
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017956569374803467,
      "loss": 2.4102,
      "step": 4297
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017955514778769395,
      "loss": 2.4023,
      "step": 4298
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017954459941657097,
      "loss": 2.4023,
      "step": 4299
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017953404863498533,
      "loss": 2.2109,
      "step": 4300
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017952349544325674,
      "loss": 2.2969,
      "step": 4301
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017951293984170503,
      "loss": 2.5547,
      "step": 4302
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017950238183065007,
      "loss": 2.3633,
      "step": 4303
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017949182141041176,
      "loss": 2.2617,
      "step": 4304
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017948125858131018,
      "loss": 2.3516,
      "step": 4305
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017947069334366538,
      "loss": 2.3711,
      "step": 4306
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.001794601256977975,
      "loss": 2.207,
      "step": 4307
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017944955564402681,
      "loss": 2.6094,
      "step": 4308
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017943898318267361,
      "loss": 2.3438,
      "step": 4309
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.001794284083140583,
      "loss": 2.3789,
      "step": 4310
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017941783103850128,
      "loss": 2.4023,
      "step": 4311
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017940725135632315,
      "loss": 2.2773,
      "step": 4312
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017939666926784443,
      "loss": 2.5586,
      "step": 4313
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017938608477338584,
      "loss": 2.5586,
      "step": 4314
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017937549787326809,
      "loss": 2.3242,
      "step": 4315
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017936490856781202,
      "loss": 2.4766,
      "step": 4316
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017935431685733856,
      "loss": 2.3906,
      "step": 4317
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017934372274216858,
      "loss": 2.3359,
      "step": 4318
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017933312622262323,
      "loss": 2.5742,
      "step": 4319
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017932252729902353,
      "loss": 2.5547,
      "step": 4320
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.001793119259716907,
      "loss": 2.0859,
      "step": 4321
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00179301322240946,
      "loss": 2.293,
      "step": 4322
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017929071610711072,
      "loss": 2.4102,
      "step": 4323
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.001792801075705063,
      "loss": 2.6406,
      "step": 4324
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0017926949663145421,
      "loss": 2.6445,
      "step": 4325
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00179258883290276,
      "loss": 2.4297,
      "step": 4326
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017924826754729323,
      "loss": 2.3828,
      "step": 4327
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017923764940282769,
      "loss": 2.582,
      "step": 4328
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017922702885720106,
      "loss": 2.2539,
      "step": 4329
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001792164059107352,
      "loss": 2.3711,
      "step": 4330
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017920578056375206,
      "loss": 2.2969,
      "step": 4331
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017919515281657357,
      "loss": 2.1172,
      "step": 4332
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017918452266952184,
      "loss": 2.2539,
      "step": 4333
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017917389012291893,
      "loss": 2.457,
      "step": 4334
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017916325517708712,
      "loss": 2.543,
      "step": 4335
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001791526178323486,
      "loss": 2.3438,
      "step": 4336
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017914197808902577,
      "loss": 2.4961,
      "step": 4337
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017913133594744104,
      "loss": 2.4805,
      "step": 4338
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017912069140791692,
      "loss": 2.5156,
      "step": 4339
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017911004447077592,
      "loss": 2.457,
      "step": 4340
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001790993951363407,
      "loss": 2.4922,
      "step": 4341
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017908874340493402,
      "loss": 2.4766,
      "step": 4342
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017907808927687863,
      "loss": 2.3672,
      "step": 4343
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017906743275249734,
      "loss": 2.5156,
      "step": 4344
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017905677383211315,
      "loss": 2.7031,
      "step": 4345
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017904611251604902,
      "loss": 2.3281,
      "step": 4346
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017903544880462801,
      "loss": 2.4922,
      "step": 4347
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001790247826981733,
      "loss": 2.2812,
      "step": 4348
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017901411419700807,
      "loss": 2.6016,
      "step": 4349
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017900344330145565,
      "loss": 2.4688,
      "step": 4350
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001789927700118394,
      "loss": 2.5547,
      "step": 4351
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017898209432848273,
      "loss": 2.4883,
      "step": 4352
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017897141625170916,
      "loss": 2.3555,
      "step": 4353
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017896073578184226,
      "loss": 2.4727,
      "step": 4354
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017895005291920572,
      "loss": 2.3438,
      "step": 4355
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017893936766412324,
      "loss": 2.6367,
      "step": 4356
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001789286800169186,
      "loss": 2.5781,
      "step": 4357
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001789179899779157,
      "loss": 2.3867,
      "step": 4358
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001789072975474385,
      "loss": 2.4688,
      "step": 4359
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017889660272581095,
      "loss": 2.3633,
      "step": 4360
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017888590551335716,
      "loss": 2.293,
      "step": 4361
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017887520591040134,
      "loss": 2.4297,
      "step": 4362
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001788645039172677,
      "loss": 2.4453,
      "step": 4363
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001788537995342805,
      "loss": 2.3203,
      "step": 4364
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001788430927617642,
      "loss": 2.4336,
      "step": 4365
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017883238360004317,
      "loss": 2.3945,
      "step": 4366
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017882167204944198,
      "loss": 2.2969,
      "step": 4367
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001788109581102852,
      "loss": 2.3438,
      "step": 4368
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001788002417828975,
      "loss": 2.4414,
      "step": 4369
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017878952306760367,
      "loss": 2.4336,
      "step": 4370
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017877880196472847,
      "loss": 2.5273,
      "step": 4371
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001787680784745968,
      "loss": 2.3867,
      "step": 4372
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001787573525975336,
      "loss": 2.4336,
      "step": 4373
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017874662433386393,
      "loss": 2.0879,
      "step": 4374
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017873589368391284,
      "loss": 2.5508,
      "step": 4375
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017872516064800557,
      "loss": 2.4727,
      "step": 4376
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017871442522646732,
      "loss": 2.5195,
      "step": 4377
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017870368741962344,
      "loss": 2.4141,
      "step": 4378
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001786929472277993,
      "loss": 2.2695,
      "step": 4379
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017868220465132034,
      "loss": 2.4844,
      "step": 4380
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017867145969051217,
      "loss": 2.4375,
      "step": 4381
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017866071234570035,
      "loss": 2.5469,
      "step": 4382
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017864996261721053,
      "loss": 2.5938,
      "step": 4383
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017863921050536846,
      "loss": 2.3906,
      "step": 4384
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017862845601050005,
      "loss": 2.4961,
      "step": 4385
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017861769913293114,
      "loss": 2.6641,
      "step": 4386
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001786069398729877,
      "loss": 2.377,
      "step": 4387
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017859617823099577,
      "loss": 2.3359,
      "step": 4388
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017858541420728146,
      "loss": 2.3359,
      "step": 4389
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017857464780217094,
      "loss": 2.4023,
      "step": 4390
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017856387901599052,
      "loss": 2.4062,
      "step": 4391
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017855310784906648,
      "loss": 2.5742,
      "step": 4392
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017854233430172526,
      "loss": 2.3184,
      "step": 4393
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001785315583742933,
      "loss": 2.3242,
      "step": 4394
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017852078006709718,
      "loss": 2.4648,
      "step": 4395
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017850999938046348,
      "loss": 2.6016,
      "step": 4396
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017849921631471891,
      "loss": 2.3359,
      "step": 4397
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017848843087019022,
      "loss": 2.543,
      "step": 4398
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017847764304720428,
      "loss": 2.5117,
      "step": 4399
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017846685284608795,
      "loss": 2.4766,
      "step": 4400
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017845606026716824,
      "loss": 2.4277,
      "step": 4401
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017844526531077222,
      "loss": 2.5352,
      "step": 4402
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017843446797722693,
      "loss": 2.6289,
      "step": 4403
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017842366826685964,
      "loss": 2.5312,
      "step": 4404
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017841286617999762,
      "loss": 2.4531,
      "step": 4405
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017840206171696813,
      "loss": 2.293,
      "step": 4406
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017839125487809867,
      "loss": 2.3672,
      "step": 4407
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017838044566371668,
      "loss": 2.4219,
      "step": 4408
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017836963407414973,
      "loss": 2.3711,
      "step": 4409
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001783588201097254,
      "loss": 2.4727,
      "step": 4410
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017834800377077148,
      "loss": 2.3984,
      "step": 4411
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017833718505761566,
      "loss": 2.3359,
      "step": 4412
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001783263639705858,
      "loss": 2.4922,
      "step": 4413
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017831554051000985,
      "loss": 2.1914,
      "step": 4414
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017830471467621576,
      "loss": 2.3496,
      "step": 4415
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001782938864695316,
      "loss": 2.4141,
      "step": 4416
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017828305589028548,
      "loss": 2.5938,
      "step": 4417
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0017827222293880565,
      "loss": 2.1758,
      "step": 4418
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017826138761542034,
      "loss": 2.5312,
      "step": 4419
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017825054992045794,
      "loss": 2.4688,
      "step": 4420
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001782397098542468,
      "loss": 2.3281,
      "step": 4421
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017822886741711546,
      "loss": 2.4062,
      "step": 4422
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017821802260939248,
      "loss": 2.3984,
      "step": 4423
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017820717543140649,
      "loss": 2.3242,
      "step": 4424
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017819632588348619,
      "loss": 2.4141,
      "step": 4425
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017818547396596031,
      "loss": 2.3945,
      "step": 4426
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001781746196791578,
      "loss": 2.332,
      "step": 4427
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001781637630234075,
      "loss": 2.3789,
      "step": 4428
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017815290399903843,
      "loss": 2.3945,
      "step": 4429
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017814204260637966,
      "loss": 2.4531,
      "step": 4430
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017813117884576029,
      "loss": 2.2734,
      "step": 4431
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017812031271750956,
      "loss": 2.3359,
      "step": 4432
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017810944422195676,
      "loss": 2.457,
      "step": 4433
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017809857335943124,
      "loss": 2.5195,
      "step": 4434
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001780877001302624,
      "loss": 2.3047,
      "step": 4435
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017807682453477973,
      "loss": 2.2891,
      "step": 4436
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001780659465733128,
      "loss": 2.5664,
      "step": 4437
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017805506624619127,
      "loss": 2.4258,
      "step": 4438
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017804418355374483,
      "loss": 2.5781,
      "step": 4439
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001780332984963033,
      "loss": 2.375,
      "step": 4440
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017802241107419646,
      "loss": 2.1816,
      "step": 4441
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017801152128775431,
      "loss": 2.5078,
      "step": 4442
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017800062913730676,
      "loss": 2.3672,
      "step": 4443
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017798973462318398,
      "loss": 2.3047,
      "step": 4444
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017797883774571606,
      "loss": 2.3203,
      "step": 4445
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017796793850523318,
      "loss": 2.4531,
      "step": 4446
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017795703690206568,
      "loss": 2.3945,
      "step": 4447
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017794613293654385,
      "loss": 2.3516,
      "step": 4448
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001779352266089982,
      "loss": 2.3398,
      "step": 4449
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017792431791975917,
      "loss": 2.3828,
      "step": 4450
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017791340686915732,
      "loss": 2.4844,
      "step": 4451
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001779024934575233,
      "loss": 2.6172,
      "step": 4452
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017789157768518787,
      "loss": 2.707,
      "step": 4453
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017788065955248176,
      "loss": 2.3789,
      "step": 4454
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017786973905973584,
      "loss": 2.3516,
      "step": 4455
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017785881620728105,
      "loss": 2.418,
      "step": 4456
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017784789099544837,
      "loss": 2.6133,
      "step": 4457
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001778369634245689,
      "loss": 2.4961,
      "step": 4458
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017782603349497373,
      "loss": 2.252,
      "step": 4459
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001778151012069941,
      "loss": 2.2383,
      "step": 4460
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017780416656096132,
      "loss": 2.4453,
      "step": 4461
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001777932295572067,
      "loss": 2.5117,
      "step": 4462
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001777822901960617,
      "loss": 2.4766,
      "step": 4463
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001777713484778578,
      "loss": 2.375,
      "step": 4464
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017776040440292658,
      "loss": 2.3359,
      "step": 4465
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017774945797159967,
      "loss": 2.5508,
      "step": 4466
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001777385091842088,
      "loss": 2.4883,
      "step": 4467
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017772755804108574,
      "loss": 2.4453,
      "step": 4468
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017771660454256235,
      "loss": 2.2969,
      "step": 4469
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017770564868897056,
      "loss": 2.5352,
      "step": 4470
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017769469048064237,
      "loss": 2.4219,
      "step": 4471
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017768372991790985,
      "loss": 2.6562,
      "step": 4472
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017767276700110513,
      "loss": 2.4648,
      "step": 4473
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017766180173056044,
      "loss": 2.4844,
      "step": 4474
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017765083410660805,
      "loss": 2.4102,
      "step": 4475
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017763986412958031,
      "loss": 2.3828,
      "step": 4476
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017762889179980968,
      "loss": 2.3477,
      "step": 4477
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001776179171176286,
      "loss": 2.3906,
      "step": 4478
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017760694008336967,
      "loss": 2.25,
      "step": 4479
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017759596069736555,
      "loss": 2.3047,
      "step": 4480
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017758497895994894,
      "loss": 2.3477,
      "step": 4481
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001775739948714526,
      "loss": 2.2832,
      "step": 4482
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017756300843220938,
      "loss": 2.5117,
      "step": 4483
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017755201964255226,
      "loss": 2.3086,
      "step": 4484
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001775410285028142,
      "loss": 2.3008,
      "step": 4485
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017753003501332824,
      "loss": 2.5039,
      "step": 4486
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017751903917442755,
      "loss": 2.3711,
      "step": 4487
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017750804098644534,
      "loss": 2.3242,
      "step": 4488
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017749704044971494,
      "loss": 2.1523,
      "step": 4489
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001774860375645696,
      "loss": 2.3438,
      "step": 4490
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017747503233134282,
      "loss": 2.4629,
      "step": 4491
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017746402475036804,
      "loss": 2.4922,
      "step": 4492
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001774530148219789,
      "loss": 2.3867,
      "step": 4493
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017744200254650893,
      "loss": 2.457,
      "step": 4494
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017743098792429195,
      "loss": 2.4062,
      "step": 4495
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001774199709556617,
      "loss": 2.5117,
      "step": 4496
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017740895164095197,
      "loss": 2.2578,
      "step": 4497
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017739792998049677,
      "loss": 2.4023,
      "step": 4498
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017738690597463003,
      "loss": 2.3672,
      "step": 4499
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017737587962368586,
      "loss": 2.3711,
      "step": 4500
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017736485092799837,
      "loss": 2.5195,
      "step": 4501
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017735381988790175,
      "loss": 2.4453,
      "step": 4502
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001773427865037303,
      "loss": 2.3984,
      "step": 4503
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017733175077581835,
      "loss": 2.4844,
      "step": 4504
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017732071270450036,
      "loss": 2.4219,
      "step": 4505
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017730967229011077,
      "loss": 2.4766,
      "step": 4506
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017729862953298418,
      "loss": 2.5117,
      "step": 4507
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001772875844334552,
      "loss": 2.3672,
      "step": 4508
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017727653699185853,
      "loss": 2.5117,
      "step": 4509
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017726548720852894,
      "loss": 2.3164,
      "step": 4510
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0017725443508380132,
      "loss": 2.3789,
      "step": 4511
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017724338061801052,
      "loss": 2.4375,
      "step": 4512
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017723232381149157,
      "loss": 2.4414,
      "step": 4513
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017722126466457953,
      "loss": 2.3906,
      "step": 4514
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017721020317760948,
      "loss": 2.8359,
      "step": 4515
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017719913935091668,
      "loss": 2.3125,
      "step": 4516
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017718807318483636,
      "loss": 2.4492,
      "step": 4517
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017717700467970389,
      "loss": 2.3711,
      "step": 4518
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017716593383585461,
      "loss": 2.5898,
      "step": 4519
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017715486065362411,
      "loss": 2.4609,
      "step": 4520
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001771437851333479,
      "loss": 2.5039,
      "step": 4521
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017713270727536157,
      "loss": 2.3086,
      "step": 4522
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017712162708000087,
      "loss": 2.2734,
      "step": 4523
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001771105445476015,
      "loss": 2.4141,
      "step": 4524
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001770994596784994,
      "loss": 2.3906,
      "step": 4525
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017708837247303033,
      "loss": 2.3066,
      "step": 4526
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017707728293153042,
      "loss": 2.5312,
      "step": 4527
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017706619105433564,
      "loss": 2.3145,
      "step": 4528
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001770550968417821,
      "loss": 2.4688,
      "step": 4529
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017704400029420605,
      "loss": 2.5469,
      "step": 4530
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017703290141194371,
      "loss": 2.3594,
      "step": 4531
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017702180019533139,
      "loss": 2.5156,
      "step": 4532
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017701069664470554,
      "loss": 2.3008,
      "step": 4533
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001769995907604026,
      "loss": 2.5195,
      "step": 4534
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017698848254275915,
      "loss": 2.4844,
      "step": 4535
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017697737199211176,
      "loss": 2.3555,
      "step": 4536
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017696625910879717,
      "loss": 2.4336,
      "step": 4537
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017695514389315212,
      "loss": 2.3594,
      "step": 4538
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017694402634551342,
      "loss": 2.3125,
      "step": 4539
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017693290646621795,
      "loss": 2.5273,
      "step": 4540
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017692178425560273,
      "loss": 2.3086,
      "step": 4541
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017691065971400476,
      "loss": 2.5391,
      "step": 4542
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017689953284176117,
      "loss": 2.4727,
      "step": 4543
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017688840363920912,
      "loss": 2.4961,
      "step": 4544
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017687727210668588,
      "loss": 2.418,
      "step": 4545
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001768661382445288,
      "loss": 2.334,
      "step": 4546
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001768550020530752,
      "loss": 2.4023,
      "step": 4547
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017684386353266262,
      "loss": 2.3047,
      "step": 4548
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017683272268362853,
      "loss": 2.4922,
      "step": 4549
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017682157950631057,
      "loss": 2.4609,
      "step": 4550
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001768104340010464,
      "loss": 2.5898,
      "step": 4551
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001767992861681738,
      "loss": 2.4961,
      "step": 4552
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017678813600803052,
      "loss": 2.3164,
      "step": 4553
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001767769835209545,
      "loss": 2.4141,
      "step": 4554
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017676582870728371,
      "loss": 2.4336,
      "step": 4555
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017675467156735613,
      "loss": 2.4219,
      "step": 4556
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017674351210150983,
      "loss": 2.5156,
      "step": 4557
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017673235031008306,
      "loss": 2.4219,
      "step": 4558
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017672118619341405,
      "loss": 2.4531,
      "step": 4559
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017671001975184104,
      "loss": 2.4062,
      "step": 4560
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017669885098570248,
      "loss": 2.4219,
      "step": 4561
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017668767989533678,
      "loss": 2.3242,
      "step": 4562
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017667650648108251,
      "loss": 2.3633,
      "step": 4563
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017666533074327817,
      "loss": 2.4102,
      "step": 4564
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017665415268226252,
      "loss": 2.3516,
      "step": 4565
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017664297229837425,
      "loss": 2.3906,
      "step": 4566
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017663178959195216,
      "loss": 2.4336,
      "step": 4567
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017662060456333508,
      "loss": 2.4375,
      "step": 4568
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017660941721286206,
      "loss": 2.4141,
      "step": 4569
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00176598227540872,
      "loss": 2.6641,
      "step": 4570
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017658703554770407,
      "loss": 2.2559,
      "step": 4571
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001765758412336974,
      "loss": 2.4531,
      "step": 4572
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017656464459919116,
      "loss": 2.4102,
      "step": 4573
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001765534456445247,
      "loss": 2.457,
      "step": 4574
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001765422443700374,
      "loss": 2.2539,
      "step": 4575
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017653104077606865,
      "loss": 2.2988,
      "step": 4576
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017651983486295798,
      "loss": 2.3438,
      "step": 4577
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017650862663104495,
      "loss": 2.4375,
      "step": 4578
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001764974160806692,
      "loss": 2.5156,
      "step": 4579
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001764862032121705,
      "loss": 2.6133,
      "step": 4580
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017647498802588859,
      "loss": 2.668,
      "step": 4581
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017646377052216334,
      "loss": 2.5078,
      "step": 4582
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017645255070133467,
      "loss": 2.4766,
      "step": 4583
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017644132856374257,
      "loss": 2.5547,
      "step": 4584
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017643010410972712,
      "loss": 2.2422,
      "step": 4585
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017641887733962846,
      "loss": 2.334,
      "step": 4586
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017640764825378682,
      "loss": 2.3867,
      "step": 4587
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017639641685254243,
      "loss": 2.2422,
      "step": 4588
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017638518313623567,
      "loss": 2.5156,
      "step": 4589
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017637394710520696,
      "loss": 2.293,
      "step": 4590
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017636270875979675,
      "loss": 2.5273,
      "step": 4591
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017635146810034566,
      "loss": 2.4883,
      "step": 4592
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017634022512719426,
      "loss": 2.5469,
      "step": 4593
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017632897984068328,
      "loss": 2.3281,
      "step": 4594
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017631773224115349,
      "loss": 2.3828,
      "step": 4595
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001763064823289457,
      "loss": 2.4766,
      "step": 4596
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017629523010440087,
      "loss": 2.5078,
      "step": 4597
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017628397556785995,
      "loss": 2.375,
      "step": 4598
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017627271871966399,
      "loss": 2.5742,
      "step": 4599
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017626145956015412,
      "loss": 2.4141,
      "step": 4600
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001762501980896715,
      "loss": 2.457,
      "step": 4601
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017623893430855743,
      "loss": 2.4297,
      "step": 4602
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001762276682171532,
      "loss": 2.6016,
      "step": 4603
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0017621639981580026,
      "loss": 2.5508,
      "step": 4604
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017620512910484006,
      "loss": 2.4297,
      "step": 4605
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017619385608461408,
      "loss": 2.2285,
      "step": 4606
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00176182580755464,
      "loss": 2.4219,
      "step": 4607
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017617130311773149,
      "loss": 2.5195,
      "step": 4608
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017616002317175825,
      "loss": 2.5273,
      "step": 4609
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017614874091788617,
      "loss": 2.3633,
      "step": 4610
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001761374563564571,
      "loss": 2.5664,
      "step": 4611
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00176126169487813,
      "loss": 2.4141,
      "step": 4612
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017611488031229591,
      "loss": 2.4531,
      "step": 4613
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017610358883024793,
      "loss": 2.2695,
      "step": 4614
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001760922950420112,
      "loss": 2.543,
      "step": 4615
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017608099894792799,
      "loss": 2.4414,
      "step": 4616
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017606970054834061,
      "loss": 2.3516,
      "step": 4617
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017605839984359145,
      "loss": 2.418,
      "step": 4618
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001760470968340229,
      "loss": 2.3438,
      "step": 4619
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017603579151997753,
      "loss": 2.4375,
      "step": 4620
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001760244839017979,
      "loss": 2.5977,
      "step": 4621
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001760131739798267,
      "loss": 2.3555,
      "step": 4622
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017600186175440664,
      "loss": 2.3594,
      "step": 4623
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001759905472258805,
      "loss": 2.5195,
      "step": 4624
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017597923039459119,
      "loss": 2.3008,
      "step": 4625
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017596791126088158,
      "loss": 2.4727,
      "step": 4626
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017595658982509476,
      "loss": 2.4805,
      "step": 4627
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017594526608757377,
      "loss": 2.3398,
      "step": 4628
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001759339400486617,
      "loss": 2.2852,
      "step": 4629
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017592261170870187,
      "loss": 2.4883,
      "step": 4630
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017591128106803748,
      "loss": 2.457,
      "step": 4631
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017589994812701195,
      "loss": 2.3594,
      "step": 4632
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017588861288596865,
      "loss": 2.3203,
      "step": 4633
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017587727534525111,
      "loss": 2.3242,
      "step": 4634
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017586593550520289,
      "loss": 2.3828,
      "step": 4635
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001758545933661676,
      "loss": 2.3359,
      "step": 4636
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017584324892848898,
      "loss": 2.4434,
      "step": 4637
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017583190219251077,
      "loss": 2.4727,
      "step": 4638
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017582055315857686,
      "loss": 2.4727,
      "step": 4639
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001758092018270311,
      "loss": 2.3047,
      "step": 4640
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017579784819821754,
      "loss": 2.3203,
      "step": 4641
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017578649227248016,
      "loss": 2.3789,
      "step": 4642
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017577513405016313,
      "loss": 2.5781,
      "step": 4643
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017576377353161067,
      "loss": 2.4102,
      "step": 4644
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017575241071716697,
      "loss": 2.4531,
      "step": 4645
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017574104560717642,
      "loss": 2.6094,
      "step": 4646
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017572967820198336,
      "loss": 2.4453,
      "step": 4647
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017571830850193226,
      "loss": 2.209,
      "step": 4648
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017570693650736774,
      "loss": 2.4961,
      "step": 4649
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017569556221863438,
      "loss": 2.4102,
      "step": 4650
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017568418563607682,
      "loss": 2.5117,
      "step": 4651
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001756728067600398,
      "loss": 2.418,
      "step": 4652
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001756614255908682,
      "loss": 2.5508,
      "step": 4653
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017565004212890685,
      "loss": 2.6016,
      "step": 4654
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017563865637450075,
      "loss": 2.4922,
      "step": 4655
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017562726832799488,
      "loss": 2.3594,
      "step": 4656
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017561587798973438,
      "loss": 2.4375,
      "step": 4657
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017560448536006437,
      "loss": 2.5859,
      "step": 4658
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001755930904393301,
      "loss": 2.3828,
      "step": 4659
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001755816932278769,
      "loss": 2.3398,
      "step": 4660
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017557029372605012,
      "loss": 2.4961,
      "step": 4661
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017555889193419524,
      "loss": 2.5195,
      "step": 4662
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001755474878526577,
      "loss": 2.4727,
      "step": 4663
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017553608148178311,
      "loss": 2.2578,
      "step": 4664
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017552467282191714,
      "loss": 2.5234,
      "step": 4665
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001755132618734055,
      "loss": 2.332,
      "step": 4666
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017550184863659398,
      "loss": 2.375,
      "step": 4667
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017549043311182845,
      "loss": 2.668,
      "step": 4668
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001754790152994548,
      "loss": 2.4375,
      "step": 4669
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017546759519981908,
      "loss": 2.4531,
      "step": 4670
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001754561728132673,
      "loss": 2.1406,
      "step": 4671
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017544474814014564,
      "loss": 2.5664,
      "step": 4672
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001754333211808003,
      "loss": 2.4062,
      "step": 4673
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017542189193557754,
      "loss": 2.3555,
      "step": 4674
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017541046040482368,
      "loss": 2.4102,
      "step": 4675
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017539902658888517,
      "loss": 2.2539,
      "step": 4676
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001753875904881085,
      "loss": 2.5156,
      "step": 4677
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017537615210284022,
      "loss": 2.5898,
      "step": 4678
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017536471143342692,
      "loss": 2.3359,
      "step": 4679
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001753532684802153,
      "loss": 2.1953,
      "step": 4680
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001753418232435521,
      "loss": 2.3828,
      "step": 4681
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001753303757237842,
      "loss": 2.5039,
      "step": 4682
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017531892592125846,
      "loss": 2.6602,
      "step": 4683
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017530747383632187,
      "loss": 2.2129,
      "step": 4684
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017529601946932145,
      "loss": 2.3516,
      "step": 4685
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001752845628206043,
      "loss": 2.5,
      "step": 4686
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001752731038905176,
      "loss": 2.4844,
      "step": 4687
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001752616426794086,
      "loss": 2.543,
      "step": 4688
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001752501791876246,
      "loss": 2.4648,
      "step": 4689
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00175238713415513,
      "loss": 2.2461,
      "step": 4690
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001752272453634212,
      "loss": 2.5039,
      "step": 4691
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017521577503169681,
      "loss": 2.3555,
      "step": 4692
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017520430242068735,
      "loss": 2.332,
      "step": 4693
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001751928275307405,
      "loss": 2.3926,
      "step": 4694
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017518135036220395,
      "loss": 2.5,
      "step": 4695
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017516987091542556,
      "loss": 2.2695,
      "step": 4696
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017515838919075315,
      "loss": 2.3242,
      "step": 4697
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0017514690518853464,
      "loss": 2.3594,
      "step": 4698
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001751354189091181,
      "loss": 2.5273,
      "step": 4699
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017512393035285154,
      "loss": 2.5078,
      "step": 4700
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017511243952008316,
      "loss": 2.5039,
      "step": 4701
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017510094641116107,
      "loss": 2.5703,
      "step": 4702
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017508945102643369,
      "loss": 2.6367,
      "step": 4703
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001750779533662492,
      "loss": 2.4062,
      "step": 4704
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017506645343095615,
      "loss": 2.1719,
      "step": 4705
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00175054951220903,
      "loss": 2.3047,
      "step": 4706
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017504344673643826,
      "loss": 2.4297,
      "step": 4707
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001750319399779106,
      "loss": 2.2812,
      "step": 4708
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017502043094566866,
      "loss": 2.582,
      "step": 4709
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017500891964006126,
      "loss": 2.3789,
      "step": 4710
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001749974060614372,
      "loss": 2.3008,
      "step": 4711
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001749858902101454,
      "loss": 2.1875,
      "step": 4712
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017497437208653479,
      "loss": 2.3945,
      "step": 4713
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017496285169095445,
      "loss": 2.4219,
      "step": 4714
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017495132902375344,
      "loss": 2.5137,
      "step": 4715
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00174939804085281,
      "loss": 2.2734,
      "step": 4716
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017492827687588628,
      "loss": 2.4805,
      "step": 4717
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001749167473959187,
      "loss": 2.3945,
      "step": 4718
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017490521564572754,
      "loss": 2.3984,
      "step": 4719
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001748936816256623,
      "loss": 2.457,
      "step": 4720
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017488214533607253,
      "loss": 2.3672,
      "step": 4721
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017487060677730776,
      "loss": 2.1797,
      "step": 4722
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017485906594971767,
      "loss": 2.2832,
      "step": 4723
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017484752285365198,
      "loss": 2.3594,
      "step": 4724
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001748359774894605,
      "loss": 2.3047,
      "step": 4725
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017482442985749308,
      "loss": 2.4648,
      "step": 4726
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017481287995809965,
      "loss": 2.3516,
      "step": 4727
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017480132779163018,
      "loss": 2.4922,
      "step": 4728
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001747897733584348,
      "loss": 2.3945,
      "step": 4729
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017477821665886361,
      "loss": 2.3633,
      "step": 4730
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017476665769326682,
      "loss": 2.2969,
      "step": 4731
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017475509646199471,
      "loss": 2.5938,
      "step": 4732
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017474353296539765,
      "loss": 2.3008,
      "step": 4733
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00174731967203826,
      "loss": 2.2188,
      "step": 4734
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017472039917763025,
      "loss": 2.4648,
      "step": 4735
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017470882888716097,
      "loss": 2.3086,
      "step": 4736
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017469725633276875,
      "loss": 2.4062,
      "step": 4737
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017468568151480434,
      "loss": 2.457,
      "step": 4738
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017467410443361845,
      "loss": 2.3359,
      "step": 4739
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017466252508956189,
      "loss": 2.3203,
      "step": 4740
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017465094348298555,
      "loss": 2.457,
      "step": 4741
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017463935961424043,
      "loss": 2.5938,
      "step": 4742
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001746277734836775,
      "loss": 2.6406,
      "step": 4743
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017461618509164794,
      "loss": 2.4688,
      "step": 4744
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017460459443850288,
      "loss": 2.3867,
      "step": 4745
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017459300152459353,
      "loss": 2.2949,
      "step": 4746
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017458140635027118,
      "loss": 2.5078,
      "step": 4747
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017456980891588727,
      "loss": 2.4414,
      "step": 4748
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017455820922179317,
      "loss": 2.3281,
      "step": 4749
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017454660726834046,
      "loss": 2.4375,
      "step": 4750
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017453500305588065,
      "loss": 2.5859,
      "step": 4751
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017452339658476541,
      "loss": 2.3984,
      "step": 4752
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017451178785534648,
      "loss": 2.3984,
      "step": 4753
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001745001768679756,
      "loss": 2.4492,
      "step": 4754
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017448856362300468,
      "loss": 2.2617,
      "step": 4755
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017447694812078556,
      "loss": 2.6172,
      "step": 4756
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017446533036167028,
      "loss": 2.3594,
      "step": 4757
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001744537103460109,
      "loss": 2.3711,
      "step": 4758
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001744420880741595,
      "loss": 2.2676,
      "step": 4759
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017443046354646834,
      "loss": 2.4102,
      "step": 4760
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017441883676328964,
      "loss": 2.4844,
      "step": 4761
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001744072077249757,
      "loss": 2.2988,
      "step": 4762
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017439557643187898,
      "loss": 2.5078,
      "step": 4763
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017438394288435194,
      "loss": 2.4766,
      "step": 4764
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017437230708274708,
      "loss": 2.3125,
      "step": 4765
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017436066902741696,
      "loss": 2.2812,
      "step": 4766
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001743490287187144,
      "loss": 2.4922,
      "step": 4767
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017433738615699197,
      "loss": 2.457,
      "step": 4768
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017432574134260256,
      "loss": 2.3828,
      "step": 4769
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001743140942758991,
      "loss": 2.6289,
      "step": 4770
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017430244495723443,
      "loss": 2.4766,
      "step": 4771
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001742907933869616,
      "loss": 2.5625,
      "step": 4772
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017427913956543372,
      "loss": 2.4414,
      "step": 4773
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017426748349300394,
      "loss": 2.2344,
      "step": 4774
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017425582517002543,
      "loss": 2.4883,
      "step": 4775
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001742441645968515,
      "loss": 2.4727,
      "step": 4776
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017423250177383551,
      "loss": 2.2852,
      "step": 4777
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001742208367013309,
      "loss": 2.457,
      "step": 4778
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017420916937969108,
      "loss": 2.3828,
      "step": 4779
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017419749980926971,
      "loss": 2.3828,
      "step": 4780
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017418582799042035,
      "loss": 2.5117,
      "step": 4781
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017417415392349674,
      "loss": 2.4375,
      "step": 4782
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001741624776088526,
      "loss": 2.5,
      "step": 4783
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001741507990468418,
      "loss": 2.4102,
      "step": 4784
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017413911823781817,
      "loss": 2.1953,
      "step": 4785
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017412743518213575,
      "loss": 2.4219,
      "step": 4786
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017411574988014857,
      "loss": 2.3945,
      "step": 4787
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017410406233221067,
      "loss": 2.2109,
      "step": 4788
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017409237253867631,
      "loss": 2.3281,
      "step": 4789
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017408068049989964,
      "loss": 2.4961,
      "step": 4790
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0017406898621623505,
      "loss": 2.4023,
      "step": 4791
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017405728968803685,
      "loss": 2.3359,
      "step": 4792
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017404559091565952,
      "loss": 2.4219,
      "step": 4793
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017403388989945757,
      "loss": 2.2227,
      "step": 4794
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017402218663978553,
      "loss": 2.4023,
      "step": 4795
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001740104811369981,
      "loss": 2.457,
      "step": 4796
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017399877339145,
      "loss": 2.3574,
      "step": 4797
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017398706340349599,
      "loss": 2.5195,
      "step": 4798
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017397535117349094,
      "loss": 2.4648,
      "step": 4799
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017396363670178971,
      "loss": 2.4062,
      "step": 4800
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017395191998874737,
      "loss": 2.4453,
      "step": 4801
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017394020103471892,
      "loss": 2.3887,
      "step": 4802
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001739284798400595,
      "loss": 2.4375,
      "step": 4803
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001739167564051243,
      "loss": 2.418,
      "step": 4804
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017390503073026857,
      "loss": 2.3594,
      "step": 4805
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017389330281584769,
      "loss": 2.418,
      "step": 4806
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017388157266221697,
      "loss": 2.4141,
      "step": 4807
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001738698402697319,
      "loss": 2.5117,
      "step": 4808
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017385810563874805,
      "loss": 2.332,
      "step": 4809
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017384636876962096,
      "loss": 2.4688,
      "step": 4810
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017383462966270634,
      "loss": 2.2578,
      "step": 4811
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001738228883183599,
      "loss": 2.3555,
      "step": 4812
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001738111447369375,
      "loss": 2.4258,
      "step": 4813
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017379939891879487,
      "loss": 2.4336,
      "step": 4814
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017378765086428812,
      "loss": 2.3789,
      "step": 4815
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017377590057377312,
      "loss": 2.3711,
      "step": 4816
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00173764148047606,
      "loss": 2.3828,
      "step": 4817
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001737523932861429,
      "loss": 2.2852,
      "step": 4818
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017374063628974004,
      "loss": 2.25,
      "step": 4819
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017372887705875365,
      "loss": 2.457,
      "step": 4820
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017371711559354011,
      "loss": 2.1777,
      "step": 4821
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017370535189445582,
      "loss": 2.4648,
      "step": 4822
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017369358596185725,
      "loss": 2.4062,
      "step": 4823
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017368181779610096,
      "loss": 2.3398,
      "step": 4824
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017367004739754358,
      "loss": 2.2461,
      "step": 4825
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017365827476654174,
      "loss": 2.4375,
      "step": 4826
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017364649990345225,
      "loss": 2.5391,
      "step": 4827
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017363472280863188,
      "loss": 2.5469,
      "step": 4828
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017362294348243754,
      "loss": 2.4023,
      "step": 4829
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017361116192522617,
      "loss": 2.3828,
      "step": 4830
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001735993781373548,
      "loss": 2.4297,
      "step": 4831
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017358759211918051,
      "loss": 2.6836,
      "step": 4832
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017357580387106046,
      "loss": 2.4336,
      "step": 4833
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017356401339335187,
      "loss": 2.3281,
      "step": 4834
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017355222068641204,
      "loss": 2.4062,
      "step": 4835
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017354042575059832,
      "loss": 2.3242,
      "step": 4836
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001735286285862681,
      "loss": 2.4062,
      "step": 4837
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017351682919377893,
      "loss": 2.3672,
      "step": 4838
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017350502757348834,
      "loss": 2.4805,
      "step": 4839
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017349322372575396,
      "loss": 2.2695,
      "step": 4840
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001734814176509335,
      "loss": 2.3281,
      "step": 4841
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017346960934938472,
      "loss": 2.3789,
      "step": 4842
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017345779882146544,
      "loss": 2.4414,
      "step": 4843
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017344598606753355,
      "loss": 2.4023,
      "step": 4844
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017343417108794704,
      "loss": 2.4648,
      "step": 4845
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017342235388306392,
      "loss": 2.4648,
      "step": 4846
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017341053445324229,
      "loss": 2.4766,
      "step": 4847
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017339871279884035,
      "loss": 2.418,
      "step": 4848
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017338688892021628,
      "loss": 2.3164,
      "step": 4849
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017337506281772841,
      "loss": 2.5547,
      "step": 4850
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017336323449173518,
      "loss": 2.5586,
      "step": 4851
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017335140394259489,
      "loss": 2.3867,
      "step": 4852
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017333957117066615,
      "loss": 2.4805,
      "step": 4853
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017332773617630749,
      "loss": 2.4023,
      "step": 4854
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017331589895987754,
      "loss": 2.4453,
      "step": 4855
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017330405952173502,
      "loss": 2.5195,
      "step": 4856
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017329221786223873,
      "loss": 2.5352,
      "step": 4857
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017328037398174749,
      "loss": 2.668,
      "step": 4858
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017326852788062017,
      "loss": 2.4219,
      "step": 4859
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017325667955921582,
      "loss": 2.2285,
      "step": 4860
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017324482901789344,
      "loss": 2.6094,
      "step": 4861
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017323297625701213,
      "loss": 2.2891,
      "step": 4862
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001732211212769311,
      "loss": 2.4141,
      "step": 4863
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017320926407800956,
      "loss": 2.3906,
      "step": 4864
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017319740466060685,
      "loss": 2.4609,
      "step": 4865
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017318554302508233,
      "loss": 2.1719,
      "step": 4866
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017317367917179546,
      "loss": 2.4922,
      "step": 4867
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017316181310110578,
      "loss": 2.3516,
      "step": 4868
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001731499448133728,
      "loss": 2.4258,
      "step": 4869
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017313807430895624,
      "loss": 2.1914,
      "step": 4870
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017312620158821575,
      "loss": 2.375,
      "step": 4871
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017311432665151117,
      "loss": 2.3672,
      "step": 4872
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017310244949920231,
      "loss": 2.4219,
      "step": 4873
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001730905701316491,
      "loss": 2.3242,
      "step": 4874
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017307868854921154,
      "loss": 2.2617,
      "step": 4875
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017306680475224967,
      "loss": 2.2969,
      "step": 4876
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017305491874112363,
      "loss": 2.3164,
      "step": 4877
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017304303051619355,
      "loss": 2.3477,
      "step": 4878
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017303114007781969,
      "loss": 2.4492,
      "step": 4879
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017301924742636242,
      "loss": 2.4102,
      "step": 4880
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001730073525621821,
      "loss": 2.4258,
      "step": 4881
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017299545548563916,
      "loss": 2.25,
      "step": 4882
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0017298355619709419,
      "loss": 2.3477,
      "step": 4883
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001729716546969077,
      "loss": 2.3457,
      "step": 4884
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017295975098544037,
      "loss": 2.4883,
      "step": 4885
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017294784506305292,
      "loss": 2.3477,
      "step": 4886
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017293593693010617,
      "loss": 2.5078,
      "step": 4887
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001729240265869609,
      "loss": 2.2578,
      "step": 4888
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017291211403397814,
      "loss": 2.2422,
      "step": 4889
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001729001992715188,
      "loss": 2.3867,
      "step": 4890
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017288828229994398,
      "loss": 2.4648,
      "step": 4891
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017287636311961473,
      "loss": 2.3086,
      "step": 4892
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017286444173089236,
      "loss": 2.3457,
      "step": 4893
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017285251813413801,
      "loss": 2.5352,
      "step": 4894
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017284059232971305,
      "loss": 2.1289,
      "step": 4895
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001728286643179789,
      "loss": 2.5781,
      "step": 4896
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017281673409929698,
      "loss": 2.4297,
      "step": 4897
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017280480167402882,
      "loss": 2.5039,
      "step": 4898
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017279286704253605,
      "loss": 2.4082,
      "step": 4899
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001727809302051803,
      "loss": 2.3203,
      "step": 4900
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017276899116232328,
      "loss": 2.5742,
      "step": 4901
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017275704991432676,
      "loss": 2.375,
      "step": 4902
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017274510646155265,
      "loss": 2.3594,
      "step": 4903
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001727331608043629,
      "loss": 2.4102,
      "step": 4904
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017272121294311944,
      "loss": 2.3789,
      "step": 4905
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017270926287818434,
      "loss": 2.5117,
      "step": 4906
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017269731060991975,
      "loss": 2.3945,
      "step": 4907
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017268535613868786,
      "loss": 2.3789,
      "step": 4908
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017267339946485092,
      "loss": 2.457,
      "step": 4909
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017266144058877126,
      "loss": 2.4883,
      "step": 4910
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017264947951081125,
      "loss": 2.3398,
      "step": 4911
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017263751623133336,
      "loss": 2.3359,
      "step": 4912
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017262555075070014,
      "loss": 2.4531,
      "step": 4913
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001726135830692742,
      "loss": 2.3828,
      "step": 4914
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017260161318741816,
      "loss": 2.332,
      "step": 4915
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017258964110549474,
      "loss": 2.332,
      "step": 4916
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017257766682386678,
      "loss": 2.4453,
      "step": 4917
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017256569034289708,
      "loss": 2.4766,
      "step": 4918
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017255371166294863,
      "loss": 2.4336,
      "step": 4919
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017254173078438434,
      "loss": 2.4727,
      "step": 4920
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017252974770756734,
      "loss": 2.6406,
      "step": 4921
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001725177624328608,
      "loss": 2.4102,
      "step": 4922
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017250577496062778,
      "loss": 2.3633,
      "step": 4923
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017249378529123165,
      "loss": 2.6797,
      "step": 4924
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017248179342503568,
      "loss": 2.3438,
      "step": 4925
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017246979936240327,
      "loss": 2.5,
      "step": 4926
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001724578031036979,
      "loss": 2.5273,
      "step": 4927
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001724458046492831,
      "loss": 2.25,
      "step": 4928
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017243380399952245,
      "loss": 2.7461,
      "step": 4929
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017242180115477957,
      "loss": 2.5039,
      "step": 4930
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017240979611541825,
      "loss": 2.3984,
      "step": 4931
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017239778888180225,
      "loss": 2.4844,
      "step": 4932
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017238577945429543,
      "loss": 2.2734,
      "step": 4933
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017237376783326172,
      "loss": 2.3711,
      "step": 4934
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017236175401906513,
      "loss": 2.375,
      "step": 4935
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017234973801206967,
      "loss": 2.4375,
      "step": 4936
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001723377198126395,
      "loss": 2.4961,
      "step": 4937
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017232569942113884,
      "loss": 2.6719,
      "step": 4938
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017231367683793186,
      "loss": 2.5469,
      "step": 4939
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017230165206338298,
      "loss": 2.6602,
      "step": 4940
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001722896250978565,
      "loss": 2.2148,
      "step": 4941
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017227759594171698,
      "loss": 2.5391,
      "step": 4942
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017226556459532883,
      "loss": 2.4141,
      "step": 4943
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017225353105905672,
      "loss": 2.3086,
      "step": 4944
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017224149533326526,
      "loss": 2.3828,
      "step": 4945
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017222945741831922,
      "loss": 2.3984,
      "step": 4946
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017221741731458335,
      "loss": 2.4727,
      "step": 4947
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001722053750224225,
      "loss": 2.4023,
      "step": 4948
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017219333054220164,
      "loss": 2.4844,
      "step": 4949
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001721812838742857,
      "loss": 2.2656,
      "step": 4950
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017216923501903974,
      "loss": 2.1777,
      "step": 4951
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001721571839768289,
      "loss": 2.5352,
      "step": 4952
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001721451307480184,
      "loss": 2.5664,
      "step": 4953
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017213307533297342,
      "loss": 2.2734,
      "step": 4954
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017212101773205932,
      "loss": 2.3145,
      "step": 4955
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001721089579456415,
      "loss": 2.5391,
      "step": 4956
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017209689597408539,
      "loss": 2.3633,
      "step": 4957
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017208483181775649,
      "loss": 2.1641,
      "step": 4958
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001720727654770204,
      "loss": 2.4297,
      "step": 4959
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017206069695224276,
      "loss": 2.6211,
      "step": 4960
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017204862624378933,
      "loss": 2.4531,
      "step": 4961
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017203655335202583,
      "loss": 2.2969,
      "step": 4962
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017202447827731815,
      "loss": 2.4062,
      "step": 4963
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017201240102003217,
      "loss": 2.3672,
      "step": 4964
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017200032158053392,
      "loss": 2.4102,
      "step": 4965
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001719882399591894,
      "loss": 2.332,
      "step": 4966
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017197615615636478,
      "loss": 2.2461,
      "step": 4967
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017196407017242615,
      "loss": 2.5781,
      "step": 4968
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001719519820077398,
      "loss": 2.5,
      "step": 4969
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001719398916626721,
      "loss": 2.5078,
      "step": 4970
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017192779913758934,
      "loss": 2.4375,
      "step": 4971
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00171915704432858,
      "loss": 2.2891,
      "step": 4972
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001719036075488446,
      "loss": 2.2461,
      "step": 4973
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001718915084859157,
      "loss": 2.3242,
      "step": 4974
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0017187940724443793,
      "loss": 2.4316,
      "step": 4975
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00171867303824778,
      "loss": 2.4844,
      "step": 4976
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001718551982273027,
      "loss": 2.4805,
      "step": 4977
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001718430904523789,
      "loss": 2.5117,
      "step": 4978
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017183098050037344,
      "loss": 2.416,
      "step": 4979
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017181886837165333,
      "loss": 2.5078,
      "step": 4980
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017180675406658556,
      "loss": 2.4727,
      "step": 4981
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001717946375855373,
      "loss": 2.5508,
      "step": 4982
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017178251892887568,
      "loss": 2.4023,
      "step": 4983
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017177039809696795,
      "loss": 2.4883,
      "step": 4984
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017175827509018143,
      "loss": 2.457,
      "step": 4985
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017174614990888345,
      "loss": 2.4062,
      "step": 4986
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017173402255344144,
      "loss": 2.543,
      "step": 4987
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001717218930242229,
      "loss": 2.5195,
      "step": 4988
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017170976132159545,
      "loss": 2.3711,
      "step": 4989
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017169762744592663,
      "loss": 2.3867,
      "step": 4990
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017168549139758424,
      "loss": 2.3945,
      "step": 4991
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017167335317693593,
      "loss": 2.5,
      "step": 4992
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017166121278434964,
      "loss": 2.2754,
      "step": 4993
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017164907022019316,
      "loss": 2.5312,
      "step": 4994
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017163692548483455,
      "loss": 2.332,
      "step": 4995
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017162477857864174,
      "loss": 2.3828,
      "step": 4996
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017161262950198288,
      "loss": 2.7266,
      "step": 4997
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017160047825522612,
      "loss": 2.2852,
      "step": 4998
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017158832483873967,
      "loss": 2.3555,
      "step": 4999
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017157616925289184,
      "loss": 2.3906,
      "step": 5000
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001715640114980509,
      "loss": 2.3242,
      "step": 5001
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001715518515745854,
      "loss": 2.3008,
      "step": 5002
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017153968948286375,
      "loss": 2.2402,
      "step": 5003
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017152752522325452,
      "loss": 2.4531,
      "step": 5004
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017151535879612633,
      "loss": 2.3672,
      "step": 5005
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017150319020184785,
      "loss": 2.293,
      "step": 5006
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001714910194407878,
      "loss": 2.4375,
      "step": 5007
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017147884651331506,
      "loss": 2.5078,
      "step": 5008
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017146667141979845,
      "loss": 2.2812,
      "step": 5009
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017145449416060697,
      "loss": 2.5664,
      "step": 5010
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017144231473610958,
      "loss": 2.2656,
      "step": 5011
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017143013314667539,
      "loss": 2.3828,
      "step": 5012
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017141794939267354,
      "loss": 2.5938,
      "step": 5013
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017140576347447322,
      "loss": 2.3906,
      "step": 5014
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017139357539244374,
      "loss": 2.5156,
      "step": 5015
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017138138514695435,
      "loss": 2.6523,
      "step": 5016
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017136919273837458,
      "loss": 2.2422,
      "step": 5017
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017135699816707378,
      "loss": 2.2539,
      "step": 5018
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017134480143342157,
      "loss": 2.3672,
      "step": 5019
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017133260253778752,
      "loss": 2.4648,
      "step": 5020
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001713204014805413,
      "loss": 2.2129,
      "step": 5021
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017130819826205264,
      "loss": 2.3906,
      "step": 5022
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017129599288269134,
      "loss": 2.4219,
      "step": 5023
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017128378534282725,
      "loss": 2.2285,
      "step": 5024
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017127157564283033,
      "loss": 2.1973,
      "step": 5025
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017125936378307052,
      "loss": 2.4023,
      "step": 5026
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017124714976391796,
      "loss": 2.5586,
      "step": 5027
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017123493358574269,
      "loss": 2.4062,
      "step": 5028
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017122271524891498,
      "loss": 2.4727,
      "step": 5029
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00171210494753805,
      "loss": 2.4453,
      "step": 5030
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017119827210078317,
      "loss": 2.3398,
      "step": 5031
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017118604729021976,
      "loss": 2.6992,
      "step": 5032
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017117382032248534,
      "loss": 2.2461,
      "step": 5033
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001711615911979503,
      "loss": 2.2695,
      "step": 5034
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017114935991698536,
      "loss": 2.3789,
      "step": 5035
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001711371264799611,
      "loss": 2.3223,
      "step": 5036
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017112489088724821,
      "loss": 2.4258,
      "step": 5037
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017111265313921752,
      "loss": 2.2539,
      "step": 5038
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001711004132362398,
      "loss": 2.5586,
      "step": 5039
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017108817117868606,
      "loss": 2.2266,
      "step": 5040
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001710759269669272,
      "loss": 2.3203,
      "step": 5041
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017106368060133428,
      "loss": 2.375,
      "step": 5042
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017105143208227841,
      "loss": 2.3594,
      "step": 5043
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017103918141013078,
      "loss": 2.5586,
      "step": 5044
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017102692858526254,
      "loss": 2.2734,
      "step": 5045
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017101467360804512,
      "loss": 2.2734,
      "step": 5046
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017100241647884978,
      "loss": 2.2539,
      "step": 5047
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017099015719804803,
      "loss": 2.2207,
      "step": 5048
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001709778957660113,
      "loss": 2.4883,
      "step": 5049
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017096563218311118,
      "loss": 2.4844,
      "step": 5050
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017095336644971928,
      "loss": 2.2695,
      "step": 5051
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017094109856620734,
      "loss": 2.3633,
      "step": 5052
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017092882853294708,
      "loss": 2.3945,
      "step": 5053
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017091655635031032,
      "loss": 2.4141,
      "step": 5054
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017090428201866894,
      "loss": 2.3711,
      "step": 5055
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017089200553839494,
      "loss": 2.4883,
      "step": 5056
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001708797269098603,
      "loss": 2.5352,
      "step": 5057
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001708674461334371,
      "loss": 2.5859,
      "step": 5058
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017085516320949749,
      "loss": 2.5859,
      "step": 5059
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017084287813841368,
      "loss": 2.5156,
      "step": 5060
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017083059092055798,
      "loss": 2.4062,
      "step": 5061
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017081830155630268,
      "loss": 2.5195,
      "step": 5062
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017080601004602026,
      "loss": 2.3398,
      "step": 5063
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017079371639008311,
      "loss": 2.4531,
      "step": 5064
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017078142058886386,
      "loss": 2.3789,
      "step": 5065
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017076912264273503,
      "loss": 2.4141,
      "step": 5066
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001707568225520693,
      "loss": 2.4922,
      "step": 5067
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017074452031723944,
      "loss": 2.2617,
      "step": 5068
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017073221593861825,
      "loss": 2.5234,
      "step": 5069
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0017071990941657856,
      "loss": 2.2852,
      "step": 5070
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017070760075149332,
      "loss": 2.3047,
      "step": 5071
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017069528994373552,
      "loss": 2.3418,
      "step": 5072
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017068297699367819,
      "loss": 2.5586,
      "step": 5073
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017067066190169452,
      "loss": 2.3281,
      "step": 5074
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001706583446681576,
      "loss": 2.3301,
      "step": 5075
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001706460252934408,
      "loss": 2.4922,
      "step": 5076
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001706337037779173,
      "loss": 2.4688,
      "step": 5077
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017062138012196063,
      "loss": 2.3613,
      "step": 5078
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001706090543259441,
      "loss": 2.4375,
      "step": 5079
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017059672639024135,
      "loss": 2.5508,
      "step": 5080
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017058439631522585,
      "loss": 2.334,
      "step": 5081
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017057206410127132,
      "loss": 2.332,
      "step": 5082
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017055972974875141,
      "loss": 2.6016,
      "step": 5083
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001705473932580399,
      "loss": 2.2617,
      "step": 5084
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017053505462951066,
      "loss": 2.375,
      "step": 5085
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017052271386353754,
      "loss": 2.4883,
      "step": 5086
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017051037096049457,
      "loss": 2.5625,
      "step": 5087
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017049802592075576,
      "loss": 2.252,
      "step": 5088
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017048567874469516,
      "loss": 2.4648,
      "step": 5089
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017047332943268697,
      "loss": 2.3867,
      "step": 5090
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017046097798510541,
      "loss": 2.2539,
      "step": 5091
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017044862440232476,
      "loss": 2.3594,
      "step": 5092
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001704362686847194,
      "loss": 2.2363,
      "step": 5093
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017042391083266371,
      "loss": 2.4102,
      "step": 5094
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001704115508465322,
      "loss": 2.4375,
      "step": 5095
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001703991887266994,
      "loss": 2.5508,
      "step": 5096
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017038682447353996,
      "loss": 2.4141,
      "step": 5097
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017037445808742852,
      "loss": 2.5,
      "step": 5098
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001703620895687398,
      "loss": 2.3516,
      "step": 5099
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017034971891784865,
      "loss": 2.4219,
      "step": 5100
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017033734613512994,
      "loss": 2.418,
      "step": 5101
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001703249712209586,
      "loss": 2.4648,
      "step": 5102
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017031259417570963,
      "loss": 2.2812,
      "step": 5103
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001703002149997581,
      "loss": 2.293,
      "step": 5104
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017028783369347914,
      "loss": 2.4141,
      "step": 5105
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017027545025724792,
      "loss": 2.4375,
      "step": 5106
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017026306469143974,
      "loss": 2.5352,
      "step": 5107
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017025067699642986,
      "loss": 2.5117,
      "step": 5108
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017023828717259372,
      "loss": 2.5664,
      "step": 5109
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017022589522030676,
      "loss": 2.4414,
      "step": 5110
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017021350113994452,
      "loss": 2.4844,
      "step": 5111
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017020110493188253,
      "loss": 2.5391,
      "step": 5112
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017018870659649648,
      "loss": 2.7109,
      "step": 5113
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017017630613416204,
      "loss": 2.3711,
      "step": 5114
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017016390354525504,
      "loss": 2.3789,
      "step": 5115
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017015149883015126,
      "loss": 2.2812,
      "step": 5116
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017013909198922664,
      "loss": 2.2676,
      "step": 5117
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017012668302285713,
      "loss": 2.4316,
      "step": 5118
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001701142719314188,
      "loss": 2.3398,
      "step": 5119
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001701018587152877,
      "loss": 2.4023,
      "step": 5120
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017008944337484001,
      "loss": 2.3047,
      "step": 5121
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017007702591045196,
      "loss": 2.4805,
      "step": 5122
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017006460632249985,
      "loss": 2.4141,
      "step": 5123
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017005218461135997,
      "loss": 2.4648,
      "step": 5124
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017003976077740884,
      "loss": 2.1738,
      "step": 5125
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017002733482102286,
      "loss": 2.4102,
      "step": 5126
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017001490674257865,
      "loss": 2.4414,
      "step": 5127
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0017000247654245274,
      "loss": 2.4609,
      "step": 5128
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016999004422102184,
      "loss": 2.4922,
      "step": 5129
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001699776097786627,
      "loss": 2.4453,
      "step": 5130
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016996517321575216,
      "loss": 2.5547,
      "step": 5131
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00169952734532667,
      "loss": 2.4727,
      "step": 5132
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001699402937297842,
      "loss": 2.4609,
      "step": 5133
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016992785080748082,
      "loss": 2.2344,
      "step": 5134
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016991540576613382,
      "loss": 2.4062,
      "step": 5135
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016990295860612036,
      "loss": 2.6094,
      "step": 5136
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016989050932781765,
      "loss": 2.375,
      "step": 5137
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016987805793160292,
      "loss": 2.5,
      "step": 5138
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001698656044178535,
      "loss": 2.457,
      "step": 5139
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001698531487869468,
      "loss": 2.4961,
      "step": 5140
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016984069103926022,
      "loss": 2.4375,
      "step": 5141
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016982823117517127,
      "loss": 2.25,
      "step": 5142
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016981576919505754,
      "loss": 2.4805,
      "step": 5143
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016980330509929668,
      "loss": 2.4922,
      "step": 5144
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016979083888826638,
      "loss": 2.2773,
      "step": 5145
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016977837056234445,
      "loss": 2.3906,
      "step": 5146
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016976590012190865,
      "loss": 2.4883,
      "step": 5147
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016975342756733692,
      "loss": 2.5391,
      "step": 5148
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016974095289900722,
      "loss": 2.3242,
      "step": 5149
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016972847611729754,
      "loss": 2.209,
      "step": 5150
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016971599722258599,
      "loss": 2.4844,
      "step": 5151
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001697035162152507,
      "loss": 2.1797,
      "step": 5152
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016969103309566994,
      "loss": 2.3828,
      "step": 5153
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016967854786422195,
      "loss": 2.3125,
      "step": 5154
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016966606052128508,
      "loss": 2.3086,
      "step": 5155
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016965357106723774,
      "loss": 2.5234,
      "step": 5156
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016964107950245837,
      "loss": 2.5312,
      "step": 5157
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016962858582732557,
      "loss": 2.5078,
      "step": 5158
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016961609004221788,
      "loss": 2.5156,
      "step": 5159
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00169603592147514,
      "loss": 2.4492,
      "step": 5160
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016959109214359264,
      "loss": 2.4258,
      "step": 5161
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016957859003083257,
      "loss": 2.457,
      "step": 5162
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0016956608580961268,
      "loss": 2.4023,
      "step": 5163
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001695535794803119,
      "loss": 2.3633,
      "step": 5164
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016954107104330918,
      "loss": 2.4805,
      "step": 5165
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016952856049898357,
      "loss": 2.4648,
      "step": 5166
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001695160478477142,
      "loss": 2.5391,
      "step": 5167
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016950353308988024,
      "loss": 2.5508,
      "step": 5168
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016949101622586089,
      "loss": 2.4766,
      "step": 5169
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016947849725603553,
      "loss": 2.207,
      "step": 5170
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016946597618078343,
      "loss": 2.4414,
      "step": 5171
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016945345300048412,
      "loss": 2.5156,
      "step": 5172
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00169440927715517,
      "loss": 2.3867,
      "step": 5173
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016942840032626169,
      "loss": 2.4336,
      "step": 5174
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016941587083309777,
      "loss": 2.4766,
      "step": 5175
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016940333923640498,
      "loss": 2.2344,
      "step": 5176
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00169390805536563,
      "loss": 2.543,
      "step": 5177
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016937826973395169,
      "loss": 2.6133,
      "step": 5178
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016936573182895094,
      "loss": 2.2695,
      "step": 5179
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016935319182194064,
      "loss": 2.5039,
      "step": 5180
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001693406497133008,
      "loss": 2.3516,
      "step": 5181
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016932810550341151,
      "loss": 2.4336,
      "step": 5182
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001693155591926529,
      "loss": 2.2852,
      "step": 5183
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016930301078140518,
      "loss": 2.5859,
      "step": 5184
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016929046027004855,
      "loss": 2.6094,
      "step": 5185
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016927790765896339,
      "loss": 2.2891,
      "step": 5186
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016926535294853006,
      "loss": 2.3125,
      "step": 5187
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00169252796139129,
      "loss": 2.1523,
      "step": 5188
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016924023723114076,
      "loss": 2.3203,
      "step": 5189
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016922767622494586,
      "loss": 2.4453,
      "step": 5190
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016921511312092499,
      "loss": 2.2012,
      "step": 5191
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001692025479194588,
      "loss": 2.5195,
      "step": 5192
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016918998062092814,
      "loss": 2.3398,
      "step": 5193
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016917741122571377,
      "loss": 2.375,
      "step": 5194
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016916483973419662,
      "loss": 2.3008,
      "step": 5195
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001691522661467576,
      "loss": 2.6992,
      "step": 5196
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001691396904637778,
      "loss": 2.1699,
      "step": 5197
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016912711268563822,
      "loss": 2.3594,
      "step": 5198
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016911453281272012,
      "loss": 2.3945,
      "step": 5199
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001691019508454046,
      "loss": 2.293,
      "step": 5200
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016908936678407302,
      "loss": 2.5391,
      "step": 5201
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016907678062910666,
      "loss": 2.543,
      "step": 5202
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016906419238088694,
      "loss": 2.3047,
      "step": 5203
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016905160203979533,
      "loss": 2.3086,
      "step": 5204
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016903900960621335,
      "loss": 2.4297,
      "step": 5205
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016902641508052259,
      "loss": 2.418,
      "step": 5206
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016901381846310475,
      "loss": 2.3789,
      "step": 5207
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016900121975434149,
      "loss": 2.5391,
      "step": 5208
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001689886189546146,
      "loss": 2.2578,
      "step": 5209
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016897601606430594,
      "loss": 2.2969,
      "step": 5210
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016896341108379746,
      "loss": 2.457,
      "step": 5211
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016895080401347108,
      "loss": 2.4766,
      "step": 5212
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016893819485370883,
      "loss": 2.3184,
      "step": 5213
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016892558360489286,
      "loss": 2.5234,
      "step": 5214
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016891297026740526,
      "loss": 2.2695,
      "step": 5215
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016890035484162832,
      "loss": 2.2344,
      "step": 5216
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016888773732794426,
      "loss": 2.2461,
      "step": 5217
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016887511772673554,
      "loss": 2.4023,
      "step": 5218
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016886249603838448,
      "loss": 2.5039,
      "step": 5219
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001688498722632736,
      "loss": 2.4297,
      "step": 5220
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016883724640178541,
      "loss": 2.332,
      "step": 5221
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016882461845430256,
      "loss": 2.4102,
      "step": 5222
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001688119884212077,
      "loss": 2.4961,
      "step": 5223
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016879935630288352,
      "loss": 2.3906,
      "step": 5224
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016878672209971288,
      "loss": 2.3477,
      "step": 5225
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001687740858120786,
      "loss": 2.5391,
      "step": 5226
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016876144744036362,
      "loss": 2.5469,
      "step": 5227
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001687488069849509,
      "loss": 2.4609,
      "step": 5228
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001687361644462235,
      "loss": 2.3828,
      "step": 5229
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016872351982456456,
      "loss": 2.3438,
      "step": 5230
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001687108731203572,
      "loss": 2.3438,
      "step": 5231
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001686982243339847,
      "loss": 2.5117,
      "step": 5232
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001686855734658303,
      "loss": 2.3008,
      "step": 5233
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016867292051627744,
      "loss": 2.3672,
      "step": 5234
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016866026548570951,
      "loss": 2.3574,
      "step": 5235
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016864760837451002,
      "loss": 2.6172,
      "step": 5236
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016863494918306246,
      "loss": 2.3633,
      "step": 5237
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016862228791175052,
      "loss": 2.4727,
      "step": 5238
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001686096245609578,
      "loss": 2.4453,
      "step": 5239
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016859695913106815,
      "loss": 2.3281,
      "step": 5240
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016858429162246527,
      "loss": 2.4453,
      "step": 5241
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016857162203553306,
      "loss": 2.4062,
      "step": 5242
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001685589503706555,
      "loss": 2.3828,
      "step": 5243
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001685462766282165,
      "loss": 2.2188,
      "step": 5244
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016853360080860017,
      "loss": 2.5781,
      "step": 5245
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016852092291219061,
      "loss": 2.375,
      "step": 5246
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00168508242939372,
      "loss": 2.4961,
      "step": 5247
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016849556089052861,
      "loss": 2.4199,
      "step": 5248
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016848287676604473,
      "loss": 2.4336,
      "step": 5249
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016847019056630472,
      "loss": 2.5703,
      "step": 5250
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016845750229169303,
      "loss": 2.5391,
      "step": 5251
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016844481194259419,
      "loss": 2.2363,
      "step": 5252
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016843211951939265,
      "loss": 2.4453,
      "step": 5253
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016841942502247313,
      "loss": 2.3594,
      "step": 5254
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001684067284522203,
      "loss": 2.3984,
      "step": 5255
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0016839402980901887,
      "loss": 2.3789,
      "step": 5256
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001683813290932537,
      "loss": 2.4062,
      "step": 5257
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016836862630530962,
      "loss": 2.3398,
      "step": 5258
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001683559214455716,
      "loss": 2.3711,
      "step": 5259
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016834321451442463,
      "loss": 2.4766,
      "step": 5260
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016833050551225376,
      "loss": 2.3613,
      "step": 5261
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001683177944394441,
      "loss": 2.332,
      "step": 5262
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016830508129638089,
      "loss": 2.3945,
      "step": 5263
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001682923660834493,
      "loss": 2.3535,
      "step": 5264
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016827964880103475,
      "loss": 2.3984,
      "step": 5265
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001682669294495225,
      "loss": 2.4023,
      "step": 5266
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001682542080292981,
      "loss": 2.6641,
      "step": 5267
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016824148454074694,
      "loss": 2.2656,
      "step": 5268
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001682287589842547,
      "loss": 2.3613,
      "step": 5269
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016821603136020688,
      "loss": 2.3164,
      "step": 5270
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016820330166898926,
      "loss": 2.4805,
      "step": 5271
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016819056991098755,
      "loss": 2.4258,
      "step": 5272
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016817783608658761,
      "loss": 2.4219,
      "step": 5273
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016816510019617525,
      "loss": 2.293,
      "step": 5274
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001681523622401365,
      "loss": 2.3906,
      "step": 5275
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016813962221885724,
      "loss": 2.1406,
      "step": 5276
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016812688013272364,
      "loss": 2.3594,
      "step": 5277
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016811413598212177,
      "loss": 2.1875,
      "step": 5278
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016810138976743785,
      "loss": 2.3242,
      "step": 5279
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016808864148905812,
      "loss": 2.3066,
      "step": 5280
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001680758911473689,
      "loss": 2.4648,
      "step": 5281
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016806313874275654,
      "loss": 2.4219,
      "step": 5282
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016805038427560753,
      "loss": 2.3477,
      "step": 5283
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001680376277463083,
      "loss": 2.3516,
      "step": 5284
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016802486915524551,
      "loss": 2.4414,
      "step": 5285
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001680121085028057,
      "loss": 2.6328,
      "step": 5286
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001679993457893756,
      "loss": 2.5742,
      "step": 5287
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016798658101534198,
      "loss": 2.5117,
      "step": 5288
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016797381418109162,
      "loss": 2.2695,
      "step": 5289
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016796104528701142,
      "loss": 2.3516,
      "step": 5290
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016794827433348827,
      "loss": 2.4258,
      "step": 5291
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016793550132090925,
      "loss": 2.4648,
      "step": 5292
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016792272624966136,
      "loss": 2.25,
      "step": 5293
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016790994912013178,
      "loss": 2.5391,
      "step": 5294
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016789716993270765,
      "loss": 2.3555,
      "step": 5295
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016788438868777624,
      "loss": 2.4297,
      "step": 5296
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016787160538572485,
      "loss": 2.3125,
      "step": 5297
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001678588200269409,
      "loss": 2.3906,
      "step": 5298
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001678460326118118,
      "loss": 2.4336,
      "step": 5299
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016783324314072505,
      "loss": 2.4609,
      "step": 5300
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001678204516140682,
      "loss": 2.4844,
      "step": 5301
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001678076580322289,
      "loss": 2.3789,
      "step": 5302
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001677948623955948,
      "loss": 2.3672,
      "step": 5303
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016778206470455374,
      "loss": 2.4375,
      "step": 5304
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016776926495949338,
      "loss": 2.3516,
      "step": 5305
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016775646316080177,
      "loss": 2.375,
      "step": 5306
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001677436593088667,
      "loss": 2.4141,
      "step": 5307
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016773085340407623,
      "loss": 2.3418,
      "step": 5308
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016771804544681843,
      "loss": 2.2969,
      "step": 5309
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016770523543748145,
      "loss": 2.3633,
      "step": 5310
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001676924233764534,
      "loss": 2.3477,
      "step": 5311
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016767960926412256,
      "loss": 2.4727,
      "step": 5312
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016766679310087724,
      "loss": 2.6523,
      "step": 5313
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016765397488710586,
      "loss": 2.2891,
      "step": 5314
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016764115462319675,
      "loss": 2.4102,
      "step": 5315
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016762833230953853,
      "loss": 2.3359,
      "step": 5316
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016761550794651965,
      "loss": 2.3359,
      "step": 5317
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001676026815345288,
      "loss": 2.3984,
      "step": 5318
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001675898530739546,
      "loss": 2.5156,
      "step": 5319
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016757702256518588,
      "loss": 2.3984,
      "step": 5320
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016756419000861136,
      "loss": 2.2266,
      "step": 5321
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016755135540461995,
      "loss": 2.4453,
      "step": 5322
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001675385187536006,
      "loss": 2.5391,
      "step": 5323
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016752568005594225,
      "loss": 2.4141,
      "step": 5324
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016751283931203402,
      "loss": 2.3711,
      "step": 5325
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00167499996522265,
      "loss": 2.418,
      "step": 5326
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016748715168702433,
      "loss": 2.3945,
      "step": 5327
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016747430480670128,
      "loss": 2.332,
      "step": 5328
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016746145588168518,
      "loss": 2.4453,
      "step": 5329
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016744860491236535,
      "loss": 2.1309,
      "step": 5330
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016743575189913122,
      "loss": 2.1836,
      "step": 5331
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016742289684237232,
      "loss": 2.3789,
      "step": 5332
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016741003974247816,
      "loss": 2.2891,
      "step": 5333
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001673971805998384,
      "loss": 2.3496,
      "step": 5334
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016738431941484264,
      "loss": 2.5156,
      "step": 5335
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016737145618788067,
      "loss": 2.4258,
      "step": 5336
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016735859091934228,
      "loss": 2.3398,
      "step": 5337
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016734572360961734,
      "loss": 2.3281,
      "step": 5338
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016733285425909572,
      "loss": 2.5352,
      "step": 5339
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016731998286816747,
      "loss": 2.4766,
      "step": 5340
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001673071094372226,
      "loss": 2.3828,
      "step": 5341
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001672942339666512,
      "loss": 2.4258,
      "step": 5342
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016728135645684347,
      "loss": 2.2734,
      "step": 5343
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016726847690818967,
      "loss": 2.4453,
      "step": 5344
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016725559532108,
      "loss": 2.3203,
      "step": 5345
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001672427116959049,
      "loss": 2.3633,
      "step": 5346
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001672298260330548,
      "loss": 2.3867,
      "step": 5347
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016721693833292007,
      "loss": 2.4609,
      "step": 5348
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0016720404859589132,
      "loss": 2.4336,
      "step": 5349
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016719115682235915,
      "loss": 2.5,
      "step": 5350
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016717826301271424,
      "loss": 2.1699,
      "step": 5351
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016716536716734726,
      "loss": 2.3633,
      "step": 5352
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016715246928664907,
      "loss": 2.5703,
      "step": 5353
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016713956937101045,
      "loss": 2.4844,
      "step": 5354
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016712666742082233,
      "loss": 2.4727,
      "step": 5355
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016711376343647572,
      "loss": 2.418,
      "step": 5356
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016710085741836159,
      "loss": 2.3633,
      "step": 5357
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016708794936687108,
      "loss": 2.4805,
      "step": 5358
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016707503928239534,
      "loss": 2.4297,
      "step": 5359
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016706212716532556,
      "loss": 2.4219,
      "step": 5360
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016704921301605306,
      "loss": 2.3672,
      "step": 5361
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016703629683496916,
      "loss": 2.6016,
      "step": 5362
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016702337862246526,
      "loss": 2.6055,
      "step": 5363
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016701045837893282,
      "loss": 2.3984,
      "step": 5364
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.001669975361047634,
      "loss": 2.3672,
      "step": 5365
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016698461180034855,
      "loss": 2.2207,
      "step": 5366
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.001669716854660799,
      "loss": 2.4648,
      "step": 5367
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016695875710234925,
      "loss": 2.4023,
      "step": 5368
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016694582670954826,
      "loss": 2.6758,
      "step": 5369
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016693289428806883,
      "loss": 2.5586,
      "step": 5370
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016691995983830284,
      "loss": 2.4062,
      "step": 5371
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016690702336064228,
      "loss": 2.6094,
      "step": 5372
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.001668940848554791,
      "loss": 2.4414,
      "step": 5373
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016688114432320542,
      "loss": 2.1406,
      "step": 5374
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016686820176421337,
      "loss": 2.2012,
      "step": 5375
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.001668552571788952,
      "loss": 2.3477,
      "step": 5376
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.001668423105676431,
      "loss": 2.2734,
      "step": 5377
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016682936193084942,
      "loss": 2.3711,
      "step": 5378
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016681641126890655,
      "loss": 2.5234,
      "step": 5379
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016680345858220696,
      "loss": 2.5352,
      "step": 5380
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.001667905038711431,
      "loss": 2.4297,
      "step": 5381
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016677754713610763,
      "loss": 2.25,
      "step": 5382
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016676458837749308,
      "loss": 2.3945,
      "step": 5383
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016675162759569222,
      "loss": 2.3828,
      "step": 5384
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016673866479109776,
      "loss": 2.3164,
      "step": 5385
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016672569996410255,
      "loss": 2.2578,
      "step": 5386
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016671273311509944,
      "loss": 2.2422,
      "step": 5387
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.001666997642444814,
      "loss": 2.2109,
      "step": 5388
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016668679335264138,
      "loss": 2.5352,
      "step": 5389
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016667382043997249,
      "loss": 2.5742,
      "step": 5390
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016666084550686782,
      "loss": 2.3945,
      "step": 5391
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016664786855372057,
      "loss": 2.2969,
      "step": 5392
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016663488958092395,
      "loss": 2.4297,
      "step": 5393
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016662190858887135,
      "loss": 2.3828,
      "step": 5394
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016660892557795602,
      "loss": 2.3359,
      "step": 5395
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016659594054857147,
      "loss": 2.4414,
      "step": 5396
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016658295350111115,
      "loss": 2.3945,
      "step": 5397
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016656996443596866,
      "loss": 2.5195,
      "step": 5398
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016655697335353754,
      "loss": 2.3516,
      "step": 5399
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016654398025421151,
      "loss": 2.3711,
      "step": 5400
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016653098513838432,
      "loss": 2.418,
      "step": 5401
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016651798800644973,
      "loss": 2.1309,
      "step": 5402
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.001665049888588016,
      "loss": 2.4102,
      "step": 5403
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016649198769583381,
      "loss": 2.5117,
      "step": 5404
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016647898451794046,
      "loss": 2.2852,
      "step": 5405
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016646597932551547,
      "loss": 2.4336,
      "step": 5406
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016645297211895296,
      "loss": 2.25,
      "step": 5407
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016643996289864714,
      "loss": 2.3203,
      "step": 5408
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016642695166499218,
      "loss": 2.5078,
      "step": 5409
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016641393841838239,
      "loss": 2.2949,
      "step": 5410
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.001664009231592121,
      "loss": 2.3164,
      "step": 5411
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016638790588787574,
      "loss": 2.2969,
      "step": 5412
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016637488660476776,
      "loss": 2.5,
      "step": 5413
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016636186531028265,
      "loss": 2.3008,
      "step": 5414
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.001663488420048151,
      "loss": 2.4844,
      "step": 5415
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016633581668875964,
      "loss": 2.4844,
      "step": 5416
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016632278936251105,
      "loss": 2.2383,
      "step": 5417
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.001663097600264641,
      "loss": 2.2344,
      "step": 5418
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.001662967286810136,
      "loss": 2.3711,
      "step": 5419
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016628369532655442,
      "loss": 2.5391,
      "step": 5420
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016627065996348159,
      "loss": 2.4727,
      "step": 5421
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016625762259219004,
      "loss": 2.457,
      "step": 5422
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016624458321307489,
      "loss": 2.2773,
      "step": 5423
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016623154182653127,
      "loss": 2.5352,
      "step": 5424
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.001662184984329544,
      "loss": 2.25,
      "step": 5425
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016620545303273947,
      "loss": 2.5352,
      "step": 5426
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016619240562628186,
      "loss": 2.5469,
      "step": 5427
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016617935621397694,
      "loss": 2.3398,
      "step": 5428
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016616630479622013,
      "loss": 2.3711,
      "step": 5429
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016615325137340692,
      "loss": 2.2246,
      "step": 5430
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016614019594593293,
      "loss": 2.582,
      "step": 5431
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016612713851419372,
      "loss": 2.457,
      "step": 5432
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016611407907858502,
      "loss": 2.4062,
      "step": 5433
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016610101763950252,
      "loss": 2.4297,
      "step": 5434
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016608795419734209,
      "loss": 2.6172,
      "step": 5435
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016607488875249952,
      "loss": 2.5234,
      "step": 5436
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.001660618213053708,
      "loss": 2.4961,
      "step": 5437
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016604875185635192,
      "loss": 2.2461,
      "step": 5438
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016603568040583884,
      "loss": 2.4531,
      "step": 5439
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016602260695422779,
      "loss": 2.2227,
      "step": 5440
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016600953150191485,
      "loss": 2.5234,
      "step": 5441
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0016599645404929628,
      "loss": 2.5352,
      "step": 5442
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016598337459676836,
      "loss": 2.6523,
      "step": 5443
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016597029314472747,
      "loss": 2.2695,
      "step": 5444
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016595720969356997,
      "loss": 2.1719,
      "step": 5445
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016594412424369238,
      "loss": 2.4531,
      "step": 5446
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001659310367954912,
      "loss": 2.4414,
      "step": 5447
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016591794734936306,
      "loss": 2.5039,
      "step": 5448
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016590485590570454,
      "loss": 2.5586,
      "step": 5449
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016589176246491243,
      "loss": 2.4492,
      "step": 5450
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016587866702738347,
      "loss": 2.3008,
      "step": 5451
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001658655695935145,
      "loss": 2.3438,
      "step": 5452
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016585247016370243,
      "loss": 2.5742,
      "step": 5453
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016583936873834418,
      "loss": 2.4844,
      "step": 5454
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001658262653178368,
      "loss": 2.4023,
      "step": 5455
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016581315990257734,
      "loss": 2.6602,
      "step": 5456
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016580005249296295,
      "loss": 2.4922,
      "step": 5457
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016578694308939086,
      "loss": 2.3945,
      "step": 5458
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016577383169225825,
      "loss": 2.1602,
      "step": 5459
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016576071830196252,
      "loss": 2.5664,
      "step": 5460
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016574760291890103,
      "loss": 2.418,
      "step": 5461
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016573448554347116,
      "loss": 2.3633,
      "step": 5462
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001657213661760705,
      "loss": 2.5352,
      "step": 5463
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016570824481709652,
      "loss": 2.4414,
      "step": 5464
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016569512146694687,
      "loss": 2.3438,
      "step": 5465
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016568199612601929,
      "loss": 2.5547,
      "step": 5466
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016566886879471146,
      "loss": 2.2617,
      "step": 5467
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016565573947342118,
      "loss": 2.2012,
      "step": 5468
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016564260816254635,
      "loss": 2.3047,
      "step": 5469
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016562947486248487,
      "loss": 2.3711,
      "step": 5470
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016561633957363471,
      "loss": 2.4609,
      "step": 5471
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001656032022963939,
      "loss": 2.4453,
      "step": 5472
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001655900630311606,
      "loss": 2.4727,
      "step": 5473
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016557692177833292,
      "loss": 2.2578,
      "step": 5474
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001655637785383091,
      "loss": 2.2695,
      "step": 5475
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016555063331148746,
      "loss": 2.375,
      "step": 5476
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016553748609826628,
      "loss": 2.457,
      "step": 5477
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00165524336899044,
      "loss": 2.3555,
      "step": 5478
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001655111857142191,
      "loss": 2.1406,
      "step": 5479
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016549803254419003,
      "loss": 2.4219,
      "step": 5480
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016548487738935545,
      "loss": 2.3555,
      "step": 5481
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00165471720250114,
      "loss": 2.1992,
      "step": 5482
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016545856112686432,
      "loss": 2.332,
      "step": 5483
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016544540002000525,
      "loss": 2.4727,
      "step": 5484
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001654322369299356,
      "loss": 2.4102,
      "step": 5485
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001654190718570542,
      "loss": 2.2031,
      "step": 5486
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016540590480176008,
      "loss": 2.5391,
      "step": 5487
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016539273576445216,
      "loss": 2.2891,
      "step": 5488
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016537956474552953,
      "loss": 2.5273,
      "step": 5489
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016536639174539137,
      "loss": 2.3281,
      "step": 5490
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016535321676443679,
      "loss": 2.3594,
      "step": 5491
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016534003980306512,
      "loss": 2.3945,
      "step": 5492
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016532686086167556,
      "loss": 2.6016,
      "step": 5493
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016531367994066755,
      "loss": 2.3242,
      "step": 5494
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001653004970404405,
      "loss": 2.5039,
      "step": 5495
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016528731216139388,
      "loss": 2.5508,
      "step": 5496
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016527412530392724,
      "loss": 2.5,
      "step": 5497
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001652609364684402,
      "loss": 2.3945,
      "step": 5498
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016524774565533243,
      "loss": 2.4102,
      "step": 5499
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016523455286500362,
      "loss": 2.4492,
      "step": 5500
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016522135809785357,
      "loss": 2.3281,
      "step": 5501
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016520816135428215,
      "loss": 2.3711,
      "step": 5502
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016519496263468923,
      "loss": 2.6055,
      "step": 5503
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016518176193947478,
      "loss": 2.5898,
      "step": 5504
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001651685592690389,
      "loss": 2.4492,
      "step": 5505
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016515535462378152,
      "loss": 2.5195,
      "step": 5506
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016514214800410292,
      "loss": 2.4688,
      "step": 5507
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016512893941040324,
      "loss": 2.5586,
      "step": 5508
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016511572884308275,
      "loss": 2.5312,
      "step": 5509
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016510251630254178,
      "loss": 2.4414,
      "step": 5510
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016508930178918077,
      "loss": 2.5625,
      "step": 5511
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016507608530340005,
      "loss": 2.3945,
      "step": 5512
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016506286684560018,
      "loss": 2.4062,
      "step": 5513
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001650496464161818,
      "loss": 2.5391,
      "step": 5514
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001650364240155454,
      "loss": 2.2109,
      "step": 5515
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016502319964409172,
      "loss": 2.4922,
      "step": 5516
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001650099733022215,
      "loss": 2.6836,
      "step": 5517
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016499674499033557,
      "loss": 2.4648,
      "step": 5518
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016498351470883472,
      "loss": 2.2695,
      "step": 5519
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016497028245811996,
      "loss": 2.3555,
      "step": 5520
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016495704823859222,
      "loss": 2.5391,
      "step": 5521
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016494381205065251,
      "loss": 2.3086,
      "step": 5522
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016493057389470201,
      "loss": 2.332,
      "step": 5523
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016491733377114184,
      "loss": 2.4375,
      "step": 5524
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001649040916803732,
      "loss": 2.5273,
      "step": 5525
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016489084762279737,
      "loss": 2.3184,
      "step": 5526
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001648776015988157,
      "loss": 2.4531,
      "step": 5527
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016486435360882964,
      "loss": 2.4492,
      "step": 5528
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016485110365324054,
      "loss": 2.3477,
      "step": 5529
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016483785173245001,
      "loss": 2.3555,
      "step": 5530
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016482459784685956,
      "loss": 2.3984,
      "step": 5531
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016481134199687092,
      "loss": 2.2188,
      "step": 5532
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016479808418288567,
      "loss": 2.3398,
      "step": 5533
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016478482440530561,
      "loss": 2.3125,
      "step": 5534
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0016477156266453262,
      "loss": 2.5273,
      "step": 5535
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016475829896096849,
      "loss": 2.2734,
      "step": 5536
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016474503329501516,
      "loss": 2.4492,
      "step": 5537
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016473176566707468,
      "loss": 2.2578,
      "step": 5538
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016471849607754905,
      "loss": 2.3164,
      "step": 5539
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016470522452684043,
      "loss": 2.4297,
      "step": 5540
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016469195101535092,
      "loss": 2.4922,
      "step": 5541
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001646786755434828,
      "loss": 2.2871,
      "step": 5542
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001646653981116384,
      "loss": 2.2539,
      "step": 5543
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016465211872021999,
      "loss": 2.2852,
      "step": 5544
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016463883736963002,
      "loss": 2.5078,
      "step": 5545
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016462555406027094,
      "loss": 2.2891,
      "step": 5546
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016461226879254528,
      "loss": 2.3633,
      "step": 5547
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016459898156685564,
      "loss": 2.6289,
      "step": 5548
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001645856923836047,
      "loss": 2.4961,
      "step": 5549
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016457240124319508,
      "loss": 2.3008,
      "step": 5550
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016455910814602963,
      "loss": 2.3555,
      "step": 5551
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016454581309251113,
      "loss": 2.3203,
      "step": 5552
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016453251608304247,
      "loss": 2.2812,
      "step": 5553
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016451921711802657,
      "loss": 2.4492,
      "step": 5554
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001645059161978665,
      "loss": 2.5195,
      "step": 5555
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016449261332296525,
      "loss": 2.3516,
      "step": 5556
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00164479308493726,
      "loss": 2.3359,
      "step": 5557
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016446600171055189,
      "loss": 2.4141,
      "step": 5558
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016445269297384617,
      "loss": 2.6211,
      "step": 5559
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016443938228401212,
      "loss": 2.3789,
      "step": 5560
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016442606964145315,
      "loss": 2.1953,
      "step": 5561
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001644127550465726,
      "loss": 2.3398,
      "step": 5562
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00164399438499774,
      "loss": 2.4805,
      "step": 5563
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016438612000146088,
      "loss": 2.3594,
      "step": 5564
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016437279955203686,
      "loss": 2.3711,
      "step": 5565
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016435947715190552,
      "loss": 2.3711,
      "step": 5566
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001643461528014706,
      "loss": 2.4414,
      "step": 5567
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001643328265011359,
      "loss": 2.4062,
      "step": 5568
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016431949825130526,
      "loss": 2.2461,
      "step": 5569
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016430616805238251,
      "loss": 2.2637,
      "step": 5570
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016429283590477168,
      "loss": 2.4023,
      "step": 5571
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001642795018088767,
      "loss": 2.5508,
      "step": 5572
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016426616576510169,
      "loss": 2.3047,
      "step": 5573
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016425282777385074,
      "loss": 2.3633,
      "step": 5574
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016423948783552804,
      "loss": 2.1602,
      "step": 5575
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016422614595053787,
      "loss": 2.4219,
      "step": 5576
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016421280211928449,
      "loss": 2.4414,
      "step": 5577
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016419945634217228,
      "loss": 2.5977,
      "step": 5578
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016418610861960567,
      "loss": 2.4297,
      "step": 5579
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016417275895198912,
      "loss": 2.5703,
      "step": 5580
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001641594073397272,
      "loss": 2.3438,
      "step": 5581
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016414605378322444,
      "loss": 2.3125,
      "step": 5582
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016413269828288557,
      "loss": 2.4844,
      "step": 5583
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001641193408391153,
      "loss": 2.4883,
      "step": 5584
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016410598145231833,
      "loss": 2.2188,
      "step": 5585
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016409262012289962,
      "loss": 2.4102,
      "step": 5586
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001640792568512639,
      "loss": 2.4648,
      "step": 5587
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001640658916378163,
      "loss": 2.375,
      "step": 5588
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016405252448296165,
      "loss": 2.3359,
      "step": 5589
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016403915538710518,
      "loss": 2.6094,
      "step": 5590
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001640257843506519,
      "loss": 2.3125,
      "step": 5591
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016401241137400707,
      "loss": 2.3906,
      "step": 5592
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016399903645757587,
      "loss": 2.4258,
      "step": 5593
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016398565960176368,
      "loss": 2.6719,
      "step": 5594
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016397228080697582,
      "loss": 2.4258,
      "step": 5595
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016395890007361769,
      "loss": 2.6367,
      "step": 5596
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001639455174020948,
      "loss": 2.3262,
      "step": 5597
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016393213279281272,
      "loss": 2.375,
      "step": 5598
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016391874624617695,
      "loss": 2.2188,
      "step": 5599
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016390535776259325,
      "loss": 2.3008,
      "step": 5600
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001638919673424673,
      "loss": 2.4805,
      "step": 5601
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016387857498620483,
      "loss": 2.2539,
      "step": 5602
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016386518069421174,
      "loss": 2.2773,
      "step": 5603
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001638517844668939,
      "loss": 2.2383,
      "step": 5604
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016383838630465721,
      "loss": 2.4062,
      "step": 5605
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016382498620790777,
      "loss": 2.2344,
      "step": 5606
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016381158417705154,
      "loss": 2.3066,
      "step": 5607
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016379818021249474,
      "loss": 2.3945,
      "step": 5608
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001637847743146435,
      "loss": 2.3633,
      "step": 5609
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016377136648390404,
      "loss": 2.4453,
      "step": 5610
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016375795672068274,
      "loss": 2.3984,
      "step": 5611
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016374454502538591,
      "loss": 2.3242,
      "step": 5612
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016373113139842,
      "loss": 2.3398,
      "step": 5613
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016371771584019145,
      "loss": 2.2383,
      "step": 5614
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016370429835110677,
      "loss": 2.3867,
      "step": 5615
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016369087893157266,
      "loss": 2.3516,
      "step": 5616
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016367745758199565,
      "loss": 2.6367,
      "step": 5617
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016366403430278255,
      "loss": 2.3633,
      "step": 5618
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016365060909434006,
      "loss": 2.3164,
      "step": 5619
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016363718195707504,
      "loss": 2.3398,
      "step": 5620
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016362375289139437,
      "loss": 2.375,
      "step": 5621
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016361032189770497,
      "loss": 2.1328,
      "step": 5622
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016359688897641393,
      "loss": 2.543,
      "step": 5623
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016358345412792819,
      "loss": 2.3984,
      "step": 5624
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016357001735265498,
      "loss": 2.418,
      "step": 5625
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016355657865100136,
      "loss": 2.2656,
      "step": 5626
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016354313802337472,
      "loss": 2.4531,
      "step": 5627
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0016352969547018224,
      "loss": 2.0957,
      "step": 5628
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016351625099183128,
      "loss": 2.4688,
      "step": 5629
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016350280458872928,
      "loss": 2.1348,
      "step": 5630
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016348935626128373,
      "loss": 2.2461,
      "step": 5631
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016347590600990212,
      "loss": 2.2402,
      "step": 5632
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016346245383499207,
      "loss": 2.457,
      "step": 5633
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016344899973696116,
      "loss": 2.3594,
      "step": 5634
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001634355437162172,
      "loss": 2.2852,
      "step": 5635
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016342208577316787,
      "loss": 2.3672,
      "step": 5636
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016340862590822098,
      "loss": 2.5,
      "step": 5637
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016339516412178447,
      "loss": 2.293,
      "step": 5638
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016338170041426626,
      "loss": 2.625,
      "step": 5639
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001633682347860743,
      "loss": 2.3633,
      "step": 5640
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016335476723761668,
      "loss": 2.582,
      "step": 5641
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016334129776930152,
      "loss": 2.4492,
      "step": 5642
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016332782638153697,
      "loss": 2.4766,
      "step": 5643
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016331435307473123,
      "loss": 2.5391,
      "step": 5644
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016330087784929264,
      "loss": 2.3105,
      "step": 5645
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016328740070562953,
      "loss": 2.3906,
      "step": 5646
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001632739216441503,
      "loss": 2.5195,
      "step": 5647
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016326044066526336,
      "loss": 2.5312,
      "step": 5648
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016324695776937727,
      "loss": 2.5742,
      "step": 5649
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016323347295690064,
      "loss": 2.3633,
      "step": 5650
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016321998622824206,
      "loss": 2.4766,
      "step": 5651
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016320649758381023,
      "loss": 2.3086,
      "step": 5652
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016319300702401392,
      "loss": 2.6328,
      "step": 5653
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016317951454926187,
      "loss": 2.1875,
      "step": 5654
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016316602015996305,
      "loss": 2.4531,
      "step": 5655
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001631525238565263,
      "loss": 2.3086,
      "step": 5656
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016313902563936064,
      "loss": 2.4414,
      "step": 5657
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001631255255088751,
      "loss": 2.3438,
      "step": 5658
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016311202346547878,
      "loss": 2.7148,
      "step": 5659
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016309851950958086,
      "loss": 2.3281,
      "step": 5660
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001630850136415905,
      "loss": 2.2734,
      "step": 5661
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016307150586191703,
      "loss": 2.3789,
      "step": 5662
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016305799617096972,
      "loss": 2.4844,
      "step": 5663
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016304448456915803,
      "loss": 2.4609,
      "step": 5664
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016303097105689135,
      "loss": 2.375,
      "step": 5665
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016301745563457924,
      "loss": 2.2305,
      "step": 5666
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016300393830263116,
      "loss": 2.2207,
      "step": 5667
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016299041906145683,
      "loss": 2.293,
      "step": 5668
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016297689791146591,
      "loss": 2.668,
      "step": 5669
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016296337485306807,
      "loss": 2.3867,
      "step": 5670
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016294984988667318,
      "loss": 2.3867,
      "step": 5671
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016293632301269106,
      "loss": 2.3008,
      "step": 5672
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001629227942315316,
      "loss": 2.4531,
      "step": 5673
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001629092635436048,
      "loss": 2.418,
      "step": 5674
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016289573094932066,
      "loss": 2.6445,
      "step": 5675
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016288219644908929,
      "loss": 2.2422,
      "step": 5676
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016286866004332078,
      "loss": 2.5938,
      "step": 5677
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001628551217324254,
      "loss": 2.5156,
      "step": 5678
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016284158151681333,
      "loss": 2.4141,
      "step": 5679
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016282803939689492,
      "loss": 2.3594,
      "step": 5680
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016281449537308055,
      "loss": 2.4375,
      "step": 5681
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016280094944578067,
      "loss": 2.2715,
      "step": 5682
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016278740161540567,
      "loss": 2.457,
      "step": 5683
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016277385188236619,
      "loss": 2.3203,
      "step": 5684
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016276030024707279,
      "loss": 2.5,
      "step": 5685
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016274674670993614,
      "loss": 2.5273,
      "step": 5686
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016273319127136695,
      "loss": 2.5273,
      "step": 5687
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016271963393177603,
      "loss": 2.2617,
      "step": 5688
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016270607469157413,
      "loss": 2.375,
      "step": 5689
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001626925135511722,
      "loss": 2.5625,
      "step": 5690
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016267895051098118,
      "loss": 2.3711,
      "step": 5691
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001626653855714121,
      "loss": 2.3027,
      "step": 5692
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016265181873287595,
      "loss": 2.2539,
      "step": 5693
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016263824999578392,
      "loss": 2.3789,
      "step": 5694
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016262467936054715,
      "loss": 2.3359,
      "step": 5695
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016261110682757687,
      "loss": 2.3477,
      "step": 5696
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001625975323972844,
      "loss": 2.4141,
      "step": 5697
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016258395607008109,
      "loss": 2.3008,
      "step": 5698
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016257037784637833,
      "loss": 2.5,
      "step": 5699
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001625567977265876,
      "loss": 2.3477,
      "step": 5700
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001625432157111204,
      "loss": 2.6562,
      "step": 5701
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001625296318003883,
      "loss": 2.4453,
      "step": 5702
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00162516045994803,
      "loss": 2.4922,
      "step": 5703
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016250245829477615,
      "loss": 2.6055,
      "step": 5704
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016248886870071945,
      "loss": 2.2715,
      "step": 5705
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001624752772130448,
      "loss": 2.6094,
      "step": 5706
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016246168383216406,
      "loss": 2.3242,
      "step": 5707
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001624480885584891,
      "loss": 2.3711,
      "step": 5708
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016243449139243193,
      "loss": 2.1777,
      "step": 5709
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016242089233440456,
      "loss": 2.3789,
      "step": 5710
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016240729138481914,
      "loss": 2.4102,
      "step": 5711
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016239368854408778,
      "loss": 2.3633,
      "step": 5712
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016238008381262272,
      "loss": 2.1875,
      "step": 5713
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001623664771908362,
      "loss": 2.1621,
      "step": 5714
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016235286867914058,
      "loss": 2.3359,
      "step": 5715
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.001623392582779482,
      "loss": 2.3516,
      "step": 5716
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016232564598767155,
      "loss": 2.3086,
      "step": 5717
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016231203180872304,
      "loss": 2.4883,
      "step": 5718
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016229841574151535,
      "loss": 2.3789,
      "step": 5719
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016228479778646098,
      "loss": 2.1504,
      "step": 5720
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0016227117794397265,
      "loss": 2.5273,
      "step": 5721
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016225755621446308,
      "loss": 2.4297,
      "step": 5722
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001622439325983451,
      "loss": 2.5703,
      "step": 5723
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001622303070960314,
      "loss": 2.3984,
      "step": 5724
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001622166797079351,
      "loss": 2.3242,
      "step": 5725
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016220305043446897,
      "loss": 2.3086,
      "step": 5726
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016218941927604606,
      "loss": 2.2793,
      "step": 5727
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016217578623307952,
      "loss": 2.3789,
      "step": 5728
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016216215130598242,
      "loss": 2.4805,
      "step": 5729
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001621485144951679,
      "loss": 2.3281,
      "step": 5730
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016213487580104928,
      "loss": 2.457,
      "step": 5731
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001621212352240398,
      "loss": 2.2617,
      "step": 5732
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016210759276455288,
      "loss": 2.3984,
      "step": 5733
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016209394842300183,
      "loss": 2.3867,
      "step": 5734
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001620803021998002,
      "loss": 2.1914,
      "step": 5735
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016206665409536152,
      "loss": 2.4219,
      "step": 5736
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016205300411009929,
      "loss": 2.3945,
      "step": 5737
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016203935224442722,
      "loss": 2.3281,
      "step": 5738
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00162025698498759,
      "loss": 2.2266,
      "step": 5739
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001620120428735084,
      "loss": 2.3828,
      "step": 5740
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016199838536908918,
      "loss": 2.4766,
      "step": 5741
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001619847259859152,
      "loss": 2.2891,
      "step": 5742
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016197106472440046,
      "loss": 2.2227,
      "step": 5743
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001619574015849589,
      "loss": 2.332,
      "step": 5744
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016194373656800449,
      "loss": 2.3281,
      "step": 5745
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016193006967395146,
      "loss": 2.4414,
      "step": 5746
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016191640090321387,
      "loss": 2.3398,
      "step": 5747
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016190273025620593,
      "loss": 2.2461,
      "step": 5748
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016188905773334194,
      "loss": 2.4102,
      "step": 5749
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001618753833350362,
      "loss": 2.4531,
      "step": 5750
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016186170706170308,
      "loss": 2.3594,
      "step": 5751
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016184802891375705,
      "loss": 2.3867,
      "step": 5752
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016183434889161256,
      "loss": 2.543,
      "step": 5753
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016182066699568422,
      "loss": 2.2832,
      "step": 5754
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001618069832263866,
      "loss": 2.4414,
      "step": 5755
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016179329758413434,
      "loss": 2.3711,
      "step": 5756
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001617796100693422,
      "loss": 2.1543,
      "step": 5757
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016176592068242496,
      "loss": 2.3145,
      "step": 5758
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016175222942379742,
      "loss": 2.4531,
      "step": 5759
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016173853629387444,
      "loss": 2.3359,
      "step": 5760
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016172484129307106,
      "loss": 2.2832,
      "step": 5761
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016171114442180225,
      "loss": 2.7305,
      "step": 5762
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016169744568048298,
      "loss": 2.4219,
      "step": 5763
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016168374506952852,
      "loss": 2.1602,
      "step": 5764
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016167004258935394,
      "loss": 2.2773,
      "step": 5765
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016165633824037449,
      "loss": 2.4453,
      "step": 5766
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016164263202300545,
      "loss": 2.4062,
      "step": 5767
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016162892393766217,
      "loss": 2.207,
      "step": 5768
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016161521398476008,
      "loss": 2.3398,
      "step": 5769
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016160150216471458,
      "loss": 2.4961,
      "step": 5770
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016158778847794127,
      "loss": 2.0703,
      "step": 5771
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001615740729248556,
      "loss": 2.4062,
      "step": 5772
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001615603555058733,
      "loss": 2.457,
      "step": 5773
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016154663622141002,
      "loss": 2.4844,
      "step": 5774
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016153291507188148,
      "loss": 2.5859,
      "step": 5775
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001615191920577035,
      "loss": 2.5234,
      "step": 5776
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016150546717929191,
      "loss": 2.3984,
      "step": 5777
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016149174043706262,
      "loss": 2.3672,
      "step": 5778
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016147801183143164,
      "loss": 2.3867,
      "step": 5779
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016146428136281493,
      "loss": 2.4023,
      "step": 5780
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001614505490316286,
      "loss": 2.332,
      "step": 5781
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016143681483828877,
      "loss": 2.3105,
      "step": 5782
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001614230787832117,
      "loss": 2.2246,
      "step": 5783
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016140934086681352,
      "loss": 2.332,
      "step": 5784
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016139560108951062,
      "loss": 2.3301,
      "step": 5785
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001613818594517193,
      "loss": 2.4043,
      "step": 5786
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016136811595385606,
      "loss": 2.5195,
      "step": 5787
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016135437059633729,
      "loss": 2.5078,
      "step": 5788
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016134062337957956,
      "loss": 2.3105,
      "step": 5789
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016132687430399943,
      "loss": 2.3594,
      "step": 5790
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016131312337001361,
      "loss": 2.2852,
      "step": 5791
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001612993705780387,
      "loss": 2.4297,
      "step": 5792
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016128561592849155,
      "loss": 2.4688,
      "step": 5793
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001612718594217889,
      "loss": 2.3223,
      "step": 5794
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016125810105834765,
      "loss": 2.2188,
      "step": 5795
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016124434083858471,
      "loss": 2.3086,
      "step": 5796
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001612305787629171,
      "loss": 2.2852,
      "step": 5797
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016121681483176177,
      "loss": 2.3125,
      "step": 5798
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016120304904553588,
      "loss": 2.2539,
      "step": 5799
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016118928140465658,
      "loss": 2.4102,
      "step": 5800
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016117551190954105,
      "loss": 2.3945,
      "step": 5801
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016116174056060655,
      "loss": 2.4258,
      "step": 5802
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016114796735827045,
      "loss": 2.2812,
      "step": 5803
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016113419230295001,
      "loss": 2.4883,
      "step": 5804
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016112041539506276,
      "loss": 2.3555,
      "step": 5805
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016110663663502617,
      "loss": 2.3477,
      "step": 5806
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016109285602325775,
      "loss": 2.293,
      "step": 5807
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016107907356017514,
      "loss": 2.4414,
      "step": 5808
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016106528924619593,
      "loss": 2.4062,
      "step": 5809
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001610515030817379,
      "loss": 2.4258,
      "step": 5810
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016103771506721877,
      "loss": 2.5,
      "step": 5811
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016102392520305638,
      "loss": 2.2031,
      "step": 5812
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016101013348966858,
      "loss": 2.4609,
      "step": 5813
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0016099633992747336,
      "loss": 2.3203,
      "step": 5814
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016098254451688866,
      "loss": 2.3477,
      "step": 5815
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016096874725833254,
      "loss": 2.2305,
      "step": 5816
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016095494815222314,
      "loss": 2.4297,
      "step": 5817
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016094114719897856,
      "loss": 2.5938,
      "step": 5818
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016092734439901704,
      "loss": 2.4141,
      "step": 5819
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016091353975275686,
      "loss": 2.3574,
      "step": 5820
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016089973326061633,
      "loss": 2.4609,
      "step": 5821
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016088592492301385,
      "loss": 2.457,
      "step": 5822
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016087211474036783,
      "loss": 2.3711,
      "step": 5823
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001608583027130968,
      "loss": 2.3672,
      "step": 5824
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016084448884161927,
      "loss": 2.2891,
      "step": 5825
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001608306731263539,
      "loss": 2.3477,
      "step": 5826
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016081685556771925,
      "loss": 2.4688,
      "step": 5827
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016080303616613416,
      "loss": 2.3496,
      "step": 5828
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016078921492201732,
      "loss": 2.3789,
      "step": 5829
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001607753918357876,
      "loss": 2.4688,
      "step": 5830
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016076156690786388,
      "loss": 2.4023,
      "step": 5831
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016074774013866506,
      "loss": 2.4766,
      "step": 5832
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016073391152861018,
      "loss": 2.418,
      "step": 5833
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016072008107811833,
      "loss": 2.5,
      "step": 5834
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001607062487876085,
      "loss": 2.2812,
      "step": 5835
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016069241465749998,
      "loss": 2.5195,
      "step": 5836
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001606785786882119,
      "loss": 2.3574,
      "step": 5837
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016066474088016359,
      "loss": 2.3789,
      "step": 5838
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016065090123377433,
      "loss": 2.207,
      "step": 5839
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016063705974946356,
      "loss": 2.3789,
      "step": 5840
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016062321642765066,
      "loss": 2.3125,
      "step": 5841
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001606093712687552,
      "loss": 2.543,
      "step": 5842
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016059552427319672,
      "loss": 2.7617,
      "step": 5843
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016058167544139477,
      "loss": 2.3047,
      "step": 5844
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016056782477376907,
      "loss": 2.3711,
      "step": 5845
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016055397227073933,
      "loss": 2.2246,
      "step": 5846
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016054011793272531,
      "loss": 2.3867,
      "step": 5847
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016052626176014685,
      "loss": 2.4531,
      "step": 5848
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016051240375342388,
      "loss": 2.6328,
      "step": 5849
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016049854391297627,
      "loss": 2.6367,
      "step": 5850
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016048468223922407,
      "loss": 2.5195,
      "step": 5851
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016047081873258732,
      "loss": 2.2266,
      "step": 5852
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016045695339348609,
      "loss": 2.4023,
      "step": 5853
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016044308622234062,
      "loss": 2.3633,
      "step": 5854
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016042921721957108,
      "loss": 2.4531,
      "step": 5855
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016041534638559776,
      "loss": 2.2227,
      "step": 5856
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016040147372084102,
      "loss": 2.3867,
      "step": 5857
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016038759922572118,
      "loss": 2.3496,
      "step": 5858
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016037372290065872,
      "loss": 2.3906,
      "step": 5859
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016035984474607418,
      "loss": 2.3945,
      "step": 5860
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016034596476238803,
      "loss": 2.3164,
      "step": 5861
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016033208295002095,
      "loss": 2.4023,
      "step": 5862
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016031819930939358,
      "loss": 2.3945,
      "step": 5863
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001603043138409266,
      "loss": 2.543,
      "step": 5864
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016029042654504084,
      "loss": 2.375,
      "step": 5865
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016027653742215714,
      "loss": 2.2852,
      "step": 5866
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016026264647269635,
      "loss": 2.4805,
      "step": 5867
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001602487536970794,
      "loss": 2.3555,
      "step": 5868
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001602348590957273,
      "loss": 2.2773,
      "step": 5869
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016022096266906111,
      "loss": 2.0703,
      "step": 5870
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00160207064417502,
      "loss": 2.3555,
      "step": 5871
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00160193164341471,
      "loss": 2.3867,
      "step": 5872
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016017926244138946,
      "loss": 2.293,
      "step": 5873
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016016535871767852,
      "loss": 2.3867,
      "step": 5874
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001601514531707596,
      "loss": 2.4727,
      "step": 5875
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016013754580105407,
      "loss": 2.5742,
      "step": 5876
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016012363660898336,
      "loss": 2.3086,
      "step": 5877
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00160109725594969,
      "loss": 2.1875,
      "step": 5878
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016009581275943248,
      "loss": 2.2266,
      "step": 5879
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016008189810279541,
      "loss": 2.418,
      "step": 5880
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001600679816254795,
      "loss": 2.3164,
      "step": 5881
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016005406332790639,
      "loss": 2.3008,
      "step": 5882
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016004014321049794,
      "loss": 2.3477,
      "step": 5883
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016002622127367593,
      "loss": 2.3086,
      "step": 5884
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0016001229751786221,
      "loss": 2.4805,
      "step": 5885
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0015999837194347877,
      "loss": 2.2578,
      "step": 5886
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0015998444455094757,
      "loss": 2.4375,
      "step": 5887
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0015997051534069064,
      "loss": 2.5312,
      "step": 5888
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0015995658431313014,
      "loss": 2.4727,
      "step": 5889
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0015994265146868818,
      "loss": 2.7695,
      "step": 5890
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0015992871680778698,
      "loss": 2.1328,
      "step": 5891
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001599147803308488,
      "loss": 2.3555,
      "step": 5892
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0015990084203829596,
      "loss": 2.2461,
      "step": 5893
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0015988690193055087,
      "loss": 2.4336,
      "step": 5894
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001598729600080359,
      "loss": 2.3672,
      "step": 5895
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001598590162711736,
      "loss": 2.5234,
      "step": 5896
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0015984507072038644,
      "loss": 2.3359,
      "step": 5897
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0015983112335609714,
      "loss": 2.4453,
      "step": 5898
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0015981717417872818,
      "loss": 2.3555,
      "step": 5899
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0015980322318870242,
      "loss": 2.3867,
      "step": 5900
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0015978927038644251,
      "loss": 2.5234,
      "step": 5901
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0015977531577237131,
      "loss": 2.2969,
      "step": 5902
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001597613593469117,
      "loss": 2.4922,
      "step": 5903
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0015974740111048661,
      "loss": 2.7227,
      "step": 5904
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00159733441063519,
      "loss": 2.2891,
      "step": 5905
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0015971947920643194,
      "loss": 2.3828,
      "step": 5906
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0015970551553964847,
      "loss": 2.4961,
      "step": 5907
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015969155006359175,
      "loss": 2.418,
      "step": 5908
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015967758277868498,
      "loss": 2.3398,
      "step": 5909
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015966361368535144,
      "loss": 2.2695,
      "step": 5910
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015964964278401444,
      "loss": 2.2344,
      "step": 5911
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001596356700750973,
      "loss": 2.4609,
      "step": 5912
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015962169555902347,
      "loss": 2.4062,
      "step": 5913
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015960771923621642,
      "loss": 2.3945,
      "step": 5914
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015959374110709966,
      "loss": 2.3633,
      "step": 5915
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001595797611720968,
      "loss": 2.1641,
      "step": 5916
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015956577943163147,
      "loss": 2.4883,
      "step": 5917
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015955179588612737,
      "loss": 2.2207,
      "step": 5918
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015953781053600821,
      "loss": 2.375,
      "step": 5919
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015952382338169785,
      "loss": 2.457,
      "step": 5920
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015950983442362013,
      "loss": 2.2148,
      "step": 5921
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001594958436621989,
      "loss": 2.3984,
      "step": 5922
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015948185109785822,
      "loss": 2.3867,
      "step": 5923
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015946785673102205,
      "loss": 2.3477,
      "step": 5924
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015945386056211448,
      "loss": 2.4609,
      "step": 5925
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015943986259155962,
      "loss": 2.2617,
      "step": 5926
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001594258628197817,
      "loss": 2.2578,
      "step": 5927
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015941186124720493,
      "loss": 2.2227,
      "step": 5928
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015939785787425361,
      "loss": 2.3438,
      "step": 5929
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015938385270135207,
      "loss": 2.5078,
      "step": 5930
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015936984572892474,
      "loss": 2.4961,
      "step": 5931
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015935583695739605,
      "loss": 2.5234,
      "step": 5932
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015934182638719058,
      "loss": 2.5156,
      "step": 5933
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015932781401873277,
      "loss": 2.543,
      "step": 5934
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001593137998524474,
      "loss": 2.5625,
      "step": 5935
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015929978388875897,
      "loss": 2.2578,
      "step": 5936
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015928576612809235,
      "loss": 2.4219,
      "step": 5937
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015927174657087227,
      "loss": 2.4805,
      "step": 5938
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015925772521752357,
      "loss": 2.4258,
      "step": 5939
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015924370206847115,
      "loss": 2.5586,
      "step": 5940
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015922967712413993,
      "loss": 2.2461,
      "step": 5941
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015921565038495493,
      "loss": 2.3125,
      "step": 5942
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015920162185134126,
      "loss": 2.5078,
      "step": 5943
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015918759152372395,
      "loss": 2.3828,
      "step": 5944
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001591735594025282,
      "loss": 2.3984,
      "step": 5945
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015915952548817922,
      "loss": 2.3359,
      "step": 5946
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001591454897811023,
      "loss": 2.3789,
      "step": 5947
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015913145228172274,
      "loss": 2.4844,
      "step": 5948
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015911741299046596,
      "loss": 2.5195,
      "step": 5949
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001591033719077574,
      "loss": 2.4688,
      "step": 5950
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015908932903402249,
      "loss": 2.4141,
      "step": 5951
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015907528436968682,
      "loss": 2.2266,
      "step": 5952
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015906123791517598,
      "loss": 2.2578,
      "step": 5953
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015904718967091563,
      "loss": 2.4844,
      "step": 5954
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015903313963733145,
      "loss": 2.2734,
      "step": 5955
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015901908781484927,
      "loss": 2.3008,
      "step": 5956
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015900503420389486,
      "loss": 2.2305,
      "step": 5957
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015899097880489408,
      "loss": 2.4141,
      "step": 5958
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015897692161827286,
      "loss": 2.4375,
      "step": 5959
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001589628626444572,
      "loss": 2.4141,
      "step": 5960
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001589488018838731,
      "loss": 2.3398,
      "step": 5961
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015893473933694668,
      "loss": 2.3828,
      "step": 5962
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015892067500410407,
      "loss": 2.1953,
      "step": 5963
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015890660888577147,
      "loss": 2.4141,
      "step": 5964
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001588925409823751,
      "loss": 2.2344,
      "step": 5965
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015887847129434133,
      "loss": 2.2227,
      "step": 5966
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015886439982209645,
      "loss": 2.2285,
      "step": 5967
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015885032656606688,
      "loss": 2.3984,
      "step": 5968
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001588362515266791,
      "loss": 2.4883,
      "step": 5969
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015882217470435966,
      "loss": 2.2852,
      "step": 5970
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001588080960995351,
      "loss": 2.1777,
      "step": 5971
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015879401571263208,
      "loss": 2.3203,
      "step": 5972
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015877993354407724,
      "loss": 2.4531,
      "step": 5973
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015876584959429731,
      "loss": 2.2812,
      "step": 5974
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015875176386371912,
      "loss": 2.1953,
      "step": 5975
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015873767635276948,
      "loss": 2.2656,
      "step": 5976
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015872358706187533,
      "loss": 2.5117,
      "step": 5977
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015870949599146359,
      "loss": 2.3828,
      "step": 5978
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015869540314196126,
      "loss": 2.3242,
      "step": 5979
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015868130851379543,
      "loss": 2.418,
      "step": 5980
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015866721210739316,
      "loss": 2.4961,
      "step": 5981
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015865311392318168,
      "loss": 2.3828,
      "step": 5982
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015863901396158818,
      "loss": 2.4062,
      "step": 5983
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015862491222303995,
      "loss": 2.3438,
      "step": 5984
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001586108087079643,
      "loss": 2.457,
      "step": 5985
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001585967034167886,
      "loss": 2.4766,
      "step": 5986
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015858259634994032,
      "loss": 2.4023,
      "step": 5987
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015856848750784693,
      "loss": 2.4062,
      "step": 5988
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00158554376890936,
      "loss": 2.3164,
      "step": 5989
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015854026449963513,
      "loss": 2.4688,
      "step": 5990
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015852615033437193,
      "loss": 2.3086,
      "step": 5991
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001585120343955741,
      "loss": 2.4805,
      "step": 5992
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015849791668366944,
      "loss": 2.3438,
      "step": 5993
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015848379719908576,
      "loss": 2.1836,
      "step": 5994
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015846967594225095,
      "loss": 2.4219,
      "step": 5995
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015845555291359283,
      "loss": 2.3516,
      "step": 5996
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015844142811353948,
      "loss": 2.293,
      "step": 5997
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015842730154251887,
      "loss": 2.4219,
      "step": 5998
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015841317320095913,
      "loss": 2.418,
      "step": 5999
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0015839904308928836,
      "loss": 2.3555,
      "step": 6000
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015838491120793476,
      "loss": 2.1855,
      "step": 6001
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015837077755732655,
      "loss": 2.3398,
      "step": 6002
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015835664213789205,
      "loss": 2.3594,
      "step": 6003
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015834250495005957,
      "loss": 2.3516,
      "step": 6004
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015832836599425758,
      "loss": 2.2676,
      "step": 6005
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015831422527091453,
      "loss": 2.2812,
      "step": 6006
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015830008278045888,
      "loss": 2.2266,
      "step": 6007
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015828593852331915,
      "loss": 2.4297,
      "step": 6008
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015827179249992412,
      "loss": 2.3359,
      "step": 6009
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001582576447107023,
      "loss": 2.4219,
      "step": 6010
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015824349515608253,
      "loss": 2.3203,
      "step": 6011
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001582293438364935,
      "loss": 2.3906,
      "step": 6012
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015821519075236413,
      "loss": 2.375,
      "step": 6013
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001582010359041232,
      "loss": 2.4609,
      "step": 6014
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015818687929219973,
      "loss": 2.5508,
      "step": 6015
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001581727209170227,
      "loss": 2.3594,
      "step": 6016
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001581585607790211,
      "loss": 2.5,
      "step": 6017
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015814439887862407,
      "loss": 2.5273,
      "step": 6018
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001581302352162608,
      "loss": 2.4062,
      "step": 6019
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015811606979236042,
      "loss": 2.3008,
      "step": 6020
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015810190260735224,
      "loss": 2.2695,
      "step": 6021
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015808773366166556,
      "loss": 2.3242,
      "step": 6022
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015807356295572973,
      "loss": 2.3086,
      "step": 6023
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015805939048997419,
      "loss": 2.2969,
      "step": 6024
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001580452162648284,
      "loss": 2.5039,
      "step": 6025
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015803104028072191,
      "loss": 2.5039,
      "step": 6026
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015801686253808427,
      "loss": 2.4219,
      "step": 6027
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001580026830373451,
      "loss": 2.5781,
      "step": 6028
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001579885017789341,
      "loss": 2.4727,
      "step": 6029
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015797431876328103,
      "loss": 2.3906,
      "step": 6030
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015796013399081569,
      "loss": 2.332,
      "step": 6031
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001579459474619679,
      "loss": 2.4062,
      "step": 6032
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015793175917716753,
      "loss": 2.293,
      "step": 6033
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001579175691368446,
      "loss": 2.4023,
      "step": 6034
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015790337734142904,
      "loss": 2.5078,
      "step": 6035
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015788918379135094,
      "loss": 2.3594,
      "step": 6036
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015787498848704043,
      "loss": 2.3242,
      "step": 6037
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015786079142892765,
      "loss": 2.3164,
      "step": 6038
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015784659261744288,
      "loss": 2.4609,
      "step": 6039
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001578323920530163,
      "loss": 2.6602,
      "step": 6040
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015781818973607824,
      "loss": 2.5352,
      "step": 6041
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015780398566705917,
      "loss": 2.5586,
      "step": 6042
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015778977984638942,
      "loss": 2.5273,
      "step": 6043
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015777557227449953,
      "loss": 2.3477,
      "step": 6044
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015776136295182002,
      "loss": 2.418,
      "step": 6045
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015774715187878146,
      "loss": 2.3594,
      "step": 6046
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015773293905581452,
      "loss": 2.4727,
      "step": 6047
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001577187244833499,
      "loss": 2.4961,
      "step": 6048
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001577045081618183,
      "loss": 2.6406,
      "step": 6049
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001576902900916506,
      "loss": 2.3672,
      "step": 6050
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015767607027327756,
      "loss": 2.375,
      "step": 6051
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015766184870713016,
      "loss": 2.4922,
      "step": 6052
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015764762539363932,
      "loss": 2.4844,
      "step": 6053
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015763340033323608,
      "loss": 2.2695,
      "step": 6054
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001576191735263515,
      "loss": 2.3438,
      "step": 6055
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015760494497341672,
      "loss": 2.6992,
      "step": 6056
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015759071467486283,
      "loss": 2.3984,
      "step": 6057
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015757648263112114,
      "loss": 2.4492,
      "step": 6058
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001575622488426229,
      "loss": 2.2812,
      "step": 6059
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015754801330979944,
      "loss": 2.4648,
      "step": 6060
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015753377603308213,
      "loss": 2.4961,
      "step": 6061
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015751953701290242,
      "loss": 2.3945,
      "step": 6062
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001575052962496918,
      "loss": 2.3008,
      "step": 6063
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015749105374388184,
      "loss": 2.5859,
      "step": 6064
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015747680949590407,
      "loss": 2.3203,
      "step": 6065
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001574625635061902,
      "loss": 2.3086,
      "step": 6066
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015744831577517186,
      "loss": 2.5039,
      "step": 6067
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015743406630328086,
      "loss": 2.4258,
      "step": 6068
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00157419815090949,
      "loss": 2.4766,
      "step": 6069
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015740556213860812,
      "loss": 2.5039,
      "step": 6070
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015739130744669017,
      "loss": 2.5586,
      "step": 6071
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015737705101562705,
      "loss": 2.5234,
      "step": 6072
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015736279284585084,
      "loss": 2.3398,
      "step": 6073
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015734853293779354,
      "loss": 2.4609,
      "step": 6074
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015733427129188736,
      "loss": 2.4219,
      "step": 6075
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001573200079085644,
      "loss": 2.375,
      "step": 6076
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015730574278825693,
      "loss": 2.4023,
      "step": 6077
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001572914759313972,
      "loss": 2.3008,
      "step": 6078
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015727720733841757,
      "loss": 2.418,
      "step": 6079
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015726293700975042,
      "loss": 2.543,
      "step": 6080
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015724866494582818,
      "loss": 2.5469,
      "step": 6081
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015723439114708332,
      "loss": 2.1602,
      "step": 6082
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001572201156139484,
      "loss": 2.3555,
      "step": 6083
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015720583834685602,
      "loss": 2.5234,
      "step": 6084
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015719155934623887,
      "loss": 2.3516,
      "step": 6085
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015717727861252956,
      "loss": 2.1816,
      "step": 6086
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015716299614616093,
      "loss": 2.4492,
      "step": 6087
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015714871194756573,
      "loss": 2.5625,
      "step": 6088
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015713442601717682,
      "loss": 2.2617,
      "step": 6089
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015712013835542714,
      "loss": 2.4062,
      "step": 6090
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015710584896274965,
      "loss": 2.2852,
      "step": 6091
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0015709155783957733,
      "loss": 2.4453,
      "step": 6092
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001570772649863433,
      "loss": 2.3398,
      "step": 6093
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015706297040348064,
      "loss": 2.4375,
      "step": 6094
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015704867409142254,
      "loss": 2.3711,
      "step": 6095
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001570343760506022,
      "loss": 2.2344,
      "step": 6096
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015702007628145293,
      "loss": 2.4102,
      "step": 6097
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015700577478440804,
      "loss": 2.3555,
      "step": 6098
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015699147155990097,
      "loss": 2.4883,
      "step": 6099
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015697716660836504,
      "loss": 2.3008,
      "step": 6100
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015696285993023384,
      "loss": 2.3281,
      "step": 6101
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015694855152594087,
      "loss": 2.3633,
      "step": 6102
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015693424139591975,
      "loss": 2.2578,
      "step": 6103
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015691992954060404,
      "loss": 2.5156,
      "step": 6104
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001569056159604275,
      "loss": 2.3516,
      "step": 6105
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001568913006558239,
      "loss": 2.2656,
      "step": 6106
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00156876983627227,
      "loss": 2.2695,
      "step": 6107
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015686266487507068,
      "loss": 2.4766,
      "step": 6108
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001568483443997888,
      "loss": 2.4688,
      "step": 6109
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015683402220181537,
      "loss": 2.4414,
      "step": 6110
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015681969828158437,
      "loss": 2.4258,
      "step": 6111
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001568053726395299,
      "loss": 2.4219,
      "step": 6112
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015679104527608603,
      "loss": 2.2773,
      "step": 6113
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015677671619168693,
      "loss": 2.4102,
      "step": 6114
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015676238538676684,
      "loss": 2.5352,
      "step": 6115
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015674805286176002,
      "loss": 2.418,
      "step": 6116
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015673371861710077,
      "loss": 2.5703,
      "step": 6117
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015671938265322352,
      "loss": 2.293,
      "step": 6118
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015670504497056262,
      "loss": 2.4414,
      "step": 6119
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001566907055695526,
      "loss": 2.5508,
      "step": 6120
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00156676364450628,
      "loss": 2.4336,
      "step": 6121
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001566620216142234,
      "loss": 2.4023,
      "step": 6122
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015664767706077341,
      "loss": 2.457,
      "step": 6123
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015663333079071271,
      "loss": 2.3906,
      "step": 6124
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015661898280447607,
      "loss": 2.4453,
      "step": 6125
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015660463310249828,
      "loss": 2.3867,
      "step": 6126
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015659028168521416,
      "loss": 2.5625,
      "step": 6127
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015657592855305863,
      "loss": 2.4648,
      "step": 6128
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001565615737064666,
      "loss": 2.3555,
      "step": 6129
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001565472171458731,
      "loss": 2.3945,
      "step": 6130
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015653285887171318,
      "loss": 2.4336,
      "step": 6131
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015651849888442192,
      "loss": 2.2109,
      "step": 6132
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015650413718443453,
      "loss": 2.4219,
      "step": 6133
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015648977377218617,
      "loss": 2.625,
      "step": 6134
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015647540864811207,
      "loss": 2.5,
      "step": 6135
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001564610418126476,
      "loss": 2.3438,
      "step": 6136
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001564466732662281,
      "loss": 2.2227,
      "step": 6137
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015643230300928896,
      "loss": 2.2656,
      "step": 6138
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001564179310422657,
      "loss": 2.3242,
      "step": 6139
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001564035573655938,
      "loss": 2.3359,
      "step": 6140
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015638918197970885,
      "loss": 2.4648,
      "step": 6141
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001563748048850464,
      "loss": 2.3242,
      "step": 6142
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015636042608204225,
      "loss": 2.2656,
      "step": 6143
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00156346045571132,
      "loss": 2.4766,
      "step": 6144
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015633166335275153,
      "loss": 2.4355,
      "step": 6145
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001563172794273366,
      "loss": 2.4141,
      "step": 6146
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015630289379532313,
      "loss": 2.3867,
      "step": 6147
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00156288506457147,
      "loss": 2.5352,
      "step": 6148
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015627411741324427,
      "loss": 2.3281,
      "step": 6149
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015625972666405091,
      "loss": 2.3125,
      "step": 6150
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015624533421000303,
      "loss": 2.0352,
      "step": 6151
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015623094005153676,
      "loss": 2.4531,
      "step": 6152
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001562165441890883,
      "loss": 2.5039,
      "step": 6153
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015620214662309389,
      "loss": 2.543,
      "step": 6154
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015618774735398984,
      "loss": 2.5938,
      "step": 6155
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015617334638221246,
      "loss": 2.3359,
      "step": 6156
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015615894370819819,
      "loss": 2.3125,
      "step": 6157
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015614453933238345,
      "loss": 2.2812,
      "step": 6158
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001561301332552047,
      "loss": 2.4844,
      "step": 6159
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015611572547709859,
      "loss": 2.2695,
      "step": 6160
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015610131599850163,
      "loss": 2.4375,
      "step": 6161
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015608690481985054,
      "loss": 2.6328,
      "step": 6162
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00156072491941582,
      "loss": 2.3477,
      "step": 6163
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015605807736413274,
      "loss": 2.3477,
      "step": 6164
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015604366108793962,
      "loss": 2.3672,
      "step": 6165
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015602924311343947,
      "loss": 2.25,
      "step": 6166
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015601482344106922,
      "loss": 2.3906,
      "step": 6167
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001560004020712658,
      "loss": 2.2773,
      "step": 6168
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015598597900446625,
      "loss": 2.3926,
      "step": 6169
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015597155424110763,
      "loss": 2.5078,
      "step": 6170
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001559571277816271,
      "loss": 2.1328,
      "step": 6171
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015594269962646173,
      "loss": 2.2305,
      "step": 6172
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015592826977604887,
      "loss": 2.2148,
      "step": 6173
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015591383823082565,
      "loss": 2.5586,
      "step": 6174
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001558994049912295,
      "loss": 2.4766,
      "step": 6175
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015588497005769775,
      "loss": 2.2812,
      "step": 6176
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015587053343066786,
      "loss": 2.5117,
      "step": 6177
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015585609511057723,
      "loss": 2.4336,
      "step": 6178
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001558416550978635,
      "loss": 2.4258,
      "step": 6179
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015582721339296418,
      "loss": 2.2773,
      "step": 6180
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015581276999631687,
      "loss": 2.4609,
      "step": 6181
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015579832490835934,
      "loss": 2.5391,
      "step": 6182
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015578387812952925,
      "loss": 2.3945,
      "step": 6183
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015576942966026444,
      "loss": 2.293,
      "step": 6184
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001557549795010027,
      "loss": 2.3203,
      "step": 6185
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0015574052765218193,
      "loss": 2.5703,
      "step": 6186
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.001557260741142401,
      "loss": 2.3828,
      "step": 6187
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015571161888761518,
      "loss": 2.5273,
      "step": 6188
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015569716197274517,
      "loss": 2.4062,
      "step": 6189
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.001556827033700682,
      "loss": 2.3828,
      "step": 6190
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015566824308002243,
      "loss": 2.3867,
      "step": 6191
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015565378110304604,
      "loss": 2.2402,
      "step": 6192
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015563931743957727,
      "loss": 2.5312,
      "step": 6193
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015562485209005441,
      "loss": 2.2656,
      "step": 6194
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.001556103850549158,
      "loss": 2.3516,
      "step": 6195
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015559591633459986,
      "loss": 2.5117,
      "step": 6196
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015558144592954504,
      "loss": 2.5039,
      "step": 6197
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015556697384018984,
      "loss": 2.2266,
      "step": 6198
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.001555525000669728,
      "loss": 2.3516,
      "step": 6199
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015553802461033253,
      "loss": 2.5664,
      "step": 6200
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.001555235474707077,
      "loss": 2.2852,
      "step": 6201
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015550906864853697,
      "loss": 2.0859,
      "step": 6202
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015549458814425915,
      "loss": 2.4258,
      "step": 6203
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015548010595831298,
      "loss": 2.3223,
      "step": 6204
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015546562209113738,
      "loss": 2.3184,
      "step": 6205
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015545113654317124,
      "loss": 2.3984,
      "step": 6206
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.001554366493148535,
      "loss": 2.5117,
      "step": 6207
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015542216040662323,
      "loss": 2.375,
      "step": 6208
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.001554076698189194,
      "loss": 2.3047,
      "step": 6209
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015539317755218118,
      "loss": 2.2734,
      "step": 6210
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015537868360684772,
      "loss": 2.3398,
      "step": 6211
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015536418798335826,
      "loss": 2.2305,
      "step": 6212
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015534969068215206,
      "loss": 2.2578,
      "step": 6213
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015533519170366837,
      "loss": 2.543,
      "step": 6214
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015532069104834663,
      "loss": 2.2422,
      "step": 6215
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015530618871662622,
      "loss": 2.332,
      "step": 6216
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015529168470894664,
      "loss": 2.4492,
      "step": 6217
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.001552771790257474,
      "loss": 2.3281,
      "step": 6218
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015526267166746804,
      "loss": 2.2734,
      "step": 6219
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015524816263454819,
      "loss": 2.3047,
      "step": 6220
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015523365192742756,
      "loss": 2.4609,
      "step": 6221
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015521913954654582,
      "loss": 2.4375,
      "step": 6222
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.001552046254923428,
      "loss": 2.4297,
      "step": 6223
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015519010976525825,
      "loss": 2.5195,
      "step": 6224
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015517559236573213,
      "loss": 2.3438,
      "step": 6225
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015516107329420427,
      "loss": 2.5,
      "step": 6226
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015514655255111473,
      "loss": 2.2051,
      "step": 6227
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015513203013690351,
      "loss": 2.0664,
      "step": 6228
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015511750605201064,
      "loss": 2.4492,
      "step": 6229
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015510298029687633,
      "loss": 2.2656,
      "step": 6230
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015508845287194068,
      "loss": 2.3477,
      "step": 6231
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015507392377764398,
      "loss": 2.4727,
      "step": 6232
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015505939301442646,
      "loss": 2.293,
      "step": 6233
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015504486058272847,
      "loss": 2.457,
      "step": 6234
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015503032648299042,
      "loss": 2.5098,
      "step": 6235
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.001550157907156527,
      "loss": 2.4023,
      "step": 6236
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.001550012532811558,
      "loss": 2.3984,
      "step": 6237
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015498671417994024,
      "loss": 2.4355,
      "step": 6238
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015497217341244665,
      "loss": 2.4141,
      "step": 6239
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015495763097911563,
      "loss": 2.375,
      "step": 6240
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015494308688038785,
      "loss": 2.3633,
      "step": 6241
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015492854111670406,
      "loss": 2.4453,
      "step": 6242
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015491399368850506,
      "loss": 2.4531,
      "step": 6243
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015489944459623165,
      "loss": 2.4414,
      "step": 6244
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015488489384032475,
      "loss": 2.4688,
      "step": 6245
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015487034142122526,
      "loss": 2.543,
      "step": 6246
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.001548557873393742,
      "loss": 2.2109,
      "step": 6247
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015484123159521259,
      "loss": 2.1387,
      "step": 6248
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015482667418918155,
      "loss": 2.332,
      "step": 6249
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015481211512172214,
      "loss": 2.4492,
      "step": 6250
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015479755439327563,
      "loss": 2.375,
      "step": 6251
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015478299200428318,
      "loss": 2.3535,
      "step": 6252
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015476842795518616,
      "loss": 2.3008,
      "step": 6253
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015475386224642587,
      "loss": 2.3555,
      "step": 6254
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015473929487844367,
      "loss": 2.2578,
      "step": 6255
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015472472585168105,
      "loss": 2.3789,
      "step": 6256
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015471015516657944,
      "loss": 2.2773,
      "step": 6257
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015469558282358044,
      "loss": 2.3477,
      "step": 6258
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015468100882312563,
      "loss": 2.625,
      "step": 6259
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015466643316565665,
      "loss": 2.5391,
      "step": 6260
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015465185585161515,
      "loss": 2.3516,
      "step": 6261
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015463727688144289,
      "loss": 2.25,
      "step": 6262
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015462269625558167,
      "loss": 2.2988,
      "step": 6263
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015460811397447335,
      "loss": 2.4219,
      "step": 6264
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015459353003855977,
      "loss": 2.3828,
      "step": 6265
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015457894444828291,
      "loss": 2.4336,
      "step": 6266
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015456435720408474,
      "loss": 2.4102,
      "step": 6267
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015454976830640735,
      "loss": 2.2969,
      "step": 6268
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015453517775569276,
      "loss": 2.4492,
      "step": 6269
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015452058555238315,
      "loss": 2.2969,
      "step": 6270
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015450599169692075,
      "loss": 2.5391,
      "step": 6271
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.001544913961897477,
      "loss": 2.2305,
      "step": 6272
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015447679903130638,
      "loss": 2.4883,
      "step": 6273
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015446220022203915,
      "loss": 2.4375,
      "step": 6274
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015444759976238828,
      "loss": 2.2578,
      "step": 6275
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015443299765279632,
      "loss": 2.4766,
      "step": 6276
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015441839389370572,
      "loss": 2.3516,
      "step": 6277
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015440378848555905,
      "loss": 2.4961,
      "step": 6278
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0015438918142879885,
      "loss": 2.5117,
      "step": 6279
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015437457272386781,
      "loss": 2.5273,
      "step": 6280
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001543599623712086,
      "loss": 2.3086,
      "step": 6281
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015434535037126401,
      "loss": 2.4297,
      "step": 6282
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015433073672447672,
      "loss": 2.3164,
      "step": 6283
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015431612143128968,
      "loss": 2.375,
      "step": 6284
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015430150449214572,
      "loss": 2.2969,
      "step": 6285
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015428688590748787,
      "loss": 2.2266,
      "step": 6286
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00154272265677759,
      "loss": 2.293,
      "step": 6287
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015425764380340222,
      "loss": 2.3906,
      "step": 6288
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001542430202848606,
      "loss": 2.4219,
      "step": 6289
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015422839512257726,
      "loss": 2.4297,
      "step": 6290
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015421376831699547,
      "loss": 2.6172,
      "step": 6291
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015419913986855838,
      "loss": 2.4766,
      "step": 6292
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015418450977770935,
      "loss": 2.6914,
      "step": 6293
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015416987804489164,
      "loss": 2.3164,
      "step": 6294
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015415524467054876,
      "loss": 2.4277,
      "step": 6295
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015414060965512402,
      "loss": 2.5352,
      "step": 6296
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00154125972999061,
      "loss": 2.3047,
      "step": 6297
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015411133470280317,
      "loss": 2.3711,
      "step": 6298
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015409669476679415,
      "loss": 2.3242,
      "step": 6299
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001540820531914776,
      "loss": 2.1543,
      "step": 6300
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001540674099772972,
      "loss": 2.1172,
      "step": 6301
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015405276512469666,
      "loss": 2.4961,
      "step": 6302
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001540381186341198,
      "loss": 2.4453,
      "step": 6303
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015402347050601042,
      "loss": 2.3984,
      "step": 6304
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015400882074081243,
      "loss": 2.4961,
      "step": 6305
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015399416933896978,
      "loss": 2.3867,
      "step": 6306
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015397951630092643,
      "loss": 2.5117,
      "step": 6307
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015396486162712639,
      "loss": 2.3867,
      "step": 6308
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015395020531801386,
      "loss": 2.4453,
      "step": 6309
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001539355473740328,
      "loss": 2.4141,
      "step": 6310
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015392088779562756,
      "loss": 2.3711,
      "step": 6311
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015390622658324228,
      "loss": 2.2617,
      "step": 6312
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015389156373732122,
      "loss": 2.4141,
      "step": 6313
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015387689925830878,
      "loss": 2.4297,
      "step": 6314
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015386223314664935,
      "loss": 2.4453,
      "step": 6315
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015384756540278727,
      "loss": 2.3984,
      "step": 6316
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015383289602716715,
      "loss": 2.4023,
      "step": 6317
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001538182250202334,
      "loss": 2.3672,
      "step": 6318
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001538035523824307,
      "loss": 2.4297,
      "step": 6319
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015378887811420354,
      "loss": 2.3984,
      "step": 6320
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015377420221599674,
      "loss": 2.4375,
      "step": 6321
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015375952468825499,
      "loss": 2.4727,
      "step": 6322
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015374484553142302,
      "loss": 2.418,
      "step": 6323
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001537301647459457,
      "loss": 2.3047,
      "step": 6324
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015371548233226791,
      "loss": 2.3867,
      "step": 6325
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015370079829083454,
      "loss": 2.3066,
      "step": 6326
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015368611262209057,
      "loss": 2.2539,
      "step": 6327
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015367142532648108,
      "loss": 2.3555,
      "step": 6328
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015365673640445109,
      "loss": 2.4141,
      "step": 6329
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015364204585644572,
      "loss": 2.3203,
      "step": 6330
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015362735368291017,
      "loss": 2.2891,
      "step": 6331
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015361265988428966,
      "loss": 2.2598,
      "step": 6332
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015359796446102938,
      "loss": 2.543,
      "step": 6333
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015358326741357479,
      "loss": 2.375,
      "step": 6334
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015356856874237117,
      "loss": 2.418,
      "step": 6335
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015355386844786395,
      "loss": 2.3711,
      "step": 6336
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001535391665304986,
      "loss": 2.5039,
      "step": 6337
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015352446299072065,
      "loss": 2.3066,
      "step": 6338
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015350975782897564,
      "loss": 2.2617,
      "step": 6339
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001534950510457092,
      "loss": 2.2441,
      "step": 6340
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00153480342641367,
      "loss": 2.4609,
      "step": 6341
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015346563261639475,
      "loss": 2.5312,
      "step": 6342
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015345092097123817,
      "loss": 2.2812,
      "step": 6343
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015343620770634314,
      "loss": 2.1934,
      "step": 6344
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015342149282215546,
      "loss": 2.4336,
      "step": 6345
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001534067763191211,
      "loss": 2.4883,
      "step": 6346
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015339205819768597,
      "loss": 2.5508,
      "step": 6347
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015337733845829612,
      "loss": 2.3281,
      "step": 6348
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015336261710139753,
      "loss": 2.3359,
      "step": 6349
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015334789412743645,
      "loss": 2.332,
      "step": 6350
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015333316953685884,
      "loss": 2.6602,
      "step": 6351
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015331844333011106,
      "loss": 2.3867,
      "step": 6352
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015330371550763928,
      "loss": 2.4922,
      "step": 6353
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015328898606988984,
      "loss": 2.3477,
      "step": 6354
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015327425501730908,
      "loss": 2.5078,
      "step": 6355
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015325952235034337,
      "loss": 2.4961,
      "step": 6356
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015324478806943921,
      "loss": 2.2422,
      "step": 6357
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015323005217504307,
      "loss": 2.4453,
      "step": 6358
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001532153146676015,
      "loss": 2.3633,
      "step": 6359
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001532005755475611,
      "loss": 2.4688,
      "step": 6360
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015318583481536848,
      "loss": 2.4805,
      "step": 6361
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015317109247147038,
      "loss": 2.3789,
      "step": 6362
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015315634851631353,
      "loss": 2.2969,
      "step": 6363
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015314160295034466,
      "loss": 2.3945,
      "step": 6364
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015312685577401073,
      "loss": 2.2734,
      "step": 6365
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015311210698775854,
      "loss": 2.5156,
      "step": 6366
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00153097356592035,
      "loss": 2.6211,
      "step": 6367
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001530826045872872,
      "loss": 2.4375,
      "step": 6368
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015306785097396207,
      "loss": 2.5664,
      "step": 6369
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001530530957525068,
      "loss": 2.457,
      "step": 6370
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001530383389233684,
      "loss": 2.3906,
      "step": 6371
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0015302358048699411,
      "loss": 2.6406,
      "step": 6372
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015300882044383117,
      "loss": 2.457,
      "step": 6373
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015299405879432685,
      "loss": 2.5039,
      "step": 6374
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015297929553892851,
      "loss": 2.4414,
      "step": 6375
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015296453067808343,
      "loss": 2.3594,
      "step": 6376
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015294976421223912,
      "loss": 2.5039,
      "step": 6377
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00152934996141843,
      "loss": 2.3906,
      "step": 6378
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015292022646734265,
      "loss": 2.5234,
      "step": 6379
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001529054551891856,
      "loss": 2.4648,
      "step": 6380
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015289068230781946,
      "loss": 2.3945,
      "step": 6381
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015287590782369189,
      "loss": 2.5,
      "step": 6382
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015286113173725068,
      "loss": 2.4453,
      "step": 6383
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001528463540489435,
      "loss": 2.5312,
      "step": 6384
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015283157475921823,
      "loss": 2.1719,
      "step": 6385
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015281679386852268,
      "loss": 2.2773,
      "step": 6386
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015280201137730476,
      "loss": 2.2578,
      "step": 6387
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001527872272860125,
      "loss": 2.668,
      "step": 6388
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015277244159509382,
      "loss": 2.5,
      "step": 6389
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015275765430499684,
      "loss": 2.6172,
      "step": 6390
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015274286541616961,
      "loss": 2.3945,
      "step": 6391
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001527280749290603,
      "loss": 2.3477,
      "step": 6392
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015271328284411716,
      "loss": 2.4961,
      "step": 6393
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015269848916178836,
      "loss": 2.4414,
      "step": 6394
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015268369388252228,
      "loss": 2.2227,
      "step": 6395
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015266889700676718,
      "loss": 2.4102,
      "step": 6396
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001526540985349715,
      "loss": 2.5117,
      "step": 6397
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015263929846758369,
      "loss": 2.3516,
      "step": 6398
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001526244968050522,
      "loss": 2.332,
      "step": 6399
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001526096935478256,
      "loss": 2.5391,
      "step": 6400
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001525948886963525,
      "loss": 2.4258,
      "step": 6401
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015258008225108148,
      "loss": 2.4258,
      "step": 6402
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015256527421246126,
      "loss": 2.3789,
      "step": 6403
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015255046458094057,
      "loss": 2.2695,
      "step": 6404
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015253565335696818,
      "loss": 2.3633,
      "step": 6405
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015252084054099293,
      "loss": 2.2461,
      "step": 6406
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015250602613346366,
      "loss": 2.3438,
      "step": 6407
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001524912101348294,
      "loss": 2.2227,
      "step": 6408
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015247639254553898,
      "loss": 2.3164,
      "step": 6409
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001524615733660415,
      "loss": 2.3672,
      "step": 6410
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015244675259678605,
      "loss": 2.3633,
      "step": 6411
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015243193023822168,
      "loss": 2.3633,
      "step": 6412
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015241710629079763,
      "loss": 2.3711,
      "step": 6413
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015240228075496308,
      "loss": 2.5039,
      "step": 6414
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015238745363116725,
      "loss": 2.2539,
      "step": 6415
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015237262491985956,
      "loss": 2.3281,
      "step": 6416
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015235779462148922,
      "loss": 2.3672,
      "step": 6417
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015234296273650579,
      "loss": 2.1621,
      "step": 6418
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001523281292653586,
      "loss": 2.1191,
      "step": 6419
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015231329420849723,
      "loss": 2.3672,
      "step": 6420
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001522984575663712,
      "loss": 2.5234,
      "step": 6421
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015228361933943013,
      "loss": 2.3594,
      "step": 6422
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015226877952812363,
      "loss": 2.3672,
      "step": 6423
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015225393813290142,
      "loss": 2.5742,
      "step": 6424
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015223909515421324,
      "loss": 2.3086,
      "step": 6425
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015222425059250892,
      "loss": 2.1562,
      "step": 6426
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001522094044482382,
      "loss": 2.3672,
      "step": 6427
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015219455672185107,
      "loss": 2.4219,
      "step": 6428
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001521797074137974,
      "loss": 2.2891,
      "step": 6429
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015216485652452723,
      "loss": 2.2734,
      "step": 6430
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015215000405449054,
      "loss": 2.4258,
      "step": 6431
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015213515000413738,
      "loss": 2.0449,
      "step": 6432
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015212029437391796,
      "loss": 2.5195,
      "step": 6433
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015210543716428241,
      "loss": 2.2188,
      "step": 6434
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015209057837568096,
      "loss": 2.3359,
      "step": 6435
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001520757180085639,
      "loss": 2.3984,
      "step": 6436
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015206085606338147,
      "loss": 2.6328,
      "step": 6437
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015204599254058412,
      "loss": 2.5469,
      "step": 6438
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015203112744062225,
      "loss": 2.1289,
      "step": 6439
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015201626076394629,
      "loss": 2.2734,
      "step": 6440
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015200139251100677,
      "loss": 2.3047,
      "step": 6441
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015198652268225423,
      "loss": 2.3398,
      "step": 6442
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015197165127813928,
      "loss": 2.377,
      "step": 6443
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001519567782991126,
      "loss": 2.4844,
      "step": 6444
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001519419037456249,
      "loss": 2.5781,
      "step": 6445
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015192702761812685,
      "loss": 2.5,
      "step": 6446
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001519121499170693,
      "loss": 2.2812,
      "step": 6447
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001518972706429031,
      "loss": 2.2422,
      "step": 6448
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001518823897960791,
      "loss": 2.3945,
      "step": 6449
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001518675073770483,
      "loss": 2.3203,
      "step": 6450
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015185262338626164,
      "loss": 2.5078,
      "step": 6451
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015183773782417014,
      "loss": 2.5078,
      "step": 6452
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015182285069122493,
      "loss": 2.4375,
      "step": 6453
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015180796198787712,
      "loss": 2.2852,
      "step": 6454
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015179307171457788,
      "loss": 2.1758,
      "step": 6455
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015177817987177841,
      "loss": 2.3906,
      "step": 6456
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015176328645993005,
      "loss": 2.3438,
      "step": 6457
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015174839147948406,
      "loss": 2.2246,
      "step": 6458
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015173349493089183,
      "loss": 2.3672,
      "step": 6459
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015171859681460474,
      "loss": 2.4336,
      "step": 6460
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001517036971310743,
      "loss": 2.4648,
      "step": 6461
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00151688795880752,
      "loss": 2.4688,
      "step": 6462
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015167389306408943,
      "loss": 2.4688,
      "step": 6463
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015165898868153814,
      "loss": 2.3828,
      "step": 6464
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0015164408273354976,
      "loss": 2.4473,
      "step": 6465
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.001516291752205761,
      "loss": 2.3828,
      "step": 6466
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015161426614306878,
      "loss": 2.3535,
      "step": 6467
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015159935550147967,
      "loss": 2.5078,
      "step": 6468
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015158444329626062,
      "loss": 2.3672,
      "step": 6469
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015156952952786347,
      "loss": 2.4609,
      "step": 6470
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.001515546141967402,
      "loss": 2.3359,
      "step": 6471
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015153969730334275,
      "loss": 2.2852,
      "step": 6472
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015152477884812319,
      "loss": 2.4648,
      "step": 6473
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015150985883153356,
      "loss": 2.3047,
      "step": 6474
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015149493725402604,
      "loss": 2.4922,
      "step": 6475
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015148001411605272,
      "loss": 2.2676,
      "step": 6476
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.001514650894180659,
      "loss": 2.4375,
      "step": 6477
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015145016316051782,
      "loss": 2.4609,
      "step": 6478
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015143523534386079,
      "loss": 2.3242,
      "step": 6479
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015142030596854718,
      "loss": 2.3086,
      "step": 6480
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.001514053750350294,
      "loss": 2.3203,
      "step": 6481
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.001513904425437599,
      "loss": 2.3555,
      "step": 6482
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015137550849519115,
      "loss": 2.3984,
      "step": 6483
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015136057288977576,
      "loss": 2.1855,
      "step": 6484
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.001513456357279663,
      "loss": 2.375,
      "step": 6485
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.001513306970102154,
      "loss": 2.3711,
      "step": 6486
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.001513157567369758,
      "loss": 2.3438,
      "step": 6487
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015130081490870018,
      "loss": 2.293,
      "step": 6488
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015128587152584136,
      "loss": 2.3867,
      "step": 6489
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015127092658885218,
      "loss": 2.375,
      "step": 6490
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015125598009818548,
      "loss": 2.4805,
      "step": 6491
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015124103205429427,
      "loss": 2.5586,
      "step": 6492
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015122608245763142,
      "loss": 2.6406,
      "step": 6493
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015121113130865003,
      "loss": 2.1289,
      "step": 6494
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015119617860780315,
      "loss": 2.4727,
      "step": 6495
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015118122435554386,
      "loss": 2.4102,
      "step": 6496
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015116626855232536,
      "loss": 2.3418,
      "step": 6497
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.001511513111986009,
      "loss": 2.3066,
      "step": 6498
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.001511363522948236,
      "loss": 2.5078,
      "step": 6499
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015112139184144692,
      "loss": 2.3984,
      "step": 6500
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015110642983892412,
      "loss": 2.4141,
      "step": 6501
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015109146628770863,
      "loss": 2.3223,
      "step": 6502
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015107650118825386,
      "loss": 2.2969,
      "step": 6503
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015106153454101335,
      "loss": 2.3867,
      "step": 6504
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015104656634644064,
      "loss": 2.4297,
      "step": 6505
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015103159660498923,
      "loss": 2.3906,
      "step": 6506
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015101662531711289,
      "loss": 2.5,
      "step": 6507
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015100165248326516,
      "loss": 2.5352,
      "step": 6508
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015098667810389983,
      "loss": 2.5781,
      "step": 6509
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015097170217947071,
      "loss": 2.4766,
      "step": 6510
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015095672471043156,
      "loss": 2.5508,
      "step": 6511
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015094174569723628,
      "loss": 2.1367,
      "step": 6512
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015092676514033877,
      "loss": 2.3984,
      "step": 6513
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015091178304019297,
      "loss": 2.4531,
      "step": 6514
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015089679939725294,
      "loss": 2.5,
      "step": 6515
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015088181421197265,
      "loss": 2.4492,
      "step": 6516
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.001508668274848063,
      "loss": 2.2422,
      "step": 6517
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015085183921620799,
      "loss": 2.4297,
      "step": 6518
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015083684940663188,
      "loss": 2.3984,
      "step": 6519
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015082185805653228,
      "loss": 2.2188,
      "step": 6520
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.001508068651663634,
      "loss": 2.4844,
      "step": 6521
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015079187073657968,
      "loss": 2.5469,
      "step": 6522
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015077687476763538,
      "loss": 2.5,
      "step": 6523
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015076187725998498,
      "loss": 2.4883,
      "step": 6524
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015074687821408298,
      "loss": 2.373,
      "step": 6525
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015073187763038388,
      "loss": 2.207,
      "step": 6526
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015071687550934224,
      "loss": 2.3711,
      "step": 6527
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015070187185141264,
      "loss": 2.4297,
      "step": 6528
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015068686665704982,
      "loss": 2.4336,
      "step": 6529
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015067185992670843,
      "loss": 2.543,
      "step": 6530
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015065685166084323,
      "loss": 2.3242,
      "step": 6531
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015064184185990903,
      "loss": 2.8047,
      "step": 6532
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015062683052436067,
      "loss": 2.1367,
      "step": 6533
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015061181765465305,
      "loss": 2.168,
      "step": 6534
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015059680325124113,
      "loss": 2.4609,
      "step": 6535
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015058178731457983,
      "loss": 2.166,
      "step": 6536
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015056676984512424,
      "loss": 2.3086,
      "step": 6537
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015055175084332942,
      "loss": 2.6602,
      "step": 6538
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.001505367303096505,
      "loss": 2.4512,
      "step": 6539
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015052170824454265,
      "loss": 2.4219,
      "step": 6540
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015050668464846107,
      "loss": 2.3984,
      "step": 6541
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015049165952186105,
      "loss": 2.3203,
      "step": 6542
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.001504766328651979,
      "loss": 2.2969,
      "step": 6543
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015046160467892694,
      "loss": 2.3594,
      "step": 6544
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015044657496350365,
      "loss": 2.5234,
      "step": 6545
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015043154371938339,
      "loss": 2.4883,
      "step": 6546
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015041651094702172,
      "loss": 2.5469,
      "step": 6547
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015040147664687415,
      "loss": 2.3711,
      "step": 6548
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015038644081939627,
      "loss": 2.3672,
      "step": 6549
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015037140346504372,
      "loss": 2.6992,
      "step": 6550
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.001503563645842722,
      "loss": 2.4297,
      "step": 6551
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015034132417753741,
      "loss": 2.3945,
      "step": 6552
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015032628224529514,
      "loss": 2.1602,
      "step": 6553
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015031123878800124,
      "loss": 2.293,
      "step": 6554
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.001502961938061115,
      "loss": 2.5977,
      "step": 6555
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015028114730008188,
      "loss": 2.5312,
      "step": 6556
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015026609927036834,
      "loss": 2.4258,
      "step": 6557
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0015025104971742689,
      "loss": 2.5078,
      "step": 6558
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0015023599864171352,
      "loss": 2.1758,
      "step": 6559
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0015022094604368443,
      "loss": 2.3633,
      "step": 6560
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0015020589192379567,
      "loss": 2.1758,
      "step": 6561
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0015019083628250351,
      "loss": 2.2305,
      "step": 6562
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0015017577912026412,
      "loss": 2.5195,
      "step": 6563
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001501607204375338,
      "loss": 2.3711,
      "step": 6564
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001501456602347689,
      "loss": 2.4102,
      "step": 6565
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0015013059851242576,
      "loss": 2.3555,
      "step": 6566
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001501155352709608,
      "loss": 2.2969,
      "step": 6567
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0015010047051083055,
      "loss": 2.4355,
      "step": 6568
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0015008540423249142,
      "loss": 2.4648,
      "step": 6569
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0015007033643640005,
      "loss": 2.3711,
      "step": 6570
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0015005526712301301,
      "loss": 2.4375,
      "step": 6571
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0015004019629278696,
      "loss": 2.3242,
      "step": 6572
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0015002512394617857,
      "loss": 2.3945,
      "step": 6573
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0015001005008364464,
      "loss": 2.4375,
      "step": 6574
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014999497470564184,
      "loss": 2.457,
      "step": 6575
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014997989781262717,
      "loss": 2.3477,
      "step": 6576
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014996481940505737,
      "loss": 2.3516,
      "step": 6577
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014994973948338946,
      "loss": 2.3516,
      "step": 6578
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014993465804808033,
      "loss": 2.3164,
      "step": 6579
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014991957509958706,
      "loss": 2.4531,
      "step": 6580
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014990449063836666,
      "loss": 2.5352,
      "step": 6581
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014988940466487627,
      "loss": 2.3906,
      "step": 6582
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014987431717957307,
      "loss": 2.4062,
      "step": 6583
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014985922818291423,
      "loss": 2.5156,
      "step": 6584
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014984413767535696,
      "loss": 2.4492,
      "step": 6585
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014982904565735864,
      "loss": 2.2656,
      "step": 6586
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014981395212937652,
      "loss": 2.3633,
      "step": 6587
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014979885709186802,
      "loss": 2.3867,
      "step": 6588
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014978376054529058,
      "loss": 2.3711,
      "step": 6589
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014976866249010166,
      "loss": 2.5,
      "step": 6590
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001497535629267588,
      "loss": 2.4531,
      "step": 6591
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014973846185571955,
      "loss": 2.3633,
      "step": 6592
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014972335927744154,
      "loss": 2.4766,
      "step": 6593
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014970825519238238,
      "loss": 2.2969,
      "step": 6594
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001496931496009998,
      "loss": 2.3281,
      "step": 6595
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014967804250375159,
      "loss": 2.3398,
      "step": 6596
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001496629339010955,
      "loss": 2.293,
      "step": 6597
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014964782379348937,
      "loss": 2.3477,
      "step": 6598
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001496327121813911,
      "loss": 2.1582,
      "step": 6599
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014961759906525858,
      "loss": 2.5078,
      "step": 6600
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001496024844455499,
      "loss": 2.3672,
      "step": 6601
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014958736832272296,
      "loss": 2.2773,
      "step": 6602
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014957225069723585,
      "loss": 2.2461,
      "step": 6603
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014955713156954676,
      "loss": 2.2266,
      "step": 6604
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014954201094011378,
      "loss": 2.4219,
      "step": 6605
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014952688880939511,
      "loss": 2.2812,
      "step": 6606
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014951176517784906,
      "loss": 2.2324,
      "step": 6607
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014949664004593386,
      "loss": 2.2871,
      "step": 6608
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001494815134141079,
      "loss": 2.3359,
      "step": 6609
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014946638528282952,
      "loss": 2.3711,
      "step": 6610
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001494512556525572,
      "loss": 2.4531,
      "step": 6611
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014943612452374938,
      "loss": 2.4922,
      "step": 6612
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001494209918968646,
      "loss": 2.4609,
      "step": 6613
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014940585777236143,
      "loss": 2.2969,
      "step": 6614
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001493907221506985,
      "loss": 2.2617,
      "step": 6615
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014937558503233443,
      "loss": 2.3555,
      "step": 6616
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014936044641772797,
      "loss": 2.5508,
      "step": 6617
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001493453063073378,
      "loss": 2.5234,
      "step": 6618
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001493301647016228,
      "loss": 2.4336,
      "step": 6619
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014931502160104174,
      "loss": 2.5859,
      "step": 6620
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014929987700605355,
      "loss": 2.3145,
      "step": 6621
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014928473091711714,
      "loss": 2.3398,
      "step": 6622
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001492695833346915,
      "loss": 2.3555,
      "step": 6623
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014925443425923563,
      "loss": 2.3047,
      "step": 6624
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001492392836912086,
      "loss": 2.4531,
      "step": 6625
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014922413163106958,
      "loss": 2.3477,
      "step": 6626
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014920897807927762,
      "loss": 2.5156,
      "step": 6627
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014919382303629203,
      "loss": 2.2812,
      "step": 6628
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00149178666502572,
      "loss": 2.5078,
      "step": 6629
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014916350847857683,
      "loss": 2.4453,
      "step": 6630
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014914834896476586,
      "loss": 2.4336,
      "step": 6631
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014913318796159847,
      "loss": 2.3086,
      "step": 6632
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014911802546953405,
      "loss": 2.4258,
      "step": 6633
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014910286148903217,
      "loss": 2.5156,
      "step": 6634
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014908769602055229,
      "loss": 2.3867,
      "step": 6635
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014907252906455396,
      "loss": 2.543,
      "step": 6636
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014905736062149682,
      "loss": 2.4766,
      "step": 6637
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014904219069184048,
      "loss": 2.2656,
      "step": 6638
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014902701927604468,
      "loss": 2.6484,
      "step": 6639
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001490118463745692,
      "loss": 2.3242,
      "step": 6640
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014899667198787373,
      "loss": 2.3633,
      "step": 6641
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014898149611641816,
      "loss": 2.3477,
      "step": 6642
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014896631876066236,
      "loss": 2.4004,
      "step": 6643
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014895113992106628,
      "loss": 2.2852,
      "step": 6644
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014893595959808983,
      "loss": 2.4805,
      "step": 6645
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014892077779219309,
      "loss": 2.1914,
      "step": 6646
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014890559450383605,
      "loss": 2.2695,
      "step": 6647
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001488904097334789,
      "loss": 2.2617,
      "step": 6648
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001488752234815817,
      "loss": 2.2617,
      "step": 6649
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001488600357486047,
      "loss": 2.3691,
      "step": 6650
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0014884484653500812,
      "loss": 2.1953,
      "step": 6651
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014882965584125224,
      "loss": 2.2969,
      "step": 6652
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014881446366779739,
      "loss": 2.1641,
      "step": 6653
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014879927001510396,
      "loss": 2.207,
      "step": 6654
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014878407488363235,
      "loss": 2.2441,
      "step": 6655
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00148768878273843,
      "loss": 2.5195,
      "step": 6656
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014875368018619647,
      "loss": 2.4883,
      "step": 6657
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014873848062115327,
      "loss": 2.3984,
      "step": 6658
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014872327957917402,
      "loss": 2.2969,
      "step": 6659
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014870807706071933,
      "loss": 2.3047,
      "step": 6660
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014869287306624992,
      "loss": 2.4219,
      "step": 6661
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001486776675962265,
      "loss": 2.3438,
      "step": 6662
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014866246065110987,
      "loss": 2.2617,
      "step": 6663
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014864725223136083,
      "loss": 2.6367,
      "step": 6664
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014863204233744028,
      "loss": 2.4219,
      "step": 6665
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014861683096980905,
      "loss": 2.2383,
      "step": 6666
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001486016181289282,
      "loss": 2.1426,
      "step": 6667
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001485864038152586,
      "loss": 2.4648,
      "step": 6668
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014857118802926142,
      "loss": 2.3828,
      "step": 6669
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014855597077139766,
      "loss": 2.3945,
      "step": 6670
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014854075204212853,
      "loss": 2.4062,
      "step": 6671
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014852553184191515,
      "loss": 2.5781,
      "step": 6672
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014851031017121877,
      "loss": 2.4961,
      "step": 6673
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014849508703050063,
      "loss": 2.3086,
      "step": 6674
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014847986242022204,
      "loss": 2.4453,
      "step": 6675
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001484646363408444,
      "loss": 2.5547,
      "step": 6676
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014844940879282906,
      "loss": 2.4844,
      "step": 6677
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014843417977663748,
      "loss": 2.3789,
      "step": 6678
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001484189492927312,
      "loss": 2.4297,
      "step": 6679
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014840371734157168,
      "loss": 2.4727,
      "step": 6680
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014838848392362053,
      "loss": 2.4648,
      "step": 6681
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014837324903933938,
      "loss": 2.4258,
      "step": 6682
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014835801268918986,
      "loss": 2.418,
      "step": 6683
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014834277487363373,
      "loss": 2.4531,
      "step": 6684
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014832753559313272,
      "loss": 2.2305,
      "step": 6685
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014831229484814862,
      "loss": 2.2969,
      "step": 6686
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014829705263914332,
      "loss": 2.2578,
      "step": 6687
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014828180896657866,
      "loss": 2.4297,
      "step": 6688
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001482665638309166,
      "loss": 2.3477,
      "step": 6689
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014825131723261908,
      "loss": 2.4062,
      "step": 6690
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014823606917214818,
      "loss": 2.4609,
      "step": 6691
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014822081964996595,
      "loss": 2.3477,
      "step": 6692
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014820556866653447,
      "loss": 2.418,
      "step": 6693
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014819031622231589,
      "loss": 2.4727,
      "step": 6694
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001481750623177725,
      "loss": 2.4727,
      "step": 6695
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001481598069533664,
      "loss": 2.1406,
      "step": 6696
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014814455012956,
      "loss": 2.4023,
      "step": 6697
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014812929184681556,
      "loss": 2.2539,
      "step": 6698
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001481140321055955,
      "loss": 2.4375,
      "step": 6699
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001480987709063622,
      "loss": 2.4961,
      "step": 6700
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014808350824957817,
      "loss": 2.3594,
      "step": 6701
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014806824413570588,
      "loss": 2.4023,
      "step": 6702
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001480529785652079,
      "loss": 2.5312,
      "step": 6703
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014803771153854683,
      "loss": 2.3047,
      "step": 6704
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014802244305618531,
      "loss": 2.2539,
      "step": 6705
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014800717311858602,
      "loss": 2.3359,
      "step": 6706
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014799190172621168,
      "loss": 2.2363,
      "step": 6707
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014797662887952507,
      "loss": 2.0898,
      "step": 6708
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014796135457898903,
      "loss": 2.4102,
      "step": 6709
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001479460788250664,
      "loss": 2.4492,
      "step": 6710
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014793080161822005,
      "loss": 2.3477,
      "step": 6711
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014791552295891303,
      "loss": 2.4258,
      "step": 6712
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014790024284760822,
      "loss": 2.4297,
      "step": 6713
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014788496128476873,
      "loss": 2.2422,
      "step": 6714
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014786967827085762,
      "loss": 2.2734,
      "step": 6715
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014785439380633801,
      "loss": 2.3711,
      "step": 6716
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014783910789167307,
      "loss": 2.457,
      "step": 6717
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014782382052732604,
      "loss": 2.5234,
      "step": 6718
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014780853171376012,
      "loss": 2.3516,
      "step": 6719
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001477932414514387,
      "loss": 2.5117,
      "step": 6720
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00147777949740825,
      "loss": 2.5547,
      "step": 6721
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014776265658238254,
      "loss": 2.2969,
      "step": 6722
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014774736197657467,
      "loss": 2.3711,
      "step": 6723
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014773206592386492,
      "loss": 2.3711,
      "step": 6724
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014771676842471675,
      "loss": 2.2812,
      "step": 6725
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014770146947959378,
      "loss": 2.4531,
      "step": 6726
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014768616908895956,
      "loss": 2.4414,
      "step": 6727
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014767086725327781,
      "loss": 2.4336,
      "step": 6728
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014765556397301216,
      "loss": 2.3867,
      "step": 6729
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001476402592486264,
      "loss": 2.2578,
      "step": 6730
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001476249530805843,
      "loss": 2.293,
      "step": 6731
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001476096454693497,
      "loss": 2.3145,
      "step": 6732
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014759433641538641,
      "loss": 2.2852,
      "step": 6733
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014757902591915843,
      "loss": 2.3945,
      "step": 6734
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014756371398112966,
      "loss": 2.4805,
      "step": 6735
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014754840060176408,
      "loss": 2.2773,
      "step": 6736
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014753308578152585,
      "loss": 2.3711,
      "step": 6737
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014751776952087892,
      "loss": 2.3945,
      "step": 6738
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014750245182028753,
      "loss": 2.4336,
      "step": 6739
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014748713268021578,
      "loss": 2.5391,
      "step": 6740
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014747181210112794,
      "loss": 2.2656,
      "step": 6741
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014745649008348824,
      "loss": 2.1172,
      "step": 6742
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014744116662776107,
      "loss": 2.6289,
      "step": 6743
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0014742584173441063,
      "loss": 2.5,
      "step": 6744
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014741051540390145,
      "loss": 2.4766,
      "step": 6745
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001473951876366979,
      "loss": 2.3633,
      "step": 6746
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001473798584332645,
      "loss": 2.3633,
      "step": 6747
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014736452779406575,
      "loss": 2.25,
      "step": 6748
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014734919571956619,
      "loss": 2.5156,
      "step": 6749
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014733386221023048,
      "loss": 2.3164,
      "step": 6750
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001473185272665233,
      "loss": 2.3984,
      "step": 6751
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014730319088890928,
      "loss": 2.3555,
      "step": 6752
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014728785307785322,
      "loss": 2.4922,
      "step": 6753
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014727251383381986,
      "loss": 2.332,
      "step": 6754
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014725717315727405,
      "loss": 2.1035,
      "step": 6755
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014724183104868065,
      "loss": 2.3516,
      "step": 6756
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014722648750850463,
      "loss": 2.3398,
      "step": 6757
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014721114253721085,
      "loss": 2.4102,
      "step": 6758
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001471957961352644,
      "loss": 2.625,
      "step": 6759
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001471804483031303,
      "loss": 2.3516,
      "step": 6760
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014716509904127365,
      "loss": 2.5078,
      "step": 6761
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014714974835015955,
      "loss": 2.2148,
      "step": 6762
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014713439623025319,
      "loss": 2.418,
      "step": 6763
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014711904268201984,
      "loss": 2.4102,
      "step": 6764
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014710368770592468,
      "loss": 2.5391,
      "step": 6765
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001470883313024331,
      "loss": 2.457,
      "step": 6766
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014707297347201036,
      "loss": 2.7109,
      "step": 6767
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001470576142151219,
      "loss": 2.168,
      "step": 6768
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014704225353223317,
      "loss": 2.4023,
      "step": 6769
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014702689142380963,
      "loss": 2.6367,
      "step": 6770
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014701152789031683,
      "loss": 2.4375,
      "step": 6771
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014699616293222025,
      "loss": 2.3203,
      "step": 6772
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001469807965499856,
      "loss": 2.4141,
      "step": 6773
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014696542874407849,
      "loss": 2.293,
      "step": 6774
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014695005951496458,
      "loss": 2.457,
      "step": 6775
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001469346888631097,
      "loss": 2.2539,
      "step": 6776
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014691931678897953,
      "loss": 2.2188,
      "step": 6777
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014690394329303998,
      "loss": 2.3906,
      "step": 6778
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014688856837575686,
      "loss": 2.2617,
      "step": 6779
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001468731920375961,
      "loss": 2.3438,
      "step": 6780
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014685781427902366,
      "loss": 2.5391,
      "step": 6781
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014684243510050552,
      "loss": 2.5273,
      "step": 6782
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014682705450250772,
      "loss": 2.5938,
      "step": 6783
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014681167248549638,
      "loss": 2.6094,
      "step": 6784
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014679628904993756,
      "loss": 2.3164,
      "step": 6785
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014678090419629748,
      "loss": 2.3633,
      "step": 6786
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014676551792504233,
      "loss": 2.4375,
      "step": 6787
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014675013023663838,
      "loss": 2.3828,
      "step": 6788
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014673474113155191,
      "loss": 2.4062,
      "step": 6789
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014671935061024927,
      "loss": 2.5391,
      "step": 6790
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014670395867319686,
      "loss": 2.4023,
      "step": 6791
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014668856532086107,
      "loss": 2.5781,
      "step": 6792
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014667317055370838,
      "loss": 2.332,
      "step": 6793
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014665777437220535,
      "loss": 2.4492,
      "step": 6794
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014664237677681844,
      "loss": 2.2266,
      "step": 6795
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014662697776801435,
      "loss": 2.2109,
      "step": 6796
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014661157734625965,
      "loss": 2.4414,
      "step": 6797
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014659617551202105,
      "loss": 2.5781,
      "step": 6798
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014658077226576526,
      "loss": 2.4688,
      "step": 6799
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014656536760795909,
      "loss": 2.5977,
      "step": 6800
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001465499615390693,
      "loss": 2.4922,
      "step": 6801
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014653455405956278,
      "loss": 2.4336,
      "step": 6802
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014651914516990638,
      "loss": 2.2812,
      "step": 6803
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014650373487056713,
      "loss": 2.457,
      "step": 6804
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014648832316201193,
      "loss": 2.2852,
      "step": 6805
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014647291004470783,
      "loss": 2.2734,
      "step": 6806
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001464574955191219,
      "loss": 2.5039,
      "step": 6807
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014644207958572127,
      "loss": 2.3359,
      "step": 6808
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014642666224497305,
      "loss": 2.457,
      "step": 6809
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001464112434973445,
      "loss": 2.4375,
      "step": 6810
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014639582334330275,
      "loss": 2.3516,
      "step": 6811
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001463804017833152,
      "loss": 2.1426,
      "step": 6812
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014636497881784912,
      "loss": 2.4414,
      "step": 6813
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014634955444737187,
      "loss": 2.4766,
      "step": 6814
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001463341286723509,
      "loss": 2.4219,
      "step": 6815
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014631870149325362,
      "loss": 2.25,
      "step": 6816
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014630327291054752,
      "loss": 2.6602,
      "step": 6817
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014628784292470014,
      "loss": 2.25,
      "step": 6818
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014627241153617914,
      "loss": 2.5391,
      "step": 6819
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014625697874545201,
      "loss": 2.4609,
      "step": 6820
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001462415445529865,
      "loss": 2.2109,
      "step": 6821
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001462261089592503,
      "loss": 2.457,
      "step": 6822
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014621067196471113,
      "loss": 2.4141,
      "step": 6823
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014619523356983683,
      "loss": 2.2422,
      "step": 6824
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014617979377509523,
      "loss": 2.3047,
      "step": 6825
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014616435258095412,
      "loss": 2.4492,
      "step": 6826
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014614890998788158,
      "loss": 2.3008,
      "step": 6827
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001461334659963454,
      "loss": 2.4688,
      "step": 6828
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001461180206068137,
      "loss": 2.25,
      "step": 6829
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014610257381975447,
      "loss": 2.1523,
      "step": 6830
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014608712563563579,
      "loss": 2.3711,
      "step": 6831
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014607167605492587,
      "loss": 2.457,
      "step": 6832
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001460562250780928,
      "loss": 2.543,
      "step": 6833
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014604077270560483,
      "loss": 2.3477,
      "step": 6834
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001460253189379302,
      "loss": 2.4688,
      "step": 6835
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014600986377553721,
      "loss": 2.3555,
      "step": 6836
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0014599440721889427,
      "loss": 2.418,
      "step": 6837
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014597894926846964,
      "loss": 2.2031,
      "step": 6838
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014596348992473188,
      "loss": 2.4141,
      "step": 6839
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014594802918814936,
      "loss": 2.3984,
      "step": 6840
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014593256705919063,
      "loss": 2.4258,
      "step": 6841
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014591710353832421,
      "loss": 2.4023,
      "step": 6842
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014590163862601877,
      "loss": 2.5,
      "step": 6843
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014588617232274286,
      "loss": 2.5156,
      "step": 6844
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014587070462896525,
      "loss": 2.3984,
      "step": 6845
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014585523554515457,
      "loss": 2.5039,
      "step": 6846
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014583976507177964,
      "loss": 2.3008,
      "step": 6847
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014582429320930926,
      "loss": 2.3359,
      "step": 6848
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014580881995821227,
      "loss": 2.543,
      "step": 6849
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014579334531895755,
      "loss": 2.418,
      "step": 6850
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014577786929201404,
      "loss": 2.377,
      "step": 6851
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014576239187785076,
      "loss": 2.3047,
      "step": 6852
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014574691307693663,
      "loss": 2.3242,
      "step": 6853
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001457314328897408,
      "loss": 2.3555,
      "step": 6854
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014571595131673233,
      "loss": 2.1934,
      "step": 6855
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014570046835838037,
      "loss": 2.3789,
      "step": 6856
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014568498401515409,
      "loss": 2.3242,
      "step": 6857
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014566949828752273,
      "loss": 2.4141,
      "step": 6858
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014565401117595553,
      "loss": 2.4414,
      "step": 6859
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014563852268092191,
      "loss": 2.5078,
      "step": 6860
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014562303280289104,
      "loss": 2.5234,
      "step": 6861
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001456075415423325,
      "loss": 2.332,
      "step": 6862
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014559204889971556,
      "loss": 2.3008,
      "step": 6863
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014557655487550984,
      "loss": 2.207,
      "step": 6864
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014556105947018476,
      "loss": 2.5469,
      "step": 6865
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014554556268420993,
      "loss": 2.3047,
      "step": 6866
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014553006451805495,
      "loss": 2.3398,
      "step": 6867
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014551456497218945,
      "loss": 2.3125,
      "step": 6868
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001454990640470831,
      "loss": 2.3945,
      "step": 6869
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001454835617432057,
      "loss": 2.3945,
      "step": 6870
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014546805806102694,
      "loss": 2.2227,
      "step": 6871
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014545255300101667,
      "loss": 2.3516,
      "step": 6872
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014543704656364476,
      "loss": 2.3145,
      "step": 6873
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001454215387493811,
      "loss": 2.3125,
      "step": 6874
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014540602955869558,
      "loss": 2.5938,
      "step": 6875
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014539051899205822,
      "loss": 2.4141,
      "step": 6876
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014537500704993901,
      "loss": 2.4883,
      "step": 6877
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001453594937328081,
      "loss": 2.4844,
      "step": 6878
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001453439790411355,
      "loss": 2.5625,
      "step": 6879
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001453284629753914,
      "loss": 2.3516,
      "step": 6880
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014531294553604595,
      "loss": 2.4023,
      "step": 6881
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014529742672356942,
      "loss": 2.3125,
      "step": 6882
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014528190653843207,
      "loss": 2.2988,
      "step": 6883
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014526638498110424,
      "loss": 2.2148,
      "step": 6884
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001452508620520562,
      "loss": 2.2031,
      "step": 6885
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001452353377517584,
      "loss": 2.3789,
      "step": 6886
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014521981208068132,
      "loss": 2.2422,
      "step": 6887
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014520428503929537,
      "loss": 2.3672,
      "step": 6888
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001451887566280711,
      "loss": 2.3633,
      "step": 6889
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014517322684747906,
      "loss": 2.4453,
      "step": 6890
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014515769569798987,
      "loss": 2.293,
      "step": 6891
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014514216318007415,
      "loss": 2.2617,
      "step": 6892
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014512662929420264,
      "loss": 2.2969,
      "step": 6893
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00145111094040846,
      "loss": 2.7188,
      "step": 6894
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014509555742047505,
      "loss": 2.2656,
      "step": 6895
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014508001943356055,
      "loss": 2.1562,
      "step": 6896
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001450644800805734,
      "loss": 2.3711,
      "step": 6897
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014504893936198447,
      "loss": 2.2891,
      "step": 6898
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001450333972782647,
      "loss": 2.3281,
      "step": 6899
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001450178538298851,
      "loss": 2.3789,
      "step": 6900
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014500230901731662,
      "loss": 2.5391,
      "step": 6901
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014498676284103033,
      "loss": 2.3125,
      "step": 6902
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014497121530149739,
      "loss": 2.4961,
      "step": 6903
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014495566639918889,
      "loss": 2.1445,
      "step": 6904
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014494011613457602,
      "loss": 2.418,
      "step": 6905
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014492456450813003,
      "loss": 2.4297,
      "step": 6906
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014490901152032216,
      "loss": 2.3789,
      "step": 6907
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014489345717162373,
      "loss": 2.3008,
      "step": 6908
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014487790146250608,
      "loss": 2.418,
      "step": 6909
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014486234439344057,
      "loss": 2.4336,
      "step": 6910
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014484678596489871,
      "loss": 2.3066,
      "step": 6911
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014483122617735187,
      "loss": 2.3398,
      "step": 6912
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014481566503127166,
      "loss": 2.3008,
      "step": 6913
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014480010252712957,
      "loss": 2.2188,
      "step": 6914
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001447845386653972,
      "loss": 2.6836,
      "step": 6915
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014476897344654622,
      "loss": 2.4102,
      "step": 6916
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014475340687104827,
      "loss": 2.4531,
      "step": 6917
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001447378389393751,
      "loss": 2.2168,
      "step": 6918
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014472226965199847,
      "loss": 2.2852,
      "step": 6919
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014470669900939013,
      "loss": 2.4102,
      "step": 6920
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00144691127012022,
      "loss": 2.0605,
      "step": 6921
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014467555366036587,
      "loss": 2.375,
      "step": 6922
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014465997895489373,
      "loss": 2.3672,
      "step": 6923
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014464440289607755,
      "loss": 2.3984,
      "step": 6924
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014462882548438927,
      "loss": 2.1484,
      "step": 6925
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014461324672030106,
      "loss": 2.3633,
      "step": 6926
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014459766660428483,
      "loss": 2.334,
      "step": 6927
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014458208513681288,
      "loss": 2.4688,
      "step": 6928
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014456650231835725,
      "loss": 2.4102,
      "step": 6929
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0014455091814939026,
      "loss": 2.5312,
      "step": 6930
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014453533263038409,
      "loss": 2.5586,
      "step": 6931
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014451974576181104,
      "loss": 2.5039,
      "step": 6932
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014450415754414347,
      "loss": 2.5898,
      "step": 6933
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014448856797785372,
      "loss": 2.293,
      "step": 6934
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014447297706341425,
      "loss": 2.4961,
      "step": 6935
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001444573848012975,
      "loss": 2.1602,
      "step": 6936
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014444179119197588,
      "loss": 2.4141,
      "step": 6937
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014442619623592208,
      "loss": 2.3633,
      "step": 6938
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014441059993360859,
      "loss": 2.1992,
      "step": 6939
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00144395002285508,
      "loss": 2.3906,
      "step": 6940
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014437940329209305,
      "loss": 2.5195,
      "step": 6941
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014436380295383643,
      "loss": 2.25,
      "step": 6942
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001443482012712108,
      "loss": 2.4297,
      "step": 6943
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00144332598244689,
      "loss": 2.1758,
      "step": 6944
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014431699387474387,
      "loss": 2.1992,
      "step": 6945
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014430138816184826,
      "loss": 2.4805,
      "step": 6946
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014428578110647504,
      "loss": 2.2148,
      "step": 6947
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014427017270909719,
      "loss": 2.3125,
      "step": 6948
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001442545629701877,
      "loss": 2.3789,
      "step": 6949
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014423895189021958,
      "loss": 2.4727,
      "step": 6950
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014422333946966588,
      "loss": 2.2695,
      "step": 6951
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014420772570899977,
      "loss": 2.2109,
      "step": 6952
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014419211060869431,
      "loss": 2.3008,
      "step": 6953
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014417649416922278,
      "loss": 2.3242,
      "step": 6954
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014416087639105833,
      "loss": 2.2012,
      "step": 6955
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001441452572746743,
      "loss": 2.1895,
      "step": 6956
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014412963682054391,
      "loss": 2.5977,
      "step": 6957
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014411401502914063,
      "loss": 2.5508,
      "step": 6958
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014409839190093776,
      "loss": 2.2695,
      "step": 6959
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014408276743640874,
      "loss": 2.4805,
      "step": 6960
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001440671416360271,
      "loss": 2.3945,
      "step": 6961
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014405151450026627,
      "loss": 2.293,
      "step": 6962
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014403588602959992,
      "loss": 2.4141,
      "step": 6963
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014402025622450153,
      "loss": 2.5352,
      "step": 6964
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014400462508544478,
      "loss": 2.375,
      "step": 6965
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014398899261290335,
      "loss": 2.3281,
      "step": 6966
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014397335880735095,
      "loss": 2.2227,
      "step": 6967
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001439577236692613,
      "loss": 2.3984,
      "step": 6968
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001439420871991083,
      "loss": 2.3945,
      "step": 6969
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014392644939736562,
      "loss": 2.5273,
      "step": 6970
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014391081026450731,
      "loss": 2.3672,
      "step": 6971
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014389516980100718,
      "loss": 2.2461,
      "step": 6972
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014387952800733923,
      "loss": 2.1387,
      "step": 6973
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014386388488397746,
      "loss": 2.4844,
      "step": 6974
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014384824043139589,
      "loss": 2.0801,
      "step": 6975
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014383259465006856,
      "loss": 2.3945,
      "step": 6976
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014381694754046967,
      "loss": 2.2812,
      "step": 6977
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014380129910307332,
      "loss": 2.4102,
      "step": 6978
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014378564933835375,
      "loss": 2.3633,
      "step": 6979
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014376999824678514,
      "loss": 2.4219,
      "step": 6980
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014375434582884184,
      "loss": 2.3828,
      "step": 6981
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014373869208499813,
      "loss": 2.3555,
      "step": 6982
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014372303701572838,
      "loss": 2.418,
      "step": 6983
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014370738062150696,
      "loss": 2.3516,
      "step": 6984
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014369172290280838,
      "loss": 2.5117,
      "step": 6985
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014367606386010703,
      "loss": 2.3398,
      "step": 6986
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014366040349387751,
      "loss": 2.2695,
      "step": 6987
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014364474180459435,
      "loss": 2.3164,
      "step": 6988
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014362907879273215,
      "loss": 2.332,
      "step": 6989
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014361341445876552,
      "loss": 2.3535,
      "step": 6990
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014359774880316918,
      "loss": 2.293,
      "step": 6991
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014358208182641786,
      "loss": 2.4062,
      "step": 6992
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001435664135289863,
      "loss": 2.4531,
      "step": 6993
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001435507439113493,
      "loss": 2.4727,
      "step": 6994
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014353507297398167,
      "loss": 2.4375,
      "step": 6995
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014351940071735834,
      "loss": 2.3242,
      "step": 6996
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014350372714195423,
      "loss": 2.4883,
      "step": 6997
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014348805224824429,
      "loss": 2.3984,
      "step": 6998
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014347237603670351,
      "loss": 2.3125,
      "step": 6999
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014345669850780694,
      "loss": 2.2383,
      "step": 7000
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014344101966202963,
      "loss": 2.4062,
      "step": 7001
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014342533949984677,
      "loss": 2.2734,
      "step": 7002
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014340965802173344,
      "loss": 2.043,
      "step": 7003
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001433939752281649,
      "loss": 2.3086,
      "step": 7004
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014337829111961639,
      "loss": 2.4844,
      "step": 7005
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014336260569656316,
      "loss": 2.2852,
      "step": 7006
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014334691895948053,
      "loss": 2.4844,
      "step": 7007
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014333123090884388,
      "loss": 2.3359,
      "step": 7008
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014331554154512858,
      "loss": 2.4258,
      "step": 7009
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001432998508688101,
      "loss": 2.4844,
      "step": 7010
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001432841588803639,
      "loss": 2.6211,
      "step": 7011
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001432684655802655,
      "loss": 2.2852,
      "step": 7012
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014325277096899048,
      "loss": 2.5508,
      "step": 7013
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001432370750470144,
      "loss": 2.5,
      "step": 7014
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014322137781481294,
      "loss": 2.4258,
      "step": 7015
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014320567927286177,
      "loss": 2.3164,
      "step": 7016
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014318997942163658,
      "loss": 2.4023,
      "step": 7017
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014317427826161314,
      "loss": 2.3242,
      "step": 7018
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014315857579326723,
      "loss": 2.3438,
      "step": 7019
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014314287201707477,
      "loss": 2.5547,
      "step": 7020
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014312716693351151,
      "loss": 2.1055,
      "step": 7021
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0014311146054305345,
      "loss": 2.7344,
      "step": 7022
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001430957528461765,
      "loss": 2.375,
      "step": 7023
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001430800438433567,
      "loss": 2.5273,
      "step": 7024
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014306433353507007,
      "loss": 2.5781,
      "step": 7025
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014304862192179267,
      "loss": 2.4062,
      "step": 7026
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014303290900400062,
      "loss": 2.4453,
      "step": 7027
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014301719478217007,
      "loss": 2.3516,
      "step": 7028
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014300147925677717,
      "loss": 2.4375,
      "step": 7029
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014298576242829828,
      "loss": 2.4336,
      "step": 7030
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014297004429720953,
      "loss": 2.4531,
      "step": 7031
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001429543248639873,
      "loss": 2.3477,
      "step": 7032
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014293860412910794,
      "loss": 2.5,
      "step": 7033
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001429228820930478,
      "loss": 2.2969,
      "step": 7034
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001429071587562834,
      "loss": 2.2305,
      "step": 7035
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001428914341192911,
      "loss": 2.2578,
      "step": 7036
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014287570818254747,
      "loss": 2.3027,
      "step": 7037
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014285998094652904,
      "loss": 2.2969,
      "step": 7038
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014284425241171239,
      "loss": 2.3828,
      "step": 7039
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001428285225785742,
      "loss": 2.5352,
      "step": 7040
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014281279144759105,
      "loss": 2.3164,
      "step": 7041
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014279705901923969,
      "loss": 2.375,
      "step": 7042
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014278132529399689,
      "loss": 2.4258,
      "step": 7043
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014276559027233935,
      "loss": 2.3789,
      "step": 7044
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00142749853954744,
      "loss": 2.2891,
      "step": 7045
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014273411634168763,
      "loss": 2.5391,
      "step": 7046
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014271837743364717,
      "loss": 2.3867,
      "step": 7047
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014270263723109955,
      "loss": 2.4414,
      "step": 7048
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014268689573452176,
      "loss": 2.4648,
      "step": 7049
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001426711529443908,
      "loss": 2.4844,
      "step": 7050
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014265540886118373,
      "loss": 2.4414,
      "step": 7051
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014263966348537765,
      "loss": 2.2559,
      "step": 7052
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014262391681744973,
      "loss": 2.4219,
      "step": 7053
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014260816885787709,
      "loss": 2.5,
      "step": 7054
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014259241960713701,
      "loss": 2.2441,
      "step": 7055
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014257666906570667,
      "loss": 2.2734,
      "step": 7056
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014256091723406344,
      "loss": 2.5039,
      "step": 7057
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001425451641126846,
      "loss": 2.1602,
      "step": 7058
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014252940970204753,
      "loss": 2.4023,
      "step": 7059
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014251365400262963,
      "loss": 2.5547,
      "step": 7060
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014249789701490838,
      "loss": 2.4258,
      "step": 7061
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014248213873936124,
      "loss": 2.3906,
      "step": 7062
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014246637917646578,
      "loss": 2.4609,
      "step": 7063
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001424506183266995,
      "loss": 2.3555,
      "step": 7064
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014243485619054007,
      "loss": 2.4102,
      "step": 7065
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001424190927684651,
      "loss": 2.2422,
      "step": 7066
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001424033280609523,
      "loss": 2.1973,
      "step": 7067
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014238756206847933,
      "loss": 2.3086,
      "step": 7068
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014237179479152401,
      "loss": 2.3438,
      "step": 7069
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014235602623056413,
      "loss": 2.3516,
      "step": 7070
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014234025638607752,
      "loss": 2.293,
      "step": 7071
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014232448525854206,
      "loss": 2.3906,
      "step": 7072
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014230871284843568,
      "loss": 2.4414,
      "step": 7073
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014229293915623631,
      "loss": 2.3242,
      "step": 7074
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014227716418242198,
      "loss": 2.4531,
      "step": 7075
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001422613879274707,
      "loss": 2.5391,
      "step": 7076
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014224561039186052,
      "loss": 2.3398,
      "step": 7077
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001422298315760696,
      "loss": 2.2363,
      "step": 7078
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014221405148057604,
      "loss": 2.3047,
      "step": 7079
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014219827010585808,
      "loss": 2.3398,
      "step": 7080
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014218248745239393,
      "loss": 2.4883,
      "step": 7081
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014216670352066184,
      "loss": 2.416,
      "step": 7082
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001421509183111401,
      "loss": 2.2734,
      "step": 7083
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014213513182430712,
      "loss": 2.4375,
      "step": 7084
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014211934406064119,
      "loss": 2.2812,
      "step": 7085
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014210355502062082,
      "loss": 2.4688,
      "step": 7086
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001420877647047244,
      "loss": 2.4727,
      "step": 7087
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001420719731134305,
      "loss": 2.2852,
      "step": 7088
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014205618024721758,
      "loss": 2.3594,
      "step": 7089
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014204038610656426,
      "loss": 2.3516,
      "step": 7090
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014202459069194914,
      "loss": 2.3242,
      "step": 7091
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001420087940038509,
      "loss": 2.2148,
      "step": 7092
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014199299604274822,
      "loss": 2.2969,
      "step": 7093
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001419771968091198,
      "loss": 2.4961,
      "step": 7094
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014196139630344442,
      "loss": 2.2012,
      "step": 7095
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014194559452620093,
      "loss": 2.3477,
      "step": 7096
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014192979147786811,
      "loss": 2.4375,
      "step": 7097
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014191398715892487,
      "loss": 2.3633,
      "step": 7098
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014189818156985017,
      "loss": 2.6445,
      "step": 7099
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014188237471112293,
      "loss": 2.3867,
      "step": 7100
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014186656658322218,
      "loss": 2.4141,
      "step": 7101
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001418507571866269,
      "loss": 2.3516,
      "step": 7102
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014183494652181623,
      "loss": 2.4785,
      "step": 7103
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014181913458926926,
      "loss": 2.5,
      "step": 7104
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014180332138946513,
      "loss": 2.3398,
      "step": 7105
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014178750692288306,
      "loss": 2.3984,
      "step": 7106
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014177169119000224,
      "loss": 2.3867,
      "step": 7107
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014175587419130197,
      "loss": 2.2852,
      "step": 7108
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001417400559272616,
      "loss": 2.3672,
      "step": 7109
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014172423639836037,
      "loss": 2.5586,
      "step": 7110
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014170841560507776,
      "loss": 2.3594,
      "step": 7111
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014169259354789312,
      "loss": 2.3984,
      "step": 7112
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014167677022728596,
      "loss": 2.3789,
      "step": 7113
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014166094564373576,
      "loss": 2.2773,
      "step": 7114
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014164511979772208,
      "loss": 2.4492,
      "step": 7115
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0014162929268972447,
      "loss": 2.4844,
      "step": 7116
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014161346432022253,
      "loss": 2.3633,
      "step": 7117
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001415976346896959,
      "loss": 2.6016,
      "step": 7118
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014158180379862436,
      "loss": 2.5,
      "step": 7119
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014156597164748752,
      "loss": 2.5078,
      "step": 7120
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014155013823676525,
      "loss": 2.6367,
      "step": 7121
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014153430356693727,
      "loss": 2.1992,
      "step": 7122
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014151846763848347,
      "loss": 2.4727,
      "step": 7123
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014150263045188374,
      "loss": 2.2852,
      "step": 7124
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014148679200761797,
      "loss": 2.2852,
      "step": 7125
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014147095230616614,
      "loss": 2.4336,
      "step": 7126
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001414551113480082,
      "loss": 2.5156,
      "step": 7127
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014143926913362422,
      "loss": 2.2891,
      "step": 7128
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014142342566349428,
      "loss": 2.2734,
      "step": 7129
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014140758093809844,
      "loss": 2.6406,
      "step": 7130
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014139173495791692,
      "loss": 2.3418,
      "step": 7131
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014137588772342986,
      "loss": 2.5547,
      "step": 7132
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014136003923511749,
      "loss": 2.4844,
      "step": 7133
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014134418949346007,
      "loss": 2.332,
      "step": 7134
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001413283384989379,
      "loss": 2.5977,
      "step": 7135
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014131248625203132,
      "loss": 2.6289,
      "step": 7136
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001412966327532207,
      "loss": 2.457,
      "step": 7137
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014128077800298641,
      "loss": 2.3047,
      "step": 7138
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014126492200180903,
      "loss": 2.4609,
      "step": 7139
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014124906475016892,
      "loss": 2.4805,
      "step": 7140
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014123320624854665,
      "loss": 2.1973,
      "step": 7141
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001412173464974228,
      "loss": 2.3887,
      "step": 7142
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014120148549727795,
      "loss": 2.2969,
      "step": 7143
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014118562324859276,
      "loss": 2.5938,
      "step": 7144
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014116975975184789,
      "loss": 2.3008,
      "step": 7145
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014115389500752406,
      "loss": 2.4844,
      "step": 7146
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014113802901610205,
      "loss": 2.2148,
      "step": 7147
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014112216177806262,
      "loss": 2.3008,
      "step": 7148
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001411062932938866,
      "loss": 2.6445,
      "step": 7149
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014109042356405489,
      "loss": 2.5117,
      "step": 7150
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014107455258904836,
      "loss": 2.4062,
      "step": 7151
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014105868036934797,
      "loss": 2.1738,
      "step": 7152
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014104280690543467,
      "loss": 2.457,
      "step": 7153
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014102693219778953,
      "loss": 2.4883,
      "step": 7154
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014101105624689354,
      "loss": 2.3789,
      "step": 7155
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014099517905322787,
      "loss": 2.3633,
      "step": 7156
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014097930061727363,
      "loss": 2.3086,
      "step": 7157
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014096342093951194,
      "loss": 2.4961,
      "step": 7158
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014094754002042405,
      "loss": 2.5547,
      "step": 7159
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001409316578604912,
      "loss": 2.2656,
      "step": 7160
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014091577446019461,
      "loss": 2.3711,
      "step": 7161
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014089988982001571,
      "loss": 2.3867,
      "step": 7162
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014088400394043578,
      "loss": 2.2461,
      "step": 7163
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014086811682193622,
      "loss": 2.4414,
      "step": 7164
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001408522284649985,
      "loss": 2.3594,
      "step": 7165
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014083633887010407,
      "loss": 2.4062,
      "step": 7166
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014082044803773442,
      "loss": 2.4219,
      "step": 7167
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014080455596837112,
      "loss": 2.4414,
      "step": 7168
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014078866266249573,
      "loss": 2.3203,
      "step": 7169
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014077276812058989,
      "loss": 2.3789,
      "step": 7170
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001407568723431352,
      "loss": 2.3711,
      "step": 7171
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014074097533061348,
      "loss": 2.293,
      "step": 7172
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001407250770835063,
      "loss": 2.2773,
      "step": 7173
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014070917760229556,
      "loss": 2.4844,
      "step": 7174
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014069327688746298,
      "loss": 2.2305,
      "step": 7175
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014067737493949047,
      "loss": 2.3594,
      "step": 7176
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014066147175885988,
      "loss": 2.3945,
      "step": 7177
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001406455673460531,
      "loss": 2.2012,
      "step": 7178
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014062966170155216,
      "loss": 2.5234,
      "step": 7179
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00140613754825839,
      "loss": 2.3516,
      "step": 7180
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014059784671939565,
      "loss": 2.418,
      "step": 7181
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001405819373827042,
      "loss": 2.4922,
      "step": 7182
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001405660268162467,
      "loss": 2.3398,
      "step": 7183
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014055011502050539,
      "loss": 2.5508,
      "step": 7184
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014053420199596235,
      "loss": 2.3691,
      "step": 7185
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014051828774309986,
      "loss": 2.5156,
      "step": 7186
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001405023722624002,
      "loss": 2.3516,
      "step": 7187
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014048645555434554,
      "loss": 2.4453,
      "step": 7188
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014047053761941832,
      "loss": 2.3008,
      "step": 7189
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014045461845810091,
      "loss": 2.3945,
      "step": 7190
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014043869807087563,
      "loss": 2.3047,
      "step": 7191
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014042277645822498,
      "loss": 2.6289,
      "step": 7192
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014040685362063142,
      "loss": 2.5039,
      "step": 7193
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014039092955857747,
      "loss": 2.2852,
      "step": 7194
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001403750042725457,
      "loss": 2.2422,
      "step": 7195
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001403590777630186,
      "loss": 2.4727,
      "step": 7196
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014034315003047895,
      "loss": 2.6602,
      "step": 7197
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001403272210754093,
      "loss": 2.3223,
      "step": 7198
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001403112908982924,
      "loss": 2.5391,
      "step": 7199
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014029535949961096,
      "loss": 2.2109,
      "step": 7200
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014027942687984776,
      "loss": 2.6016,
      "step": 7201
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014026349303948563,
      "loss": 2.418,
      "step": 7202
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001402475579790074,
      "loss": 2.3438,
      "step": 7203
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014023162169889594,
      "loss": 2.3945,
      "step": 7204
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014021568419963421,
      "loss": 2.2676,
      "step": 7205
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014019974548170513,
      "loss": 2.2676,
      "step": 7206
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014018380554559173,
      "loss": 2.5625,
      "step": 7207
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014016786439177702,
      "loss": 2.2969,
      "step": 7208
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0014015192202074408,
      "loss": 2.4219,
      "step": 7209
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00140135978432976,
      "loss": 2.3984,
      "step": 7210
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0014012003362895596,
      "loss": 2.2617,
      "step": 7211
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0014010408760916707,
      "loss": 2.3789,
      "step": 7212
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0014008814037409264,
      "loss": 2.2031,
      "step": 7213
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0014007219192421583,
      "loss": 2.5508,
      "step": 7214
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0014005624226002,
      "loss": 2.1289,
      "step": 7215
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0014004029138198844,
      "loss": 2.3281,
      "step": 7216
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0014002433929060454,
      "loss": 2.4727,
      "step": 7217
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0014000838598635169,
      "loss": 2.4688,
      "step": 7218
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013999243146971332,
      "loss": 2.3457,
      "step": 7219
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013997647574117292,
      "loss": 2.3633,
      "step": 7220
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013996051880121394,
      "loss": 2.3672,
      "step": 7221
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013994456065032001,
      "loss": 2.2383,
      "step": 7222
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001399286012889747,
      "loss": 2.2305,
      "step": 7223
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013991264071766159,
      "loss": 2.4141,
      "step": 7224
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013989667893686438,
      "loss": 2.3125,
      "step": 7225
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013988071594706673,
      "loss": 2.5781,
      "step": 7226
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013986475174875238,
      "loss": 2.4844,
      "step": 7227
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013984878634240513,
      "loss": 2.2695,
      "step": 7228
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013983281972850873,
      "loss": 2.3438,
      "step": 7229
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013981685190754707,
      "loss": 2.5117,
      "step": 7230
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00139800882880004,
      "loss": 2.3203,
      "step": 7231
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013978491264636343,
      "loss": 2.3926,
      "step": 7232
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013976894120710935,
      "loss": 2.4375,
      "step": 7233
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013975296856272568,
      "loss": 2.4414,
      "step": 7234
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013973699471369653,
      "loss": 2.4609,
      "step": 7235
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013972101966050585,
      "loss": 2.4023,
      "step": 7236
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013970504340363782,
      "loss": 2.4609,
      "step": 7237
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001396890659435766,
      "loss": 2.5273,
      "step": 7238
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013967308728080623,
      "loss": 2.4062,
      "step": 7239
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013965710741581105,
      "loss": 2.2539,
      "step": 7240
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013964112634907524,
      "loss": 2.3457,
      "step": 7241
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013962514408108308,
      "loss": 2.3633,
      "step": 7242
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001396091606123189,
      "loss": 2.3633,
      "step": 7243
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013959317594326706,
      "loss": 2.3438,
      "step": 7244
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001395771900744119,
      "loss": 2.4922,
      "step": 7245
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001395612030062379,
      "loss": 2.375,
      "step": 7246
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013954521473922947,
      "loss": 2.4297,
      "step": 7247
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001395292252738712,
      "loss": 2.4844,
      "step": 7248
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001395132346106475,
      "loss": 2.3477,
      "step": 7249
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00139497242750043,
      "loss": 2.3477,
      "step": 7250
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013948124969254232,
      "loss": 2.3828,
      "step": 7251
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013946525543863009,
      "loss": 2.4062,
      "step": 7252
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013944925998879097,
      "loss": 2.3867,
      "step": 7253
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001394332633435097,
      "loss": 2.3359,
      "step": 7254
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00139417265503271,
      "loss": 2.5586,
      "step": 7255
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013940126646855974,
      "loss": 2.3594,
      "step": 7256
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001393852662398606,
      "loss": 2.3906,
      "step": 7257
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013936926481765855,
      "loss": 2.3672,
      "step": 7258
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013935326220243845,
      "loss": 2.457,
      "step": 7259
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013933725839468524,
      "loss": 2.4805,
      "step": 7260
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013932125339488391,
      "loss": 2.3594,
      "step": 7261
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001393052472035194,
      "loss": 2.2305,
      "step": 7262
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013928923982107681,
      "loss": 2.3984,
      "step": 7263
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013927323124804118,
      "loss": 2.2227,
      "step": 7264
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013925722148489768,
      "loss": 2.668,
      "step": 7265
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001392412105321314,
      "loss": 2.3477,
      "step": 7266
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013922519839022751,
      "loss": 2.3359,
      "step": 7267
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013920918505967129,
      "loss": 2.3867,
      "step": 7268
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013919317054094799,
      "loss": 2.375,
      "step": 7269
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001391771548345428,
      "loss": 2.4922,
      "step": 7270
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013916113794094122,
      "loss": 2.6367,
      "step": 7271
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013914511986062846,
      "loss": 2.3652,
      "step": 7272
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013912910059409001,
      "loss": 2.2188,
      "step": 7273
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013911308014181128,
      "loss": 2.4531,
      "step": 7274
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013909705850427773,
      "loss": 2.4531,
      "step": 7275
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001390810356819749,
      "loss": 2.4062,
      "step": 7276
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013906501167538833,
      "loss": 2.3477,
      "step": 7277
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013904898648500355,
      "loss": 2.2969,
      "step": 7278
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013903296011130621,
      "loss": 2.4434,
      "step": 7279
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013901693255478195,
      "loss": 2.4219,
      "step": 7280
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013900090381591655,
      "loss": 2.3828,
      "step": 7281
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013898487389519556,
      "loss": 2.2227,
      "step": 7282
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001389688427931049,
      "loss": 2.4219,
      "step": 7283
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013895281051013028,
      "loss": 2.293,
      "step": 7284
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001389367770467575,
      "loss": 2.3242,
      "step": 7285
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013892074240347255,
      "loss": 2.4414,
      "step": 7286
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013890470658076122,
      "loss": 2.4531,
      "step": 7287
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013888866957910946,
      "loss": 2.2695,
      "step": 7288
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013887263139900333,
      "loss": 2.375,
      "step": 7289
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013885659204092872,
      "loss": 2.3223,
      "step": 7290
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013884055150537177,
      "loss": 2.3672,
      "step": 7291
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013882450979281853,
      "loss": 2.5039,
      "step": 7292
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001388084669037551,
      "loss": 2.3086,
      "step": 7293
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013879242283866763,
      "loss": 2.5195,
      "step": 7294
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013877637759804233,
      "loss": 2.2969,
      "step": 7295
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013876033118236544,
      "loss": 2.4141,
      "step": 7296
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013874428359212316,
      "loss": 2.5508,
      "step": 7297
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013872823482780185,
      "loss": 2.3828,
      "step": 7298
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001387121848898878,
      "loss": 2.4141,
      "step": 7299
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001386961337788674,
      "loss": 2.4023,
      "step": 7300
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013868008149522703,
      "loss": 2.4883,
      "step": 7301
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0013866402803945311,
      "loss": 2.2539,
      "step": 7302
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013864797341203213,
      "loss": 2.5156,
      "step": 7303
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013863191761345065,
      "loss": 2.4766,
      "step": 7304
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013861586064419513,
      "loss": 2.4961,
      "step": 7305
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013859980250475218,
      "loss": 2.1504,
      "step": 7306
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013858374319560846,
      "loss": 2.2402,
      "step": 7307
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013856768271725056,
      "loss": 2.1445,
      "step": 7308
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001385516210701652,
      "loss": 2.4102,
      "step": 7309
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013853555825483906,
      "loss": 2.5469,
      "step": 7310
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013851949427175897,
      "loss": 2.3828,
      "step": 7311
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013850342912141162,
      "loss": 2.4805,
      "step": 7312
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013848736280428389,
      "loss": 2.3672,
      "step": 7313
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001384712953208627,
      "loss": 2.373,
      "step": 7314
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013845522667163483,
      "loss": 2.5078,
      "step": 7315
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001384391568570873,
      "loss": 2.2617,
      "step": 7316
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013842308587770707,
      "loss": 2.2695,
      "step": 7317
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001384070137339811,
      "loss": 2.457,
      "step": 7318
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013839094042639645,
      "loss": 2.4297,
      "step": 7319
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013837486595544024,
      "loss": 2.457,
      "step": 7320
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013835879032159948,
      "loss": 2.3594,
      "step": 7321
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013834271352536143,
      "loss": 2.252,
      "step": 7322
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013832663556721317,
      "loss": 2.4102,
      "step": 7323
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00138310556447642,
      "loss": 2.5859,
      "step": 7324
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013829447616713507,
      "loss": 2.3008,
      "step": 7325
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013827839472617973,
      "loss": 2.4648,
      "step": 7326
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013826231212526333,
      "loss": 2.5664,
      "step": 7327
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013824622836487318,
      "loss": 2.5391,
      "step": 7328
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013823014344549664,
      "loss": 2.3906,
      "step": 7329
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001382140573676212,
      "loss": 2.3047,
      "step": 7330
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001381979701317343,
      "loss": 2.3594,
      "step": 7331
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013818188173832342,
      "loss": 2.2734,
      "step": 7332
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013816579218787614,
      "loss": 2.2695,
      "step": 7333
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013814970148087996,
      "loss": 2.2715,
      "step": 7334
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001381336096178225,
      "loss": 2.3867,
      "step": 7335
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013811751659919141,
      "loss": 2.2383,
      "step": 7336
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001381014224254744,
      "loss": 2.168,
      "step": 7337
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013808532709715907,
      "loss": 2.375,
      "step": 7338
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013806923061473327,
      "loss": 2.1914,
      "step": 7339
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001380531329786847,
      "loss": 2.3555,
      "step": 7340
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013803703418950124,
      "loss": 2.2578,
      "step": 7341
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013802093424767068,
      "loss": 2.5391,
      "step": 7342
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013800483315368093,
      "loss": 2.3945,
      "step": 7343
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001379887309080199,
      "loss": 2.6172,
      "step": 7344
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013797262751117554,
      "loss": 2.2656,
      "step": 7345
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013795652296363578,
      "loss": 2.3281,
      "step": 7346
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013794041726588877,
      "loss": 2.3867,
      "step": 7347
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013792431041842244,
      "loss": 2.125,
      "step": 7348
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013790820242172495,
      "loss": 2.3828,
      "step": 7349
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001378920932762844,
      "loss": 2.4727,
      "step": 7350
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013787598298258897,
      "loss": 2.3203,
      "step": 7351
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013785987154112682,
      "loss": 2.4043,
      "step": 7352
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013784375895238622,
      "loss": 2.332,
      "step": 7353
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013782764521685538,
      "loss": 2.2578,
      "step": 7354
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013781153033502267,
      "loss": 2.2031,
      "step": 7355
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013779541430737636,
      "loss": 2.6289,
      "step": 7356
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001377792971344049,
      "loss": 2.3555,
      "step": 7357
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013776317881659657,
      "loss": 2.3984,
      "step": 7358
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001377470593544399,
      "loss": 2.5508,
      "step": 7359
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013773093874842335,
      "loss": 2.375,
      "step": 7360
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013771481699903542,
      "loss": 2.332,
      "step": 7361
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013769869410676463,
      "loss": 2.3477,
      "step": 7362
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001376825700720996,
      "loss": 2.2109,
      "step": 7363
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013766644489552888,
      "loss": 2.3516,
      "step": 7364
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001376503185775412,
      "loss": 2.4375,
      "step": 7365
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013763419111862513,
      "loss": 2.2188,
      "step": 7366
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001376180625192695,
      "loss": 2.4453,
      "step": 7367
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00137601932779963,
      "loss": 2.2695,
      "step": 7368
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001375858019011944,
      "loss": 2.3125,
      "step": 7369
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013756966988345257,
      "loss": 2.4805,
      "step": 7370
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001375535367272263,
      "loss": 2.4648,
      "step": 7371
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013753740243300455,
      "loss": 2.2656,
      "step": 7372
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013752126700127616,
      "loss": 2.3125,
      "step": 7373
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013750513043253015,
      "loss": 2.3379,
      "step": 7374
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001374889927272555,
      "loss": 2.2109,
      "step": 7375
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013747285388594121,
      "loss": 2.3945,
      "step": 7376
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013745671390907638,
      "loss": 2.4414,
      "step": 7377
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013744057279715008,
      "loss": 2.4297,
      "step": 7378
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001374244305506514,
      "loss": 2.3438,
      "step": 7379
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001374082871700696,
      "loss": 2.3359,
      "step": 7380
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013739214265589374,
      "loss": 2.3945,
      "step": 7381
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013737599700861319,
      "loss": 2.457,
      "step": 7382
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013735985022871715,
      "loss": 2.2383,
      "step": 7383
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013734370231669494,
      "loss": 2.3945,
      "step": 7384
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013732755327303585,
      "loss": 2.3066,
      "step": 7385
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013731140309822928,
      "loss": 2.3945,
      "step": 7386
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013729525179276465,
      "loss": 2.4766,
      "step": 7387
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013727909935713142,
      "loss": 2.3594,
      "step": 7388
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013726294579181897,
      "loss": 2.4336,
      "step": 7389
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013724679109731691,
      "loss": 2.4453,
      "step": 7390
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013723063527411468,
      "loss": 2.2695,
      "step": 7391
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013721447832270193,
      "loss": 2.2188,
      "step": 7392
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013719832024356824,
      "loss": 2.5273,
      "step": 7393
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013718216103720327,
      "loss": 2.3672,
      "step": 7394
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0013716600070409668,
      "loss": 2.2461,
      "step": 7395
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013714983924473817,
      "loss": 2.3633,
      "step": 7396
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001371336766596175,
      "loss": 2.5117,
      "step": 7397
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013711751294922447,
      "loss": 2.2656,
      "step": 7398
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013710134811404887,
      "loss": 2.3359,
      "step": 7399
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013708518215458053,
      "loss": 2.2188,
      "step": 7400
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013706901507130938,
      "loss": 2.4766,
      "step": 7401
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001370528468647253,
      "loss": 2.375,
      "step": 7402
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013703667753531823,
      "loss": 2.5234,
      "step": 7403
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013702050708357821,
      "loss": 2.3887,
      "step": 7404
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001370043355099952,
      "loss": 2.4844,
      "step": 7405
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013698816281505924,
      "loss": 2.5039,
      "step": 7406
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001369719889992605,
      "loss": 2.2539,
      "step": 7407
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00136955814063089,
      "loss": 2.2383,
      "step": 7408
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00136939638007035,
      "loss": 2.3672,
      "step": 7409
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013692346083158857,
      "loss": 2.3242,
      "step": 7410
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013690728253724002,
      "loss": 2.5078,
      "step": 7411
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013689110312447956,
      "loss": 2.5,
      "step": 7412
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013687492259379752,
      "loss": 2.3125,
      "step": 7413
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013685874094568418,
      "loss": 2.3555,
      "step": 7414
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013684255818062993,
      "loss": 2.4062,
      "step": 7415
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013682637429912512,
      "loss": 2.2812,
      "step": 7416
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013681018930166023,
      "loss": 2.3906,
      "step": 7417
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013679400318872567,
      "loss": 2.4688,
      "step": 7418
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013677781596081195,
      "loss": 2.2422,
      "step": 7419
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001367616276184096,
      "loss": 2.2578,
      "step": 7420
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001367454381620092,
      "loss": 2.2891,
      "step": 7421
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001367292475921013,
      "loss": 2.4141,
      "step": 7422
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013671305590917658,
      "loss": 2.3789,
      "step": 7423
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013669686311372563,
      "loss": 2.2969,
      "step": 7424
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013668066920623921,
      "loss": 2.3789,
      "step": 7425
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013666447418720802,
      "loss": 2.2969,
      "step": 7426
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013664827805712281,
      "loss": 2.4297,
      "step": 7427
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001366320808164744,
      "loss": 2.2539,
      "step": 7428
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013661588246575362,
      "loss": 2.4219,
      "step": 7429
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013659968300545132,
      "loss": 2.4258,
      "step": 7430
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013658348243605844,
      "loss": 2.375,
      "step": 7431
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001365672807580658,
      "loss": 2.25,
      "step": 7432
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013655107797196447,
      "loss": 2.3477,
      "step": 7433
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013653487407824542,
      "loss": 2.4258,
      "step": 7434
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013651866907739966,
      "loss": 2.3672,
      "step": 7435
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001365024629699183,
      "loss": 2.3477,
      "step": 7436
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013648625575629239,
      "loss": 2.5117,
      "step": 7437
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013647004743701308,
      "loss": 2.3906,
      "step": 7438
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013645383801257154,
      "loss": 2.3145,
      "step": 7439
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013643762748345894,
      "loss": 2.293,
      "step": 7440
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013642141585016659,
      "loss": 2.2734,
      "step": 7441
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013640520311318566,
      "loss": 2.3203,
      "step": 7442
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013638898927300748,
      "loss": 2.3066,
      "step": 7443
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013637277433012343,
      "loss": 2.4648,
      "step": 7444
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001363565582850248,
      "loss": 2.3906,
      "step": 7445
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013634034113820309,
      "loss": 2.3359,
      "step": 7446
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013632412289014961,
      "loss": 2.5078,
      "step": 7447
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013630790354135591,
      "loss": 2.543,
      "step": 7448
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001362916830923135,
      "loss": 2.4102,
      "step": 7449
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013627546154351385,
      "loss": 2.5156,
      "step": 7450
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013625923889544855,
      "loss": 2.4062,
      "step": 7451
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013624301514860923,
      "loss": 2.2285,
      "step": 7452
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013622679030348749,
      "loss": 2.418,
      "step": 7453
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013621056436057502,
      "loss": 2.2539,
      "step": 7454
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013619433732036347,
      "loss": 2.3047,
      "step": 7455
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013617810918334463,
      "loss": 2.1523,
      "step": 7456
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013616187995001024,
      "loss": 2.3906,
      "step": 7457
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001361456496208521,
      "loss": 2.3594,
      "step": 7458
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013612941819636205,
      "loss": 2.4219,
      "step": 7459
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013611318567703194,
      "loss": 2.3984,
      "step": 7460
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001360969520633537,
      "loss": 2.5977,
      "step": 7461
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013608071735581925,
      "loss": 2.498,
      "step": 7462
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013606448155492048,
      "loss": 2.5547,
      "step": 7463
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013604824466114953,
      "loss": 2.5195,
      "step": 7464
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001360320066749983,
      "loss": 2.4297,
      "step": 7465
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013601576759695892,
      "loss": 2.2891,
      "step": 7466
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001359995274275235,
      "loss": 2.3008,
      "step": 7467
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013598328616718414,
      "loss": 2.4141,
      "step": 7468
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00135967043816433,
      "loss": 2.668,
      "step": 7469
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001359508003757623,
      "loss": 2.418,
      "step": 7470
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013593455584566428,
      "loss": 2.4414,
      "step": 7471
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013591831022663114,
      "loss": 2.2598,
      "step": 7472
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013590206351915522,
      "loss": 2.418,
      "step": 7473
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013588581572372886,
      "loss": 2.4102,
      "step": 7474
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013586956684084439,
      "loss": 2.1914,
      "step": 7475
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013585331687099422,
      "loss": 2.293,
      "step": 7476
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001358370658146708,
      "loss": 2.1641,
      "step": 7477
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013582081367236657,
      "loss": 2.1523,
      "step": 7478
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00135804560444574,
      "loss": 2.252,
      "step": 7479
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013578830613178562,
      "loss": 2.3555,
      "step": 7480
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013577205073449403,
      "loss": 2.4805,
      "step": 7481
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013575579425319179,
      "loss": 2.4375,
      "step": 7482
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013573953668837154,
      "loss": 2.418,
      "step": 7483
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013572327804052594,
      "loss": 2.2461,
      "step": 7484
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013570701831014764,
      "loss": 2.0918,
      "step": 7485
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013569075749772944,
      "loss": 2.6133,
      "step": 7486
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0013567449560376401,
      "loss": 2.5,
      "step": 7487
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001356582326287442,
      "loss": 2.4297,
      "step": 7488
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013564196857316281,
      "loss": 2.5625,
      "step": 7489
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001356257034375127,
      "loss": 2.2695,
      "step": 7490
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013560943722228673,
      "loss": 2.1914,
      "step": 7491
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013559316992797785,
      "loss": 2.4648,
      "step": 7492
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00135576901555079,
      "loss": 2.123,
      "step": 7493
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001355606321040832,
      "loss": 2.3789,
      "step": 7494
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013554436157548343,
      "loss": 2.3633,
      "step": 7495
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001355280899697727,
      "loss": 2.2246,
      "step": 7496
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001355118172874442,
      "loss": 2.1895,
      "step": 7497
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013549554352899093,
      "loss": 2.3711,
      "step": 7498
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013547926869490615,
      "loss": 2.3242,
      "step": 7499
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013546299278568298,
      "loss": 2.2598,
      "step": 7500
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001354467158018146,
      "loss": 2.3438,
      "step": 7501
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001354304377437943,
      "loss": 2.3867,
      "step": 7502
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001354141586121154,
      "loss": 2.1875,
      "step": 7503
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013539787840727113,
      "loss": 2.2285,
      "step": 7504
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013538159712975489,
      "loss": 2.4316,
      "step": 7505
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013536531478006,
      "loss": 2.3203,
      "step": 7506
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013534903135867995,
      "loss": 2.2266,
      "step": 7507
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013533274686610807,
      "loss": 2.3477,
      "step": 7508
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013531646130283796,
      "loss": 2.4297,
      "step": 7509
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013530017466936305,
      "loss": 2.4219,
      "step": 7510
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001352838869661769,
      "loss": 2.3418,
      "step": 7511
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013526759819377304,
      "loss": 2.4414,
      "step": 7512
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013525130835264514,
      "loss": 2.5312,
      "step": 7513
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013523501744328677,
      "loss": 2.3047,
      "step": 7514
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013521872546619167,
      "loss": 2.3203,
      "step": 7515
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013520243242185347,
      "loss": 2.4492,
      "step": 7516
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013518613831076597,
      "loss": 2.3555,
      "step": 7517
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013516984313342287,
      "loss": 2.2969,
      "step": 7518
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00135153546890318,
      "loss": 2.4648,
      "step": 7519
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013513724958194517,
      "loss": 2.4688,
      "step": 7520
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013512095120879828,
      "loss": 2.6016,
      "step": 7521
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001351046517713712,
      "loss": 2.6289,
      "step": 7522
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013508835127015787,
      "loss": 2.3906,
      "step": 7523
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013507204970565224,
      "loss": 2.2344,
      "step": 7524
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013505574707834826,
      "loss": 2.2656,
      "step": 7525
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013503944338874004,
      "loss": 2.5312,
      "step": 7526
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013502313863732157,
      "loss": 2.3789,
      "step": 7527
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013500683282458693,
      "loss": 2.3516,
      "step": 7528
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001349905259510303,
      "loss": 2.3867,
      "step": 7529
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001349742180171458,
      "loss": 2.2383,
      "step": 7530
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013495790902342756,
      "loss": 2.2324,
      "step": 7531
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013494159897036993,
      "loss": 2.4141,
      "step": 7532
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00134925287858467,
      "loss": 2.418,
      "step": 7533
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013490897568821313,
      "loss": 2.2734,
      "step": 7534
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013489266246010268,
      "loss": 2.5078,
      "step": 7535
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001348763481746299,
      "loss": 2.3516,
      "step": 7536
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013486003283228922,
      "loss": 2.4805,
      "step": 7537
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013484371643357504,
      "loss": 2.1934,
      "step": 7538
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013482739897898177,
      "loss": 2.3125,
      "step": 7539
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013481108046900397,
      "loss": 2.3242,
      "step": 7540
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00134794760904136,
      "loss": 2.1621,
      "step": 7541
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013477844028487254,
      "loss": 2.3711,
      "step": 7542
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013476211861170808,
      "loss": 2.3477,
      "step": 7543
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013474579588513725,
      "loss": 2.4961,
      "step": 7544
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013472947210565467,
      "loss": 2.5508,
      "step": 7545
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013471314727375502,
      "loss": 2.4414,
      "step": 7546
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013469682138993293,
      "loss": 2.3672,
      "step": 7547
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013468049445468323,
      "loss": 2.4453,
      "step": 7548
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001346641664685006,
      "loss": 2.4141,
      "step": 7549
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001346478374318799,
      "loss": 2.2051,
      "step": 7550
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013463150734531583,
      "loss": 2.4727,
      "step": 7551
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001346151762093034,
      "loss": 2.4023,
      "step": 7552
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001345988440243374,
      "loss": 2.1875,
      "step": 7553
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013458251079091282,
      "loss": 2.3008,
      "step": 7554
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013456617650952451,
      "loss": 2.4141,
      "step": 7555
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013454984118066752,
      "loss": 2.3359,
      "step": 7556
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001345335048048369,
      "loss": 2.3867,
      "step": 7557
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001345171673825276,
      "loss": 2.5078,
      "step": 7558
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013450082891423474,
      "loss": 2.3242,
      "step": 7559
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013448448940045347,
      "loss": 2.3594,
      "step": 7560
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001344681488416789,
      "loss": 2.2422,
      "step": 7561
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013445180723840613,
      "loss": 2.3555,
      "step": 7562
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001344354645911305,
      "loss": 2.4492,
      "step": 7563
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013441912090034717,
      "loss": 2.2188,
      "step": 7564
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001344027761665514,
      "loss": 2.1895,
      "step": 7565
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001343864303902385,
      "loss": 2.2012,
      "step": 7566
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013437008357190384,
      "loss": 2.3789,
      "step": 7567
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013435373571204273,
      "loss": 2.4609,
      "step": 7568
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013433738681115058,
      "loss": 2.5859,
      "step": 7569
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013432103686972282,
      "loss": 2.4922,
      "step": 7570
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001343046858882549,
      "loss": 2.1133,
      "step": 7571
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013428833386724228,
      "loss": 2.1953,
      "step": 7572
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013427198080718057,
      "loss": 2.5039,
      "step": 7573
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013425562670856524,
      "loss": 2.6094,
      "step": 7574
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001342392715718919,
      "loss": 2.3359,
      "step": 7575
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013422291539765617,
      "loss": 2.4805,
      "step": 7576
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013420655818635369,
      "loss": 2.3555,
      "step": 7577
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013419019993848012,
      "loss": 2.3711,
      "step": 7578
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001341738406545312,
      "loss": 2.4961,
      "step": 7579
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013415748033500262,
      "loss": 2.3203,
      "step": 7580
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0013414111898039022,
      "loss": 2.3828,
      "step": 7581
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013412475659118975,
      "loss": 2.4492,
      "step": 7582
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013410839316789706,
      "loss": 2.3672,
      "step": 7583
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013409202871100803,
      "loss": 2.5625,
      "step": 7584
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013407566322101855,
      "loss": 2.25,
      "step": 7585
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001340592966984245,
      "loss": 2.5977,
      "step": 7586
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013404292914372194,
      "loss": 2.3828,
      "step": 7587
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013402656055740679,
      "loss": 2.5078,
      "step": 7588
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013401019093997506,
      "loss": 2.3984,
      "step": 7589
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013399382029192282,
      "loss": 2.2734,
      "step": 7590
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001339774486137462,
      "loss": 2.1992,
      "step": 7591
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013396107590594125,
      "loss": 2.4141,
      "step": 7592
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013394470216900414,
      "loss": 2.3906,
      "step": 7593
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013392832740343106,
      "loss": 2.3281,
      "step": 7594
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001339119516097182,
      "loss": 2.4844,
      "step": 7595
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013389557478836185,
      "loss": 2.3984,
      "step": 7596
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001338791969398582,
      "loss": 2.2891,
      "step": 7597
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013386281806470363,
      "loss": 2.3984,
      "step": 7598
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013384643816339442,
      "loss": 2.1758,
      "step": 7599
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013383005723642696,
      "loss": 2.2168,
      "step": 7600
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013381367528429765,
      "loss": 2.3555,
      "step": 7601
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001337972923075029,
      "loss": 2.2734,
      "step": 7602
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013378090830653917,
      "loss": 2.4727,
      "step": 7603
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013376452328190296,
      "loss": 2.2656,
      "step": 7604
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013374813723409078,
      "loss": 2.3867,
      "step": 7605
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001337317501635992,
      "loss": 2.3672,
      "step": 7606
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013371536207092477,
      "loss": 2.1875,
      "step": 7607
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013369897295656412,
      "loss": 2.5078,
      "step": 7608
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013368258282101392,
      "loss": 2.543,
      "step": 7609
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013366619166477079,
      "loss": 2.4141,
      "step": 7610
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001336497994883315,
      "loss": 2.3164,
      "step": 7611
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013363340629219272,
      "loss": 2.5078,
      "step": 7612
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013361701207685126,
      "loss": 2.4727,
      "step": 7613
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013360061684280391,
      "loss": 2.4062,
      "step": 7614
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013358422059054746,
      "loss": 2.5312,
      "step": 7615
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013356782332057887,
      "loss": 2.3789,
      "step": 7616
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013355142503339494,
      "loss": 2.375,
      "step": 7617
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013353502572949264,
      "loss": 2.4492,
      "step": 7618
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013351862540936887,
      "loss": 2.127,
      "step": 7619
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013350222407352069,
      "loss": 2.2852,
      "step": 7620
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013348582172244504,
      "loss": 2.5703,
      "step": 7621
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00133469418356639,
      "loss": 2.4141,
      "step": 7622
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013345301397659963,
      "loss": 2.2754,
      "step": 7623
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001334366085828241,
      "loss": 2.3398,
      "step": 7624
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013342020217580943,
      "loss": 2.2891,
      "step": 7625
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013340379475605291,
      "loss": 2.5117,
      "step": 7626
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013338738632405168,
      "loss": 2.5117,
      "step": 7627
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013337097688030295,
      "loss": 2.5234,
      "step": 7628
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013335456642530402,
      "loss": 2.3203,
      "step": 7629
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013333815495955212,
      "loss": 2.4727,
      "step": 7630
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013332174248354468,
      "loss": 2.3359,
      "step": 7631
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013330532899777895,
      "loss": 2.3945,
      "step": 7632
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013328891450275235,
      "loss": 2.1094,
      "step": 7633
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001332724989989623,
      "loss": 2.1523,
      "step": 7634
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013325608248690624,
      "loss": 2.2129,
      "step": 7635
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013323966496708165,
      "loss": 2.3594,
      "step": 7636
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013322324643998602,
      "loss": 2.5,
      "step": 7637
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013320682690611686,
      "loss": 2.2832,
      "step": 7638
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013319040636597182,
      "loss": 2.2383,
      "step": 7639
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013317398482004838,
      "loss": 2.3945,
      "step": 7640
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013315756226884427,
      "loss": 2.457,
      "step": 7641
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013314113871285712,
      "loss": 2.2578,
      "step": 7642
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013312471415258458,
      "loss": 2.457,
      "step": 7643
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001331082885885244,
      "loss": 2.1953,
      "step": 7644
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013309186202117432,
      "loss": 2.3984,
      "step": 7645
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013307543445103213,
      "loss": 2.457,
      "step": 7646
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013305900587859561,
      "loss": 2.4102,
      "step": 7647
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001330425763043626,
      "loss": 2.3594,
      "step": 7648
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013302614572883104,
      "loss": 2.1426,
      "step": 7649
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013300971415249876,
      "loss": 2.4043,
      "step": 7650
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001329932815758637,
      "loss": 2.3516,
      "step": 7651
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013297684799942384,
      "loss": 2.4492,
      "step": 7652
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013296041342367717,
      "loss": 2.3086,
      "step": 7653
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013294397784912172,
      "loss": 2.3555,
      "step": 7654
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013292754127625548,
      "loss": 2.4805,
      "step": 7655
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001329111037055766,
      "loss": 2.4141,
      "step": 7656
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013289466513758319,
      "loss": 2.3984,
      "step": 7657
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013287822557277334,
      "loss": 2.0781,
      "step": 7658
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001328617850116453,
      "loss": 2.2539,
      "step": 7659
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013284534345469718,
      "loss": 2.3359,
      "step": 7660
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013282890090242727,
      "loss": 2.5469,
      "step": 7661
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013281245735533385,
      "loss": 2.3867,
      "step": 7662
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001327960128139152,
      "loss": 2.3555,
      "step": 7663
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013277956727866962,
      "loss": 2.2871,
      "step": 7664
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013276312075009547,
      "loss": 2.2266,
      "step": 7665
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013274667322869112,
      "loss": 2.2891,
      "step": 7666
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013273022471495502,
      "loss": 2.2461,
      "step": 7667
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001327137752093856,
      "loss": 2.5547,
      "step": 7668
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013269732471248134,
      "loss": 2.3828,
      "step": 7669
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013268087322474073,
      "loss": 2.3516,
      "step": 7670
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013266442074666232,
      "loss": 2.2305,
      "step": 7671
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013264796727874468,
      "loss": 2.3242,
      "step": 7672
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0013263151282148636,
      "loss": 2.6602,
      "step": 7673
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00132615057375386,
      "loss": 2.4453,
      "step": 7674
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.001325986009409423,
      "loss": 2.4219,
      "step": 7675
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013258214351865392,
      "loss": 2.4805,
      "step": 7676
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013256568510901954,
      "loss": 2.1094,
      "step": 7677
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013254922571253793,
      "loss": 2.2773,
      "step": 7678
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013253276532970788,
      "loss": 2.5508,
      "step": 7679
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013251630396102817,
      "loss": 2.2617,
      "step": 7680
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013249984160699762,
      "loss": 2.2383,
      "step": 7681
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013248337826811513,
      "loss": 2.4023,
      "step": 7682
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013246691394487957,
      "loss": 2.2422,
      "step": 7683
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013245044863778987,
      "loss": 2.2969,
      "step": 7684
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013243398234734501,
      "loss": 2.373,
      "step": 7685
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013241751507404391,
      "loss": 2.2305,
      "step": 7686
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013240104681838563,
      "loss": 2.4023,
      "step": 7687
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013238457758086922,
      "loss": 2.2656,
      "step": 7688
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.001323681073619937,
      "loss": 2.3906,
      "step": 7689
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013235163616225822,
      "loss": 2.2695,
      "step": 7690
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013233516398216188,
      "loss": 2.3438,
      "step": 7691
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013231869082220389,
      "loss": 2.1875,
      "step": 7692
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013230221668288336,
      "loss": 2.4922,
      "step": 7693
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.001322857415646996,
      "loss": 2.3672,
      "step": 7694
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013226926546815179,
      "loss": 2.4023,
      "step": 7695
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013225278839373927,
      "loss": 2.4297,
      "step": 7696
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.001322363103419613,
      "loss": 2.4375,
      "step": 7697
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013221983131331723,
      "loss": 2.2969,
      "step": 7698
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013220335130830643,
      "loss": 2.248,
      "step": 7699
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013218687032742831,
      "loss": 2.5781,
      "step": 7700
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.001321703883711823,
      "loss": 2.543,
      "step": 7701
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013215390544006782,
      "loss": 2.4922,
      "step": 7702
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013213742153458444,
      "loss": 2.4219,
      "step": 7703
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013212093665523155,
      "loss": 2.5469,
      "step": 7704
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013210445080250883,
      "loss": 2.457,
      "step": 7705
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013208796397691576,
      "loss": 2.3516,
      "step": 7706
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00132071476178952,
      "loss": 2.2754,
      "step": 7707
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013205498740911717,
      "loss": 2.2695,
      "step": 7708
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013203849766791089,
      "loss": 2.4219,
      "step": 7709
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013202200695583294,
      "loss": 2.5,
      "step": 7710
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013200551527338296,
      "loss": 2.2031,
      "step": 7711
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.001319890226210607,
      "loss": 2.3125,
      "step": 7712
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013197252899936605,
      "loss": 2.25,
      "step": 7713
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.001319560344087987,
      "loss": 2.4766,
      "step": 7714
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013193953884985856,
      "loss": 2.4141,
      "step": 7715
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013192304232304546,
      "loss": 2.209,
      "step": 7716
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013190654482885932,
      "loss": 2.293,
      "step": 7717
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.001318900463678001,
      "loss": 2.293,
      "step": 7718
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013187354694036769,
      "loss": 2.332,
      "step": 7719
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.001318570465470621,
      "loss": 2.2812,
      "step": 7720
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013184054518838337,
      "loss": 2.3867,
      "step": 7721
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013182404286483152,
      "loss": 2.3828,
      "step": 7722
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013180753957690665,
      "loss": 2.4961,
      "step": 7723
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013179103532510884,
      "loss": 2.4805,
      "step": 7724
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013177453010993826,
      "loss": 2.4688,
      "step": 7725
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00131758023931895,
      "loss": 2.2695,
      "step": 7726
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013174151679147931,
      "loss": 2.3672,
      "step": 7727
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.001317250086891914,
      "loss": 2.5078,
      "step": 7728
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013170849962553153,
      "loss": 2.1719,
      "step": 7729
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013169198960099994,
      "loss": 2.3906,
      "step": 7730
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00131675478616097,
      "loss": 2.4023,
      "step": 7731
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013165896667132295,
      "loss": 2.2422,
      "step": 7732
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013164245376717828,
      "loss": 2.332,
      "step": 7733
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013162593990416328,
      "loss": 2.332,
      "step": 7734
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013160942508277842,
      "loss": 2.3672,
      "step": 7735
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013159290930352416,
      "loss": 2.4648,
      "step": 7736
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013157639256690097,
      "loss": 2.2168,
      "step": 7737
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013155987487340937,
      "loss": 2.3281,
      "step": 7738
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.001315433562235499,
      "loss": 2.2715,
      "step": 7739
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.001315268366178231,
      "loss": 2.293,
      "step": 7740
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013151031605672958,
      "loss": 2.4727,
      "step": 7741
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013149379454077,
      "loss": 2.3359,
      "step": 7742
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00131477272070445,
      "loss": 2.5586,
      "step": 7743
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013146074864625525,
      "loss": 2.5547,
      "step": 7744
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013144422426870147,
      "loss": 2.3203,
      "step": 7745
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013142769893828442,
      "loss": 2.1719,
      "step": 7746
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.001314111726555048,
      "loss": 2.5117,
      "step": 7747
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013139464542086356,
      "loss": 2.3516,
      "step": 7748
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013137811723486137,
      "loss": 2.4023,
      "step": 7749
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.001313615880979992,
      "loss": 2.4141,
      "step": 7750
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013134505801077787,
      "loss": 2.457,
      "step": 7751
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013132852697369832,
      "loss": 2.375,
      "step": 7752
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013131199498726152,
      "loss": 2.3906,
      "step": 7753
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.001312954620519684,
      "loss": 2.4297,
      "step": 7754
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013127892816831995,
      "loss": 2.2676,
      "step": 7755
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013126239333681729,
      "loss": 2.2422,
      "step": 7756
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013124585755796138,
      "loss": 2.1445,
      "step": 7757
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013122932083225339,
      "loss": 2.3047,
      "step": 7758
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.001312127831601943,
      "loss": 2.4043,
      "step": 7759
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013119624454228545,
      "loss": 2.2969,
      "step": 7760
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013117970497902789,
      "loss": 2.2891,
      "step": 7761
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013116316447092284,
      "loss": 2.457,
      "step": 7762
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013114662301847155,
      "loss": 2.4141,
      "step": 7763
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013113008062217526,
      "loss": 2.3945,
      "step": 7764
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013111353728253528,
      "loss": 2.4453,
      "step": 7765
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013109699300005294,
      "loss": 2.4727,
      "step": 7766
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013108044777522952,
      "loss": 2.3242,
      "step": 7767
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0013106390160856644,
      "loss": 2.3672,
      "step": 7768
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013104735450056512,
      "loss": 2.3164,
      "step": 7769
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00131030806451727,
      "loss": 2.4023,
      "step": 7770
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001310142574625535,
      "loss": 2.2598,
      "step": 7771
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001309977075335461,
      "loss": 2.418,
      "step": 7772
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013098115666520637,
      "loss": 2.4219,
      "step": 7773
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001309646048580358,
      "loss": 2.252,
      "step": 7774
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00130948052112536,
      "loss": 2.4258,
      "step": 7775
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013093149842920858,
      "loss": 2.3711,
      "step": 7776
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001309149438085551,
      "loss": 2.4453,
      "step": 7777
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013089838825107733,
      "loss": 2.3984,
      "step": 7778
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013088183175727689,
      "loss": 2.5547,
      "step": 7779
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013086527432765547,
      "loss": 2.4355,
      "step": 7780
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013084871596271488,
      "loss": 2.418,
      "step": 7781
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013083215666295684,
      "loss": 2.2891,
      "step": 7782
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001308155964288832,
      "loss": 2.1562,
      "step": 7783
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001307990352609958,
      "loss": 2.3438,
      "step": 7784
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001307824731597964,
      "loss": 2.4062,
      "step": 7785
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013076591012578698,
      "loss": 2.3398,
      "step": 7786
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013074934615946944,
      "loss": 2.3125,
      "step": 7787
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013073278126134564,
      "loss": 2.4531,
      "step": 7788
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001307162154319177,
      "loss": 2.4688,
      "step": 7789
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013069964867168746,
      "loss": 2.1934,
      "step": 7790
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013068308098115708,
      "loss": 2.5039,
      "step": 7791
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001306665123608285,
      "loss": 2.4961,
      "step": 7792
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013064994281120393,
      "loss": 2.4219,
      "step": 7793
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013063337233278536,
      "loss": 2.4609,
      "step": 7794
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013061680092607503,
      "loss": 2.4844,
      "step": 7795
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013060022859157504,
      "loss": 2.3105,
      "step": 7796
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013058365532978757,
      "loss": 2.2656,
      "step": 7797
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013056708114121492,
      "loss": 2.2812,
      "step": 7798
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013055050602635932,
      "loss": 2.5156,
      "step": 7799
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00130533929985723,
      "loss": 2.3125,
      "step": 7800
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001305173530198083,
      "loss": 2.3438,
      "step": 7801
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001305007751291176,
      "loss": 2.1445,
      "step": 7802
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001304841963141532,
      "loss": 2.543,
      "step": 7803
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013046761657541752,
      "loss": 2.4727,
      "step": 7804
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013045103591341296,
      "loss": 2.4141,
      "step": 7805
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013043445432864202,
      "loss": 2.2891,
      "step": 7806
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013041787182160713,
      "loss": 2.5977,
      "step": 7807
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013040128839281078,
      "loss": 2.3203,
      "step": 7808
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013038470404275557,
      "loss": 2.4141,
      "step": 7809
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00130368118771944,
      "loss": 2.2188,
      "step": 7810
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013035153258087865,
      "loss": 2.332,
      "step": 7811
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001303349454700622,
      "loss": 2.248,
      "step": 7812
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013031835743999728,
      "loss": 2.4531,
      "step": 7813
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001303017684911865,
      "loss": 2.5312,
      "step": 7814
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001302851786241326,
      "loss": 2.2402,
      "step": 7815
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001302685878393383,
      "loss": 2.3164,
      "step": 7816
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013025199613730639,
      "loss": 2.1914,
      "step": 7817
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001302354035185396,
      "loss": 2.2422,
      "step": 7818
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013021880998354079,
      "loss": 2.5117,
      "step": 7819
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013020221553281274,
      "loss": 2.5,
      "step": 7820
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001301856201668584,
      "loss": 2.4492,
      "step": 7821
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013016902388618056,
      "loss": 2.2461,
      "step": 7822
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013015242669128222,
      "loss": 2.2734,
      "step": 7823
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013013582858266634,
      "loss": 2.3945,
      "step": 7824
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013011922956083582,
      "loss": 2.3555,
      "step": 7825
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013010262962629372,
      "loss": 2.4277,
      "step": 7826
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013008602877954308,
      "loss": 2.4199,
      "step": 7827
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013006942702108693,
      "loss": 2.2539,
      "step": 7828
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013005282435142836,
      "loss": 2.3828,
      "step": 7829
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001300362207710705,
      "loss": 2.4492,
      "step": 7830
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0013001961628051645,
      "loss": 2.3418,
      "step": 7831
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001300030108802695,
      "loss": 2.4727,
      "step": 7832
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012998640457083268,
      "loss": 2.3398,
      "step": 7833
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012996979735270934,
      "loss": 2.4102,
      "step": 7834
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001299531892264027,
      "loss": 2.3555,
      "step": 7835
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012993658019241603,
      "loss": 2.3711,
      "step": 7836
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012991997025125267,
      "loss": 2.3203,
      "step": 7837
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012990335940341589,
      "loss": 2.4102,
      "step": 7838
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012988674764940914,
      "loss": 2.3672,
      "step": 7839
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012987013498973572,
      "loss": 2.5508,
      "step": 7840
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012985352142489907,
      "loss": 2.2324,
      "step": 7841
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012983690695540274,
      "loss": 2.5312,
      "step": 7842
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012982029158175004,
      "loss": 2.4766,
      "step": 7843
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012980367530444458,
      "loss": 2.207,
      "step": 7844
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012978705812398987,
      "loss": 2.4023,
      "step": 7845
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012977044004088944,
      "loss": 2.4414,
      "step": 7846
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012975382105564692,
      "loss": 2.3789,
      "step": 7847
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012973720116876586,
      "loss": 2.5078,
      "step": 7848
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012972058038074991,
      "loss": 2.4844,
      "step": 7849
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012970395869210279,
      "loss": 2.0723,
      "step": 7850
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001296873361033281,
      "loss": 2.4961,
      "step": 7851
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012967071261492963,
      "loss": 2.5898,
      "step": 7852
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001296540882274111,
      "loss": 2.207,
      "step": 7853
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012963746294127629,
      "loss": 2.3945,
      "step": 7854
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012962083675702903,
      "loss": 2.4219,
      "step": 7855
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012960420967517306,
      "loss": 2.4297,
      "step": 7856
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012958758169621233,
      "loss": 2.2969,
      "step": 7857
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012957095282065069,
      "loss": 2.4688,
      "step": 7858
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012955432304899205,
      "loss": 2.5117,
      "step": 7859
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012953769238174032,
      "loss": 2.3438,
      "step": 7860
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0012952106081939947,
      "loss": 2.3008,
      "step": 7861
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012950442836247354,
      "loss": 2.543,
      "step": 7862
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001294877950114665,
      "loss": 2.3477,
      "step": 7863
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001294711607668824,
      "loss": 2.543,
      "step": 7864
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012945452562922535,
      "loss": 2.4453,
      "step": 7865
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001294378895989994,
      "loss": 2.418,
      "step": 7866
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001294212526767087,
      "loss": 2.2539,
      "step": 7867
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001294046148628574,
      "loss": 2.3242,
      "step": 7868
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001293879761579497,
      "loss": 2.2695,
      "step": 7869
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012937133656248975,
      "loss": 2.2969,
      "step": 7870
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012935469607698185,
      "loss": 2.2324,
      "step": 7871
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012933805470193023,
      "loss": 2.457,
      "step": 7872
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012932141243783917,
      "loss": 2.2734,
      "step": 7873
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00129304769285213,
      "loss": 2.4805,
      "step": 7874
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012928812524455608,
      "loss": 2.373,
      "step": 7875
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012927148031637273,
      "loss": 2.084,
      "step": 7876
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012925483450116739,
      "loss": 2.5547,
      "step": 7877
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001292381877994445,
      "loss": 2.1895,
      "step": 7878
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012922154021170842,
      "loss": 2.2695,
      "step": 7879
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012920489173846373,
      "loss": 2.5234,
      "step": 7880
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012918824238021488,
      "loss": 2.3711,
      "step": 7881
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012917159213746636,
      "loss": 2.3008,
      "step": 7882
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012915494101072285,
      "loss": 2.2207,
      "step": 7883
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012913828900048881,
      "loss": 2.3789,
      "step": 7884
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012912163610726893,
      "loss": 2.4141,
      "step": 7885
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012910498233156778,
      "loss": 2.4629,
      "step": 7886
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012908832767389007,
      "loss": 2.3203,
      "step": 7887
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012907167213474051,
      "loss": 2.4609,
      "step": 7888
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012905501571462378,
      "loss": 2.3438,
      "step": 7889
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001290383584140446,
      "loss": 2.4883,
      "step": 7890
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001290217002335078,
      "loss": 2.457,
      "step": 7891
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012900504117351814,
      "loss": 2.4961,
      "step": 7892
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012898838123458047,
      "loss": 2.3281,
      "step": 7893
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012897172041719965,
      "loss": 2.2852,
      "step": 7894
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012895505872188048,
      "loss": 2.2715,
      "step": 7895
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012893839614912797,
      "loss": 2.5273,
      "step": 7896
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012892173269944695,
      "loss": 2.2656,
      "step": 7897
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001289050683733425,
      "loss": 2.4531,
      "step": 7898
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012888840317131947,
      "loss": 2.5312,
      "step": 7899
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012887173709388296,
      "loss": 2.3281,
      "step": 7900
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012885507014153794,
      "loss": 2.3828,
      "step": 7901
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012883840231478953,
      "loss": 2.3555,
      "step": 7902
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012882173361414282,
      "loss": 2.2402,
      "step": 7903
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001288050640401029,
      "loss": 2.3711,
      "step": 7904
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001287883935931749,
      "loss": 2.375,
      "step": 7905
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012877172227386405,
      "loss": 2.3945,
      "step": 7906
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012875505008267548,
      "loss": 2.543,
      "step": 7907
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012873837702011444,
      "loss": 2.4805,
      "step": 7908
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012872170308668616,
      "loss": 2.3711,
      "step": 7909
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012870502828289593,
      "loss": 2.5273,
      "step": 7910
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001286883526092491,
      "loss": 2.4062,
      "step": 7911
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012867167606625091,
      "loss": 2.3945,
      "step": 7912
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012865499865440677,
      "loss": 2.5117,
      "step": 7913
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012863832037422202,
      "loss": 2.4727,
      "step": 7914
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001286216412262021,
      "loss": 2.3125,
      "step": 7915
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012860496121085245,
      "loss": 2.1211,
      "step": 7916
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001285882803286785,
      "loss": 2.3984,
      "step": 7917
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012857159858018579,
      "loss": 2.2383,
      "step": 7918
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012855491596587974,
      "loss": 2.4883,
      "step": 7919
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012853823248626594,
      "loss": 2.4102,
      "step": 7920
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012852154814184998,
      "loss": 2.207,
      "step": 7921
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012850486293313741,
      "loss": 2.2441,
      "step": 7922
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012848817686063386,
      "loss": 2.2559,
      "step": 7923
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00128471489924845,
      "loss": 2.4453,
      "step": 7924
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001284548021262764,
      "loss": 2.4648,
      "step": 7925
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012843811346543391,
      "loss": 2.168,
      "step": 7926
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001284214239428231,
      "loss": 2.4375,
      "step": 7927
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012840473355894982,
      "loss": 2.3789,
      "step": 7928
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012838804231431983,
      "loss": 2.2637,
      "step": 7929
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012837135020943883,
      "loss": 2.2109,
      "step": 7930
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012835465724481284,
      "loss": 2.6289,
      "step": 7931
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001283379634209475,
      "loss": 2.2539,
      "step": 7932
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012832126873834884,
      "loss": 2.4336,
      "step": 7933
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012830457319752268,
      "loss": 2.3594,
      "step": 7934
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012828787679897498,
      "loss": 2.4805,
      "step": 7935
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012827117954321168,
      "loss": 2.3281,
      "step": 7936
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012825448143073878,
      "loss": 2.6523,
      "step": 7937
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001282377824620623,
      "loss": 2.3555,
      "step": 7938
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012822108263768825,
      "loss": 2.2656,
      "step": 7939
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012820438195812267,
      "loss": 2.1094,
      "step": 7940
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012818768042387172,
      "loss": 2.4141,
      "step": 7941
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012817097803544141,
      "loss": 2.3672,
      "step": 7942
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012815427479333796,
      "loss": 2.3789,
      "step": 7943
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012813757069806751,
      "loss": 2.2656,
      "step": 7944
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012812086575013622,
      "loss": 2.4727,
      "step": 7945
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012810415995005034,
      "loss": 2.4844,
      "step": 7946
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001280874532983161,
      "loss": 2.3359,
      "step": 7947
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012807074579543976,
      "loss": 2.3047,
      "step": 7948
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012805403744192761,
      "loss": 2.4688,
      "step": 7949
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012803732823828593,
      "loss": 2.3477,
      "step": 7950
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001280206181850212,
      "loss": 2.2266,
      "step": 7951
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012800390728263961,
      "loss": 2.4219,
      "step": 7952
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0012798719553164769,
      "loss": 2.3945,
      "step": 7953
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001279704829325518,
      "loss": 2.3535,
      "step": 7954
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.001279537694858584,
      "loss": 2.4414,
      "step": 7955
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012793705519207397,
      "loss": 2.2461,
      "step": 7956
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012792034005170499,
      "loss": 2.2715,
      "step": 7957
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012790362406525798,
      "loss": 2.2832,
      "step": 7958
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012788690723323955,
      "loss": 2.3594,
      "step": 7959
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012787018955615617,
      "loss": 2.3633,
      "step": 7960
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012785347103451453,
      "loss": 2.3164,
      "step": 7961
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.001278367516688212,
      "loss": 2.3945,
      "step": 7962
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012782003145958287,
      "loss": 2.3223,
      "step": 7963
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012780331040730623,
      "loss": 2.3359,
      "step": 7964
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.001277865885124979,
      "loss": 2.3867,
      "step": 7965
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012776986577566472,
      "loss": 2.3711,
      "step": 7966
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012775314219731335,
      "loss": 2.3672,
      "step": 7967
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012773641777795062,
      "loss": 2.2031,
      "step": 7968
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012771969251808334,
      "loss": 2.3477,
      "step": 7969
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.001277029664182183,
      "loss": 2.2891,
      "step": 7970
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.001276862394788624,
      "loss": 2.2539,
      "step": 7971
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012766951170052247,
      "loss": 2.2559,
      "step": 7972
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012765278308370545,
      "loss": 2.168,
      "step": 7973
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012763605362891832,
      "loss": 2.2891,
      "step": 7974
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012761932333666792,
      "loss": 2.4219,
      "step": 7975
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012760259220746134,
      "loss": 2.3359,
      "step": 7976
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012758586024180555,
      "loss": 2.4922,
      "step": 7977
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012756912744020755,
      "loss": 2.4531,
      "step": 7978
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012755239380317445,
      "loss": 2.5352,
      "step": 7979
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.001275356593312133,
      "loss": 2.3438,
      "step": 7980
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012751892402483123,
      "loss": 2.3555,
      "step": 7981
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012750218788453536,
      "loss": 2.6328,
      "step": 7982
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012748545091083286,
      "loss": 2.418,
      "step": 7983
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012746871310423094,
      "loss": 2.5547,
      "step": 7984
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012745197446523673,
      "loss": 2.1816,
      "step": 7985
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012743523499435757,
      "loss": 2.4648,
      "step": 7986
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012741849469210065,
      "loss": 2.248,
      "step": 7987
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012740175355897328,
      "loss": 2.3203,
      "step": 7988
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012738501159548275,
      "loss": 2.3125,
      "step": 7989
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012736826880213644,
      "loss": 2.4492,
      "step": 7990
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012735152517944167,
      "loss": 2.2852,
      "step": 7991
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012733478072790585,
      "loss": 2.3672,
      "step": 7992
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012731803544803637,
      "loss": 2.4062,
      "step": 7993
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.001273012893403407,
      "loss": 2.2617,
      "step": 7994
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012728454240532624,
      "loss": 2.1738,
      "step": 7995
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012726779464350057,
      "loss": 2.1914,
      "step": 7996
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012725104605537116,
      "loss": 2.293,
      "step": 7997
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012723429664144553,
      "loss": 2.3008,
      "step": 7998
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012721754640223123,
      "loss": 2.4805,
      "step": 7999
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012720079533823586,
      "loss": 2.4844,
      "step": 8000
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012718404344996706,
      "loss": 2.2461,
      "step": 8001
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012716729073793244,
      "loss": 2.123,
      "step": 8002
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012715053720263971,
      "loss": 2.4805,
      "step": 8003
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012713378284459648,
      "loss": 2.3828,
      "step": 8004
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012711702766431052,
      "loss": 2.3125,
      "step": 8005
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012710027166228952,
      "loss": 2.3438,
      "step": 8006
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012708351483904133,
      "loss": 2.3242,
      "step": 8007
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012706675719507362,
      "loss": 2.3906,
      "step": 8008
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012704999873089427,
      "loss": 2.4141,
      "step": 8009
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.001270332394470111,
      "loss": 2.4922,
      "step": 8010
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00127016479343932,
      "loss": 2.3398,
      "step": 8011
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.001269997184221648,
      "loss": 2.5,
      "step": 8012
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012698295668221746,
      "loss": 2.3477,
      "step": 8013
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.001269661941245979,
      "loss": 2.5117,
      "step": 8014
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012694943074981406,
      "loss": 2.4727,
      "step": 8015
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012693266655837397,
      "loss": 2.1797,
      "step": 8016
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.001269159015507856,
      "loss": 2.4414,
      "step": 8017
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00126899135727557,
      "loss": 2.418,
      "step": 8018
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012688236908919624,
      "loss": 2.375,
      "step": 8019
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012686560163621139,
      "loss": 2.5664,
      "step": 8020
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012684883336911055,
      "loss": 2.3242,
      "step": 8021
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012683206428840189,
      "loss": 2.3359,
      "step": 8022
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012681529439459351,
      "loss": 2.2695,
      "step": 8023
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012679852368819363,
      "loss": 2.4062,
      "step": 8024
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.001267817521697105,
      "loss": 2.3906,
      "step": 8025
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012676497983965225,
      "loss": 2.5352,
      "step": 8026
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012674820669852725,
      "loss": 2.3398,
      "step": 8027
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012673143274684368,
      "loss": 2.4336,
      "step": 8028
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012671465798510988,
      "loss": 2.5703,
      "step": 8029
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012669788241383422,
      "loss": 2.293,
      "step": 8030
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012668110603352503,
      "loss": 2.5469,
      "step": 8031
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012666432884469066,
      "loss": 2.3008,
      "step": 8032
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012664755084783957,
      "loss": 2.4648,
      "step": 8033
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.001266307720434801,
      "loss": 2.3867,
      "step": 8034
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012661399243212084,
      "loss": 2.5508,
      "step": 8035
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012659721201427013,
      "loss": 2.3086,
      "step": 8036
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012658043079043653,
      "loss": 2.4219,
      "step": 8037
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012656364876112859,
      "loss": 2.1953,
      "step": 8038
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.001265468659268548,
      "loss": 2.3242,
      "step": 8039
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012653008228812384,
      "loss": 2.375,
      "step": 8040
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012651329784544416,
      "loss": 2.4062,
      "step": 8041
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012649651259932452,
      "loss": 2.3086,
      "step": 8042
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012647972655027348,
      "loss": 2.4102,
      "step": 8043
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012646293969879978,
      "loss": 2.4102,
      "step": 8044
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012644615204541205,
      "loss": 2.3672,
      "step": 8045
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012642936359061907,
      "loss": 2.3594,
      "step": 8046
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0012641257433492954,
      "loss": 2.4766,
      "step": 8047
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012639578427885226,
      "loss": 2.2734,
      "step": 8048
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012637899342289596,
      "loss": 2.3789,
      "step": 8049
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012636220176756958,
      "loss": 2.1406,
      "step": 8050
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012634540931338184,
      "loss": 2.332,
      "step": 8051
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012632861606084167,
      "loss": 2.2559,
      "step": 8052
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012631182201045797,
      "loss": 2.6445,
      "step": 8053
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012629502716273962,
      "loss": 2.4805,
      "step": 8054
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012627823151819557,
      "loss": 2.375,
      "step": 8055
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001262614350773348,
      "loss": 2.3047,
      "step": 8056
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012624463784066627,
      "loss": 2.5703,
      "step": 8057
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012622783980869904,
      "loss": 2.5117,
      "step": 8058
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012621104098194205,
      "loss": 2.5195,
      "step": 8059
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012619424136090446,
      "loss": 2.4414,
      "step": 8060
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001261774409460953,
      "loss": 2.5,
      "step": 8061
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012616063973802368,
      "loss": 2.4023,
      "step": 8062
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012614383773719875,
      "loss": 2.4414,
      "step": 8063
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012612703494412967,
      "loss": 2.4062,
      "step": 8064
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001261102313593256,
      "loss": 2.3633,
      "step": 8065
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012609342698329579,
      "loss": 2.3984,
      "step": 8066
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012607662181654935,
      "loss": 2.4336,
      "step": 8067
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001260598158595957,
      "loss": 2.3828,
      "step": 8068
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012604300911294396,
      "loss": 2.3086,
      "step": 8069
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012602620157710354,
      "loss": 2.5195,
      "step": 8070
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012600939325258368,
      "loss": 2.1914,
      "step": 8071
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001259925841398938,
      "loss": 2.3867,
      "step": 8072
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012597577423954325,
      "loss": 2.4062,
      "step": 8073
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012595896355204143,
      "loss": 2.2812,
      "step": 8074
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001259421520778977,
      "loss": 2.3301,
      "step": 8075
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012592533981762154,
      "loss": 2.3281,
      "step": 8076
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012590852677172243,
      "loss": 2.3633,
      "step": 8077
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001258917129407099,
      "loss": 2.2969,
      "step": 8078
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012587489832509339,
      "loss": 2.4414,
      "step": 8079
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012585808292538245,
      "loss": 2.3438,
      "step": 8080
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012584126674208668,
      "loss": 2.2773,
      "step": 8081
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012582444977571562,
      "loss": 2.2266,
      "step": 8082
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012580763202677894,
      "loss": 2.4258,
      "step": 8083
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001257908134957862,
      "loss": 2.2695,
      "step": 8084
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001257739941832471,
      "loss": 2.2656,
      "step": 8085
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012575717408967134,
      "loss": 2.2578,
      "step": 8086
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012574035321556859,
      "loss": 2.3594,
      "step": 8087
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012572353156144857,
      "loss": 2.4531,
      "step": 8088
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012570670912782104,
      "loss": 2.5117,
      "step": 8089
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001256898859151958,
      "loss": 2.2676,
      "step": 8090
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012567306192408263,
      "loss": 2.3164,
      "step": 8091
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012565623715499134,
      "loss": 2.3125,
      "step": 8092
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012563941160843182,
      "loss": 2.3867,
      "step": 8093
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012562258528491387,
      "loss": 2.2969,
      "step": 8094
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001256057581849474,
      "loss": 2.4102,
      "step": 8095
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012558893030904241,
      "loss": 2.4258,
      "step": 8096
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012557210165770876,
      "loss": 2.3906,
      "step": 8097
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012555527223145641,
      "loss": 2.2891,
      "step": 8098
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012553844203079538,
      "loss": 2.2676,
      "step": 8099
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012552161105623565,
      "loss": 2.543,
      "step": 8100
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001255047793082873,
      "loss": 2.2344,
      "step": 8101
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012548794678746034,
      "loss": 2.4375,
      "step": 8102
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012547111349426486,
      "loss": 2.1738,
      "step": 8103
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00125454279429211,
      "loss": 2.5977,
      "step": 8104
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012543744459280887,
      "loss": 2.3789,
      "step": 8105
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012542060898556855,
      "loss": 2.334,
      "step": 8106
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012540377260800034,
      "loss": 2.4297,
      "step": 8107
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012538693546061434,
      "loss": 2.293,
      "step": 8108
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001253700975439208,
      "loss": 2.3281,
      "step": 8109
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012535325885843,
      "loss": 2.5117,
      "step": 8110
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012533641940465216,
      "loss": 2.3906,
      "step": 8111
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012531957918309757,
      "loss": 2.3555,
      "step": 8112
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012530273819427657,
      "loss": 2.4922,
      "step": 8113
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012528589643869949,
      "loss": 2.4062,
      "step": 8114
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012526905391687668,
      "loss": 2.4727,
      "step": 8115
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012525221062931857,
      "loss": 2.6289,
      "step": 8116
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012523536657653546,
      "loss": 2.2012,
      "step": 8117
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012521852175903792,
      "loss": 2.3359,
      "step": 8118
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012520167617733628,
      "loss": 2.4219,
      "step": 8119
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012518482983194111,
      "loss": 2.5156,
      "step": 8120
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012516798272336285,
      "loss": 2.4375,
      "step": 8121
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012515113485211205,
      "loss": 2.3008,
      "step": 8122
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012513428621869923,
      "loss": 2.332,
      "step": 8123
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012511743682363501,
      "loss": 2.2852,
      "step": 8124
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012510058666742989,
      "loss": 2.3555,
      "step": 8125
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012508373575059462,
      "loss": 2.375,
      "step": 8126
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001250668840736397,
      "loss": 2.1758,
      "step": 8127
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012505003163707587,
      "loss": 2.2773,
      "step": 8128
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001250331784414138,
      "loss": 2.5391,
      "step": 8129
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001250163244871642,
      "loss": 2.4062,
      "step": 8130
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012499946977483779,
      "loss": 2.2578,
      "step": 8131
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012498261430494532,
      "loss": 2.4609,
      "step": 8132
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012496575807799757,
      "loss": 2.3125,
      "step": 8133
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012494890109450536,
      "loss": 2.2734,
      "step": 8134
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012493204335497948,
      "loss": 2.5039,
      "step": 8135
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012491518485993078,
      "loss": 2.293,
      "step": 8136
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012489832560987019,
      "loss": 2.1953,
      "step": 8137
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001248814656053085,
      "loss": 2.3438,
      "step": 8138
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012486460484675667,
      "loss": 2.1836,
      "step": 8139
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0012484774333472565,
      "loss": 2.5273,
      "step": 8140
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.001248308810697264,
      "loss": 2.3281,
      "step": 8141
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012481401805226986,
      "loss": 2.332,
      "step": 8142
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012479715428286707,
      "loss": 2.5234,
      "step": 8143
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.001247802897620291,
      "loss": 2.3164,
      "step": 8144
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012476342449026687,
      "loss": 2.5117,
      "step": 8145
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012474655846809158,
      "loss": 2.3008,
      "step": 8146
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012472969169601428,
      "loss": 2.4258,
      "step": 8147
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012471282417454608,
      "loss": 2.4062,
      "step": 8148
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012469595590419815,
      "loss": 2.2461,
      "step": 8149
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.001246790868854816,
      "loss": 2.3398,
      "step": 8150
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012466221711890766,
      "loss": 2.3516,
      "step": 8151
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012464534660498756,
      "loss": 2.3516,
      "step": 8152
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012462847534423247,
      "loss": 2.5938,
      "step": 8153
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.001246116033371537,
      "loss": 2.4062,
      "step": 8154
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012459473058426252,
      "loss": 2.2363,
      "step": 8155
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.001245778570860702,
      "loss": 2.3164,
      "step": 8156
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012456098284308805,
      "loss": 2.4961,
      "step": 8157
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012454410785582744,
      "loss": 2.3594,
      "step": 8158
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.001245272321247998,
      "loss": 2.3711,
      "step": 8159
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012451035565051638,
      "loss": 2.2344,
      "step": 8160
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012449347843348872,
      "loss": 2.5156,
      "step": 8161
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012447660047422819,
      "loss": 2.4688,
      "step": 8162
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.001244597217732463,
      "loss": 2.3379,
      "step": 8163
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012444284233105445,
      "loss": 2.418,
      "step": 8164
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012442596214816421,
      "loss": 2.4414,
      "step": 8165
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012440908122508705,
      "loss": 2.2227,
      "step": 8166
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.001243921995623346,
      "loss": 2.3867,
      "step": 8167
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012437531716041833,
      "loss": 2.4062,
      "step": 8168
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012435843401984992,
      "loss": 2.459,
      "step": 8169
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012434155014114095,
      "loss": 2.4141,
      "step": 8170
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012432466552480302,
      "loss": 2.4414,
      "step": 8171
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012430778017134786,
      "loss": 2.2891,
      "step": 8172
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012429089408128708,
      "loss": 2.3086,
      "step": 8173
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012427400725513245,
      "loss": 2.3633,
      "step": 8174
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012425711969339564,
      "loss": 2.3672,
      "step": 8175
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012424023139658842,
      "loss": 2.2734,
      "step": 8176
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012422334236522259,
      "loss": 2.3828,
      "step": 8177
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012420645259980988,
      "loss": 2.2812,
      "step": 8178
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012418956210086217,
      "loss": 2.418,
      "step": 8179
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012417267086889125,
      "loss": 2.4102,
      "step": 8180
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012415577890440904,
      "loss": 2.4531,
      "step": 8181
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012413888620792736,
      "loss": 2.4023,
      "step": 8182
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012412199277995813,
      "loss": 2.2969,
      "step": 8183
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012410509862101327,
      "loss": 2.3145,
      "step": 8184
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012408820373160476,
      "loss": 2.4766,
      "step": 8185
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012407130811224454,
      "loss": 2.2891,
      "step": 8186
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012405441176344466,
      "loss": 2.293,
      "step": 8187
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012403751468571702,
      "loss": 2.2246,
      "step": 8188
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012402061687957376,
      "loss": 2.1719,
      "step": 8189
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.001240037183455269,
      "loss": 2.1738,
      "step": 8190
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012398681908408853,
      "loss": 2.3672,
      "step": 8191
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012396991909577077,
      "loss": 2.3945,
      "step": 8192
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012395301838108567,
      "loss": 2.2227,
      "step": 8193
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012393611694054547,
      "loss": 2.5859,
      "step": 8194
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.001239192147746623,
      "loss": 2.0684,
      "step": 8195
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012390231188394835,
      "loss": 2.166,
      "step": 8196
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012388540826891586,
      "loss": 2.2051,
      "step": 8197
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00123868503930077,
      "loss": 2.4219,
      "step": 8198
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012385159886794408,
      "loss": 2.2695,
      "step": 8199
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.001238346930830294,
      "loss": 2.3203,
      "step": 8200
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012381778657584517,
      "loss": 2.3633,
      "step": 8201
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012380087934690384,
      "loss": 2.1738,
      "step": 8202
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.001237839713967176,
      "loss": 2.2109,
      "step": 8203
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012376706272579894,
      "loss": 2.4648,
      "step": 8204
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012375015333466021,
      "loss": 2.375,
      "step": 8205
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012373324322381384,
      "loss": 2.4648,
      "step": 8206
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012371633239377222,
      "loss": 2.5273,
      "step": 8207
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012369942084504784,
      "loss": 2.4141,
      "step": 8208
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012368250857815312,
      "loss": 2.3125,
      "step": 8209
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012366559559360065,
      "loss": 2.3906,
      "step": 8210
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012364868189190285,
      "loss": 2.4414,
      "step": 8211
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012363176747357233,
      "loss": 2.3828,
      "step": 8212
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012361485233912163,
      "loss": 2.4609,
      "step": 8213
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012359793648906332,
      "loss": 2.4648,
      "step": 8214
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012358101992391004,
      "loss": 2.4766,
      "step": 8215
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.001235641026441744,
      "loss": 2.4297,
      "step": 8216
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00123547184650369,
      "loss": 2.4023,
      "step": 8217
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012353026594300663,
      "loss": 2.332,
      "step": 8218
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012351334652259984,
      "loss": 2.207,
      "step": 8219
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012349642638966147,
      "loss": 2.3281,
      "step": 8220
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012347950554470418,
      "loss": 2.4922,
      "step": 8221
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012346258398824074,
      "loss": 2.4492,
      "step": 8222
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012344566172078394,
      "loss": 2.4961,
      "step": 8223
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012342873874284655,
      "loss": 2.5547,
      "step": 8224
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012341181505494143,
      "loss": 2.4609,
      "step": 8225
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012339489065758143,
      "loss": 2.5469,
      "step": 8226
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012337796555127937,
      "loss": 2.2969,
      "step": 8227
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012336103973654817,
      "loss": 2.1934,
      "step": 8228
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012334411321390075,
      "loss": 2.3203,
      "step": 8229
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012332718598385,
      "loss": 2.3594,
      "step": 8230
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.001233102580469089,
      "loss": 2.4453,
      "step": 8231
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012329332940359038,
      "loss": 2.3984,
      "step": 8232
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0012327640005440753,
      "loss": 2.2969,
      "step": 8233
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012325946999987322,
      "loss": 2.4531,
      "step": 8234
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012324253924050064,
      "loss": 2.2129,
      "step": 8235
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012322560777680272,
      "loss": 2.1289,
      "step": 8236
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012320867560929262,
      "loss": 2.4062,
      "step": 8237
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.001231917427384834,
      "loss": 2.3672,
      "step": 8238
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012317480916488818,
      "loss": 2.3438,
      "step": 8239
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012315787488902015,
      "loss": 2.4688,
      "step": 8240
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012314093991139244,
      "loss": 2.2695,
      "step": 8241
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.001231240042325182,
      "loss": 2.2656,
      "step": 8242
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012310706785291072,
      "loss": 2.5273,
      "step": 8243
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012309013077308314,
      "loss": 2.3594,
      "step": 8244
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012307319299354879,
      "loss": 2.4375,
      "step": 8245
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012305625451482088,
      "loss": 2.4141,
      "step": 8246
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012303931533741272,
      "loss": 2.4961,
      "step": 8247
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012302237546183764,
      "loss": 2.2539,
      "step": 8248
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012300543488860895,
      "loss": 2.5039,
      "step": 8249
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012298849361824,
      "loss": 2.4609,
      "step": 8250
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012297155165124421,
      "loss": 2.3594,
      "step": 8251
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.001229546089881349,
      "loss": 2.5898,
      "step": 8252
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.001229376656294256,
      "loss": 2.3398,
      "step": 8253
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012292072157562962,
      "loss": 2.2617,
      "step": 8254
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012290377682726056,
      "loss": 2.5547,
      "step": 8255
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.001228868313848318,
      "loss": 2.3594,
      "step": 8256
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012286988524885683,
      "loss": 2.3203,
      "step": 8257
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012285293841984926,
      "loss": 2.3711,
      "step": 8258
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012283599089832255,
      "loss": 2.3789,
      "step": 8259
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012281904268479033,
      "loss": 2.3438,
      "step": 8260
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012280209377976616,
      "loss": 2.4297,
      "step": 8261
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012278514418376362,
      "loss": 2.375,
      "step": 8262
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.001227681938972964,
      "loss": 2.2891,
      "step": 8263
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012275124292087812,
      "loss": 2.3223,
      "step": 8264
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.001227342912550224,
      "loss": 2.375,
      "step": 8265
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012271733890024303,
      "loss": 2.3086,
      "step": 8266
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012270038585705362,
      "loss": 2.2969,
      "step": 8267
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00122683432125968,
      "loss": 2.3203,
      "step": 8268
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012266647770749987,
      "loss": 2.2285,
      "step": 8269
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012264952260216298,
      "loss": 2.1504,
      "step": 8270
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012263256681047116,
      "loss": 2.457,
      "step": 8271
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012261561033293825,
      "loss": 2.4219,
      "step": 8272
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012259865317007805,
      "loss": 2.2578,
      "step": 8273
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012258169532240442,
      "loss": 2.5117,
      "step": 8274
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012256473679043123,
      "loss": 2.375,
      "step": 8275
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012254777757467244,
      "loss": 2.2539,
      "step": 8276
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012253081767564188,
      "loss": 2.3633,
      "step": 8277
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012251385709385353,
      "loss": 2.3398,
      "step": 8278
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012249689582982137,
      "loss": 2.4531,
      "step": 8279
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012247993388405938,
      "loss": 2.2637,
      "step": 8280
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012246297125708154,
      "loss": 2.1211,
      "step": 8281
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012244600794940191,
      "loss": 2.3711,
      "step": 8282
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012242904396153446,
      "loss": 2.3125,
      "step": 8283
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012241207929399333,
      "loss": 2.3516,
      "step": 8284
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012239511394729256,
      "loss": 2.1992,
      "step": 8285
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012237814792194633,
      "loss": 2.418,
      "step": 8286
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012236118121846866,
      "loss": 2.5312,
      "step": 8287
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012234421383737375,
      "loss": 2.3086,
      "step": 8288
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012232724577917577,
      "loss": 2.4492,
      "step": 8289
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.001223102770443889,
      "loss": 2.1328,
      "step": 8290
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012229330763352737,
      "loss": 2.4961,
      "step": 8291
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.001222763375471054,
      "loss": 2.3984,
      "step": 8292
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012225936678563717,
      "loss": 2.3555,
      "step": 8293
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012224239534963707,
      "loss": 2.6953,
      "step": 8294
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012222542323961927,
      "loss": 2.3945,
      "step": 8295
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012220845045609816,
      "loss": 2.418,
      "step": 8296
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012219147699958808,
      "loss": 2.3516,
      "step": 8297
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012217450287060332,
      "loss": 2.2969,
      "step": 8298
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012215752806965829,
      "loss": 2.3711,
      "step": 8299
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012214055259726737,
      "loss": 2.2891,
      "step": 8300
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012212357645394504,
      "loss": 2.2578,
      "step": 8301
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012210659964020558,
      "loss": 2.2734,
      "step": 8302
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012208962215656358,
      "loss": 2.457,
      "step": 8303
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012207264400353349,
      "loss": 2.3984,
      "step": 8304
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012205566518162976,
      "loss": 2.4258,
      "step": 8305
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.001220386856913669,
      "loss": 2.5508,
      "step": 8306
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.001220217055332595,
      "loss": 2.3516,
      "step": 8307
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012200472470782207,
      "loss": 2.5273,
      "step": 8308
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012198774321556924,
      "loss": 2.2539,
      "step": 8309
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012197076105701552,
      "loss": 2.3789,
      "step": 8310
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.001219537782326756,
      "loss": 2.2461,
      "step": 8311
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012193679474306407,
      "loss": 2.2461,
      "step": 8312
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012191981058869562,
      "loss": 2.4688,
      "step": 8313
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012190282577008488,
      "loss": 2.4766,
      "step": 8314
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.001218858402877466,
      "loss": 2.3789,
      "step": 8315
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012186885414219545,
      "loss": 2.334,
      "step": 8316
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012185186733394617,
      "loss": 2.3711,
      "step": 8317
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012183487986351352,
      "loss": 2.4297,
      "step": 8318
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012181789173141234,
      "loss": 2.2812,
      "step": 8319
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012180090293815733,
      "loss": 2.4805,
      "step": 8320
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012178391348426337,
      "loss": 2.4688,
      "step": 8321
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012176692337024526,
      "loss": 2.457,
      "step": 8322
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012174993259661789,
      "loss": 2.3711,
      "step": 8323
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.001217329411638961,
      "loss": 2.418,
      "step": 8324
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012171594907259482,
      "loss": 2.4141,
      "step": 8325
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0012169895632322893,
      "loss": 2.375,
      "step": 8326
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012168196291631344,
      "loss": 2.4375,
      "step": 8327
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012166496885236318,
      "loss": 2.2637,
      "step": 8328
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012164797413189326,
      "loss": 2.332,
      "step": 8329
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012163097875541858,
      "loss": 2.4805,
      "step": 8330
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001216139827234542,
      "loss": 2.4883,
      "step": 8331
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012159698603651512,
      "loss": 2.1543,
      "step": 8332
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012157998869511647,
      "loss": 2.3672,
      "step": 8333
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012156299069977323,
      "loss": 2.0703,
      "step": 8334
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012154599205100056,
      "loss": 2.5234,
      "step": 8335
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012152899274931355,
      "loss": 2.2344,
      "step": 8336
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012151199279522736,
      "loss": 2.2695,
      "step": 8337
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001214949921892571,
      "loss": 2.4219,
      "step": 8338
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012147799093191799,
      "loss": 2.2734,
      "step": 8339
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001214609890237252,
      "loss": 2.1758,
      "step": 8340
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012144398646519391,
      "loss": 2.1641,
      "step": 8341
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012142698325683945,
      "loss": 2.2305,
      "step": 8342
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012140997939917696,
      "loss": 2.3984,
      "step": 8343
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012139297489272183,
      "loss": 2.3828,
      "step": 8344
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012137596973798926,
      "loss": 2.4727,
      "step": 8345
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012135896393549457,
      "loss": 2.4766,
      "step": 8346
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012134195748575315,
      "loss": 2.2148,
      "step": 8347
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001213249503892803,
      "loss": 2.3047,
      "step": 8348
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012130794264659137,
      "loss": 2.4258,
      "step": 8349
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012129093425820182,
      "loss": 2.2578,
      "step": 8350
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012127392522462699,
      "loss": 2.4258,
      "step": 8351
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001212569155463824,
      "loss": 2.5859,
      "step": 8352
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001212399052239834,
      "loss": 2.3125,
      "step": 8353
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012122289425794553,
      "loss": 2.3281,
      "step": 8354
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012120588264878424,
      "loss": 2.3359,
      "step": 8355
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012118887039701506,
      "loss": 2.5508,
      "step": 8356
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012117185750315346,
      "loss": 2.3398,
      "step": 8357
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012115484396771508,
      "loss": 2.3828,
      "step": 8358
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001211378297912154,
      "loss": 2.1602,
      "step": 8359
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001211208149741701,
      "loss": 2.2305,
      "step": 8360
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012110379951709466,
      "loss": 2.2148,
      "step": 8361
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012108678342050486,
      "loss": 2.3125,
      "step": 8362
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012106976668491618,
      "loss": 2.2344,
      "step": 8363
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012105274931084437,
      "loss": 2.375,
      "step": 8364
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012103573129880515,
      "loss": 2.3047,
      "step": 8365
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012101871264931412,
      "loss": 2.3105,
      "step": 8366
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012100169336288708,
      "loss": 2.2891,
      "step": 8367
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012098467344003974,
      "loss": 2.2422,
      "step": 8368
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012096765288128783,
      "loss": 2.5859,
      "step": 8369
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012095063168714724,
      "loss": 2.1348,
      "step": 8370
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012093360985813361,
      "loss": 2.5156,
      "step": 8371
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012091658739476288,
      "loss": 2.3984,
      "step": 8372
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012089956429755084,
      "loss": 2.4141,
      "step": 8373
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012088254056701333,
      "loss": 2.25,
      "step": 8374
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001208655162036663,
      "loss": 2.4492,
      "step": 8375
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012084849120802552,
      "loss": 2.2031,
      "step": 8376
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012083146558060703,
      "loss": 2.6055,
      "step": 8377
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012081443932192668,
      "loss": 2.293,
      "step": 8378
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012079741243250046,
      "loss": 2.332,
      "step": 8379
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001207803849128443,
      "loss": 2.2578,
      "step": 8380
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012076335676347424,
      "loss": 2.3086,
      "step": 8381
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012074632798490627,
      "loss": 2.6445,
      "step": 8382
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012072929857765641,
      "loss": 2.4492,
      "step": 8383
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001207122685422407,
      "loss": 2.168,
      "step": 8384
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012069523787917524,
      "loss": 2.4727,
      "step": 8385
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012067820658897607,
      "loss": 2.4258,
      "step": 8386
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012066117467215932,
      "loss": 2.4102,
      "step": 8387
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001206441421292411,
      "loss": 2.332,
      "step": 8388
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012062710896073759,
      "loss": 2.4297,
      "step": 8389
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001206100751671649,
      "loss": 2.4922,
      "step": 8390
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012059304074903926,
      "loss": 2.5664,
      "step": 8391
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012057600570687678,
      "loss": 2.418,
      "step": 8392
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012055897004119383,
      "loss": 2.4102,
      "step": 8393
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012054193375250649,
      "loss": 2.4258,
      "step": 8394
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001205248968413311,
      "loss": 2.2656,
      "step": 8395
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012050785930818391,
      "loss": 2.293,
      "step": 8396
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001204908211535812,
      "loss": 2.4062,
      "step": 8397
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012047378237803935,
      "loss": 2.5547,
      "step": 8398
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001204567429820746,
      "loss": 2.1758,
      "step": 8399
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012043970296620335,
      "loss": 2.5156,
      "step": 8400
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012042266233094198,
      "loss": 2.168,
      "step": 8401
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012040562107680682,
      "loss": 2.3945,
      "step": 8402
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012038857920431433,
      "loss": 2.5938,
      "step": 8403
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012037153671398092,
      "loss": 2.1328,
      "step": 8404
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012035449360632302,
      "loss": 2.5547,
      "step": 8405
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012033744988185714,
      "loss": 2.1523,
      "step": 8406
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012032040554109968,
      "loss": 2.5039,
      "step": 8407
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001203033605845672,
      "loss": 2.2812,
      "step": 8408
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001202863150127762,
      "loss": 2.2949,
      "step": 8409
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012026926882624323,
      "loss": 2.332,
      "step": 8410
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012025222202548484,
      "loss": 2.1738,
      "step": 8411
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012023517461101755,
      "loss": 2.2539,
      "step": 8412
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012021812658335805,
      "loss": 2.4258,
      "step": 8413
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012020107794302288,
      "loss": 2.3867,
      "step": 8414
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012018402869052869,
      "loss": 2.2695,
      "step": 8415
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012016697882639216,
      "loss": 2.4336,
      "step": 8416
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012014992835112988,
      "loss": 2.5469,
      "step": 8417
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0012013287726525864,
      "loss": 2.4297,
      "step": 8418
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00120115825569295,
      "loss": 2.1934,
      "step": 8419
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0012009877326375584,
      "loss": 2.5391,
      "step": 8420
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.001200817203491578,
      "loss": 2.5117,
      "step": 8421
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0012006466682601769,
      "loss": 2.5312,
      "step": 8422
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0012004761269485227,
      "loss": 2.3633,
      "step": 8423
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0012003055795617831,
      "loss": 2.2812,
      "step": 8424
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0012001350261051265,
      "loss": 2.4102,
      "step": 8425
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011999644665837215,
      "loss": 2.4531,
      "step": 8426
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.001199793901002736,
      "loss": 2.1973,
      "step": 8427
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.001199623329367339,
      "loss": 2.25,
      "step": 8428
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011994527516826993,
      "loss": 2.3438,
      "step": 8429
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011992821679539865,
      "loss": 2.4141,
      "step": 8430
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011991115781863691,
      "loss": 2.3008,
      "step": 8431
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011989409823850168,
      "loss": 2.3555,
      "step": 8432
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011987703805550996,
      "loss": 2.4336,
      "step": 8433
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011985997727017865,
      "loss": 2.6328,
      "step": 8434
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.001198429158830248,
      "loss": 2.5391,
      "step": 8435
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011982585389456546,
      "loss": 2.3359,
      "step": 8436
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011980879130531756,
      "loss": 2.5859,
      "step": 8437
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011979172811579827,
      "loss": 2.4102,
      "step": 8438
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011977466432652457,
      "loss": 2.2363,
      "step": 8439
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011975759993801361,
      "loss": 2.3125,
      "step": 8440
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011974053495078247,
      "loss": 2.5176,
      "step": 8441
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011972346936534827,
      "loss": 2.0977,
      "step": 8442
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011970640318222816,
      "loss": 2.3203,
      "step": 8443
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.001196893364019393,
      "loss": 2.3359,
      "step": 8444
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011967226902499886,
      "loss": 2.3711,
      "step": 8445
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011965520105192407,
      "loss": 2.2617,
      "step": 8446
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.001196381324832321,
      "loss": 2.543,
      "step": 8447
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011962106331944024,
      "loss": 2.4531,
      "step": 8448
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011960399356106567,
      "loss": 2.3047,
      "step": 8449
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011958692320862571,
      "loss": 2.1836,
      "step": 8450
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011956985226263769,
      "loss": 2.4336,
      "step": 8451
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011955278072361879,
      "loss": 2.2773,
      "step": 8452
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011953570859208644,
      "loss": 2.4727,
      "step": 8453
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011951863586855795,
      "loss": 2.3926,
      "step": 8454
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011950156255355069,
      "loss": 2.2305,
      "step": 8455
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00119484488647582,
      "loss": 2.377,
      "step": 8456
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011946741415116934,
      "loss": 2.3828,
      "step": 8457
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011945033906483004,
      "loss": 2.293,
      "step": 8458
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011943326338908161,
      "loss": 2.2305,
      "step": 8459
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011941618712444143,
      "loss": 2.3301,
      "step": 8460
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011939911027142704,
      "loss": 2.4297,
      "step": 8461
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011938203283055585,
      "loss": 2.4023,
      "step": 8462
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.001193649548023454,
      "loss": 2.3984,
      "step": 8463
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011934787618731325,
      "loss": 2.4102,
      "step": 8464
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011933079698597689,
      "loss": 2.3164,
      "step": 8465
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011931371719885386,
      "loss": 2.3438,
      "step": 8466
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011929663682646178,
      "loss": 2.3203,
      "step": 8467
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011927955586931815,
      "loss": 2.2617,
      "step": 8468
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011926247432794072,
      "loss": 2.2109,
      "step": 8469
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011924539220284703,
      "loss": 2.375,
      "step": 8470
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011922830949455472,
      "loss": 2.2891,
      "step": 8471
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011921122620358149,
      "loss": 2.3164,
      "step": 8472
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011919414233044498,
      "loss": 2.4688,
      "step": 8473
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011917705787566294,
      "loss": 2.5117,
      "step": 8474
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011915997283975304,
      "loss": 2.4727,
      "step": 8475
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011914288722323302,
      "loss": 2.543,
      "step": 8476
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011912580102662064,
      "loss": 2.3281,
      "step": 8477
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011910871425043364,
      "loss": 2.2617,
      "step": 8478
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.001190916268951899,
      "loss": 2.2305,
      "step": 8479
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011907453896140708,
      "loss": 2.5664,
      "step": 8480
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.001190574504496031,
      "loss": 2.4062,
      "step": 8481
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011904036136029578,
      "loss": 2.3789,
      "step": 8482
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011902327169400293,
      "loss": 2.2734,
      "step": 8483
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011900618145124248,
      "loss": 2.5312,
      "step": 8484
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011898909063253228,
      "loss": 2.1367,
      "step": 8485
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.001189719992383903,
      "loss": 2.375,
      "step": 8486
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011895490726933442,
      "loss": 2.2891,
      "step": 8487
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011893781472588258,
      "loss": 2.3906,
      "step": 8488
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011892072160855274,
      "loss": 2.248,
      "step": 8489
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011890362791786289,
      "loss": 2.375,
      "step": 8490
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011888653365433103,
      "loss": 2.2695,
      "step": 8491
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011886943881847514,
      "loss": 2.3477,
      "step": 8492
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011885234341081326,
      "loss": 2.1934,
      "step": 8493
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011883524743186349,
      "loss": 2.3594,
      "step": 8494
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.001188181508821438,
      "loss": 2.2812,
      "step": 8495
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011880105376217236,
      "loss": 2.5703,
      "step": 8496
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011878395607246724,
      "loss": 2.3477,
      "step": 8497
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011876685781354653,
      "loss": 2.5078,
      "step": 8498
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011874975898592838,
      "loss": 2.0879,
      "step": 8499
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011873265959013095,
      "loss": 2.375,
      "step": 8500
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.001187155596266724,
      "loss": 2.3711,
      "step": 8501
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011869845909607093,
      "loss": 2.2617,
      "step": 8502
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.001186813579988447,
      "loss": 2.3984,
      "step": 8503
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011866425633551198,
      "loss": 2.1797,
      "step": 8504
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011864715410659099,
      "loss": 2.4453,
      "step": 8505
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011863005131259995,
      "loss": 2.3242,
      "step": 8506
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.001186129479540572,
      "loss": 2.4219,
      "step": 8507
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011859584403148095,
      "loss": 2.3613,
      "step": 8508
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011857873954538958,
      "loss": 2.4102,
      "step": 8509
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011856163449630135,
      "loss": 2.4023,
      "step": 8510
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.001185445288847346,
      "loss": 2.4766,
      "step": 8511
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011852742271120775,
      "loss": 2.3926,
      "step": 8512
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001185103159762391,
      "loss": 2.377,
      "step": 8513
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001184932086803471,
      "loss": 2.3945,
      "step": 8514
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001184761008240501,
      "loss": 2.418,
      "step": 8515
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001184589924078666,
      "loss": 2.248,
      "step": 8516
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011844188343231496,
      "loss": 2.2617,
      "step": 8517
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011842477389791368,
      "loss": 2.4844,
      "step": 8518
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011840766380518122,
      "loss": 2.2227,
      "step": 8519
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011839055315463613,
      "loss": 2.3027,
      "step": 8520
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001183734419467968,
      "loss": 2.6055,
      "step": 8521
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001183563301821819,
      "loss": 2.25,
      "step": 8522
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011833921786130984,
      "loss": 2.3594,
      "step": 8523
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011832210498469923,
      "loss": 2.3281,
      "step": 8524
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011830499155286872,
      "loss": 2.4062,
      "step": 8525
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011828787756633676,
      "loss": 2.3457,
      "step": 8526
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001182707630256221,
      "loss": 2.3066,
      "step": 8527
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011825364793124327,
      "loss": 2.3242,
      "step": 8528
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011823653228371896,
      "loss": 2.3633,
      "step": 8529
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001182194160835678,
      "loss": 2.4141,
      "step": 8530
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001182022993313085,
      "loss": 2.4375,
      "step": 8531
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011818518202745976,
      "loss": 2.3379,
      "step": 8532
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011816806417254025,
      "loss": 2.5156,
      "step": 8533
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011815094576706868,
      "loss": 2.2539,
      "step": 8534
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001181338268115639,
      "loss": 2.5,
      "step": 8535
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011811670730654455,
      "loss": 2.3555,
      "step": 8536
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001180995872525295,
      "loss": 2.5352,
      "step": 8537
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011808246665003749,
      "loss": 2.2148,
      "step": 8538
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011806534549958733,
      "loss": 2.1504,
      "step": 8539
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011804822380169786,
      "loss": 2.3477,
      "step": 8540
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011803110155688792,
      "loss": 2.3594,
      "step": 8541
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011801397876567638,
      "loss": 2.2539,
      "step": 8542
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011799685542858212,
      "loss": 2.5,
      "step": 8543
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00117979731546124,
      "loss": 2.375,
      "step": 8544
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011796260711882099,
      "loss": 2.1191,
      "step": 8545
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011794548214719195,
      "loss": 2.4062,
      "step": 8546
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011792835663175585,
      "loss": 2.2656,
      "step": 8547
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011791123057303169,
      "loss": 2.5859,
      "step": 8548
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001178941039715384,
      "loss": 2.4766,
      "step": 8549
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011787697682779494,
      "loss": 2.3086,
      "step": 8550
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011785984914232039,
      "loss": 2.2969,
      "step": 8551
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011784272091563373,
      "loss": 2.2305,
      "step": 8552
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011782559214825407,
      "loss": 2.418,
      "step": 8553
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011780846284070035,
      "loss": 2.418,
      "step": 8554
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011779133299349173,
      "loss": 2.4023,
      "step": 8555
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001177742026071473,
      "loss": 2.2227,
      "step": 8556
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001177570716821861,
      "loss": 2.6211,
      "step": 8557
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011773994021912733,
      "loss": 2.3594,
      "step": 8558
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001177228082184901,
      "loss": 2.5078,
      "step": 8559
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011770567568079357,
      "loss": 2.3398,
      "step": 8560
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011768854260655686,
      "loss": 2.3516,
      "step": 8561
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011767140899629925,
      "loss": 2.3047,
      "step": 8562
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001176542748505399,
      "loss": 2.3594,
      "step": 8563
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011763714016979803,
      "loss": 2.4883,
      "step": 8564
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011762000495459286,
      "loss": 2.293,
      "step": 8565
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011760286920544367,
      "loss": 2.2734,
      "step": 8566
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011758573292286972,
      "loss": 2.3867,
      "step": 8567
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011756859610739033,
      "loss": 2.3359,
      "step": 8568
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001175514587595247,
      "loss": 2.332,
      "step": 8569
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001175343208797923,
      "loss": 2.1602,
      "step": 8570
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001175171824687123,
      "loss": 2.3125,
      "step": 8571
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011750004352680417,
      "loss": 2.0957,
      "step": 8572
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011748290405458723,
      "loss": 2.3516,
      "step": 8573
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001174657640525809,
      "loss": 2.2891,
      "step": 8574
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011744862352130452,
      "loss": 2.4141,
      "step": 8575
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011743148246127753,
      "loss": 2.3164,
      "step": 8576
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011741434087301935,
      "loss": 2.4141,
      "step": 8577
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011739719875704946,
      "loss": 2.5156,
      "step": 8578
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011738005611388728,
      "loss": 2.3828,
      "step": 8579
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011736291294405232,
      "loss": 2.2754,
      "step": 8580
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001173457692480641,
      "loss": 2.4258,
      "step": 8581
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011732862502644205,
      "loss": 2.1172,
      "step": 8582
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011731148027970574,
      "loss": 2.2852,
      "step": 8583
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011729433500837474,
      "loss": 2.6328,
      "step": 8584
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011727718921296854,
      "loss": 2.4922,
      "step": 8585
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001172600428940068,
      "loss": 2.3477,
      "step": 8586
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011724289605200904,
      "loss": 2.3789,
      "step": 8587
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011722574868749491,
      "loss": 2.2969,
      "step": 8588
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011720860080098397,
      "loss": 2.3789,
      "step": 8589
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011719145239299593,
      "loss": 2.375,
      "step": 8590
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001171743034640504,
      "loss": 2.7891,
      "step": 8591
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011715715401466708,
      "loss": 2.3789,
      "step": 8592
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011714000404536562,
      "loss": 2.332,
      "step": 8593
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011712285355666575,
      "loss": 2.3555,
      "step": 8594
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011710570254908714,
      "loss": 2.5117,
      "step": 8595
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001170885510231496,
      "loss": 2.457,
      "step": 8596
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011707139897937278,
      "loss": 2.1406,
      "step": 8597
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011705424641827653,
      "loss": 2.457,
      "step": 8598
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011703709334038059,
      "loss": 2.2852,
      "step": 8599
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011701993974620472,
      "loss": 2.3945,
      "step": 8600
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011700278563626884,
      "loss": 2.4414,
      "step": 8601
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011698563101109262,
      "loss": 2.4102,
      "step": 8602
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011696847587119607,
      "loss": 2.457,
      "step": 8603
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011695132021709892,
      "loss": 2.2578,
      "step": 8604
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011693416404932107,
      "loss": 2.3516,
      "step": 8605
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011691700736838246,
      "loss": 2.3281,
      "step": 8606
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011689985017480293,
      "loss": 2.4648,
      "step": 8607
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011688269246910245,
      "loss": 2.25,
      "step": 8608
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011686553425180094,
      "loss": 2.2734,
      "step": 8609
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011684837552341828,
      "loss": 2.3867,
      "step": 8610
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011683121628447456,
      "loss": 2.5508,
      "step": 8611
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011681405653548966,
      "loss": 2.3555,
      "step": 8612
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011679689627698364,
      "loss": 2.5078,
      "step": 8613
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.001167797355094765,
      "loss": 2.3867,
      "step": 8614
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011676257423348822,
      "loss": 2.1855,
      "step": 8615
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.001167454124495389,
      "loss": 2.3906,
      "step": 8616
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.001167282501581486,
      "loss": 2.3945,
      "step": 8617
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011671108735983734,
      "loss": 2.1914,
      "step": 8618
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011669392405512524,
      "loss": 2.2207,
      "step": 8619
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.001166767602445324,
      "loss": 2.293,
      "step": 8620
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011665959592857898,
      "loss": 2.418,
      "step": 8621
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011664243110778502,
      "loss": 2.2617,
      "step": 8622
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011662526578267076,
      "loss": 2.3906,
      "step": 8623
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011660809995375637,
      "loss": 2.4062,
      "step": 8624
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011659093362156195,
      "loss": 2.5117,
      "step": 8625
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011657376678660776,
      "loss": 2.3125,
      "step": 8626
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011655659944941402,
      "loss": 2.4297,
      "step": 8627
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011653943161050089,
      "loss": 2.0762,
      "step": 8628
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.001165222632703887,
      "loss": 2.2637,
      "step": 8629
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.001165050944295976,
      "loss": 2.252,
      "step": 8630
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011648792508864795,
      "loss": 2.332,
      "step": 8631
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011647075524806002,
      "loss": 2.3984,
      "step": 8632
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011645358490835409,
      "loss": 2.4414,
      "step": 8633
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.001164364140700505,
      "loss": 2.1387,
      "step": 8634
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011641924273366954,
      "loss": 2.3672,
      "step": 8635
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011640207089973168,
      "loss": 2.1973,
      "step": 8636
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.001163848985687571,
      "loss": 2.2227,
      "step": 8637
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011636772574126631,
      "loss": 2.2344,
      "step": 8638
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011635055241777964,
      "loss": 2.2891,
      "step": 8639
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011633337859881757,
      "loss": 2.2305,
      "step": 8640
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011631620428490046,
      "loss": 2.3008,
      "step": 8641
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011629902947654877,
      "loss": 2.4844,
      "step": 8642
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.001162818541742829,
      "loss": 2.3223,
      "step": 8643
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011626467837862343,
      "loss": 2.4805,
      "step": 8644
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011624750209009071,
      "loss": 2.2227,
      "step": 8645
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011623032530920536,
      "loss": 2.4766,
      "step": 8646
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011621314803648784,
      "loss": 2.2695,
      "step": 8647
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011619597027245866,
      "loss": 2.3008,
      "step": 8648
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.001161787920176384,
      "loss": 2.4805,
      "step": 8649
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011616161327254757,
      "loss": 2.4961,
      "step": 8650
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011614443403770679,
      "loss": 2.4727,
      "step": 8651
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.001161272543136366,
      "loss": 2.5391,
      "step": 8652
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011611007410085763,
      "loss": 2.2617,
      "step": 8653
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011609289339989054,
      "loss": 2.125,
      "step": 8654
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011607571221125589,
      "loss": 2.3906,
      "step": 8655
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011605853053547434,
      "loss": 2.2852,
      "step": 8656
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011604134837306659,
      "loss": 2.4531,
      "step": 8657
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011602416572455327,
      "loss": 2.3359,
      "step": 8658
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011600698259045512,
      "loss": 2.1797,
      "step": 8659
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.001159897989712928,
      "loss": 2.4648,
      "step": 8660
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011597261486758703,
      "loss": 2.3359,
      "step": 8661
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011595543027985863,
      "loss": 2.3359,
      "step": 8662
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011593824520862819,
      "loss": 2.3828,
      "step": 8663
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011592105965441662,
      "loss": 2.2969,
      "step": 8664
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011590387361774463,
      "loss": 2.332,
      "step": 8665
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011588668709913304,
      "loss": 2.4414,
      "step": 8666
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011586950009910264,
      "loss": 2.3984,
      "step": 8667
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011585231261817426,
      "loss": 2.4922,
      "step": 8668
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011583512465686873,
      "loss": 2.4922,
      "step": 8669
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011581793621570694,
      "loss": 2.4648,
      "step": 8670
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011580074729520967,
      "loss": 2.293,
      "step": 8671
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011578355789589787,
      "loss": 2.2578,
      "step": 8672
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011576636801829243,
      "loss": 2.3711,
      "step": 8673
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011574917766291426,
      "loss": 2.334,
      "step": 8674
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011573198683028428,
      "loss": 2.4258,
      "step": 8675
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011571479552092336,
      "loss": 2.2344,
      "step": 8676
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011569760373535262,
      "loss": 2.4219,
      "step": 8677
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011568041147409283,
      "loss": 2.4805,
      "step": 8678
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.001156632187376651,
      "loss": 2.25,
      "step": 8679
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011564602552659041,
      "loss": 2.5078,
      "step": 8680
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011562883184138974,
      "loss": 2.6094,
      "step": 8681
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011561163768258411,
      "loss": 2.3672,
      "step": 8682
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011559444305069457,
      "loss": 2.293,
      "step": 8683
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.001155772479462422,
      "loss": 2.4141,
      "step": 8684
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011556005236974807,
      "loss": 2.5078,
      "step": 8685
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.001155428563217332,
      "loss": 2.043,
      "step": 8686
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011552565980271876,
      "loss": 2.1504,
      "step": 8687
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.001155084628132258,
      "loss": 2.0996,
      "step": 8688
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.001154912653537755,
      "loss": 2.3398,
      "step": 8689
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011547406742488896,
      "loss": 2.2012,
      "step": 8690
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011545686902708736,
      "loss": 2.4805,
      "step": 8691
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011543967016089186,
      "loss": 2.1445,
      "step": 8692
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011542247082682363,
      "loss": 2.4297,
      "step": 8693
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011540527102540383,
      "loss": 2.4922,
      "step": 8694
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011538807075715377,
      "loss": 2.2031,
      "step": 8695
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.001153708700225946,
      "loss": 2.2734,
      "step": 8696
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011535366882224761,
      "loss": 2.375,
      "step": 8697
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011533646715663397,
      "loss": 2.2578,
      "step": 8698
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00115319265026275,
      "loss": 2.3789,
      "step": 8699
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00115302062431692,
      "loss": 2.4727,
      "step": 8700
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011528485937340627,
      "loss": 2.4805,
      "step": 8701
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011526765585193905,
      "loss": 2.3281,
      "step": 8702
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011525045186781173,
      "loss": 2.2773,
      "step": 8703
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011523324742154562,
      "loss": 2.4609,
      "step": 8704
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001152160425136621,
      "loss": 2.4805,
      "step": 8705
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011519883714468245,
      "loss": 2.2734,
      "step": 8706
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011518163131512813,
      "loss": 2.3906,
      "step": 8707
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011516442502552053,
      "loss": 2.3164,
      "step": 8708
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011514721827638101,
      "loss": 2.4805,
      "step": 8709
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011513001106823106,
      "loss": 2.3594,
      "step": 8710
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011511280340159205,
      "loss": 2.1855,
      "step": 8711
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011509559527698545,
      "loss": 2.2188,
      "step": 8712
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011507838669493275,
      "loss": 2.4922,
      "step": 8713
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001150611776559554,
      "loss": 2.4688,
      "step": 8714
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001150439681605749,
      "loss": 2.375,
      "step": 8715
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011502675820931271,
      "loss": 2.4648,
      "step": 8716
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011500954780269042,
      "loss": 2.2754,
      "step": 8717
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011499233694122952,
      "loss": 2.1875,
      "step": 8718
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011497512562545155,
      "loss": 2.2227,
      "step": 8719
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011495791385587812,
      "loss": 2.2539,
      "step": 8720
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011494070163303072,
      "loss": 2.3555,
      "step": 8721
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011492348895743101,
      "loss": 2.2422,
      "step": 8722
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011490627582960056,
      "loss": 2.5859,
      "step": 8723
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00114889062250061,
      "loss": 2.1953,
      "step": 8724
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011487184821933393,
      "loss": 2.25,
      "step": 8725
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00114854633737941,
      "loss": 2.457,
      "step": 8726
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001148374188064039,
      "loss": 2.4453,
      "step": 8727
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011482020342524425,
      "loss": 2.1719,
      "step": 8728
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011480298759498375,
      "loss": 2.3242,
      "step": 8729
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011478577131614413,
      "loss": 2.4453,
      "step": 8730
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011476855458924704,
      "loss": 2.3691,
      "step": 8731
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011475133741481426,
      "loss": 2.1914,
      "step": 8732
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011473411979336747,
      "loss": 2.3594,
      "step": 8733
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011471690172542848,
      "loss": 2.1895,
      "step": 8734
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011469968321151903,
      "loss": 2.2969,
      "step": 8735
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011468246425216087,
      "loss": 2.3281,
      "step": 8736
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001146652448478758,
      "loss": 2.332,
      "step": 8737
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011464802499918567,
      "loss": 2.2773,
      "step": 8738
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011463080470661224,
      "loss": 2.3633,
      "step": 8739
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011461358397067741,
      "loss": 2.3477,
      "step": 8740
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011459636279190295,
      "loss": 2.4102,
      "step": 8741
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011457914117081077,
      "loss": 2.3555,
      "step": 8742
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011456191910792272,
      "loss": 2.3281,
      "step": 8743
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011454469660376065,
      "loss": 2.3008,
      "step": 8744
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011452747365884655,
      "loss": 2.5547,
      "step": 8745
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011451025027370224,
      "loss": 2.4609,
      "step": 8746
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011449302644884968,
      "loss": 2.4688,
      "step": 8747
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011447580218481085,
      "loss": 2.3438,
      "step": 8748
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011445857748210763,
      "loss": 2.4531,
      "step": 8749
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011444135234126203,
      "loss": 2.4102,
      "step": 8750
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011442412676279604,
      "loss": 2.5156,
      "step": 8751
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011440690074723157,
      "loss": 2.5234,
      "step": 8752
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011438967429509075,
      "loss": 2.4453,
      "step": 8753
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011437244740689547,
      "loss": 2.5547,
      "step": 8754
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011435522008316785,
      "loss": 2.2109,
      "step": 8755
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001143379923244299,
      "loss": 2.5742,
      "step": 8756
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011432076413120371,
      "loss": 2.3867,
      "step": 8757
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011430353550401133,
      "loss": 2.1855,
      "step": 8758
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011428630644337483,
      "loss": 2.4023,
      "step": 8759
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011426907694981627,
      "loss": 2.3945,
      "step": 8760
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001142518470238579,
      "loss": 2.4258,
      "step": 8761
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011423461666602167,
      "loss": 2.5,
      "step": 8762
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011421738587682985,
      "loss": 2.582,
      "step": 8763
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011420015465680449,
      "loss": 2.3789,
      "step": 8764
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011418292300646783,
      "loss": 2.4141,
      "step": 8765
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00114165690926342,
      "loss": 2.3242,
      "step": 8766
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001141484584169492,
      "loss": 2.375,
      "step": 8767
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011413122547881166,
      "loss": 2.3594,
      "step": 8768
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011411399211245154,
      "loss": 2.4531,
      "step": 8769
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011409675831839108,
      "loss": 2.4414,
      "step": 8770
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011407952409715262,
      "loss": 2.3984,
      "step": 8771
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011406228944925822,
      "loss": 2.5469,
      "step": 8772
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011404505437523035,
      "loss": 2.5273,
      "step": 8773
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011402781887559115,
      "loss": 2.125,
      "step": 8774
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011401058295086297,
      "loss": 2.3496,
      "step": 8775
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011399334660156812,
      "loss": 2.3398,
      "step": 8776
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001139761098282289,
      "loss": 2.375,
      "step": 8777
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001139588726313676,
      "loss": 2.457,
      "step": 8778
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011394163501150668,
      "loss": 2.5078,
      "step": 8779
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011392439696916834,
      "loss": 2.3242,
      "step": 8780
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011390715850487512,
      "loss": 2.2891,
      "step": 8781
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011388991961914926,
      "loss": 2.5469,
      "step": 8782
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001138726803125132,
      "loss": 2.4844,
      "step": 8783
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011385544058548937,
      "loss": 2.3242,
      "step": 8784
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011383820043860018,
      "loss": 2.4023,
      "step": 8785
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001138209598723681,
      "loss": 2.4883,
      "step": 8786
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001138037188873155,
      "loss": 2.2422,
      "step": 8787
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011378647748396488,
      "loss": 2.418,
      "step": 8788
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001137692356628387,
      "loss": 2.4883,
      "step": 8789
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011375199342445945,
      "loss": 2.4375,
      "step": 8790
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011373475076934963,
      "loss": 2.3008,
      "step": 8791
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011371750769803176,
      "loss": 2.3828,
      "step": 8792
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001137002642110283,
      "loss": 2.3359,
      "step": 8793
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001136830203088619,
      "loss": 2.4375,
      "step": 8794
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011366577599205498,
      "loss": 2.1328,
      "step": 8795
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001136485312611302,
      "loss": 2.375,
      "step": 8796
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011363128611661007,
      "loss": 2.2812,
      "step": 8797
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001136140405590172,
      "loss": 2.4375,
      "step": 8798
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011359679458887418,
      "loss": 2.4883,
      "step": 8799
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011357954820670362,
      "loss": 2.3438,
      "step": 8800
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011356230141302815,
      "loss": 2.4336,
      "step": 8801
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011354505420837038,
      "loss": 2.127,
      "step": 8802
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011352780659325296,
      "loss": 2.4141,
      "step": 8803
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011351055856819864,
      "loss": 2.4531,
      "step": 8804
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011349331013372995,
      "loss": 2.418,
      "step": 8805
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011347606129036964,
      "loss": 2.4258,
      "step": 8806
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011345881203864044,
      "loss": 2.3203,
      "step": 8807
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00113441562379065,
      "loss": 2.332,
      "step": 8808
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011342431231216607,
      "loss": 2.2656,
      "step": 8809
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011340706183846638,
      "loss": 2.5586,
      "step": 8810
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011338981095848871,
      "loss": 2.2422,
      "step": 8811
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011337255967275575,
      "loss": 2.4297,
      "step": 8812
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011335530798179028,
      "loss": 2.4609,
      "step": 8813
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011333805588611516,
      "loss": 2.4688,
      "step": 8814
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001133208033862531,
      "loss": 2.3828,
      "step": 8815
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011330355048272695,
      "loss": 2.3672,
      "step": 8816
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011328629717605955,
      "loss": 2.3359,
      "step": 8817
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011326904346677367,
      "loss": 2.3984,
      "step": 8818
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001132517893553922,
      "loss": 2.1875,
      "step": 8819
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011323453484243795,
      "loss": 2.4043,
      "step": 8820
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011321727992843387,
      "loss": 2.3281,
      "step": 8821
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011320002461390278,
      "loss": 2.3477,
      "step": 8822
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011318276889936757,
      "loss": 2.3086,
      "step": 8823
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011316551278535117,
      "loss": 2.3398,
      "step": 8824
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011314825627237648,
      "loss": 2.3555,
      "step": 8825
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011313099936096644,
      "loss": 2.2148,
      "step": 8826
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011311374205164398,
      "loss": 2.4688,
      "step": 8827
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011309648434493205,
      "loss": 2.3594,
      "step": 8828
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011307922624135367,
      "loss": 2.0684,
      "step": 8829
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011306196774143172,
      "loss": 2.5938,
      "step": 8830
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011304470884568928,
      "loss": 2.3301,
      "step": 8831
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011302744955464929,
      "loss": 2.4062,
      "step": 8832
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011301018986883478,
      "loss": 2.4102,
      "step": 8833
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011299292978876878,
      "loss": 2.4492,
      "step": 8834
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011297566931497435,
      "loss": 2.3086,
      "step": 8835
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001129584084479745,
      "loss": 2.2441,
      "step": 8836
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011294114718829234,
      "loss": 2.5703,
      "step": 8837
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011292388553645085,
      "loss": 2.4375,
      "step": 8838
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011290662349297323,
      "loss": 2.4297,
      "step": 8839
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001128893610583825,
      "loss": 2.207,
      "step": 8840
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001128720982332018,
      "loss": 2.1758,
      "step": 8841
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011285483501795423,
      "loss": 2.4219,
      "step": 8842
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011283757141316295,
      "loss": 2.1758,
      "step": 8843
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011282030741935109,
      "loss": 2.2539,
      "step": 8844
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011280304303704178,
      "loss": 2.1543,
      "step": 8845
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001127857782667582,
      "loss": 2.2539,
      "step": 8846
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001127685131090236,
      "loss": 2.3203,
      "step": 8847
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011275124756436104,
      "loss": 2.4531,
      "step": 8848
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011273398163329383,
      "loss": 2.3438,
      "step": 8849
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011271671531634512,
      "loss": 2.1016,
      "step": 8850
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001126994486140382,
      "loss": 2.2148,
      "step": 8851
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011268218152689627,
      "loss": 2.1699,
      "step": 8852
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011266491405544255,
      "loss": 2.3438,
      "step": 8853
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011264764620020034,
      "loss": 2.4688,
      "step": 8854
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011263037796169293,
      "loss": 2.1582,
      "step": 8855
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011261310934044355,
      "loss": 2.2969,
      "step": 8856
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011259584033697554,
      "loss": 2.4531,
      "step": 8857
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001125785709518122,
      "loss": 2.4336,
      "step": 8858
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011256130118547682,
      "loss": 2.3594,
      "step": 8859
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011254403103849277,
      "loss": 2.1699,
      "step": 8860
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011252676051138337,
      "loss": 2.4688,
      "step": 8861
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00112509489604672,
      "loss": 2.4961,
      "step": 8862
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011249221831888196,
      "loss": 2.3164,
      "step": 8863
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001124749466545367,
      "loss": 2.2656,
      "step": 8864
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001124576746121596,
      "loss": 2.4805,
      "step": 8865
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00112440402192274,
      "loss": 2.3633,
      "step": 8866
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011242312939540335,
      "loss": 2.2891,
      "step": 8867
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001124058562220711,
      "loss": 2.3203,
      "step": 8868
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011238858267280062,
      "loss": 2.4375,
      "step": 8869
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011237130874811544,
      "loss": 2.3027,
      "step": 8870
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011235403444853891,
      "loss": 2.5039,
      "step": 8871
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011233675977459462,
      "loss": 2.2695,
      "step": 8872
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011231948472680592,
      "loss": 2.4766,
      "step": 8873
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011230220930569638,
      "loss": 2.2422,
      "step": 8874
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001122849335117895,
      "loss": 2.3477,
      "step": 8875
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001122676573456088,
      "loss": 2.3203,
      "step": 8876
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011225038080767775,
      "loss": 2.2969,
      "step": 8877
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011223310389851995,
      "loss": 2.3398,
      "step": 8878
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001122158266186589,
      "loss": 2.6055,
      "step": 8879
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011219854896861818,
      "loss": 2.2539,
      "step": 8880
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011218127094892137,
      "loss": 2.375,
      "step": 8881
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011216399256009201,
      "loss": 2.4062,
      "step": 8882
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011214671380265374,
      "loss": 2.3633,
      "step": 8883
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011212943467713015,
      "loss": 2.2578,
      "step": 8884
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011211215518404482,
      "loss": 2.4648,
      "step": 8885
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011209487532392141,
      "loss": 2.4492,
      "step": 8886
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011207759509728355,
      "loss": 2.3906,
      "step": 8887
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011206031450465492,
      "loss": 2.3047,
      "step": 8888
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001120430335465591,
      "loss": 2.4102,
      "step": 8889
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011202575222351984,
      "loss": 2.375,
      "step": 8890
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011200847053606073,
      "loss": 2.3203,
      "step": 8891
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011199118848470558,
      "loss": 2.3594,
      "step": 8892
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011197390606997799,
      "loss": 2.4336,
      "step": 8893
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011195662329240173,
      "loss": 2.3496,
      "step": 8894
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001119393401525005,
      "loss": 2.4766,
      "step": 8895
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011192205665079805,
      "loss": 2.3633,
      "step": 8896
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011190477278781813,
      "loss": 2.3652,
      "step": 8897
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011188748856408447,
      "loss": 2.418,
      "step": 8898
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011187020398012086,
      "loss": 2.1934,
      "step": 8899
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011185291903645109,
      "loss": 2.2344,
      "step": 8900
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011183563373359895,
      "loss": 2.293,
      "step": 8901
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001118183480720882,
      "loss": 2.332,
      "step": 8902
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011180106205244272,
      "loss": 2.2773,
      "step": 8903
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011178377567518626,
      "loss": 2.4453,
      "step": 8904
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001117664889408427,
      "loss": 2.3125,
      "step": 8905
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011174920184993588,
      "loss": 2.3477,
      "step": 8906
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011173191440298966,
      "loss": 2.457,
      "step": 8907
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011171462660052789,
      "loss": 2.3828,
      "step": 8908
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011169733844307445,
      "loss": 2.2734,
      "step": 8909
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011168004993115323,
      "loss": 2.3203,
      "step": 8910
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011166276106528812,
      "loss": 2.2422,
      "step": 8911
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011164547184600304,
      "loss": 2.4844,
      "step": 8912
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011162818227382194,
      "loss": 2.5234,
      "step": 8913
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011161089234926868,
      "loss": 2.3438,
      "step": 8914
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011159360207286728,
      "loss": 2.3008,
      "step": 8915
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011157631144514165,
      "loss": 2.5117,
      "step": 8916
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011155902046661571,
      "loss": 2.3125,
      "step": 8917
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011154172913781352,
      "loss": 2.4336,
      "step": 8918
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011152443745925905,
      "loss": 2.4609,
      "step": 8919
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011150714543147623,
      "loss": 2.3086,
      "step": 8920
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011148985305498914,
      "loss": 2.4219,
      "step": 8921
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011147256033032168,
      "loss": 2.2266,
      "step": 8922
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011145526725799806,
      "loss": 2.4414,
      "step": 8923
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011143797383854216,
      "loss": 2.5195,
      "step": 8924
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011142068007247807,
      "loss": 2.3984,
      "step": 8925
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011140338596032989,
      "loss": 2.1875,
      "step": 8926
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011138609150262164,
      "loss": 2.3555,
      "step": 8927
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011136879669987742,
      "loss": 2.293,
      "step": 8928
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001113515015526213,
      "loss": 2.375,
      "step": 8929
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001113342060613774,
      "loss": 2.2246,
      "step": 8930
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011131691022666988,
      "loss": 2.3164,
      "step": 8931
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011129961404902273,
      "loss": 2.3828,
      "step": 8932
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011128231752896018,
      "loss": 2.2539,
      "step": 8933
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011126502066700636,
      "loss": 2.4531,
      "step": 8934
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001112477234636854,
      "loss": 2.5469,
      "step": 8935
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011123042591952151,
      "loss": 2.5059,
      "step": 8936
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011121312803503878,
      "loss": 2.3594,
      "step": 8937
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011119582981076147,
      "loss": 2.2734,
      "step": 8938
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001111785312472137,
      "loss": 2.3203,
      "step": 8939
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011116123234491974,
      "loss": 2.3438,
      "step": 8940
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011114393310440378,
      "loss": 2.2734,
      "step": 8941
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011112663352619003,
      "loss": 2.3867,
      "step": 8942
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011110933361080275,
      "loss": 2.4688,
      "step": 8943
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011109203335876617,
      "loss": 2.3203,
      "step": 8944
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001110747327706045,
      "loss": 2.293,
      "step": 8945
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011105743184684211,
      "loss": 2.3438,
      "step": 8946
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011104013058800318,
      "loss": 2.4531,
      "step": 8947
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011102282899461205,
      "loss": 2.4277,
      "step": 8948
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011100552706719297,
      "loss": 2.4688,
      "step": 8949
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001109882248062703,
      "loss": 2.2578,
      "step": 8950
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001109709222123683,
      "loss": 2.5117,
      "step": 8951
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001109536192860113,
      "loss": 2.3945,
      "step": 8952
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001109363160277237,
      "loss": 2.2383,
      "step": 8953
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011091901243802979,
      "loss": 2.3906,
      "step": 8954
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001109017085174539,
      "loss": 2.3672,
      "step": 8955
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011088440426652046,
      "loss": 2.2539,
      "step": 8956
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011086709968575379,
      "loss": 2.3438,
      "step": 8957
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011084979477567834,
      "loss": 2.4375,
      "step": 8958
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011083248953681847,
      "loss": 2.3203,
      "step": 8959
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011081518396969857,
      "loss": 2.25,
      "step": 8960
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011079787807484307,
      "loss": 2.3359,
      "step": 8961
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011078057185277639,
      "loss": 2.4531,
      "step": 8962
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011076326530402296,
      "loss": 2.332,
      "step": 8963
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011074595842910729,
      "loss": 2.2617,
      "step": 8964
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011072865122855372,
      "loss": 2.2188,
      "step": 8965
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011071134370288678,
      "loss": 2.4102,
      "step": 8966
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011069403585263098,
      "loss": 2.2461,
      "step": 8967
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011067672767831073,
      "loss": 2.3711,
      "step": 8968
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001106594191804506,
      "loss": 2.375,
      "step": 8969
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00110642110359575,
      "loss": 2.2305,
      "step": 8970
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011062480121620856,
      "loss": 2.3438,
      "step": 8971
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001106074917508757,
      "loss": 2.2578,
      "step": 8972
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00110590181964101,
      "loss": 2.418,
      "step": 8973
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00110572871856409,
      "loss": 2.3398,
      "step": 8974
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011055556142832428,
      "loss": 2.4316,
      "step": 8975
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011053825068037136,
      "loss": 2.1777,
      "step": 8976
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001105209396130748,
      "loss": 2.4668,
      "step": 8977
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011050362822695922,
      "loss": 2.4375,
      "step": 8978
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011048631652254926,
      "loss": 2.2988,
      "step": 8979
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001104690045003694,
      "loss": 2.168,
      "step": 8980
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011045169216094435,
      "loss": 2.2852,
      "step": 8981
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001104343795047987,
      "loss": 2.4648,
      "step": 8982
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011041706653245704,
      "loss": 2.5664,
      "step": 8983
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011039975324444408,
      "loss": 2.3789,
      "step": 8984
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001103824396412844,
      "loss": 2.3477,
      "step": 8985
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011036512572350273,
      "loss": 2.3516,
      "step": 8986
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011034781149162369,
      "loss": 2.1914,
      "step": 8987
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011033049694617195,
      "loss": 2.4023,
      "step": 8988
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011031318208767227,
      "loss": 2.5898,
      "step": 8989
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011029586691664924,
      "loss": 2.3359,
      "step": 8990
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011027855143362765,
      "loss": 2.3203,
      "step": 8991
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011026123563913218,
      "loss": 2.3906,
      "step": 8992
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011024391953368758,
      "loss": 2.3789,
      "step": 8993
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011022660311781857,
      "loss": 2.1855,
      "step": 8994
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011020928639204986,
      "loss": 2.2441,
      "step": 8995
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011019196935690625,
      "loss": 2.1172,
      "step": 8996
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011017465201291253,
      "loss": 2.3086,
      "step": 8997
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011015733436059336,
      "loss": 2.293,
      "step": 8998
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011014001640047364,
      "loss": 2.3008,
      "step": 8999
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011012269813307812,
      "loss": 2.4004,
      "step": 9000
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011010537955893158,
      "loss": 2.2148,
      "step": 9001
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011008806067855886,
      "loss": 2.1348,
      "step": 9002
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011007074149248475,
      "loss": 2.375,
      "step": 9003
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011005342200123408,
      "loss": 2.5078,
      "step": 9004
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011003610220533173,
      "loss": 2.3398,
      "step": 9005
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011001878210530247,
      "loss": 2.2812,
      "step": 9006
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011000146170167125,
      "loss": 2.3359,
      "step": 9007
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010998414099496288,
      "loss": 2.4531,
      "step": 9008
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010996681998570225,
      "loss": 2.3203,
      "step": 9009
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001099494986744142,
      "loss": 2.5391,
      "step": 9010
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010993217706162365,
      "loss": 2.4922,
      "step": 9011
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010991485514785558,
      "loss": 2.4688,
      "step": 9012
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010989753293363476,
      "loss": 2.3047,
      "step": 9013
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010988021041948622,
      "loss": 2.3203,
      "step": 9014
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001098628876059348,
      "loss": 2.3398,
      "step": 9015
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010984556449350556,
      "loss": 2.3203,
      "step": 9016
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010982824108272332,
      "loss": 2.6055,
      "step": 9017
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010981091737411312,
      "loss": 2.5195,
      "step": 9018
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010979359336819989,
      "loss": 2.2598,
      "step": 9019
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010977626906550862,
      "loss": 2.5391,
      "step": 9020
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010975894446656426,
      "loss": 2.3398,
      "step": 9021
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010974161957189186,
      "loss": 2.4531,
      "step": 9022
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010972429438201635,
      "loss": 2.2656,
      "step": 9023
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001097069688974628,
      "loss": 2.1445,
      "step": 9024
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001096896431187562,
      "loss": 2.5586,
      "step": 9025
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010967231704642158,
      "loss": 2.3984,
      "step": 9026
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00109654990680984,
      "loss": 2.4531,
      "step": 9027
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010963766402296846,
      "loss": 2.2695,
      "step": 9028
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010962033707290005,
      "loss": 2.3047,
      "step": 9029
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010960300983130387,
      "loss": 2.2656,
      "step": 9030
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010958568229870488,
      "loss": 2.5273,
      "step": 9031
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001095683544756283,
      "loss": 2.5,
      "step": 9032
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010955102636259909,
      "loss": 2.3047,
      "step": 9033
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001095336979601424,
      "loss": 2.3789,
      "step": 9034
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010951636926878339,
      "loss": 2.3516,
      "step": 9035
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001094990402890471,
      "loss": 2.3086,
      "step": 9036
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010948171102145871,
      "loss": 2.4844,
      "step": 9037
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010946438146654334,
      "loss": 2.1758,
      "step": 9038
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010944705162482609,
      "loss": 2.4375,
      "step": 9039
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001094297214968322,
      "loss": 2.293,
      "step": 9040
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001094123910830867,
      "loss": 2.3477,
      "step": 9041
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010939506038411487,
      "loss": 2.3262,
      "step": 9042
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010937772940044185,
      "loss": 2.3359,
      "step": 9043
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001093603981325928,
      "loss": 2.4766,
      "step": 9044
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010934306658109297,
      "loss": 2.293,
      "step": 9045
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001093257347464675,
      "loss": 2.3516,
      "step": 9046
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010930840262924166,
      "loss": 2.3926,
      "step": 9047
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010929107022994065,
      "loss": 2.168,
      "step": 9048
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001092737375490897,
      "loss": 2.3125,
      "step": 9049
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00109256404587214,
      "loss": 2.6094,
      "step": 9050
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010923907134483886,
      "loss": 2.5,
      "step": 9051
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010922173782248951,
      "loss": 2.0566,
      "step": 9052
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010920440402069121,
      "loss": 2.3711,
      "step": 9053
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010918706993996922,
      "loss": 2.3105,
      "step": 9054
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010916973558084886,
      "loss": 2.5977,
      "step": 9055
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010915240094385536,
      "loss": 2.2617,
      "step": 9056
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010913506602951409,
      "loss": 2.3281,
      "step": 9057
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010911773083835028,
      "loss": 2.2539,
      "step": 9058
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010910039537088928,
      "loss": 2.0449,
      "step": 9059
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001090830596276564,
      "loss": 2.0977,
      "step": 9060
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00109065723609177,
      "loss": 2.3555,
      "step": 9061
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010904838731597636,
      "loss": 2.332,
      "step": 9062
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001090310507485799,
      "loss": 2.1953,
      "step": 9063
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010901371390751292,
      "loss": 2.2383,
      "step": 9064
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010899637679330084,
      "loss": 2.2969,
      "step": 9065
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001089790394064689,
      "loss": 2.207,
      "step": 9066
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010896170174754265,
      "loss": 2.5273,
      "step": 9067
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010894436381704738,
      "loss": 2.3398,
      "step": 9068
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010892702561550848,
      "loss": 2.3848,
      "step": 9069
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010890968714345143,
      "loss": 2.1387,
      "step": 9070
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010889234840140154,
      "loss": 2.3789,
      "step": 9071
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001088750093898843,
      "loss": 2.3242,
      "step": 9072
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010885767010942516,
      "loss": 2.5,
      "step": 9073
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010884033056054946,
      "loss": 2.3359,
      "step": 9074
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010882299074378274,
      "loss": 2.377,
      "step": 9075
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010880565065965043,
      "loss": 2.3867,
      "step": 9076
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010878831030867796,
      "loss": 2.4609,
      "step": 9077
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010877096969139082,
      "loss": 2.4082,
      "step": 9078
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001087536288083145,
      "loss": 2.2461,
      "step": 9079
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010873628765997445,
      "loss": 2.2441,
      "step": 9080
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001087189462468962,
      "loss": 2.2246,
      "step": 9081
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010870160456960523,
      "loss": 2.2051,
      "step": 9082
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010868426262862706,
      "loss": 2.3789,
      "step": 9083
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010866692042448723,
      "loss": 2.3086,
      "step": 9084
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010864957795771125,
      "loss": 2.4258,
      "step": 9085
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010863223522882461,
      "loss": 2.7148,
      "step": 9086
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010861489223835288,
      "loss": 2.1953,
      "step": 9087
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010859754898682166,
      "loss": 2.1289,
      "step": 9088
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010858020547475642,
      "loss": 2.3672,
      "step": 9089
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001085628617026828,
      "loss": 2.4805,
      "step": 9090
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010854551767112632,
      "loss": 2.1836,
      "step": 9091
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010852817338061261,
      "loss": 2.4023,
      "step": 9092
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010851082883166724,
      "loss": 2.2656,
      "step": 9093
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010849348402481576,
      "loss": 2.2969,
      "step": 9094
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001084761389605838,
      "loss": 2.4609,
      "step": 9095
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010845879363949706,
      "loss": 2.5273,
      "step": 9096
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010844144806208102,
      "loss": 2.3164,
      "step": 9097
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010842410222886146,
      "loss": 2.4492,
      "step": 9098
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010840675614036384,
      "loss": 2.2344,
      "step": 9099
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010838940979711394,
      "loss": 2.2266,
      "step": 9100
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010837206319963735,
      "loss": 2.3438,
      "step": 9101
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010835471634845974,
      "loss": 2.5664,
      "step": 9102
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001083373692441068,
      "loss": 2.3281,
      "step": 9103
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010832002188710418,
      "loss": 2.4922,
      "step": 9104
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010830267427797756,
      "loss": 2.5078,
      "step": 9105
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010828532641725267,
      "loss": 2.4414,
      "step": 9106
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010826797830545511,
      "loss": 2.3906,
      "step": 9107
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010825062994311069,
      "loss": 2.1719,
      "step": 9108
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010823328133074506,
      "loss": 2.2148,
      "step": 9109
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00108215932468884,
      "loss": 2.2031,
      "step": 9110
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010819858335805318,
      "loss": 2.4609,
      "step": 9111
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010818123399877833,
      "loss": 2.4336,
      "step": 9112
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010816388439158521,
      "loss": 2.3672,
      "step": 9113
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010814653453699963,
      "loss": 2.5195,
      "step": 9114
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010812918443554725,
      "loss": 2.375,
      "step": 9115
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001081118340877539,
      "loss": 2.375,
      "step": 9116
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001080944834941453,
      "loss": 2.5664,
      "step": 9117
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010807713265524727,
      "loss": 2.0781,
      "step": 9118
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010805978157158562,
      "loss": 2.2891,
      "step": 9119
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010804243024368607,
      "loss": 2.4062,
      "step": 9120
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010802507867207452,
      "loss": 2.5586,
      "step": 9121
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001080077268572767,
      "loss": 2.4414,
      "step": 9122
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010799037479981843,
      "loss": 2.4141,
      "step": 9123
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010797302250022559,
      "loss": 2.4453,
      "step": 9124
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010795566995902394,
      "loss": 2.207,
      "step": 9125
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001079383171767394,
      "loss": 2.5352,
      "step": 9126
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010792096415389776,
      "loss": 2.2734,
      "step": 9127
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010790361089102487,
      "loss": 2.3203,
      "step": 9128
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010788625738864664,
      "loss": 2.4453,
      "step": 9129
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010786890364728888,
      "loss": 2.6055,
      "step": 9130
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001078515496674775,
      "loss": 2.3828,
      "step": 9131
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010783419544973835,
      "loss": 2.5234,
      "step": 9132
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010781684099459739,
      "loss": 2.3047,
      "step": 9133
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010779948630258046,
      "loss": 2.2559,
      "step": 9134
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010778213137421343,
      "loss": 2.3359,
      "step": 9135
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010776477621002231,
      "loss": 2.2695,
      "step": 9136
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010774742081053295,
      "loss": 2.3164,
      "step": 9137
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010773006517627126,
      "loss": 2.3672,
      "step": 9138
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010771270930776324,
      "loss": 2.2891,
      "step": 9139
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010769535320553478,
      "loss": 2.4805,
      "step": 9140
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010767799687011184,
      "loss": 2.3828,
      "step": 9141
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001076606403020204,
      "loss": 2.2383,
      "step": 9142
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010764328350178637,
      "loss": 2.2031,
      "step": 9143
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010762592646993575,
      "loss": 2.2617,
      "step": 9144
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010760856920699448,
      "loss": 2.3594,
      "step": 9145
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001075912117134886,
      "loss": 2.3867,
      "step": 9146
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010757385398994406,
      "loss": 2.3125,
      "step": 9147
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010755649603688686,
      "loss": 2.1133,
      "step": 9148
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010753913785484304,
      "loss": 2.3516,
      "step": 9149
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010752177944433853,
      "loss": 2.4531,
      "step": 9150
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010750442080589941,
      "loss": 2.3672,
      "step": 9151
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010748706194005171,
      "loss": 2.2578,
      "step": 9152
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010746970284732143,
      "loss": 2.4141,
      "step": 9153
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010745234352823464,
      "loss": 2.375,
      "step": 9154
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001074349839833173,
      "loss": 2.3516,
      "step": 9155
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010741762421309555,
      "loss": 2.5547,
      "step": 9156
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010740026421809544,
      "loss": 2.3027,
      "step": 9157
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00107382903998843,
      "loss": 2.2188,
      "step": 9158
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010736554355586434,
      "loss": 2.1152,
      "step": 9159
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001073481828896855,
      "loss": 2.332,
      "step": 9160
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010733082200083258,
      "loss": 2.5938,
      "step": 9161
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010731346088983166,
      "loss": 2.3281,
      "step": 9162
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010729609955720887,
      "loss": 2.2461,
      "step": 9163
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001072787380034903,
      "loss": 2.2168,
      "step": 9164
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010726137622920206,
      "loss": 2.1641,
      "step": 9165
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010724401423487025,
      "loss": 2.2695,
      "step": 9166
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010722665202102103,
      "loss": 2.5234,
      "step": 9167
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010720928958818051,
      "loss": 2.3086,
      "step": 9168
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010719192693687482,
      "loss": 2.2793,
      "step": 9169
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010717456406763015,
      "loss": 2.3906,
      "step": 9170
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001071572009809726,
      "loss": 2.543,
      "step": 9171
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010713983767742837,
      "loss": 2.2812,
      "step": 9172
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010712247415752356,
      "loss": 2.418,
      "step": 9173
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010710511042178442,
      "loss": 2.3516,
      "step": 9174
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001070877464707371,
      "loss": 2.2363,
      "step": 9175
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010707038230490778,
      "loss": 2.3887,
      "step": 9176
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010705301792482262,
      "loss": 2.3711,
      "step": 9177
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010703565333100788,
      "loss": 2.2148,
      "step": 9178
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010701828852398975,
      "loss": 2.1875,
      "step": 9179
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010700092350429441,
      "loss": 2.3164,
      "step": 9180
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010698355827244805,
      "loss": 2.2168,
      "step": 9181
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010696619282897699,
      "loss": 2.3516,
      "step": 9182
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010694882717440736,
      "loss": 2.2617,
      "step": 9183
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010693146130926546,
      "loss": 2.3164,
      "step": 9184
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010691409523407751,
      "loss": 2.3398,
      "step": 9185
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010689672894936978,
      "loss": 2.5898,
      "step": 9186
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001068793624556685,
      "loss": 2.2129,
      "step": 9187
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010686199575349992,
      "loss": 2.2578,
      "step": 9188
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010684462884339035,
      "loss": 2.3516,
      "step": 9189
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010682726172586605,
      "loss": 2.4219,
      "step": 9190
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010680989440145327,
      "loss": 2.3398,
      "step": 9191
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010679252687067833,
      "loss": 2.3242,
      "step": 9192
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010677515913406752,
      "loss": 2.2031,
      "step": 9193
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010675779119214712,
      "loss": 2.2812,
      "step": 9194
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010674042304544347,
      "loss": 2.2637,
      "step": 9195
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010672305469448281,
      "loss": 2.375,
      "step": 9196
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001067056861397916,
      "loss": 2.5508,
      "step": 9197
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00106688317381896,
      "loss": 2.4609,
      "step": 9198
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010667094842132243,
      "loss": 2.2578,
      "step": 9199
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010665357925859723,
      "loss": 2.3184,
      "step": 9200
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001066362098942467,
      "loss": 2.418,
      "step": 9201
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010661884032879723,
      "loss": 2.332,
      "step": 9202
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010660147056277514,
      "loss": 2.4258,
      "step": 9203
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010658410059670679,
      "loss": 2.4531,
      "step": 9204
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001065667304311186,
      "loss": 2.4062,
      "step": 9205
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010654936006653688,
      "loss": 2.3516,
      "step": 9206
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010653198950348805,
      "loss": 2.2402,
      "step": 9207
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010651461874249847,
      "loss": 2.3008,
      "step": 9208
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010649724778409458,
      "loss": 2.375,
      "step": 9209
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010647987662880272,
      "loss": 2.4219,
      "step": 9210
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010646250527714932,
      "loss": 2.3906,
      "step": 9211
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010644513372966076,
      "loss": 2.4688,
      "step": 9212
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001064277619868635,
      "loss": 2.2969,
      "step": 9213
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010641039004928388,
      "loss": 2.3984,
      "step": 9214
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010639301791744848,
      "loss": 2.2773,
      "step": 9215
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010637564559188356,
      "loss": 2.2461,
      "step": 9216
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010635827307311566,
      "loss": 2.3086,
      "step": 9217
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001063409003616712,
      "loss": 2.5,
      "step": 9218
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010632352745807664,
      "loss": 2.3828,
      "step": 9219
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010630615436285841,
      "loss": 2.3359,
      "step": 9220
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00106288781076543,
      "loss": 2.2852,
      "step": 9221
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010627140759965686,
      "loss": 2.2617,
      "step": 9222
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010625403393272647,
      "loss": 2.3008,
      "step": 9223
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001062366600762783,
      "loss": 2.2617,
      "step": 9224
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010621928603083888,
      "loss": 2.2539,
      "step": 9225
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001062019117969346,
      "loss": 2.2266,
      "step": 9226
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001061845373750921,
      "loss": 2.457,
      "step": 9227
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010616716276583775,
      "loss": 2.3398,
      "step": 9228
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010614978796969813,
      "loss": 2.5078,
      "step": 9229
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010613241298719973,
      "loss": 2.3945,
      "step": 9230
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010611503781886905,
      "loss": 2.3711,
      "step": 9231
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010609766246523265,
      "loss": 2.3438,
      "step": 9232
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010608028692681707,
      "loss": 2.4805,
      "step": 9233
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010606291120414878,
      "loss": 2.3281,
      "step": 9234
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001060455352977544,
      "loss": 2.2109,
      "step": 9235
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010602815920816044,
      "loss": 2.5391,
      "step": 9236
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010601078293589344,
      "loss": 2.1836,
      "step": 9237
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010599340648148,
      "loss": 2.4023,
      "step": 9238
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001059760298454466,
      "loss": 2.1953,
      "step": 9239
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010595865302831995,
      "loss": 2.3711,
      "step": 9240
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010594127603062646,
      "loss": 2.2305,
      "step": 9241
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010592389885289283,
      "loss": 2.5117,
      "step": 9242
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010590652149564562,
      "loss": 2.1914,
      "step": 9243
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010588914395941139,
      "loss": 2.4023,
      "step": 9244
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010587176624471673,
      "loss": 2.3359,
      "step": 9245
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010585438835208829,
      "loss": 2.209,
      "step": 9246
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010583701028205263,
      "loss": 2.3672,
      "step": 9247
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010581963203513643,
      "loss": 2.3828,
      "step": 9248
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001058022536118662,
      "loss": 2.4023,
      "step": 9249
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010578487501276869,
      "loss": 2.1934,
      "step": 9250
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010576749623837044,
      "loss": 2.291,
      "step": 9251
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001057501172891981,
      "loss": 2.3438,
      "step": 9252
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010573273816577833,
      "loss": 2.3438,
      "step": 9253
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010571535886863776,
      "loss": 2.3555,
      "step": 9254
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010569797939830301,
      "loss": 2.3789,
      "step": 9255
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010568059975530082,
      "loss": 2.375,
      "step": 9256
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010566321994015776,
      "loss": 2.4375,
      "step": 9257
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010564583995340056,
      "loss": 2.3711,
      "step": 9258
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010562845979555583,
      "loss": 2.2188,
      "step": 9259
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010561107946715032,
      "loss": 2.2832,
      "step": 9260
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010559369896871065,
      "loss": 2.5352,
      "step": 9261
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010557631830076352,
      "loss": 2.4609,
      "step": 9262
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010555893746383564,
      "loss": 2.3672,
      "step": 9263
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001055415564584537,
      "loss": 2.5039,
      "step": 9264
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010552417528514435,
      "loss": 2.5117,
      "step": 9265
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010550679394443442,
      "loss": 2.2402,
      "step": 9266
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010548941243685049,
      "loss": 2.2617,
      "step": 9267
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010547203076291933,
      "loss": 2.2656,
      "step": 9268
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001054546489231677,
      "loss": 2.127,
      "step": 9269
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010543726691812226,
      "loss": 2.3086,
      "step": 9270
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001054198847483098,
      "loss": 2.2461,
      "step": 9271
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00105402502414257,
      "loss": 2.1602,
      "step": 9272
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010538511991649065,
      "loss": 2.2656,
      "step": 9273
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010536773725553746,
      "loss": 2.4062,
      "step": 9274
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001053503544319242,
      "loss": 2.332,
      "step": 9275
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010533297144617764,
      "loss": 2.2539,
      "step": 9276
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010531558829882453,
      "loss": 2.332,
      "step": 9277
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010529820499039161,
      "loss": 2.1582,
      "step": 9278
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001052808215214057,
      "loss": 2.0762,
      "step": 9279
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010526343789239352,
      "loss": 2.3281,
      "step": 9280
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010524605410388193,
      "loss": 2.3555,
      "step": 9281
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010522867015639763,
      "loss": 2.3633,
      "step": 9282
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010521128605046747,
      "loss": 2.2129,
      "step": 9283
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001051939017866182,
      "loss": 2.4336,
      "step": 9284
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010517651736537668,
      "loss": 2.2852,
      "step": 9285
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010515913278726968,
      "loss": 2.2734,
      "step": 9286
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010514174805282396,
      "loss": 2.2852,
      "step": 9287
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010512436316256644,
      "loss": 2.3555,
      "step": 9288
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010510697811702385,
      "loss": 2.0898,
      "step": 9289
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010508959291672304,
      "loss": 2.2871,
      "step": 9290
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001050722075621909,
      "loss": 2.2227,
      "step": 9291
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010505482205395414,
      "loss": 2.2188,
      "step": 9292
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010503743639253972,
      "loss": 2.1953,
      "step": 9293
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001050200505784744,
      "loss": 2.1816,
      "step": 9294
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010500266461228507,
      "loss": 2.6484,
      "step": 9295
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010498527849449857,
      "loss": 2.3984,
      "step": 9296
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010496789222564176,
      "loss": 2.2617,
      "step": 9297
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010495050580624145,
      "loss": 2.3438,
      "step": 9298
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010493311923682463,
      "loss": 2.418,
      "step": 9299
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010491573251791805,
      "loss": 2.4219,
      "step": 9300
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010489834565004864,
      "loss": 2.2578,
      "step": 9301
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010488095863374325,
      "loss": 2.334,
      "step": 9302
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010486357146952878,
      "loss": 2.5156,
      "step": 9303
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010484618415793215,
      "loss": 2.332,
      "step": 9304
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010482879669948017,
      "loss": 2.0527,
      "step": 9305
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010481140909469984,
      "loss": 2.2695,
      "step": 9306
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010479402134411797,
      "loss": 2.0664,
      "step": 9307
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010477663344826153,
      "loss": 2.4961,
      "step": 9308
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001047592454076574,
      "loss": 2.2344,
      "step": 9309
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001047418572228325,
      "loss": 2.3984,
      "step": 9310
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010472446889431377,
      "loss": 2.1035,
      "step": 9311
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010470708042262808,
      "loss": 2.2695,
      "step": 9312
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001046896918083024,
      "loss": 2.1172,
      "step": 9313
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010467230305186367,
      "loss": 2.0879,
      "step": 9314
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001046549141538388,
      "loss": 2.3711,
      "step": 9315
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010463752511475472,
      "loss": 2.2754,
      "step": 9316
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010462013593513844,
      "loss": 2.3984,
      "step": 9317
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010460274661551682,
      "loss": 2.168,
      "step": 9318
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001045853571564169,
      "loss": 2.3164,
      "step": 9319
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010456796755836557,
      "loss": 2.3672,
      "step": 9320
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010455057782188984,
      "loss": 2.2852,
      "step": 9321
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010453318794751663,
      "loss": 2.1602,
      "step": 9322
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010451579793577294,
      "loss": 2.3008,
      "step": 9323
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010449840778718575,
      "loss": 2.3945,
      "step": 9324
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00104481017502282,
      "loss": 2.5039,
      "step": 9325
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010446362708158871,
      "loss": 2.2266,
      "step": 9326
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010444623652563288,
      "loss": 2.418,
      "step": 9327
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010442884583494148,
      "loss": 2.4121,
      "step": 9328
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010441145501004147,
      "loss": 2.3281,
      "step": 9329
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001043940640514599,
      "loss": 2.2148,
      "step": 9330
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010437667295972375,
      "loss": 2.2578,
      "step": 9331
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010435928173536007,
      "loss": 2.1406,
      "step": 9332
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010434189037889577,
      "loss": 2.2109,
      "step": 9333
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010432449889085798,
      "loss": 2.2578,
      "step": 9334
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010430710727177364,
      "loss": 2.0625,
      "step": 9335
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010428971552216982,
      "loss": 2.1719,
      "step": 9336
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001042723236425735,
      "loss": 2.2363,
      "step": 9337
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010425493163351179,
      "loss": 2.5156,
      "step": 9338
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010423753949551165,
      "loss": 2.2266,
      "step": 9339
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010422014722910014,
      "loss": 2.041,
      "step": 9340
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010420275483480428,
      "loss": 2.1562,
      "step": 9341
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010418536231315116,
      "loss": 2.293,
      "step": 9342
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010416796966466785,
      "loss": 2.2656,
      "step": 9343
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010415057688988132,
      "loss": 2.1934,
      "step": 9344
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001041331839893187,
      "loss": 2.0645,
      "step": 9345
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00104115790963507,
      "loss": 2.2852,
      "step": 9346
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001040983978129734,
      "loss": 2.332,
      "step": 9347
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010408100453824479,
      "loss": 2.1504,
      "step": 9348
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010406361113984837,
      "loss": 2.2578,
      "step": 9349
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.001040462176183112,
      "loss": 2.3125,
      "step": 9350
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010402882397416032,
      "loss": 2.1055,
      "step": 9351
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010401143020792286,
      "loss": 2.3516,
      "step": 9352
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010399403632012588,
      "loss": 2.1504,
      "step": 9353
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010397664231129647,
      "loss": 2.1504,
      "step": 9354
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010395924818196174,
      "loss": 2.4336,
      "step": 9355
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010394185393264876,
      "loss": 2.2891,
      "step": 9356
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010392445956388472,
      "loss": 2.3672,
      "step": 9357
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010390706507619662,
      "loss": 2.1914,
      "step": 9358
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010388967047011161,
      "loss": 2.25,
      "step": 9359
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010387227574615682,
      "loss": 2.4805,
      "step": 9360
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010385488090485938,
      "loss": 2.1719,
      "step": 9361
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010383748594674637,
      "loss": 2.0195,
      "step": 9362
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010382009087234491,
      "loss": 2.1387,
      "step": 9363
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010380269568218215,
      "loss": 2.1953,
      "step": 9364
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010378530037678526,
      "loss": 2.2188,
      "step": 9365
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.001037679049566813,
      "loss": 2.0527,
      "step": 9366
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010375050942239745,
      "loss": 2.3164,
      "step": 9367
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010373311377446083,
      "loss": 2.418,
      "step": 9368
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010371571801339862,
      "loss": 2.3086,
      "step": 9369
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010369832213973796,
      "loss": 2.2266,
      "step": 9370
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010368092615400597,
      "loss": 2.3594,
      "step": 9371
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010366353005672982,
      "loss": 2.3555,
      "step": 9372
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010364613384843669,
      "loss": 2.2148,
      "step": 9373
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010362873752965372,
      "loss": 2.2363,
      "step": 9374
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.001036113411009081,
      "loss": 2.375,
      "step": 9375
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010359394456272695,
      "loss": 2.1836,
      "step": 9376
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010357654791563749,
      "loss": 2.2266,
      "step": 9377
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010355915116016688,
      "loss": 2.3184,
      "step": 9378
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.001035417542968423,
      "loss": 2.3672,
      "step": 9379
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010352435732619094,
      "loss": 2.291,
      "step": 9380
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010350696024873996,
      "loss": 2.1602,
      "step": 9381
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010348956306501656,
      "loss": 2.3281,
      "step": 9382
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010347216577554796,
      "loss": 2.25,
      "step": 9383
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010345476838086133,
      "loss": 2.4297,
      "step": 9384
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010343737088148385,
      "loss": 2.1797,
      "step": 9385
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010341997327794274,
      "loss": 2.3086,
      "step": 9386
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010340257557076525,
      "loss": 2.2344,
      "step": 9387
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010338517776047852,
      "loss": 2.2695,
      "step": 9388
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010336777984760975,
      "loss": 2.1289,
      "step": 9389
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010335038183268623,
      "loss": 2.3047,
      "step": 9390
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010333298371623509,
      "loss": 2.2695,
      "step": 9391
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010331558549878364,
      "loss": 2.123,
      "step": 9392
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010329818718085905,
      "loss": 2.4609,
      "step": 9393
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010328078876298853,
      "loss": 2.3379,
      "step": 9394
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010326339024569935,
      "loss": 2.2305,
      "step": 9395
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010324599162951874,
      "loss": 2.4453,
      "step": 9396
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.001032285929149739,
      "loss": 2.25,
      "step": 9397
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.001032111941025921,
      "loss": 2.5195,
      "step": 9398
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010319379519290056,
      "loss": 2.1875,
      "step": 9399
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010317639618642655,
      "loss": 2.1328,
      "step": 9400
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.001031589970836973,
      "loss": 2.1445,
      "step": 9401
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010314159788524005,
      "loss": 2.1328,
      "step": 9402
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010312419859158206,
      "loss": 2.2695,
      "step": 9403
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010310679920325061,
      "loss": 2.166,
      "step": 9404
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010308939972077291,
      "loss": 2.1738,
      "step": 9405
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010307200014467628,
      "loss": 2.2461,
      "step": 9406
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010305460047548795,
      "loss": 2.5,
      "step": 9407
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.001030372007137352,
      "loss": 2.3398,
      "step": 9408
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010301980085994525,
      "loss": 2.1777,
      "step": 9409
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010300240091464543,
      "loss": 2.2578,
      "step": 9410
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010298500087836302,
      "loss": 2.1875,
      "step": 9411
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010296760075162528,
      "loss": 2.1934,
      "step": 9412
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.001029502005349595,
      "loss": 2.2617,
      "step": 9413
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010293280022889292,
      "loss": 2.0781,
      "step": 9414
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010291539983395285,
      "loss": 2.2539,
      "step": 9415
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010289799935066662,
      "loss": 2.3984,
      "step": 9416
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010288059877956149,
      "loss": 2.1465,
      "step": 9417
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010286319812116474,
      "loss": 2.4453,
      "step": 9418
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010284579737600368,
      "loss": 2.5039,
      "step": 9419
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010282839654460563,
      "loss": 1.9707,
      "step": 9420
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010281099562749784,
      "loss": 2.3984,
      "step": 9421
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010279359462520767,
      "loss": 2.4238,
      "step": 9422
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010277619353826245,
      "loss": 2.1562,
      "step": 9423
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010275879236718937,
      "loss": 2.3457,
      "step": 9424
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010274139111251586,
      "loss": 2.375,
      "step": 9425
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010272398977476918,
      "loss": 2.2266,
      "step": 9426
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010270658835447668,
      "loss": 2.2773,
      "step": 9427
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010268918685216565,
      "loss": 2.3672,
      "step": 9428
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010267178526836343,
      "loss": 2.2852,
      "step": 9429
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.001026543836035973,
      "loss": 2.1035,
      "step": 9430
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010263698185839472,
      "loss": 2.293,
      "step": 9431
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010261958003328284,
      "loss": 2.1562,
      "step": 9432
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010260217812878914,
      "loss": 2.332,
      "step": 9433
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010258477614544083,
      "loss": 2.2031,
      "step": 9434
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010256737408376538,
      "loss": 2.2754,
      "step": 9435
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010254997194429002,
      "loss": 2.3555,
      "step": 9436
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010253256972754215,
      "loss": 2.4961,
      "step": 9437
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.001025151674340491,
      "loss": 2.3906,
      "step": 9438
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.001024977650643382,
      "loss": 2.3828,
      "step": 9439
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.001024803626189368,
      "loss": 2.332,
      "step": 9440
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010246296009837233,
      "loss": 2.3633,
      "step": 9441
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010244555750317202,
      "loss": 2.3281,
      "step": 9442
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001024281548338633,
      "loss": 2.3906,
      "step": 9443
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010241075209097353,
      "loss": 2.2109,
      "step": 9444
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010239334927503003,
      "loss": 2.0332,
      "step": 9445
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001023759463865602,
      "loss": 2.4883,
      "step": 9446
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010235854342609137,
      "loss": 2.2383,
      "step": 9447
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010234114039415095,
      "loss": 2.2969,
      "step": 9448
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010232373729126627,
      "loss": 2.2637,
      "step": 9449
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001023063341179647,
      "loss": 2.1387,
      "step": 9450
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001022889308747737,
      "loss": 2.1133,
      "step": 9451
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001022715275622205,
      "loss": 2.0977,
      "step": 9452
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010225412418083258,
      "loss": 2.1797,
      "step": 9453
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010223672073113729,
      "loss": 2.2969,
      "step": 9454
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00102219317213662,
      "loss": 2.375,
      "step": 9455
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010220191362893415,
      "loss": 2.3555,
      "step": 9456
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010218450997748103,
      "loss": 2.3438,
      "step": 9457
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010216710625983011,
      "loss": 2.2559,
      "step": 9458
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010214970247650877,
      "loss": 2.3867,
      "step": 9459
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010213229862804437,
      "loss": 2.4805,
      "step": 9460
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010211489471496432,
      "loss": 2.2969,
      "step": 9461
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010209749073779601,
      "loss": 2.25,
      "step": 9462
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010208008669706683,
      "loss": 2.3359,
      "step": 9463
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010206268259330422,
      "loss": 2.4414,
      "step": 9464
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001020452784270355,
      "loss": 2.4023,
      "step": 9465
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010202787419878818,
      "loss": 2.2734,
      "step": 9466
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010201046990908958,
      "loss": 2.1367,
      "step": 9467
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010199306555846715,
      "loss": 2.0898,
      "step": 9468
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010197566114744827,
      "loss": 2.2852,
      "step": 9469
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001019582566765604,
      "loss": 2.1895,
      "step": 9470
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001019408521463309,
      "loss": 2.4922,
      "step": 9471
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001019234475572872,
      "loss": 2.2363,
      "step": 9472
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001019060429099567,
      "loss": 2.2129,
      "step": 9473
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010188863820486688,
      "loss": 2.0332,
      "step": 9474
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001018712334425451,
      "loss": 2.1836,
      "step": 9475
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010185382862351882,
      "loss": 2.2344,
      "step": 9476
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010183642374831541,
      "loss": 2.2266,
      "step": 9477
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010181901881746237,
      "loss": 2.4375,
      "step": 9478
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010180161383148705,
      "loss": 2.3555,
      "step": 9479
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010178420879091692,
      "loss": 2.2109,
      "step": 9480
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010176680369627942,
      "loss": 2.2148,
      "step": 9481
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010174939854810194,
      "loss": 2.1113,
      "step": 9482
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010173199334691193,
      "loss": 2.3242,
      "step": 9483
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010171458809323688,
      "loss": 2.1875,
      "step": 9484
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010169718278760411,
      "loss": 1.8906,
      "step": 9485
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010167977743054117,
      "loss": 2.2148,
      "step": 9486
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010166237202257546,
      "loss": 2.3828,
      "step": 9487
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010164496656423442,
      "loss": 2.1602,
      "step": 9488
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010162756105604547,
      "loss": 2.2656,
      "step": 9489
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010161015549853608,
      "loss": 2.2266,
      "step": 9490
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010159274989223368,
      "loss": 2.293,
      "step": 9491
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010157534423766575,
      "loss": 2.248,
      "step": 9492
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010155793853535969,
      "loss": 2.2734,
      "step": 9493
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00101540532785843,
      "loss": 2.209,
      "step": 9494
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010152312698964308,
      "loss": 2.3359,
      "step": 9495
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010150572114728741,
      "loss": 2.5117,
      "step": 9496
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010148831525930348,
      "loss": 2.3242,
      "step": 9497
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010147090932621865,
      "loss": 2.3438,
      "step": 9498
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010145350334856051,
      "loss": 2.4141,
      "step": 9499
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001014360973268564,
      "loss": 2.3555,
      "step": 9500
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001014186912616338,
      "loss": 2.1641,
      "step": 9501
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010140128515342024,
      "loss": 2.2109,
      "step": 9502
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001013838790027431,
      "loss": 2.2617,
      "step": 9503
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010136647281012991,
      "loss": 2.3281,
      "step": 9504
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010134906657610812,
      "loss": 2.2734,
      "step": 9505
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010133166030120513,
      "loss": 2.1562,
      "step": 9506
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001013142539859485,
      "loss": 2.1992,
      "step": 9507
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001012968476308656,
      "loss": 2.1543,
      "step": 9508
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010127944123648402,
      "loss": 2.2734,
      "step": 9509
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010126203480333117,
      "loss": 2.4922,
      "step": 9510
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001012446283319345,
      "loss": 2.4805,
      "step": 9511
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010122722182282148,
      "loss": 2.1953,
      "step": 9512
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010120981527651964,
      "loss": 2.1523,
      "step": 9513
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010119240869355642,
      "loss": 2.1504,
      "step": 9514
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001011750020744593,
      "loss": 2.3789,
      "step": 9515
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010115759541975571,
      "loss": 2.2754,
      "step": 9516
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010114018872997323,
      "loss": 2.2656,
      "step": 9517
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010112278200563928,
      "loss": 2.1562,
      "step": 9518
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010110537524728133,
      "loss": 2.1719,
      "step": 9519
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010108796845542686,
      "loss": 2.1582,
      "step": 9520
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010107056163060342,
      "loss": 2.1914,
      "step": 9521
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010105315477333843,
      "loss": 2.2715,
      "step": 9522
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001010357478841594,
      "loss": 2.3672,
      "step": 9523
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010101834096359374,
      "loss": 2.1562,
      "step": 9524
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001010009340121691,
      "loss": 2.166,
      "step": 9525
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001009835270304128,
      "loss": 2.3086,
      "step": 9526
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010096612001885244,
      "loss": 2.1016,
      "step": 9527
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010094871297801544,
      "loss": 2.3906,
      "step": 9528
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010093130590842936,
      "loss": 2.1562,
      "step": 9529
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010091389881062163,
      "loss": 2.3398,
      "step": 9530
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010089649168511974,
      "loss": 2.2539,
      "step": 9531
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010087908453245125,
      "loss": 2.1367,
      "step": 9532
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010086167735314357,
      "loss": 2.4727,
      "step": 9533
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010084427014772426,
      "loss": 2.1641,
      "step": 9534
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001008268629167208,
      "loss": 2.2715,
      "step": 9535
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010080945566066067,
      "loss": 2.2539,
      "step": 9536
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010079204838007137,
      "loss": 2.2715,
      "step": 9537
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.001007746410754804,
      "loss": 2.168,
      "step": 9538
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010075723374741526,
      "loss": 2.3203,
      "step": 9539
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010073982639640347,
      "loss": 2.3711,
      "step": 9540
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010072241902297247,
      "loss": 2.2656,
      "step": 9541
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010070501162764984,
      "loss": 2.4102,
      "step": 9542
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010068760421096303,
      "loss": 2.0176,
      "step": 9543
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010067019677343957,
      "loss": 2.5156,
      "step": 9544
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.001006527893156069,
      "loss": 2.3047,
      "step": 9545
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.001006353818379926,
      "loss": 2.4453,
      "step": 9546
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010061797434112415,
      "loss": 2.0723,
      "step": 9547
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010060056682552904,
      "loss": 2.25,
      "step": 9548
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010058315929173476,
      "loss": 2.2461,
      "step": 9549
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010056575174026887,
      "loss": 2.0645,
      "step": 9550
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010054834417165882,
      "loss": 2.2812,
      "step": 9551
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010053093658643215,
      "loss": 2.3828,
      "step": 9552
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010051352898511636,
      "loss": 2.2617,
      "step": 9553
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010049612136823897,
      "loss": 2.0273,
      "step": 9554
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010047871373632747,
      "loss": 2.1992,
      "step": 9555
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010046130608990936,
      "loss": 2.3555,
      "step": 9556
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010044389842951212,
      "loss": 2.1504,
      "step": 9557
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010042649075566337,
      "loss": 2.3887,
      "step": 9558
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.001004090830688905,
      "loss": 2.4141,
      "step": 9559
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.001003916753697211,
      "loss": 2.1602,
      "step": 9560
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010037426765868262,
      "loss": 2.2266,
      "step": 9561
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.001003568599363026,
      "loss": 2.332,
      "step": 9562
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010033945220310858,
      "loss": 2.2539,
      "step": 9563
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010032204445962803,
      "loss": 2.2891,
      "step": 9564
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.001003046367063885,
      "loss": 2.1289,
      "step": 9565
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010028722894391742,
      "loss": 2.1582,
      "step": 9566
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010026982117274242,
      "loss": 2.1953,
      "step": 9567
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.001002524133933909,
      "loss": 2.3359,
      "step": 9568
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010023500560639048,
      "loss": 2.1504,
      "step": 9569
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010021759781226858,
      "loss": 2.1602,
      "step": 9570
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010020019001155277,
      "loss": 2.3906,
      "step": 9571
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010018278220477051,
      "loss": 2.3164,
      "step": 9572
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.001001653743924494,
      "loss": 2.3086,
      "step": 9573
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010014796657511684,
      "loss": 2.3242,
      "step": 9574
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010013055875330047,
      "loss": 2.2891,
      "step": 9575
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.001001131509275277,
      "loss": 2.3164,
      "step": 9576
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.001000957430983261,
      "loss": 2.4102,
      "step": 9577
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010007833526622318,
      "loss": 2.1875,
      "step": 9578
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010006092743174643,
      "loss": 2.2715,
      "step": 9579
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.001000435195954234,
      "loss": 2.1914,
      "step": 9580
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010002611175778157,
      "loss": 2.3008,
      "step": 9581
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010000870391934842,
      "loss": 2.4219,
      "step": 9582
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009999129608065157,
      "loss": 2.3359,
      "step": 9583
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009997388824221846,
      "loss": 2.2012,
      "step": 9584
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009995648040457663,
      "loss": 2.1973,
      "step": 9585
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009993907256825362,
      "loss": 2.2969,
      "step": 9586
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009992166473377683,
      "loss": 2.3164,
      "step": 9587
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.000999042569016739,
      "loss": 2.3945,
      "step": 9588
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009988684907247232,
      "loss": 2.3242,
      "step": 9589
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009986944124669955,
      "loss": 2.457,
      "step": 9590
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009985203342488314,
      "loss": 2.293,
      "step": 9591
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009983462560755063,
      "loss": 2.2852,
      "step": 9592
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009981721779522951,
      "loss": 2.1387,
      "step": 9593
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009979980998844728,
      "loss": 2.207,
      "step": 9594
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009978240218773144,
      "loss": 2.2188,
      "step": 9595
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009976499439360955,
      "loss": 2.1836,
      "step": 9596
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.000997475866066091,
      "loss": 2.293,
      "step": 9597
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.000997301788272576,
      "loss": 2.2305,
      "step": 9598
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009971277105608257,
      "loss": 2.4375,
      "step": 9599
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009969536329361153,
      "loss": 2.3516,
      "step": 9600
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00099677955540372,
      "loss": 2.3398,
      "step": 9601
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.000996605477968914,
      "loss": 2.2578,
      "step": 9602
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.000996431400636974,
      "loss": 2.2695,
      "step": 9603
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.000996257323413174,
      "loss": 2.1562,
      "step": 9604
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009960832463027894,
      "loss": 2.3633,
      "step": 9605
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.000995909169311095,
      "loss": 2.3398,
      "step": 9606
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009957350924433665,
      "loss": 2.3066,
      "step": 9607
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009955610157048789,
      "loss": 2.1562,
      "step": 9608
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009953869391009069,
      "loss": 2.4648,
      "step": 9609
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009952128626367256,
      "loss": 2.0176,
      "step": 9610
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009950387863176104,
      "loss": 2.2344,
      "step": 9611
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009948647101488365,
      "loss": 2.2715,
      "step": 9612
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009946906341356785,
      "loss": 2.2402,
      "step": 9613
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009945165582834117,
      "loss": 2.3086,
      "step": 9614
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009943424825973113,
      "loss": 2.1328,
      "step": 9615
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009941684070826524,
      "loss": 2.2148,
      "step": 9616
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00099399433174471,
      "loss": 2.1758,
      "step": 9617
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009938202565887586,
      "loss": 2.1895,
      "step": 9618
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009936461816200742,
      "loss": 2.3398,
      "step": 9619
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.000993472106843931,
      "loss": 2.2031,
      "step": 9620
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009932980322656048,
      "loss": 2.3047,
      "step": 9621
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009931239578903697,
      "loss": 2.4531,
      "step": 9622
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009929498837235018,
      "loss": 2.2695,
      "step": 9623
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009927758097702754,
      "loss": 2.2188,
      "step": 9624
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009926017360359655,
      "loss": 2.2969,
      "step": 9625
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009924276625258473,
      "loss": 2.2812,
      "step": 9626
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.000992253589245196,
      "loss": 2.2852,
      "step": 9627
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0009920795161992863,
      "loss": 2.2637,
      "step": 9628
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009919054433933938,
      "loss": 2.1875,
      "step": 9629
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000991731370832792,
      "loss": 2.2109,
      "step": 9630
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009915572985227574,
      "loss": 2.1934,
      "step": 9631
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009913832264685644,
      "loss": 2.4688,
      "step": 9632
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009912091546754878,
      "loss": 2.2109,
      "step": 9633
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009910350831488024,
      "loss": 2.2109,
      "step": 9634
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000990861011893784,
      "loss": 2.291,
      "step": 9635
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009906869409157066,
      "loss": 2.1797,
      "step": 9636
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009905128702198459,
      "loss": 2.082,
      "step": 9637
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009903387998114756,
      "loss": 2.1953,
      "step": 9638
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000990164729695872,
      "loss": 2.4297,
      "step": 9639
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009899906598783094,
      "loss": 2.3281,
      "step": 9640
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009898165903640625,
      "loss": 2.2363,
      "step": 9641
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009896425211584064,
      "loss": 2.3203,
      "step": 9642
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000989468452266616,
      "loss": 2.4336,
      "step": 9643
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000989294383693966,
      "loss": 2.1289,
      "step": 9644
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009891203154457312,
      "loss": 2.3242,
      "step": 9645
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000988946247527187,
      "loss": 2.3945,
      "step": 9646
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009887721799436075,
      "loss": 2.4805,
      "step": 9647
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000988598112700268,
      "loss": 2.1992,
      "step": 9648
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000988424045802443,
      "loss": 2.1562,
      "step": 9649
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009882499792554073,
      "loss": 2.1836,
      "step": 9650
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000988075913064436,
      "loss": 2.4062,
      "step": 9651
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000987901847234804,
      "loss": 2.3906,
      "step": 9652
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009877277817717852,
      "loss": 2.1523,
      "step": 9653
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009875537166806553,
      "loss": 2.457,
      "step": 9654
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009873796519666886,
      "loss": 2.25,
      "step": 9655
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009872055876351598,
      "loss": 2.1445,
      "step": 9656
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009870315236913437,
      "loss": 2.332,
      "step": 9657
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009868574601405152,
      "loss": 2.2695,
      "step": 9658
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000986683396987949,
      "loss": 2.332,
      "step": 9659
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009865093342389193,
      "loss": 2.2188,
      "step": 9660
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000986335271898701,
      "loss": 2.2578,
      "step": 9661
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000986161209972569,
      "loss": 2.3867,
      "step": 9662
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009859871484657978,
      "loss": 2.1152,
      "step": 9663
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000985813087383662,
      "loss": 2.1797,
      "step": 9664
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000985639026731436,
      "loss": 2.1875,
      "step": 9665
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009854649665143951,
      "loss": 2.1836,
      "step": 9666
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009852909067378135,
      "loss": 2.3242,
      "step": 9667
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009851168474069656,
      "loss": 2.2852,
      "step": 9668
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000984942788527126,
      "loss": 2.3359,
      "step": 9669
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009847687301035692,
      "loss": 2.2305,
      "step": 9670
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009845946721415704,
      "loss": 2.3281,
      "step": 9671
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009844206146464034,
      "loss": 2.2227,
      "step": 9672
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009842465576233425,
      "loss": 2.2812,
      "step": 9673
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009840725010776634,
      "loss": 2.3867,
      "step": 9674
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009838984450146395,
      "loss": 2.3164,
      "step": 9675
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009837243894395456,
      "loss": 2.3516,
      "step": 9676
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000983550334357656,
      "loss": 2.2695,
      "step": 9677
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009833762797742457,
      "loss": 2.2734,
      "step": 9678
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009832022256945883,
      "loss": 2.1992,
      "step": 9679
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009830281721239587,
      "loss": 2.2793,
      "step": 9680
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009828541190676314,
      "loss": 2.1992,
      "step": 9681
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009826800665308807,
      "loss": 2.3125,
      "step": 9682
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009825060145189808,
      "loss": 2.2324,
      "step": 9683
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000982331963037206,
      "loss": 2.2461,
      "step": 9684
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000982157912090831,
      "loss": 2.2539,
      "step": 9685
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009819838616851296,
      "loss": 2.2305,
      "step": 9686
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009818098118253768,
      "loss": 2.0312,
      "step": 9687
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009816357625168457,
      "loss": 2.3125,
      "step": 9688
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000981461713764812,
      "loss": 2.1309,
      "step": 9689
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000981287665574549,
      "loss": 2.2539,
      "step": 9690
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009811136179513314,
      "loss": 2.0801,
      "step": 9691
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000980939570900433,
      "loss": 2.0625,
      "step": 9692
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000980765524427128,
      "loss": 2.1914,
      "step": 9693
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009805914785366912,
      "loss": 2.3906,
      "step": 9694
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009804174332343964,
      "loss": 2.3203,
      "step": 9695
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000980243388525517,
      "loss": 2.1738,
      "step": 9696
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009800693444153286,
      "loss": 2.2969,
      "step": 9697
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009798953009091044,
      "loss": 2.3164,
      "step": 9698
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009797212580121184,
      "loss": 2.3164,
      "step": 9699
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000979547215729645,
      "loss": 2.3359,
      "step": 9700
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000979373174066958,
      "loss": 2.3359,
      "step": 9701
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000979199133029332,
      "loss": 2.2812,
      "step": 9702
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009790250926220404,
      "loss": 2.4922,
      "step": 9703
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009788510528503569,
      "loss": 2.332,
      "step": 9704
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009786770137195564,
      "loss": 2.334,
      "step": 9705
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009785029752349126,
      "loss": 2.4336,
      "step": 9706
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000978328937401699,
      "loss": 2.1836,
      "step": 9707
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009781549002251897,
      "loss": 2.3203,
      "step": 9708
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009779808637106586,
      "loss": 2.1973,
      "step": 9709
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009778068278633802,
      "loss": 2.2617,
      "step": 9710
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009776327926886274,
      "loss": 2.1875,
      "step": 9711
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009774587581916744,
      "loss": 2.1797,
      "step": 9712
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009772847243777953,
      "loss": 2.2852,
      "step": 9713
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009771106912522635,
      "loss": 2.2695,
      "step": 9714
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000976936658820353,
      "loss": 2.252,
      "step": 9715
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009767626270873375,
      "loss": 2.2129,
      "step": 9716
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009765885960584908,
      "loss": 2.0508,
      "step": 9717
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009764145657390868,
      "loss": 2.0977,
      "step": 9718
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000976240536134398,
      "loss": 2.2012,
      "step": 9719
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0009760665072497,
      "loss": 2.2773,
      "step": 9720
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000975892479090265,
      "loss": 2.2129,
      "step": 9721
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009757184516613671,
      "loss": 2.0996,
      "step": 9722
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009755444249682798,
      "loss": 2.4102,
      "step": 9723
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009753703990162769,
      "loss": 2.1914,
      "step": 9724
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.000975196373810632,
      "loss": 2.2422,
      "step": 9725
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009750223493566183,
      "loss": 2.5273,
      "step": 9726
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009748483256595092,
      "loss": 2.3457,
      "step": 9727
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009746743027245786,
      "loss": 2.0879,
      "step": 9728
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009745002805570999,
      "loss": 2.3359,
      "step": 9729
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009743262591623465,
      "loss": 2.3789,
      "step": 9730
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009741522385455914,
      "loss": 2.4688,
      "step": 9731
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009739782187121088,
      "loss": 2.2617,
      "step": 9732
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009738041996671717,
      "loss": 2.332,
      "step": 9733
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009736301814160533,
      "loss": 2.1992,
      "step": 9734
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009734561639640267,
      "loss": 2.3516,
      "step": 9735
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009732821473163659,
      "loss": 2.1914,
      "step": 9736
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009731081314783436,
      "loss": 2.3516,
      "step": 9737
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009729341164552336,
      "loss": 2.3281,
      "step": 9738
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.000972760102252308,
      "loss": 2.4141,
      "step": 9739
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009725860888748417,
      "loss": 2.2109,
      "step": 9740
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009724120763281065,
      "loss": 2.2461,
      "step": 9741
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009722380646173761,
      "loss": 2.2148,
      "step": 9742
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009720640537479232,
      "loss": 2.291,
      "step": 9743
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009718900437250215,
      "loss": 2.0938,
      "step": 9744
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.000971716034553944,
      "loss": 2.2695,
      "step": 9745
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009715420262399636,
      "loss": 2.2266,
      "step": 9746
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009713680187883526,
      "loss": 2.1934,
      "step": 9747
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009711940122043854,
      "loss": 2.2891,
      "step": 9748
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.000971020006493334,
      "loss": 2.2656,
      "step": 9749
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009708460016604714,
      "loss": 2.1523,
      "step": 9750
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.000970671997711071,
      "loss": 2.3984,
      "step": 9751
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009704979946504053,
      "loss": 2.0605,
      "step": 9752
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009703239924837476,
      "loss": 2.2852,
      "step": 9753
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009701499912163697,
      "loss": 2.2773,
      "step": 9754
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009699759908535457,
      "loss": 2.2227,
      "step": 9755
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009698019914005477,
      "loss": 2.3047,
      "step": 9756
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009696279928626485,
      "loss": 2.3008,
      "step": 9757
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009694539952451207,
      "loss": 2.4062,
      "step": 9758
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009692799985532374,
      "loss": 2.2734,
      "step": 9759
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009691060027922709,
      "loss": 2.0273,
      "step": 9760
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009689320079674943,
      "loss": 2.25,
      "step": 9761
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009687580140841793,
      "loss": 2.2969,
      "step": 9762
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009685840211475998,
      "loss": 2.3828,
      "step": 9763
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009684100291630273,
      "loss": 2.2852,
      "step": 9764
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009682360381357348,
      "loss": 2.2754,
      "step": 9765
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009680620480709945,
      "loss": 2.207,
      "step": 9766
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009678880589740792,
      "loss": 2.4805,
      "step": 9767
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009677140708502613,
      "loss": 2.2891,
      "step": 9768
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009675400837048131,
      "loss": 2.4141,
      "step": 9769
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009673660975430067,
      "loss": 2.0137,
      "step": 9770
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009671921123701148,
      "loss": 2.1777,
      "step": 9771
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009670181281914098,
      "loss": 2.4375,
      "step": 9772
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009668441450121639,
      "loss": 2.2422,
      "step": 9773
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.000966670162837649,
      "loss": 2.2129,
      "step": 9774
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009664961816731379,
      "loss": 2.3477,
      "step": 9775
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009663222015239029,
      "loss": 2.1934,
      "step": 9776
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009661482223952154,
      "loss": 2.3125,
      "step": 9777
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009659742442923478,
      "loss": 2.1348,
      "step": 9778
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009658002672205725,
      "loss": 2.2734,
      "step": 9779
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009656262911851616,
      "loss": 2.3125,
      "step": 9780
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009654523161913872,
      "loss": 2.125,
      "step": 9781
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009652783422445203,
      "loss": 2.1875,
      "step": 9782
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009651043693498345,
      "loss": 2.3477,
      "step": 9783
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009649303975126007,
      "loss": 2.2148,
      "step": 9784
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009647564267380909,
      "loss": 2.1328,
      "step": 9785
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009645824570315771,
      "loss": 2.3828,
      "step": 9786
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009644084883983313,
      "loss": 2.3438,
      "step": 9787
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009642345208436253,
      "loss": 2.1387,
      "step": 9788
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009640605543727305,
      "loss": 2.2773,
      "step": 9789
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009638865889909191,
      "loss": 2.2969,
      "step": 9790
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009637126247034631,
      "loss": 2.084,
      "step": 9791
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009635386615156335,
      "loss": 2.4375,
      "step": 9792
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009633646994327018,
      "loss": 2.2812,
      "step": 9793
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009631907384599405,
      "loss": 2.418,
      "step": 9794
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009630167786026207,
      "loss": 2.1016,
      "step": 9795
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009628428198660139,
      "loss": 2.207,
      "step": 9796
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009626688622553916,
      "loss": 2.0449,
      "step": 9797
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009624949057760256,
      "loss": 2.5273,
      "step": 9798
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009623209504331874,
      "loss": 2.1113,
      "step": 9799
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009621469962321479,
      "loss": 2.1328,
      "step": 9800
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009619730431781785,
      "loss": 2.1992,
      "step": 9801
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009617990912765509,
      "loss": 2.2227,
      "step": 9802
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009616251405325365,
      "loss": 2.2227,
      "step": 9803
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009614511909514067,
      "loss": 2.0469,
      "step": 9804
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009612772425384315,
      "loss": 2.2812,
      "step": 9805
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009611032952988839,
      "loss": 2.3066,
      "step": 9806
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.000960929349238034,
      "loss": 2.2344,
      "step": 9807
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009607554043611532,
      "loss": 2.1797,
      "step": 9808
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009605814606735122,
      "loss": 2.1445,
      "step": 9809
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009604075181803826,
      "loss": 2.3398,
      "step": 9810
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009602335768870354,
      "loss": 2.2246,
      "step": 9811
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009600596367987416,
      "loss": 2.4375,
      "step": 9812
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009598856979207714,
      "loss": 2.0312,
      "step": 9813
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0009597117602583971,
      "loss": 2.4141,
      "step": 9814
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009595378238168883,
      "loss": 2.1055,
      "step": 9815
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009593638886015164,
      "loss": 2.2344,
      "step": 9816
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.000959189954617552,
      "loss": 2.4609,
      "step": 9817
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009590160218702664,
      "loss": 2.2656,
      "step": 9818
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00095884209036493,
      "loss": 2.1016,
      "step": 9819
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009586681601068132,
      "loss": 2.1035,
      "step": 9820
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009584942311011869,
      "loss": 2.2812,
      "step": 9821
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009583203033533218,
      "loss": 2.3516,
      "step": 9822
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009581463768684885,
      "loss": 2.1797,
      "step": 9823
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009579724516519573,
      "loss": 1.9668,
      "step": 9824
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009577985277089989,
      "loss": 2.2012,
      "step": 9825
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009576246050448838,
      "loss": 2.0957,
      "step": 9826
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009574506836648825,
      "loss": 2.2383,
      "step": 9827
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009572767635742648,
      "loss": 2.1895,
      "step": 9828
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.000957102844778302,
      "loss": 2.2305,
      "step": 9829
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009569289272822638,
      "loss": 2.4102,
      "step": 9830
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009567550110914205,
      "loss": 1.9727,
      "step": 9831
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009565810962110421,
      "loss": 2.1309,
      "step": 9832
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009564071826463996,
      "loss": 2.3848,
      "step": 9833
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009562332704027627,
      "loss": 2.3945,
      "step": 9834
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009560593594854013,
      "loss": 2.2734,
      "step": 9835
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009558854498995853,
      "loss": 2.293,
      "step": 9836
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009557115416505855,
      "loss": 2.123,
      "step": 9837
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009555376347436714,
      "loss": 2.0391,
      "step": 9838
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009553637291841129,
      "loss": 2.1914,
      "step": 9839
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009551898249771799,
      "loss": 2.0938,
      "step": 9840
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009550159221281426,
      "loss": 2.4258,
      "step": 9841
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009548420206422709,
      "loss": 2.2812,
      "step": 9842
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009546681205248341,
      "loss": 2.2734,
      "step": 9843
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009544942217811018,
      "loss": 2.168,
      "step": 9844
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009543203244163444,
      "loss": 2.2578,
      "step": 9845
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009541464284358312,
      "loss": 2.1582,
      "step": 9846
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.000953972533844832,
      "loss": 2.0664,
      "step": 9847
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009537986406486157,
      "loss": 2.1465,
      "step": 9848
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009536247488524527,
      "loss": 2.2031,
      "step": 9849
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009534508584616122,
      "loss": 2.4727,
      "step": 9850
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009532769694813635,
      "loss": 2.1758,
      "step": 9851
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009531030819169759,
      "loss": 2.1797,
      "step": 9852
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009529291957737193,
      "loss": 2.1875,
      "step": 9853
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009527553110568626,
      "loss": 2.1699,
      "step": 9854
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009525814277716754,
      "loss": 2.3125,
      "step": 9855
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009524075459234258,
      "loss": 2.3047,
      "step": 9856
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009522336655173849,
      "loss": 2.2461,
      "step": 9857
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009520597865588205,
      "loss": 2.2441,
      "step": 9858
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009518859090530019,
      "loss": 2.4141,
      "step": 9859
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009517120330051981,
      "loss": 2.3203,
      "step": 9860
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009515381584206787,
      "loss": 2.3789,
      "step": 9861
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009513642853047124,
      "loss": 2.0742,
      "step": 9862
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009511904136625674,
      "loss": 2.2207,
      "step": 9863
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009510165434995139,
      "loss": 2.3828,
      "step": 9864
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009508426748208198,
      "loss": 2.2461,
      "step": 9865
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.000950668807631754,
      "loss": 2.3086,
      "step": 9866
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009504949419375852,
      "loss": 2.3906,
      "step": 9867
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009503210777435826,
      "loss": 2.2773,
      "step": 9868
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009501472150550144,
      "loss": 2.2188,
      "step": 9869
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009499733538771497,
      "loss": 2.3516,
      "step": 9870
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009497994942152559,
      "loss": 2.3438,
      "step": 9871
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009496256360746031,
      "loss": 2.4141,
      "step": 9872
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009494517794604587,
      "loss": 2.0781,
      "step": 9873
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009492779243780914,
      "loss": 2.2266,
      "step": 9874
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009491040708327695,
      "loss": 2.2773,
      "step": 9875
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009489302188297616,
      "loss": 2.1094,
      "step": 9876
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009487563683743358,
      "loss": 2.252,
      "step": 9877
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009485825194717606,
      "loss": 2.5039,
      "step": 9878
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009484086721273033,
      "loss": 2.3438,
      "step": 9879
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009482348263462334,
      "loss": 2.3047,
      "step": 9880
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.000948060982133818,
      "loss": 2.293,
      "step": 9881
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009478871394953255,
      "loss": 1.9941,
      "step": 9882
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009477132984360236,
      "loss": 2.2891,
      "step": 9883
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009475394589611808,
      "loss": 2.3398,
      "step": 9884
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009473656210760649,
      "loss": 2.1992,
      "step": 9885
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009471917847859434,
      "loss": 2.1641,
      "step": 9886
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009470179500960839,
      "loss": 2.1367,
      "step": 9887
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009468441170117548,
      "loss": 2.2266,
      "step": 9888
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009466702855382237,
      "loss": 2.4141,
      "step": 9889
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009464964556807581,
      "loss": 2.5312,
      "step": 9890
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009463226274446254,
      "loss": 2.3047,
      "step": 9891
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009461488008350936,
      "loss": 2.3125,
      "step": 9892
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009459749758574303,
      "loss": 2.1602,
      "step": 9893
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009458011525169024,
      "loss": 2.0898,
      "step": 9894
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009456273308187775,
      "loss": 2.457,
      "step": 9895
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009454535107683232,
      "loss": 2.3438,
      "step": 9896
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009452796923708067,
      "loss": 2.4492,
      "step": 9897
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009451058756314955,
      "loss": 2.1406,
      "step": 9898
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.000944932060555656,
      "loss": 2.207,
      "step": 9899
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009447582471485565,
      "loss": 2.3398,
      "step": 9900
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009445844354154635,
      "loss": 2.2734,
      "step": 9901
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009444106253616438,
      "loss": 2.2539,
      "step": 9902
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009442368169923649,
      "loss": 2.3008,
      "step": 9903
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009440630103128937,
      "loss": 2.168,
      "step": 9904
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009438892053284971,
      "loss": 2.2578,
      "step": 9905
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009437154020444416,
      "loss": 2.1699,
      "step": 9906
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0009435416004659944,
      "loss": 2.0781,
      "step": 9907
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009433678005984226,
      "loss": 2.1738,
      "step": 9908
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009431940024469921,
      "loss": 2.1953,
      "step": 9909
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009430202060169698,
      "loss": 2.252,
      "step": 9910
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009428464113136227,
      "loss": 2.2773,
      "step": 9911
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009426726183422169,
      "loss": 2.3516,
      "step": 9912
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009424988271080195,
      "loss": 2.2422,
      "step": 9913
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009423250376162956,
      "loss": 2.2852,
      "step": 9914
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009421512498723134,
      "loss": 2.1211,
      "step": 9915
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.000941977463881338,
      "loss": 2.1621,
      "step": 9916
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009418036796486362,
      "loss": 2.3828,
      "step": 9917
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009416298971794737,
      "loss": 2.2539,
      "step": 9918
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009414561164791172,
      "loss": 2.2383,
      "step": 9919
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009412823375528328,
      "loss": 2.1758,
      "step": 9920
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009411085604058867,
      "loss": 2.1719,
      "step": 9921
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009409347850435439,
      "loss": 2.2656,
      "step": 9922
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009407610114710718,
      "loss": 2.0859,
      "step": 9923
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009405872396937355,
      "loss": 2.3652,
      "step": 9924
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.000940413469716801,
      "loss": 2.1484,
      "step": 9925
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009402397015455337,
      "loss": 2.3945,
      "step": 9926
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009400659351852001,
      "loss": 2.3594,
      "step": 9927
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009398921706410658,
      "loss": 2.2148,
      "step": 9928
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009397184079183959,
      "loss": 2.3457,
      "step": 9929
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009395446470224562,
      "loss": 2.2109,
      "step": 9930
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009393708879585122,
      "loss": 2.1738,
      "step": 9931
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009391971307318297,
      "loss": 2.3516,
      "step": 9932
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009390233753476737,
      "loss": 2.3008,
      "step": 9933
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009388496218113095,
      "loss": 2.3281,
      "step": 9934
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009386758701280029,
      "loss": 2.2383,
      "step": 9935
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009385021203030192,
      "loss": 2.3047,
      "step": 9936
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009383283723416225,
      "loss": 2.2188,
      "step": 9937
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009381546262490794,
      "loss": 2.6133,
      "step": 9938
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009379808820306539,
      "loss": 2.4375,
      "step": 9939
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009378071396916116,
      "loss": 2.2266,
      "step": 9940
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.000937633399237217,
      "loss": 2.5391,
      "step": 9941
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009374596606727353,
      "loss": 2.3984,
      "step": 9942
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009372859240034318,
      "loss": 2.3633,
      "step": 9943
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009371121892345703,
      "loss": 2.3242,
      "step": 9944
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.000936938456371416,
      "loss": 2.1172,
      "step": 9945
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009367647254192339,
      "loss": 2.1035,
      "step": 9946
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009365909963832881,
      "loss": 2.5547,
      "step": 9947
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009364172692688436,
      "loss": 2.0898,
      "step": 9948
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009362435440811644,
      "loss": 2.1641,
      "step": 9949
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009360698208255155,
      "loss": 2.4414,
      "step": 9950
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009358960995071613,
      "loss": 2.0898,
      "step": 9951
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009357223801313656,
      "loss": 2.1406,
      "step": 9952
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009355486627033926,
      "loss": 2.2422,
      "step": 9953
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009353749472285071,
      "loss": 2.3906,
      "step": 9954
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.000935201233711973,
      "loss": 2.3438,
      "step": 9955
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009350275221590547,
      "loss": 2.1406,
      "step": 9956
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.000934853812575015,
      "loss": 2.4141,
      "step": 9957
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009346801049651197,
      "loss": 2.1309,
      "step": 9958
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009345063993346313,
      "loss": 2.457,
      "step": 9959
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009343326956888142,
      "loss": 2.2305,
      "step": 9960
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009341589940329321,
      "loss": 2.0684,
      "step": 9961
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009339852943722488,
      "loss": 2.2461,
      "step": 9962
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.000933811596712028,
      "loss": 2.1641,
      "step": 9963
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009336379010575335,
      "loss": 2.3945,
      "step": 9964
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009334642074140279,
      "loss": 2.3672,
      "step": 9965
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009332905157867758,
      "loss": 2.1699,
      "step": 9966
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009331168261810402,
      "loss": 2.0762,
      "step": 9967
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009329431386020844,
      "loss": 2.2715,
      "step": 9968
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009327694530551716,
      "loss": 2.0176,
      "step": 9969
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009325957695455653,
      "loss": 2.2539,
      "step": 9970
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009324220880785288,
      "loss": 2.4102,
      "step": 9971
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009322484086593251,
      "loss": 2.3477,
      "step": 9972
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009320747312932166,
      "loss": 2.5039,
      "step": 9973
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009319010559854675,
      "loss": 2.123,
      "step": 9974
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009317273827413398,
      "loss": 2.293,
      "step": 9975
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009315537115660965,
      "loss": 2.2871,
      "step": 9976
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009313800424650007,
      "loss": 2.1602,
      "step": 9977
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009312063754433151,
      "loss": 2.1777,
      "step": 9978
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009310327105063026,
      "loss": 2.3477,
      "step": 9979
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009308590476592247,
      "loss": 2.2168,
      "step": 9980
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009306853869073455,
      "loss": 2.2852,
      "step": 9981
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009305117282559266,
      "loss": 2.2227,
      "step": 9982
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009303380717102306,
      "loss": 2.1289,
      "step": 9983
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009301644172755195,
      "loss": 2.25,
      "step": 9984
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009299907649570563,
      "loss": 2.3594,
      "step": 9985
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009298171147601028,
      "loss": 2.1484,
      "step": 9986
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009296434666899214,
      "loss": 2.1836,
      "step": 9987
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009294698207517736,
      "loss": 2.3711,
      "step": 9988
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009292961769509225,
      "loss": 2.3516,
      "step": 9989
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009291225352926291,
      "loss": 2.1426,
      "step": 9990
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009289488957821559,
      "loss": 2.293,
      "step": 9991
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009287752584247643,
      "loss": 2.2012,
      "step": 9992
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009286016232257165,
      "loss": 2.1992,
      "step": 9993
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009284279901902744,
      "loss": 2.3984,
      "step": 9994
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009282543593236989,
      "loss": 2.3398,
      "step": 9995
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009280807306312519,
      "loss": 2.3633,
      "step": 9996
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009279071041181951,
      "loss": 2.3633,
      "step": 9997
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00092773347978979,
      "loss": 2.2969,
      "step": 9998
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009275598576512976,
      "loss": 2.2734,
      "step": 9999
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0009273862377079795,
      "loss": 2.4492,
      "step": 10000
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.000927212619965097,
      "loss": 2.1367,
      "step": 10001
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009270390044279114,
      "loss": 2.1309,
      "step": 10002
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009268653911016835,
      "loss": 2.3828,
      "step": 10003
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009266917799916743,
      "loss": 2.2383,
      "step": 10004
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009265181711031452,
      "loss": 2.2266,
      "step": 10005
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009263445644413568,
      "loss": 2.3594,
      "step": 10006
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009261709600115702,
      "loss": 2.3984,
      "step": 10007
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009259973578190455,
      "loss": 2.5273,
      "step": 10008
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009258237578690445,
      "loss": 2.2969,
      "step": 10009
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009256501601668273,
      "loss": 2.0645,
      "step": 10010
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.000925476564717654,
      "loss": 2.1797,
      "step": 10011
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009253029715267858,
      "loss": 2.1738,
      "step": 10012
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.000925129380599483,
      "loss": 2.1621,
      "step": 10013
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.000924955791941006,
      "loss": 2.3984,
      "step": 10014
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009247822055566147,
      "loss": 2.1758,
      "step": 10015
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009246086214515698,
      "loss": 2.582,
      "step": 10016
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009244350396311316,
      "loss": 2.3594,
      "step": 10017
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009242614601005597,
      "loss": 2.4414,
      "step": 10018
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009240878828651141,
      "loss": 2.3359,
      "step": 10019
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009239143079300552,
      "loss": 1.9883,
      "step": 10020
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009237407353006428,
      "loss": 2.2852,
      "step": 10021
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009235671649821369,
      "loss": 2.3828,
      "step": 10022
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009233935969797962,
      "loss": 2.3438,
      "step": 10023
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009232200312988818,
      "loss": 2.1758,
      "step": 10024
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009230464679446524,
      "loss": 2.4219,
      "step": 10025
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009228729069223678,
      "loss": 2.3242,
      "step": 10026
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009226993482372873,
      "loss": 2.3164,
      "step": 10027
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009225257918946707,
      "loss": 2.4219,
      "step": 10028
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009223522378997771,
      "loss": 2.1113,
      "step": 10029
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009221786862578659,
      "loss": 2.2227,
      "step": 10030
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009220051369741955,
      "loss": 2.1465,
      "step": 10031
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009218315900540264,
      "loss": 2.4297,
      "step": 10032
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009216580455026165,
      "loss": 2.1562,
      "step": 10033
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009214845033252252,
      "loss": 2.5,
      "step": 10034
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009213109635271113,
      "loss": 2.3203,
      "step": 10035
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009211374261135338,
      "loss": 2.3379,
      "step": 10036
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009209638910897516,
      "loss": 2.1719,
      "step": 10037
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009207903584610228,
      "loss": 2.3086,
      "step": 10038
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009206168282326062,
      "loss": 2.3164,
      "step": 10039
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009204433004097605,
      "loss": 2.2715,
      "step": 10040
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009202697749977443,
      "loss": 2.3555,
      "step": 10041
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009200962520018158,
      "loss": 2.2637,
      "step": 10042
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009199227314272331,
      "loss": 2.3008,
      "step": 10043
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009197492132792549,
      "loss": 2.2891,
      "step": 10044
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009195756975631394,
      "loss": 2.2109,
      "step": 10045
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009194021842841441,
      "loss": 2.5586,
      "step": 10046
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009192286734475273,
      "loss": 2.3633,
      "step": 10047
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009190551650585471,
      "loss": 2.0664,
      "step": 10048
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009188816591224613,
      "loss": 2.2812,
      "step": 10049
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009187081556445276,
      "loss": 2.2246,
      "step": 10050
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.000918534654630004,
      "loss": 2.332,
      "step": 10051
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009183611560841478,
      "loss": 2.2793,
      "step": 10052
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009181876600122171,
      "loss": 2.3711,
      "step": 10053
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009180141664194684,
      "loss": 2.3047,
      "step": 10054
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009178406753111604,
      "loss": 2.1016,
      "step": 10055
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009176671866925495,
      "loss": 2.166,
      "step": 10056
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009174937005688934,
      "loss": 2.3789,
      "step": 10057
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009173202169454489,
      "loss": 2.1094,
      "step": 10058
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009171467358274737,
      "loss": 2.4414,
      "step": 10059
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009169732572202247,
      "loss": 2.3398,
      "step": 10060
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009167997811289585,
      "loss": 2.1855,
      "step": 10061
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.000916626307558932,
      "loss": 2.2539,
      "step": 10062
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009164528365154026,
      "loss": 2.127,
      "step": 10063
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009162793680036267,
      "loss": 2.375,
      "step": 10064
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009161059020288607,
      "loss": 2.4141,
      "step": 10065
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009159324385963615,
      "loss": 2.293,
      "step": 10066
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009157589777113857,
      "loss": 2.2656,
      "step": 10067
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009155855193791897,
      "loss": 2.0645,
      "step": 10068
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009154120636050297,
      "loss": 2.4609,
      "step": 10069
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009152386103941618,
      "loss": 2.1172,
      "step": 10070
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009150651597518426,
      "loss": 2.0859,
      "step": 10071
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.000914891711683328,
      "loss": 2.3203,
      "step": 10072
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009147182661938744,
      "loss": 2.3086,
      "step": 10073
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009145448232887367,
      "loss": 2.1992,
      "step": 10074
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009143713829731722,
      "loss": 2.3594,
      "step": 10075
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.000914197945252436,
      "loss": 2.2266,
      "step": 10076
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009140245101317838,
      "loss": 2.2812,
      "step": 10077
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009138510776164712,
      "loss": 2.2773,
      "step": 10078
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009136776477117541,
      "loss": 2.3125,
      "step": 10079
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009135042204228878,
      "loss": 2.1816,
      "step": 10080
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.000913330795755128,
      "loss": 2.1406,
      "step": 10081
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009131573737137292,
      "loss": 2.207,
      "step": 10082
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009129839543039477,
      "loss": 2.2539,
      "step": 10083
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009128105375310382,
      "loss": 2.2539,
      "step": 10084
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009126371234002555,
      "loss": 2.1074,
      "step": 10085
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009124637119168552,
      "loss": 2.2383,
      "step": 10086
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.000912290303086092,
      "loss": 2.4531,
      "step": 10087
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009121168969132208,
      "loss": 2.2188,
      "step": 10088
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009119434934034958,
      "loss": 2.2344,
      "step": 10089
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009117700925621727,
      "loss": 2.2949,
      "step": 10090
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009115966943945055,
      "loss": 2.0078,
      "step": 10091
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0009114232989057489,
      "loss": 2.3984,
      "step": 10092
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.000911249906101157,
      "loss": 2.5156,
      "step": 10093
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009110765159859847,
      "loss": 2.1992,
      "step": 10094
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.000910903128565486,
      "loss": 2.209,
      "step": 10095
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009107297438449154,
      "loss": 2.0801,
      "step": 10096
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009105563618295263,
      "loss": 2.4023,
      "step": 10097
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009103829825245738,
      "loss": 2.3125,
      "step": 10098
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.000910209605935311,
      "loss": 2.2578,
      "step": 10099
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009100362320669922,
      "loss": 2.2559,
      "step": 10100
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009098628609248708,
      "loss": 2.2344,
      "step": 10101
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009096894925142011,
      "loss": 2.0918,
      "step": 10102
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009095161268402365,
      "loss": 2.3086,
      "step": 10103
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009093427639082303,
      "loss": 2.5352,
      "step": 10104
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.000909169403723436,
      "loss": 2.3867,
      "step": 10105
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009089960462911074,
      "loss": 2.4141,
      "step": 10106
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009088226916164975,
      "loss": 2.6016,
      "step": 10107
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009086493397048594,
      "loss": 2.0723,
      "step": 10108
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009084759905614463,
      "loss": 2.1758,
      "step": 10109
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009083026441915114,
      "loss": 2.4844,
      "step": 10110
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009081293006003079,
      "loss": 2.293,
      "step": 10111
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009079559597930882,
      "loss": 2.5117,
      "step": 10112
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.000907782621775105,
      "loss": 2.1797,
      "step": 10113
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009076092865516114,
      "loss": 2.3789,
      "step": 10114
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009074359541278601,
      "loss": 2.2656,
      "step": 10115
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009072626245091035,
      "loss": 2.2188,
      "step": 10116
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009070892977005935,
      "loss": 2.2559,
      "step": 10117
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009069159737075835,
      "loss": 2.3066,
      "step": 10118
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.000906742652535325,
      "loss": 2.1016,
      "step": 10119
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009065693341890706,
      "loss": 2.1289,
      "step": 10120
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.000906396018674072,
      "loss": 2.1816,
      "step": 10121
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009062227059955818,
      "loss": 2.1113,
      "step": 10122
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009060493961588515,
      "loss": 2.3438,
      "step": 10123
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.000905876089169133,
      "loss": 2.4688,
      "step": 10124
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009057027850316783,
      "loss": 2.3789,
      "step": 10125
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009055294837517393,
      "loss": 2.207,
      "step": 10126
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.000905356185334567,
      "loss": 2.2012,
      "step": 10127
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009051828897854128,
      "loss": 2.0449,
      "step": 10128
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009050095971095289,
      "loss": 2.2422,
      "step": 10129
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009048363073121662,
      "loss": 2.1328,
      "step": 10130
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009046630203985759,
      "loss": 2.4102,
      "step": 10131
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009044897363740092,
      "loss": 2.2188,
      "step": 10132
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009043164552437174,
      "loss": 2.2461,
      "step": 10133
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009041431770129513,
      "loss": 2.4141,
      "step": 10134
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009039699016869618,
      "loss": 2.5547,
      "step": 10135
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009037966292709994,
      "loss": 2.4805,
      "step": 10136
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009036233597703154,
      "loss": 2.4688,
      "step": 10137
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009034500931901602,
      "loss": 2.3867,
      "step": 10138
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009032768295357845,
      "loss": 2.207,
      "step": 10139
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.000903103568812438,
      "loss": 2.2461,
      "step": 10140
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009029303110253723,
      "loss": 2.3789,
      "step": 10141
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009027570561798367,
      "loss": 2.2227,
      "step": 10142
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009025838042810818,
      "loss": 2.3398,
      "step": 10143
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009024105553343575,
      "loss": 2.2012,
      "step": 10144
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.000902237309344914,
      "loss": 2.2773,
      "step": 10145
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009020640663180012,
      "loss": 2.3242,
      "step": 10146
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009018908262588691,
      "loss": 2.2461,
      "step": 10147
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009017175891727666,
      "loss": 2.1758,
      "step": 10148
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009015443550649447,
      "loss": 2.3789,
      "step": 10149
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009013711239406519,
      "loss": 2.3281,
      "step": 10150
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009011978958051381,
      "loss": 2.1797,
      "step": 10151
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009010246706636525,
      "loss": 2.3281,
      "step": 10152
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009008514485214445,
      "loss": 2.332,
      "step": 10153
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009006782293837636,
      "loss": 2.2227,
      "step": 10154
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009005050132558584,
      "loss": 2.375,
      "step": 10155
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009003318001429779,
      "loss": 2.1758,
      "step": 10156
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0009001585900503715,
      "loss": 2.1855,
      "step": 10157
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008999853829832877,
      "loss": 2.1484,
      "step": 10158
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008998121789469753,
      "loss": 2.1875,
      "step": 10159
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.000899638977946683,
      "loss": 2.3027,
      "step": 10160
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008994657799876592,
      "loss": 2.2109,
      "step": 10161
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.000899292585075153,
      "loss": 2.293,
      "step": 10162
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008991193932144115,
      "loss": 2.293,
      "step": 10163
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008989462044106844,
      "loss": 2.3438,
      "step": 10164
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008987730186692191,
      "loss": 2.1836,
      "step": 10165
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008985998359952637,
      "loss": 2.3555,
      "step": 10166
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008984266563940663,
      "loss": 2.0957,
      "step": 10167
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.000898253479870875,
      "loss": 2.3398,
      "step": 10168
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008980803064309377,
      "loss": 2.2305,
      "step": 10169
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008979071360795017,
      "loss": 2.4277,
      "step": 10170
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008977339688218147,
      "loss": 2.2734,
      "step": 10171
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008975608046631245,
      "loss": 2.2207,
      "step": 10172
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008973876436086783,
      "loss": 2.3398,
      "step": 10173
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008972144856637238,
      "loss": 2.2695,
      "step": 10174
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008970413308335076,
      "loss": 2.2383,
      "step": 10175
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008968681791232775,
      "loss": 2.2266,
      "step": 10176
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008966950305382808,
      "loss": 2.3594,
      "step": 10177
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008965218850837635,
      "loss": 2.2852,
      "step": 10178
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008963487427649729,
      "loss": 2.0078,
      "step": 10179
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008961756035871561,
      "loss": 2.209,
      "step": 10180
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008960024675555595,
      "loss": 2.2188,
      "step": 10181
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008958293346754301,
      "loss": 2.3496,
      "step": 10182
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008956562049520131,
      "loss": 2.4766,
      "step": 10183
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008954830783905567,
      "loss": 2.1484,
      "step": 10184
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.000895309954996306,
      "loss": 2.1523,
      "step": 10185
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008951368347745078,
      "loss": 2.4141,
      "step": 10186
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008949637177304075,
      "loss": 2.3633,
      "step": 10187
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008947906038692519,
      "loss": 2.3906,
      "step": 10188
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008946174931962865,
      "loss": 2.1602,
      "step": 10189
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008944443857167577,
      "loss": 2.2891,
      "step": 10190
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008942712814359098,
      "loss": 2.3281,
      "step": 10191
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008940981803589902,
      "loss": 2.2695,
      "step": 10192
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008939250824912433,
      "loss": 2.2227,
      "step": 10193
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008937519878379148,
      "loss": 2.2441,
      "step": 10194
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008935788964042499,
      "loss": 1.9961,
      "step": 10195
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008934058081954944,
      "loss": 2.3125,
      "step": 10196
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008932327232168929,
      "loss": 2.3906,
      "step": 10197
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008930596414736902,
      "loss": 2.3867,
      "step": 10198
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008928865629711322,
      "loss": 2.3223,
      "step": 10199
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008927134877144632,
      "loss": 2.1758,
      "step": 10200
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008925404157089276,
      "loss": 2.0293,
      "step": 10201
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008923673469597704,
      "loss": 2.3262,
      "step": 10202
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008921942814722363,
      "loss": 2.2344,
      "step": 10203
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008920212192515695,
      "loss": 2.2812,
      "step": 10204
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008918481603030148,
      "loss": 2.334,
      "step": 10205
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008916751046318153,
      "loss": 2.2773,
      "step": 10206
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008915020522432168,
      "loss": 2.1562,
      "step": 10207
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008913290031424622,
      "loss": 2.3281,
      "step": 10208
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008911559573347957,
      "loss": 2.3945,
      "step": 10209
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008909829148254612,
      "loss": 2.0977,
      "step": 10210
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008908098756197024,
      "loss": 2.166,
      "step": 10211
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008906368397227632,
      "loss": 2.1074,
      "step": 10212
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008904638071398872,
      "loss": 2.2402,
      "step": 10213
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.000890290777876317,
      "loss": 2.4023,
      "step": 10214
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008901177519372974,
      "loss": 2.3242,
      "step": 10215
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008899447293280704,
      "loss": 2.4453,
      "step": 10216
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008897717100538798,
      "loss": 2.332,
      "step": 10217
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008895986941199681,
      "loss": 2.3203,
      "step": 10218
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008894256815315789,
      "loss": 2.293,
      "step": 10219
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.000889252672293955,
      "loss": 2.1855,
      "step": 10220
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008890796664123387,
      "loss": 2.2617,
      "step": 10221
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008889066638919726,
      "loss": 2.166,
      "step": 10222
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008887336647380997,
      "loss": 2.0664,
      "step": 10223
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008885606689559623,
      "loss": 2.332,
      "step": 10224
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008883876765508027,
      "loss": 2.3789,
      "step": 10225
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008882146875278629,
      "loss": 2.2578,
      "step": 10226
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008880417018923855,
      "loss": 2.3594,
      "step": 10227
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008878687196496125,
      "loss": 2.25,
      "step": 10228
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008876957408047853,
      "loss": 2.2363,
      "step": 10229
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008875227653631459,
      "loss": 2.209,
      "step": 10230
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008873497933299365,
      "loss": 2.3457,
      "step": 10231
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008871768247103983,
      "loss": 2.1855,
      "step": 10232
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008870038595097732,
      "loss": 2.3164,
      "step": 10233
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008868308977333015,
      "loss": 2.1484,
      "step": 10234
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.000886657939386226,
      "loss": 2.2578,
      "step": 10235
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008864849844737872,
      "loss": 2.2305,
      "step": 10236
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.000886312033001226,
      "loss": 2.1953,
      "step": 10237
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008861390849737838,
      "loss": 2.207,
      "step": 10238
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008859661403967014,
      "loss": 2.1543,
      "step": 10239
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008857931992752195,
      "loss": 2.1367,
      "step": 10240
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008856202616145786,
      "loss": 2.1055,
      "step": 10241
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008854473274200196,
      "loss": 2.3633,
      "step": 10242
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008852743966967832,
      "loss": 2.2598,
      "step": 10243
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008851014694501091,
      "loss": 2.2617,
      "step": 10244
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008849285456852379,
      "loss": 2.3496,
      "step": 10245
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008847556254074098,
      "loss": 2.2988,
      "step": 10246
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008845827086218647,
      "loss": 2.1348,
      "step": 10247
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.000884409795333843,
      "loss": 2.2969,
      "step": 10248
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008842368855485836,
      "loss": 2.1914,
      "step": 10249
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008840639792713275,
      "loss": 2.1328,
      "step": 10250
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008838910765073132,
      "loss": 2.166,
      "step": 10251
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008837181772617809,
      "loss": 2.2539,
      "step": 10252
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008835452815399695,
      "loss": 2.252,
      "step": 10253
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008833723893471188,
      "loss": 2.2578,
      "step": 10254
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008831995006884679,
      "loss": 2.2227,
      "step": 10255
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008830266155692559,
      "loss": 2.2363,
      "step": 10256
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008828537339947211,
      "loss": 2.4102,
      "step": 10257
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008826808559701037,
      "loss": 2.3203,
      "step": 10258
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008825079815006413,
      "loss": 2.1445,
      "step": 10259
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008823351105915732,
      "loss": 2.2285,
      "step": 10260
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008821622432481375,
      "loss": 2.3086,
      "step": 10261
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008819893794755729,
      "loss": 2.5078,
      "step": 10262
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008818165192791182,
      "loss": 2.3164,
      "step": 10263
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008816436626640109,
      "loss": 2.1719,
      "step": 10264
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.000881470809635489,
      "loss": 2.248,
      "step": 10265
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008812979601987915,
      "loss": 2.293,
      "step": 10266
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008811251143591555,
      "loss": 2.2637,
      "step": 10267
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008809522721218191,
      "loss": 2.3516,
      "step": 10268
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008807794334920195,
      "loss": 2.0801,
      "step": 10269
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008806065984749951,
      "loss": 2.2891,
      "step": 10270
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008804337670759832,
      "loss": 2.1641,
      "step": 10271
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00088026093930022,
      "loss": 2.2363,
      "step": 10272
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008800881151529445,
      "loss": 2.3828,
      "step": 10273
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008799152946393926,
      "loss": 2.2891,
      "step": 10274
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.000879742477764802,
      "loss": 2.209,
      "step": 10275
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.000879569664534409,
      "loss": 2.2773,
      "step": 10276
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.000879396854953451,
      "loss": 2.1836,
      "step": 10277
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008792240490271646,
      "loss": 2.4766,
      "step": 10278
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008790512467607861,
      "loss": 2.293,
      "step": 10279
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008788784481595518,
      "loss": 2.2578,
      "step": 10280
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008787056532286988,
      "loss": 2.2598,
      "step": 10281
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008785328619734627,
      "loss": 2.3281,
      "step": 10282
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00087836007439908,
      "loss": 2.3477,
      "step": 10283
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008781872905107864,
      "loss": 2.2637,
      "step": 10284
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008780145103138182,
      "loss": 2.168,
      "step": 10285
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008778417338134113,
      "loss": 2.0859,
      "step": 10286
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008776689610148009,
      "loss": 2.1562,
      "step": 10287
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008774961919232225,
      "loss": 2.293,
      "step": 10288
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008773234265439123,
      "loss": 2.3945,
      "step": 10289
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.000877150664882105,
      "loss": 2.2852,
      "step": 10290
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008769779069430365,
      "loss": 1.9805,
      "step": 10291
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008768051527319408,
      "loss": 2.2812,
      "step": 10292
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008766324022540542,
      "loss": 2.2266,
      "step": 10293
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008764596555146111,
      "loss": 2.3398,
      "step": 10294
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008762869125188461,
      "loss": 2.1523,
      "step": 10295
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008761141732719938,
      "loss": 2.3438,
      "step": 10296
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008759414377792891,
      "loss": 2.2344,
      "step": 10297
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008757687060459665,
      "loss": 2.1641,
      "step": 10298
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008755959780772604,
      "loss": 2.3145,
      "step": 10299
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.000875423253878404,
      "loss": 2.3438,
      "step": 10300
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008752505334546331,
      "loss": 2.3359,
      "step": 10301
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008750778168111805,
      "loss": 2.25,
      "step": 10302
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008749051039532803,
      "loss": 2.3516,
      "step": 10303
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008747323948861662,
      "loss": 2.3594,
      "step": 10304
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008745596896150723,
      "loss": 2.2617,
      "step": 10305
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008743869881452318,
      "loss": 2.3047,
      "step": 10306
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008742142904818784,
      "loss": 2.4258,
      "step": 10307
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008740415966302444,
      "loss": 2.332,
      "step": 10308
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008738689065955647,
      "loss": 2.2539,
      "step": 10309
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008736962203830709,
      "loss": 2.3574,
      "step": 10310
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008735235379979966,
      "loss": 2.3203,
      "step": 10311
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008733508594455746,
      "loss": 2.2461,
      "step": 10312
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008731781847310376,
      "loss": 2.4688,
      "step": 10313
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008730055138596184,
      "loss": 2.2539,
      "step": 10314
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008728328468365486,
      "loss": 2.5352,
      "step": 10315
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008726601836670621,
      "loss": 2.3086,
      "step": 10316
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008724875243563899,
      "loss": 2.2266,
      "step": 10317
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008723148689097647,
      "loss": 2.2109,
      "step": 10318
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008721422173324179,
      "loss": 2.125,
      "step": 10319
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008719695696295824,
      "loss": 2.1152,
      "step": 10320
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008717969258064894,
      "loss": 2.0645,
      "step": 10321
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.000871624285868371,
      "loss": 2.2812,
      "step": 10322
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008714516498204576,
      "loss": 2.3086,
      "step": 10323
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008712790176679822,
      "loss": 2.6133,
      "step": 10324
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008711063894161752,
      "loss": 2.3594,
      "step": 10325
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.000870933765070268,
      "loss": 2.3789,
      "step": 10326
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008707611446354914,
      "loss": 2.2656,
      "step": 10327
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008705885281170769,
      "loss": 2.4766,
      "step": 10328
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008704159155202552,
      "loss": 2.1484,
      "step": 10329
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008702433068502568,
      "loss": 2.3789,
      "step": 10330
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008700707021123122,
      "loss": 2.5977,
      "step": 10331
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008698981013116523,
      "loss": 2.3672,
      "step": 10332
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008697255044535074,
      "loss": 2.1328,
      "step": 10333
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008695529115431076,
      "loss": 2.3223,
      "step": 10334
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008693803225856828,
      "loss": 2.2227,
      "step": 10335
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008692077375864636,
      "loss": 2.3164,
      "step": 10336
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008690351565506796,
      "loss": 2.1953,
      "step": 10337
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008688625794835605,
      "loss": 2.0859,
      "step": 10338
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008686900063903358,
      "loss": 2.3828,
      "step": 10339
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008685174372762354,
      "loss": 2.0918,
      "step": 10340
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008683448721464884,
      "loss": 2.2207,
      "step": 10341
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008681723110063247,
      "loss": 2.209,
      "step": 10342
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008679997538609723,
      "loss": 2.2383,
      "step": 10343
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008678272007156616,
      "loss": 2.2969,
      "step": 10344
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008676546515756205,
      "loss": 2.3555,
      "step": 10345
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008674821064460781,
      "loss": 2.2539,
      "step": 10346
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008673095653322633,
      "loss": 2.2305,
      "step": 10347
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008671370282394048,
      "loss": 2.1445,
      "step": 10348
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008669644951727304,
      "loss": 2.1602,
      "step": 10349
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.000866791966137469,
      "loss": 2.3945,
      "step": 10350
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008666194411388484,
      "loss": 2.1777,
      "step": 10351
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008664469201820973,
      "loss": 2.4922,
      "step": 10352
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.000866274403272443,
      "loss": 2.168,
      "step": 10353
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008661018904151133,
      "loss": 2.1973,
      "step": 10354
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008659293816153362,
      "loss": 2.3086,
      "step": 10355
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008657568768783394,
      "loss": 2.2852,
      "step": 10356
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008655843762093504,
      "loss": 2.1602,
      "step": 10357
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008654118796135957,
      "loss": 2.2617,
      "step": 10358
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008652393870963038,
      "loss": 2.3398,
      "step": 10359
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008650668986627008,
      "loss": 2.3203,
      "step": 10360
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008648944143180141,
      "loss": 2.3633,
      "step": 10361
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008647219340674701,
      "loss": 2.3086,
      "step": 10362
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008645494579162963,
      "loss": 2.2773,
      "step": 10363
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008643769858697187,
      "loss": 2.1602,
      "step": 10364
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008642045179329641,
      "loss": 2.1973,
      "step": 10365
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008640320541112582,
      "loss": 2.2383,
      "step": 10366
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008638595944098282,
      "loss": 2.2617,
      "step": 10367
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008636871388338995,
      "loss": 2.2109,
      "step": 10368
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008635146873886982,
      "loss": 2.4512,
      "step": 10369
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00086334224007945,
      "loss": 2.4062,
      "step": 10370
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008631697969113812,
      "loss": 2.2383,
      "step": 10371
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.000862997357889717,
      "loss": 2.0547,
      "step": 10372
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008628249230196828,
      "loss": 2.3203,
      "step": 10373
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008626524923065038,
      "loss": 2.1602,
      "step": 10374
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008624800657554057,
      "loss": 2.4023,
      "step": 10375
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008623076433716132,
      "loss": 2.2285,
      "step": 10376
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008621352251603515,
      "loss": 2.1855,
      "step": 10377
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008619628111268451,
      "loss": 2.3047,
      "step": 10378
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008617904012763191,
      "loss": 2.2773,
      "step": 10379
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008616179956139982,
      "loss": 2.3438,
      "step": 10380
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008614455941451064,
      "loss": 2.25,
      "step": 10381
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.000861273196874868,
      "loss": 2.4336,
      "step": 10382
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008611008038085078,
      "loss": 2.3672,
      "step": 10383
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008609284149512493,
      "loss": 2.3242,
      "step": 10384
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008607560303083164,
      "loss": 2.2637,
      "step": 10385
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008605836498849336,
      "loss": 2.1484,
      "step": 10386
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008604112736863239,
      "loss": 2.2344,
      "step": 10387
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008602389017177115,
      "loss": 2.4375,
      "step": 10388
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008600665339843188,
      "loss": 2.25,
      "step": 10389
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008598941704913703,
      "loss": 2.2461,
      "step": 10390
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008597218112440886,
      "loss": 2.1699,
      "step": 10391
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008595494562476968,
      "loss": 2.3086,
      "step": 10392
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008593771055074175,
      "loss": 2.1934,
      "step": 10393
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008592047590284742,
      "loss": 2.2695,
      "step": 10394
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008590324168160893,
      "loss": 2.2227,
      "step": 10395
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008588600788754851,
      "loss": 2.2773,
      "step": 10396
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008586877452118838,
      "loss": 2.2539,
      "step": 10397
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008585154158305082,
      "loss": 2.2012,
      "step": 10398
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008583430907365803,
      "loss": 1.9512,
      "step": 10399
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008581707699353221,
      "loss": 2.3145,
      "step": 10400
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008579984534319552,
      "loss": 2.2617,
      "step": 10401
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008578261412317018,
      "loss": 2.1875,
      "step": 10402
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008576538333397836,
      "loss": 2.2031,
      "step": 10403
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008574815297614216,
      "loss": 2.2617,
      "step": 10404
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.000857309230501837,
      "loss": 2.123,
      "step": 10405
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.000857136935566252,
      "loss": 2.1895,
      "step": 10406
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008569646449598869,
      "loss": 2.2168,
      "step": 10407
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008567923586879631,
      "loss": 2.3555,
      "step": 10408
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008566200767557006,
      "loss": 2.2695,
      "step": 10409
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008564477991683215,
      "loss": 2.125,
      "step": 10410
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008562755259310454,
      "loss": 2.2324,
      "step": 10411
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008561032570490929,
      "loss": 2.2246,
      "step": 10412
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008559309925276843,
      "loss": 2.4414,
      "step": 10413
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008557587323720399,
      "loss": 2.3555,
      "step": 10414
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008555864765873799,
      "loss": 2.0898,
      "step": 10415
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008554142251789241,
      "loss": 2.375,
      "step": 10416
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008552419781518916,
      "loss": 2.1836,
      "step": 10417
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008550697355115033,
      "loss": 2.2852,
      "step": 10418
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008548974972629779,
      "loss": 2.3086,
      "step": 10419
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008547252634115347,
      "loss": 2.2773,
      "step": 10420
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008545530339623936,
      "loss": 2.3047,
      "step": 10421
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008543808089207732,
      "loss": 2.0566,
      "step": 10422
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008542085882918928,
      "loss": 2.4805,
      "step": 10423
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008540363720809705,
      "loss": 2.2227,
      "step": 10424
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008538641602932263,
      "loss": 2.1777,
      "step": 10425
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008536919529338777,
      "loss": 2.5977,
      "step": 10426
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008535197500081435,
      "loss": 2.1445,
      "step": 10427
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.000853347551521242,
      "loss": 2.0996,
      "step": 10428
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008531753574783916,
      "loss": 2.3906,
      "step": 10429
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008530031678848101,
      "loss": 2.2852,
      "step": 10430
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008528309827457156,
      "loss": 2.2227,
      "step": 10431
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008526588020663252,
      "loss": 2.3008,
      "step": 10432
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008524866258518578,
      "loss": 2.082,
      "step": 10433
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008523144541075299,
      "loss": 2.168,
      "step": 10434
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.000852142286838559,
      "loss": 2.3203,
      "step": 10435
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008519701240501625,
      "loss": 2.3047,
      "step": 10436
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008517979657475576,
      "loss": 2.6719,
      "step": 10437
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008516258119359614,
      "loss": 2.2812,
      "step": 10438
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008514536626205902,
      "loss": 2.1914,
      "step": 10439
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008512815178066609,
      "loss": 2.1934,
      "step": 10440
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008511093774993902,
      "loss": 2.3516,
      "step": 10441
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008509372417039946,
      "loss": 2.1895,
      "step": 10442
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00085076511042569,
      "loss": 2.5938,
      "step": 10443
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008505929836696926,
      "loss": 2.1113,
      "step": 10444
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.000850420861441219,
      "loss": 2.2266,
      "step": 10445
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008502487437454846,
      "loss": 2.2266,
      "step": 10446
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008500766305877052,
      "loss": 2.3418,
      "step": 10447
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008499045219730959,
      "loss": 2.25,
      "step": 10448
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008497324179068729,
      "loss": 2.1641,
      "step": 10449
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008495603183942512,
      "loss": 2.2461,
      "step": 10450
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008493882234404464,
      "loss": 2.4883,
      "step": 10451
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008492161330506724,
      "loss": 2.3438,
      "step": 10452
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008490440472301455,
      "loss": 2.1445,
      "step": 10453
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008488719659840797,
      "loss": 2.3203,
      "step": 10454
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008486998893176898,
      "loss": 2.4102,
      "step": 10455
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008485278172361898,
      "loss": 2.3633,
      "step": 10456
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008483557497447949,
      "loss": 2.2812,
      "step": 10457
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008481836868487188,
      "loss": 2.3008,
      "step": 10458
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008480116285531755,
      "loss": 2.2734,
      "step": 10459
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008478395748633794,
      "loss": 2.5586,
      "step": 10460
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008476675257845441,
      "loss": 2.2969,
      "step": 10461
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008474954813218829,
      "loss": 2.0469,
      "step": 10462
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008473234414806094,
      "loss": 2.2266,
      "step": 10463
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008471514062659374,
      "loss": 2.2715,
      "step": 10464
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008469793756830799,
      "loss": 2.3672,
      "step": 10465
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008468073497372499,
      "loss": 2.3867,
      "step": 10466
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008466353284336604,
      "loss": 2.1836,
      "step": 10467
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008464633117775241,
      "loss": 2.2695,
      "step": 10468
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008462912997740542,
      "loss": 2.3789,
      "step": 10469
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008461192924284625,
      "loss": 2.3633,
      "step": 10470
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008459472897459616,
      "loss": 2.127,
      "step": 10471
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008457752917317641,
      "loss": 2.2305,
      "step": 10472
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008456032983910817,
      "loss": 2.4023,
      "step": 10473
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008454313097291269,
      "loss": 2.4023,
      "step": 10474
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008452593257511103,
      "loss": 2.2422,
      "step": 10475
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008450873464622453,
      "loss": 2.2363,
      "step": 10476
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008449153718677421,
      "loss": 2.0664,
      "step": 10477
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008447434019728127,
      "loss": 2.1816,
      "step": 10478
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.000844571436782668,
      "loss": 2.1953,
      "step": 10479
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008443994763025196,
      "loss": 2.2852,
      "step": 10480
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.000844227520537578,
      "loss": 2.3125,
      "step": 10481
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008440555694930545,
      "loss": 2.2734,
      "step": 10482
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008438836231741589,
      "loss": 2.2695,
      "step": 10483
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.000843711681586103,
      "loss": 2.2578,
      "step": 10484
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008435397447340963,
      "loss": 2.248,
      "step": 10485
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008433678126233492,
      "loss": 2.1602,
      "step": 10486
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008431958852590717,
      "loss": 2.2207,
      "step": 10487
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008430239626464742,
      "loss": 2.1348,
      "step": 10488
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008428520447907664,
      "loss": 2.0723,
      "step": 10489
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008426801316971577,
      "loss": 2.1328,
      "step": 10490
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008425082233708576,
      "loss": 2.4688,
      "step": 10491
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008423363198170757,
      "loss": 2.2324,
      "step": 10492
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008421644210410213,
      "loss": 2.2695,
      "step": 10493
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008419925270479035,
      "loss": 2.1953,
      "step": 10494
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008418206378429309,
      "loss": 2.0156,
      "step": 10495
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008416487534313126,
      "loss": 2.2266,
      "step": 10496
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008414768738182576,
      "loss": 2.0488,
      "step": 10497
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008413049990089735,
      "loss": 2.3398,
      "step": 10498
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008411331290086697,
      "loss": 2.248,
      "step": 10499
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008409612638225537,
      "loss": 2.3789,
      "step": 10500
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008407894034558339,
      "loss": 2.1758,
      "step": 10501
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.000840617547913718,
      "loss": 2.2969,
      "step": 10502
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008404456972014141,
      "loss": 2.5039,
      "step": 10503
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008402738513241298,
      "loss": 2.3906,
      "step": 10504
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008401020102870723,
      "loss": 2.25,
      "step": 10505
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.000839930174095449,
      "loss": 2.2832,
      "step": 10506
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008397583427544673,
      "loss": 2.4141,
      "step": 10507
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008395865162693344,
      "loss": 2.375,
      "step": 10508
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008394146946452568,
      "loss": 2.4141,
      "step": 10509
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008392428778874413,
      "loss": 2.0352,
      "step": 10510
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008390710660010947,
      "loss": 2.2148,
      "step": 10511
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008388992589914238,
      "loss": 2.1035,
      "step": 10512
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008387274568636343,
      "loss": 2.3164,
      "step": 10513
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008385556596229324,
      "loss": 2.3711,
      "step": 10514
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008383838672745245,
      "loss": 2.3164,
      "step": 10515
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008382120798236163,
      "loss": 2.2031,
      "step": 10516
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008380402972754138,
      "loss": 2.457,
      "step": 10517
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008378685196351217,
      "loss": 2.0625,
      "step": 10518
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008376967469079465,
      "loss": 2.5352,
      "step": 10519
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008375249790990929,
      "loss": 2.0,
      "step": 10520
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008373532162137662,
      "loss": 2.3906,
      "step": 10521
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008371814582571709,
      "loss": 2.2188,
      "step": 10522
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008370097052345126,
      "loss": 2.1621,
      "step": 10523
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008368379571509956,
      "loss": 2.418,
      "step": 10524
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008366662140118247,
      "loss": 2.4492,
      "step": 10525
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008364944758222033,
      "loss": 2.2422,
      "step": 10526
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008363227425873371,
      "loss": 2.3086,
      "step": 10527
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008361510143124291,
      "loss": 2.2168,
      "step": 10528
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008359792910026838,
      "loss": 2.2812,
      "step": 10529
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008358075726633043,
      "loss": 2.3066,
      "step": 10530
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.000835635859299495,
      "loss": 2.3008,
      "step": 10531
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008354641509164594,
      "loss": 2.3867,
      "step": 10532
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008352924475193998,
      "loss": 2.2363,
      "step": 10533
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008351207491135206,
      "loss": 2.3398,
      "step": 10534
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008349490557040243,
      "loss": 2.3672,
      "step": 10535
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008347773672961135,
      "loss": 2.4023,
      "step": 10536
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008346056838949912,
      "loss": 2.2324,
      "step": 10537
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008344340055058601,
      "loss": 2.375,
      "step": 10538
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008342623321339225,
      "loss": 2.2578,
      "step": 10539
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008340906637843808,
      "loss": 2.0996,
      "step": 10540
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008339190004624364,
      "loss": 2.2539,
      "step": 10541
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008337473421732924,
      "loss": 2.0293,
      "step": 10542
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008335756889221499,
      "loss": 2.4961,
      "step": 10543
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008334040407142107,
      "loss": 2.2656,
      "step": 10544
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008332323975546761,
      "loss": 2.1953,
      "step": 10545
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008330607594487479,
      "loss": 2.4023,
      "step": 10546
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008328891264016269,
      "loss": 2.2148,
      "step": 10547
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008327174984185145,
      "loss": 2.166,
      "step": 10548
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008325458755046109,
      "loss": 2.25,
      "step": 10549
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008323742576651178,
      "loss": 2.2539,
      "step": 10550
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008322026449052353,
      "loss": 2.2266,
      "step": 10551
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008320310372301638,
      "loss": 2.0039,
      "step": 10552
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008318594346451032,
      "loss": 2.207,
      "step": 10553
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008316878371552545,
      "loss": 2.2129,
      "step": 10554
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008315162447658173,
      "loss": 2.4688,
      "step": 10555
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008313446574819912,
      "loss": 2.2617,
      "step": 10556
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008311730753089757,
      "loss": 2.1406,
      "step": 10557
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008310014982519708,
      "loss": 2.2168,
      "step": 10558
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008308299263161756,
      "loss": 2.4023,
      "step": 10559
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008306583595067893,
      "loss": 2.4805,
      "step": 10560
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008304867978290109,
      "loss": 2.1719,
      "step": 10561
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008303152412880394,
      "loss": 2.4102,
      "step": 10562
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008301436898890737,
      "loss": 2.3047,
      "step": 10563
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.000829972143637312,
      "loss": 2.168,
      "step": 10564
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008298006025379527,
      "loss": 2.1699,
      "step": 10565
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008296290665961943,
      "loss": 2.3008,
      "step": 10566
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008294575358172349,
      "loss": 2.1777,
      "step": 10567
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008292860102062725,
      "loss": 2.4883,
      "step": 10568
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008291144897685041,
      "loss": 2.207,
      "step": 10569
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008289429745091287,
      "loss": 2.1836,
      "step": 10570
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008287714644333429,
      "loss": 2.1875,
      "step": 10571
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008285999595463438,
      "loss": 2.1074,
      "step": 10572
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008284284598533293,
      "loss": 2.375,
      "step": 10573
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.000828256965359496,
      "loss": 2.0977,
      "step": 10574
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008280854760700408,
      "loss": 2.1641,
      "step": 10575
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008279139919901602,
      "loss": 2.3984,
      "step": 10576
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008277425131250511,
      "loss": 2.2012,
      "step": 10577
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008275710394799098,
      "loss": 2.1328,
      "step": 10578
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008273995710599322,
      "loss": 2.2344,
      "step": 10579
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008272281078703145,
      "loss": 2.3027,
      "step": 10580
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008270566499162528,
      "loss": 2.207,
      "step": 10581
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008268851972029426,
      "loss": 2.1699,
      "step": 10582
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008267137497355799,
      "loss": 2.3047,
      "step": 10583
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008265423075193592,
      "loss": 2.2969,
      "step": 10584
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008263708705594769,
      "loss": 2.1582,
      "step": 10585
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008261994388611274,
      "loss": 2.2266,
      "step": 10586
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008260280124295057,
      "loss": 2.2695,
      "step": 10587
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008258565912698065,
      "loss": 2.3398,
      "step": 10588
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008256851753872249,
      "loss": 2.0977,
      "step": 10589
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008255137647869551,
      "loss": 2.2852,
      "step": 10590
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008253423594741916,
      "loss": 2.1191,
      "step": 10591
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008251709594541274,
      "loss": 2.0801,
      "step": 10592
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008249995647319583,
      "loss": 2.3477,
      "step": 10593
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008248281753128771,
      "loss": 2.1445,
      "step": 10594
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008246567912020775,
      "loss": 2.0664,
      "step": 10595
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008244854124047528,
      "loss": 2.4375,
      "step": 10596
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008243140389260969,
      "loss": 2.2617,
      "step": 10597
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.000824142670771303,
      "loss": 2.2773,
      "step": 10598
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008239713079455635,
      "loss": 2.2793,
      "step": 10599
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008237999504540715,
      "loss": 2.2695,
      "step": 10600
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00082362859830202,
      "loss": 2.1719,
      "step": 10601
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008234572514946013,
      "loss": 2.3281,
      "step": 10602
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008232859100370075,
      "loss": 2.4102,
      "step": 10603
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008231145739344312,
      "loss": 2.3594,
      "step": 10604
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008229432431920646,
      "loss": 2.3164,
      "step": 10605
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008227719178150994,
      "loss": 2.2051,
      "step": 10606
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008226005978087266,
      "loss": 2.3359,
      "step": 10607
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008224292831781391,
      "loss": 2.3945,
      "step": 10608
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008222579739285274,
      "loss": 2.3828,
      "step": 10609
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008220866700650829,
      "loss": 2.2148,
      "step": 10610
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008219153715929966,
      "loss": 2.1562,
      "step": 10611
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008217440785174596,
      "loss": 2.3555,
      "step": 10612
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008215727908436628,
      "loss": 2.1016,
      "step": 10613
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008214015085767964,
      "loss": 2.1914,
      "step": 10614
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008212302317220506,
      "loss": 2.4062,
      "step": 10615
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008210589602846163,
      "loss": 2.2773,
      "step": 10616
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008208876942696834,
      "loss": 2.1113,
      "step": 10617
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008207164336824415,
      "loss": 2.2891,
      "step": 10618
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008205451785280806,
      "loss": 2.334,
      "step": 10619
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008203739288117902,
      "loss": 1.957,
      "step": 10620
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008202026845387602,
      "loss": 2.1875,
      "step": 10621
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008200314457141793,
      "loss": 2.125,
      "step": 10622
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008198602123432363,
      "loss": 2.3516,
      "step": 10623
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.000819688984431121,
      "loss": 2.2734,
      "step": 10624
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008195177619830217,
      "loss": 2.2422,
      "step": 10625
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008193465450041272,
      "loss": 2.2812,
      "step": 10626
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008191753334996253,
      "loss": 2.1582,
      "step": 10627
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008190041274747051,
      "loss": 2.5078,
      "step": 10628
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008188329269345545,
      "loss": 2.0938,
      "step": 10629
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008186617318843613,
      "loss": 2.2578,
      "step": 10630
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008184905423293129,
      "loss": 2.1719,
      "step": 10631
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008183193582745977,
      "loss": 2.1602,
      "step": 10632
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008181481797254026,
      "loss": 2.1367,
      "step": 10633
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008179770066869152,
      "loss": 2.2812,
      "step": 10634
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008178058391643218,
      "loss": 2.4141,
      "step": 10635
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008176346771628107,
      "loss": 2.3516,
      "step": 10636
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008174635206875675,
      "loss": 2.4375,
      "step": 10637
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008172923697437794,
      "loss": 2.1836,
      "step": 10638
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008171212243366324,
      "loss": 2.2715,
      "step": 10639
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008169500844713132,
      "loss": 2.2578,
      "step": 10640
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008167789501530076,
      "loss": 2.207,
      "step": 10641
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008166078213869021,
      "loss": 2.4062,
      "step": 10642
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008164366981781812,
      "loss": 2.2402,
      "step": 10643
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.000816265580532032,
      "loss": 2.0371,
      "step": 10644
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008160944684536391,
      "loss": 2.334,
      "step": 10645
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008159233619481876,
      "loss": 2.2227,
      "step": 10646
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008157522610208632,
      "loss": 2.2148,
      "step": 10647
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008155811656768505,
      "loss": 2.1719,
      "step": 10648
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008154100759213345,
      "loss": 2.3164,
      "step": 10649
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008152389917594988,
      "loss": 2.2578,
      "step": 10650
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008150679131965292,
      "loss": 2.0645,
      "step": 10651
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008148968402376092,
      "loss": 2.3613,
      "step": 10652
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008147257728879228,
      "loss": 2.2539,
      "step": 10653
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008145547111526539,
      "loss": 2.2266,
      "step": 10654
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008143836550369868,
      "loss": 2.2305,
      "step": 10655
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008142126045461045,
      "loss": 2.1934,
      "step": 10656
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008140415596851907,
      "loss": 2.2695,
      "step": 10657
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.000813870520459428,
      "loss": 1.9766,
      "step": 10658
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008136994868740004,
      "loss": 2.332,
      "step": 10659
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008135284589340904,
      "loss": 2.332,
      "step": 10660
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008133574366448803,
      "loss": 2.1289,
      "step": 10661
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008131864200115528,
      "loss": 2.1426,
      "step": 10662
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008130154090392908,
      "loss": 2.123,
      "step": 10663
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008128444037332762,
      "loss": 2.2617,
      "step": 10664
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008126734040986907,
      "loss": 2.0996,
      "step": 10665
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008125024101407162,
      "loss": 2.4355,
      "step": 10666
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008123314218645349,
      "loss": 2.1816,
      "step": 10667
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.000812160439275328,
      "loss": 2.2695,
      "step": 10668
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008119894623782766,
      "loss": 2.1992,
      "step": 10669
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008118184911785619,
      "loss": 2.2383,
      "step": 10670
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008116475256813654,
      "loss": 2.2109,
      "step": 10671
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008114765658918675,
      "loss": 2.3594,
      "step": 10672
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.000811305611815249,
      "loss": 2.0098,
      "step": 10673
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00081113466345669,
      "loss": 1.998,
      "step": 10674
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008109637208213713,
      "loss": 2.2773,
      "step": 10675
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008107927839144728,
      "loss": 2.2051,
      "step": 10676
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008106218527411746,
      "loss": 2.2188,
      "step": 10677
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008104509273066557,
      "loss": 2.1992,
      "step": 10678
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.000810280007616097,
      "loss": 2.332,
      "step": 10679
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008101090936746771,
      "loss": 2.0977,
      "step": 10680
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008099381854875751,
      "loss": 2.2148,
      "step": 10681
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008097672830599707,
      "loss": 2.5273,
      "step": 10682
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008095963863970426,
      "loss": 2.3223,
      "step": 10683
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008094254955039692,
      "loss": 2.3438,
      "step": 10684
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008092546103859293,
      "loss": 2.1387,
      "step": 10685
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008090837310481014,
      "loss": 2.2812,
      "step": 10686
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008089128574956637,
      "loss": 2.2695,
      "step": 10687
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.000808741989733794,
      "loss": 2.2656,
      "step": 10688
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008085711277676699,
      "loss": 2.3477,
      "step": 10689
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008084002716024697,
      "loss": 2.2188,
      "step": 10690
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008082294212433707,
      "loss": 2.2266,
      "step": 10691
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008080585766955504,
      "loss": 2.2266,
      "step": 10692
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008078877379641851,
      "loss": 2.4297,
      "step": 10693
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008077169050544529,
      "loss": 2.3633,
      "step": 10694
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00080754607797153,
      "loss": 2.2344,
      "step": 10695
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.000807375256720593,
      "loss": 2.293,
      "step": 10696
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008072044413068184,
      "loss": 2.2383,
      "step": 10697
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008070336317353826,
      "loss": 2.2715,
      "step": 10698
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008068628280114616,
      "loss": 2.3164,
      "step": 10699
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008066920301402316,
      "loss": 2.4375,
      "step": 10700
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008065212381268674,
      "loss": 2.3555,
      "step": 10701
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008063504519765459,
      "loss": 2.3633,
      "step": 10702
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008061796716944416,
      "loss": 2.2598,
      "step": 10703
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008060088972857299,
      "loss": 2.2148,
      "step": 10704
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008058381287555856,
      "loss": 2.1328,
      "step": 10705
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.000805667366109184,
      "loss": 2.1699,
      "step": 10706
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008054966093516998,
      "loss": 2.3008,
      "step": 10707
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008053258584883071,
      "loss": 2.168,
      "step": 10708
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008051551135241801,
      "loss": 2.5039,
      "step": 10709
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008049843744644933,
      "loss": 2.2207,
      "step": 10710
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008048136413144205,
      "loss": 2.4062,
      "step": 10711
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008046429140791357,
      "loss": 2.3672,
      "step": 10712
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.000804472192763812,
      "loss": 2.3711,
      "step": 10713
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008043014773736234,
      "loss": 2.1875,
      "step": 10714
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008041307679137429,
      "loss": 2.4922,
      "step": 10715
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008039600643893435,
      "loss": 2.4414,
      "step": 10716
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008037893668055979,
      "loss": 2.375,
      "step": 10717
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008036186751676791,
      "loss": 2.3633,
      "step": 10718
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008034479894807596,
      "loss": 2.123,
      "step": 10719
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008032773097500115,
      "loss": 2.1719,
      "step": 10720
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008031066359806072,
      "loss": 2.1055,
      "step": 10721
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008029359681777186,
      "loss": 2.3555,
      "step": 10722
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008027653063465177,
      "loss": 2.3203,
      "step": 10723
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008025946504921753,
      "loss": 2.3984,
      "step": 10724
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008024240006198641,
      "loss": 2.2852,
      "step": 10725
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008022533567347544,
      "loss": 2.3633,
      "step": 10726
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008020827188420176,
      "loss": 2.1406,
      "step": 10727
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008019120869468243,
      "loss": 2.2773,
      "step": 10728
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008017414610543457,
      "loss": 2.2578,
      "step": 10729
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008015708411697521,
      "loss": 2.4492,
      "step": 10730
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008014002272982137,
      "loss": 2.2148,
      "step": 10731
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008012296194449007,
      "loss": 2.3945,
      "step": 10732
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008010590176149833,
      "loss": 2.2031,
      "step": 10733
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.000800888421813631,
      "loss": 2.4258,
      "step": 10734
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008007178320460137,
      "loss": 2.4531,
      "step": 10735
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008005472483173005,
      "loss": 2.0742,
      "step": 10736
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008003766706326609,
      "loss": 2.0977,
      "step": 10737
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008002060989972644,
      "loss": 2.2695,
      "step": 10738
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.000800035533416279,
      "loss": 2.2305,
      "step": 10739
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0007998649738948736,
      "loss": 2.1621,
      "step": 10740
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.000799694420438217,
      "loss": 2.4062,
      "step": 10741
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0007995238730514776,
      "loss": 2.3242,
      "step": 10742
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0007993533317398234,
      "loss": 2.3359,
      "step": 10743
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0007991827965084218,
      "loss": 2.2812,
      "step": 10744
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007990122673624417,
      "loss": 2.2676,
      "step": 10745
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007988417443070499,
      "loss": 2.1699,
      "step": 10746
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007986712273474142,
      "loss": 2.3047,
      "step": 10747
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007985007164887011,
      "loss": 2.3438,
      "step": 10748
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007983302117360786,
      "loss": 2.4492,
      "step": 10749
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007981597130947132,
      "loss": 2.3672,
      "step": 10750
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007979892205697716,
      "loss": 2.3984,
      "step": 10751
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007978187341664194,
      "loss": 2.1484,
      "step": 10752
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007976482538898245,
      "loss": 2.1953,
      "step": 10753
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.000797477779745152,
      "loss": 2.3672,
      "step": 10754
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007973073117375678,
      "loss": 2.2539,
      "step": 10755
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.000797136849872238,
      "loss": 2.4062,
      "step": 10756
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007969663941543282,
      "loss": 2.3301,
      "step": 10757
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007967959445890035,
      "loss": 2.3203,
      "step": 10758
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007966255011814287,
      "loss": 2.2539,
      "step": 10759
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007964550639367698,
      "loss": 2.3516,
      "step": 10760
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007962846328601911,
      "loss": 2.2637,
      "step": 10761
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007961142079568569,
      "loss": 2.0547,
      "step": 10762
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007959437892319319,
      "loss": 2.2461,
      "step": 10763
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007957733766905805,
      "loss": 2.2695,
      "step": 10764
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007956029703379666,
      "loss": 2.3945,
      "step": 10765
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007954325701792544,
      "loss": 2.1406,
      "step": 10766
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007952621762196066,
      "loss": 1.9922,
      "step": 10767
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007950917884641881,
      "loss": 2.1914,
      "step": 10768
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007949214069181611,
      "loss": 2.3477,
      "step": 10769
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007947510315866892,
      "loss": 2.2266,
      "step": 10770
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007945806624749352,
      "loss": 2.3008,
      "step": 10771
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.000794410299588062,
      "loss": 2.2383,
      "step": 10772
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007942399429312321,
      "loss": 2.0762,
      "step": 10773
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007940695925096079,
      "loss": 2.3359,
      "step": 10774
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007938992483283511,
      "loss": 2.2656,
      "step": 10775
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007937289103926242,
      "loss": 2.0879,
      "step": 10776
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.000793558578707589,
      "loss": 2.3379,
      "step": 10777
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007933882532784069,
      "loss": 2.2734,
      "step": 10778
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007932179341102394,
      "loss": 2.1836,
      "step": 10779
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007930476212082477,
      "loss": 2.3203,
      "step": 10780
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007928773145775931,
      "loss": 2.1445,
      "step": 10781
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007927070142234363,
      "loss": 2.3008,
      "step": 10782
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007925367201509374,
      "loss": 2.2246,
      "step": 10783
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007923664323652576,
      "loss": 2.3125,
      "step": 10784
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.000792196150871557,
      "loss": 2.3164,
      "step": 10785
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007920258756749959,
      "loss": 2.2852,
      "step": 10786
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007918556067807332,
      "loss": 2.0566,
      "step": 10787
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007916853441939298,
      "loss": 2.1562,
      "step": 10788
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007915150879197448,
      "loss": 2.2031,
      "step": 10789
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007913448379633374,
      "loss": 2.1738,
      "step": 10790
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007911745943298666,
      "loss": 2.2227,
      "step": 10791
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007910043570244917,
      "loss": 2.1738,
      "step": 10792
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007908341260523713,
      "loss": 2.2051,
      "step": 10793
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007906639014186637,
      "loss": 2.1016,
      "step": 10794
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007904936831285279,
      "loss": 2.2012,
      "step": 10795
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007903234711871217,
      "loss": 2.2129,
      "step": 10796
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.000790153265599603,
      "loss": 2.3516,
      "step": 10797
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007899830663711294,
      "loss": 2.2109,
      "step": 10798
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.000789812873506859,
      "loss": 2.4258,
      "step": 10799
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007896426870119489,
      "loss": 2.4023,
      "step": 10800
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007894725068915562,
      "loss": 2.3516,
      "step": 10801
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007893023331508382,
      "loss": 2.3164,
      "step": 10802
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007891321657949517,
      "loss": 2.2266,
      "step": 10803
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007889620048290533,
      "loss": 2.207,
      "step": 10804
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007887918502582994,
      "loss": 2.4297,
      "step": 10805
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007886217020878457,
      "loss": 2.4023,
      "step": 10806
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007884515603228492,
      "loss": 2.0059,
      "step": 10807
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007882814249684653,
      "loss": 2.3359,
      "step": 10808
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00078811129602985,
      "loss": 2.293,
      "step": 10809
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007879411735121576,
      "loss": 2.3906,
      "step": 10810
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007877710574205449,
      "loss": 2.4297,
      "step": 10811
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007876009477601661,
      "loss": 2.3223,
      "step": 10812
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007874308445361763,
      "loss": 2.4062,
      "step": 10813
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007872607477537299,
      "loss": 2.2656,
      "step": 10814
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007870906574179819,
      "loss": 2.0566,
      "step": 10815
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007869205735340864,
      "loss": 2.3672,
      "step": 10816
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007867504961071977,
      "loss": 2.2734,
      "step": 10817
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007865804251424686,
      "loss": 2.2285,
      "step": 10818
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007864103606450545,
      "loss": 2.2227,
      "step": 10819
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007862403026201077,
      "loss": 2.209,
      "step": 10820
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.000786070251072782,
      "loss": 2.2734,
      "step": 10821
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007859002060082301,
      "loss": 2.3125,
      "step": 10822
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007857301674316055,
      "loss": 2.3828,
      "step": 10823
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007855601353480609,
      "loss": 2.3477,
      "step": 10824
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007853901097627484,
      "loss": 2.4883,
      "step": 10825
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007852200906808203,
      "loss": 2.2617,
      "step": 10826
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007850500781074291,
      "loss": 2.3281,
      "step": 10827
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007848800720477267,
      "loss": 2.2852,
      "step": 10828
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007847100725068646,
      "loss": 2.0723,
      "step": 10829
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007845400794899944,
      "loss": 2.1367,
      "step": 10830
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007843700930022678,
      "loss": 2.3125,
      "step": 10831
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007842001130488359,
      "loss": 2.5117,
      "step": 10832
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007840301396348486,
      "loss": 2.3789,
      "step": 10833
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007838601727654582,
      "loss": 2.3516,
      "step": 10834
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007836902124458145,
      "loss": 2.3125,
      "step": 10835
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007835202586810678,
      "loss": 2.1406,
      "step": 10836
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0007833503114763681,
      "loss": 1.9629,
      "step": 10837
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007831803708368658,
      "loss": 2.1426,
      "step": 10838
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007830104367677108,
      "loss": 2.1641,
      "step": 10839
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.000782840509274052,
      "loss": 2.4023,
      "step": 10840
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.000782670588361039,
      "loss": 2.3438,
      "step": 10841
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007825006740338212,
      "loss": 2.1172,
      "step": 10842
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007823307662975475,
      "loss": 2.2168,
      "step": 10843
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007821608651573665,
      "loss": 2.1953,
      "step": 10844
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007819909706184268,
      "loss": 2.1895,
      "step": 10845
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007818210826858767,
      "loss": 2.125,
      "step": 10846
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007816512013648648,
      "loss": 2.4258,
      "step": 10847
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007814813266605387,
      "loss": 2.2656,
      "step": 10848
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007813114585780459,
      "loss": 2.166,
      "step": 10849
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007811415971225344,
      "loss": 2.3906,
      "step": 10850
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007809717422991515,
      "loss": 2.3633,
      "step": 10851
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007808018941130444,
      "loss": 2.4336,
      "step": 10852
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007806320525693593,
      "loss": 2.0801,
      "step": 10853
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007804622176732442,
      "loss": 2.125,
      "step": 10854
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.000780292389429845,
      "loss": 2.3398,
      "step": 10855
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007801225678443079,
      "loss": 2.0879,
      "step": 10856
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007799527529217792,
      "loss": 2.2695,
      "step": 10857
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.000779782944667405,
      "loss": 2.2344,
      "step": 10858
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007796131430863309,
      "loss": 2.3047,
      "step": 10859
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007794433481837029,
      "loss": 2.0957,
      "step": 10860
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007792735599646652,
      "loss": 2.3008,
      "step": 10861
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007791037784343642,
      "loss": 2.2891,
      "step": 10862
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007789340035979442,
      "loss": 2.3047,
      "step": 10863
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007787642354605501,
      "loss": 2.3125,
      "step": 10864
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.000778594474027326,
      "loss": 2.293,
      "step": 10865
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007784247193034171,
      "loss": 2.1348,
      "step": 10866
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007782549712939671,
      "loss": 2.3398,
      "step": 10867
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007780852300041192,
      "loss": 2.4258,
      "step": 10868
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007779154954390184,
      "loss": 2.4766,
      "step": 10869
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007777457676038075,
      "loss": 2.125,
      "step": 10870
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007775760465036298,
      "loss": 2.1934,
      "step": 10871
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007774063321436284,
      "loss": 2.3555,
      "step": 10872
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007772366245289464,
      "loss": 2.1406,
      "step": 10873
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007770669236647264,
      "loss": 2.1758,
      "step": 10874
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007768972295561112,
      "loss": 2.4609,
      "step": 10875
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007767275422082421,
      "loss": 2.2461,
      "step": 10876
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007765578616262626,
      "loss": 2.2266,
      "step": 10877
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007763881878153136,
      "loss": 2.2891,
      "step": 10878
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.000776218520780537,
      "loss": 2.1836,
      "step": 10879
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007760488605270742,
      "loss": 2.2227,
      "step": 10880
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007758792070600666,
      "loss": 2.0742,
      "step": 10881
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007757095603846553,
      "loss": 2.3398,
      "step": 10882
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007755399205059814,
      "loss": 2.2539,
      "step": 10883
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007753702874291845,
      "loss": 2.1895,
      "step": 10884
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007752006611594064,
      "loss": 2.3906,
      "step": 10885
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007750310417017864,
      "loss": 2.4297,
      "step": 10886
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007748614290614648,
      "loss": 2.4922,
      "step": 10887
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007746918232435814,
      "loss": 2.3203,
      "step": 10888
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007745222242532759,
      "loss": 2.375,
      "step": 10889
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007743526320956879,
      "loss": 2.4258,
      "step": 10890
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007741830467759562,
      "loss": 2.4922,
      "step": 10891
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007740134682992197,
      "loss": 2.1055,
      "step": 10892
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007738438966706176,
      "loss": 2.2188,
      "step": 10893
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007736743318952884,
      "loss": 2.4023,
      "step": 10894
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007735047739783703,
      "loss": 2.1953,
      "step": 10895
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007733352229250014,
      "loss": 2.2051,
      "step": 10896
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007731656787403199,
      "loss": 2.3633,
      "step": 10897
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007729961414294637,
      "loss": 2.3672,
      "step": 10898
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.00077282661099757,
      "loss": 2.1777,
      "step": 10899
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007726570874497759,
      "loss": 2.1367,
      "step": 10900
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.000772487570791219,
      "loss": 2.0664,
      "step": 10901
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007723180610270361,
      "loss": 2.0234,
      "step": 10902
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007721485581623639,
      "loss": 2.3223,
      "step": 10903
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007719790622023383,
      "loss": 1.9961,
      "step": 10904
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007718095731520969,
      "loss": 2.1953,
      "step": 10905
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007716400910167747,
      "loss": 2.0684,
      "step": 10906
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007714706158015077,
      "loss": 2.3125,
      "step": 10907
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007713011475114317,
      "loss": 2.4375,
      "step": 10908
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007711316861516824,
      "loss": 2.2578,
      "step": 10909
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007709622317273947,
      "loss": 2.2188,
      "step": 10910
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007707927842437035,
      "loss": 2.3145,
      "step": 10911
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.000770623343705744,
      "loss": 2.2617,
      "step": 10912
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.000770453910118651,
      "loss": 2.0488,
      "step": 10913
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007702844834875582,
      "loss": 2.2109,
      "step": 10914
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007701150638176,
      "loss": 2.168,
      "step": 10915
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007699456511139107,
      "loss": 2.1992,
      "step": 10916
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007697762453816238,
      "loss": 2.293,
      "step": 10917
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007696068466258732,
      "loss": 2.3164,
      "step": 10918
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007694374548517913,
      "loss": 2.4141,
      "step": 10919
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007692680700645124,
      "loss": 2.3262,
      "step": 10920
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007690986922691687,
      "loss": 2.0566,
      "step": 10921
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007689293214708931,
      "loss": 2.2734,
      "step": 10922
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.000768759957674818,
      "loss": 2.2383,
      "step": 10923
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007685906008860758,
      "loss": 2.3086,
      "step": 10924
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007684212511097987,
      "loss": 2.3711,
      "step": 10925
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007682519083511185,
      "loss": 2.2578,
      "step": 10926
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.000768082572615166,
      "loss": 2.3496,
      "step": 10927
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007679132439070741,
      "loss": 2.2852,
      "step": 10928
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007677439222319731,
      "loss": 2.1016,
      "step": 10929
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007675746075949941,
      "loss": 2.3086,
      "step": 10930
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0007674053000012677,
      "loss": 2.3867,
      "step": 10931
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.000767235999455925,
      "loss": 2.1914,
      "step": 10932
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007670667059640964,
      "loss": 2.375,
      "step": 10933
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007668974195309114,
      "loss": 2.332,
      "step": 10934
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007667281401615002,
      "loss": 2.3359,
      "step": 10935
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007665588678609927,
      "loss": 2.2812,
      "step": 10936
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007663896026345184,
      "loss": 2.4062,
      "step": 10937
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007662203444872064,
      "loss": 2.3711,
      "step": 10938
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007660510934241857,
      "loss": 2.2656,
      "step": 10939
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007658818494505857,
      "loss": 2.25,
      "step": 10940
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007657126125715348,
      "loss": 2.1855,
      "step": 10941
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007655433827921607,
      "loss": 2.2578,
      "step": 10942
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007653741601175929,
      "loss": 2.4141,
      "step": 10943
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007652049445529585,
      "loss": 2.3945,
      "step": 10944
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007650357361033857,
      "loss": 2.2559,
      "step": 10945
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007648665347740015,
      "loss": 2.4883,
      "step": 10946
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007646973405699339,
      "loss": 2.166,
      "step": 10947
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00076452815349631,
      "loss": 2.4766,
      "step": 10948
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007643589735582565,
      "loss": 2.0234,
      "step": 10949
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007641898007608997,
      "loss": 2.3242,
      "step": 10950
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007640206351093668,
      "loss": 2.2422,
      "step": 10951
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007638514766087839,
      "loss": 1.9922,
      "step": 10952
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007636823252642769,
      "loss": 2.1582,
      "step": 10953
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007635131810809715,
      "loss": 2.418,
      "step": 10954
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007633440440639937,
      "loss": 2.0938,
      "step": 10955
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.000763174914218469,
      "loss": 2.1719,
      "step": 10956
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007630057915495221,
      "loss": 2.3516,
      "step": 10957
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.000762836676062278,
      "loss": 2.3711,
      "step": 10958
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007626675677618619,
      "loss": 2.4727,
      "step": 10959
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007624984666533979,
      "loss": 2.0605,
      "step": 10960
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007623293727420106,
      "loss": 2.1523,
      "step": 10961
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.000762160286032824,
      "loss": 2.0566,
      "step": 10962
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.000761991206530962,
      "loss": 2.2305,
      "step": 10963
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007618221342415484,
      "loss": 2.4336,
      "step": 10964
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007616530691697065,
      "loss": 2.1074,
      "step": 10965
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007614840113205592,
      "loss": 1.9941,
      "step": 10966
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00076131496069923,
      "loss": 2.3047,
      "step": 10967
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007611459173108416,
      "loss": 2.3828,
      "step": 10968
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007609768811605166,
      "loss": 2.2344,
      "step": 10969
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007608078522533768,
      "loss": 2.1562,
      "step": 10970
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007606388305945453,
      "loss": 2.168,
      "step": 10971
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007604698161891433,
      "loss": 2.3516,
      "step": 10972
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007603008090422927,
      "loss": 2.084,
      "step": 10973
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007601318091591148,
      "loss": 2.2383,
      "step": 10974
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007599628165447311,
      "loss": 2.2656,
      "step": 10975
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007597938312042625,
      "loss": 2.3047,
      "step": 10976
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007596248531428301,
      "loss": 2.2891,
      "step": 10977
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007594558823655536,
      "loss": 2.2227,
      "step": 10978
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007592869188775547,
      "loss": 2.332,
      "step": 10979
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007591179626839526,
      "loss": 2.2031,
      "step": 10980
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007589490137898673,
      "loss": 2.1816,
      "step": 10981
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007587800722004188,
      "loss": 1.9902,
      "step": 10982
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007586111379207267,
      "loss": 2.2773,
      "step": 10983
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007584422109559101,
      "loss": 2.3398,
      "step": 10984
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007582732913110873,
      "loss": 2.1113,
      "step": 10985
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007581043789913785,
      "loss": 2.1562,
      "step": 10986
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007579354740019014,
      "loss": 2.0996,
      "step": 10987
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007577665763477745,
      "loss": 2.3555,
      "step": 10988
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007575976860341158,
      "loss": 2.2148,
      "step": 10989
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007574288030660438,
      "loss": 2.3516,
      "step": 10990
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007572599274486757,
      "loss": 2.1211,
      "step": 10991
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007570910591871295,
      "loss": 2.0742,
      "step": 10992
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007569221982865216,
      "loss": 2.332,
      "step": 10993
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007567533447519699,
      "loss": 2.2207,
      "step": 10994
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007565844985885908,
      "loss": 2.2344,
      "step": 10995
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.000756415659801501,
      "loss": 2.2949,
      "step": 10996
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007562468283958166,
      "loss": 2.1367,
      "step": 10997
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007560780043766541,
      "loss": 2.2148,
      "step": 10998
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007559091877491296,
      "loss": 2.2383,
      "step": 10999
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007557403785183583,
      "loss": 2.3516,
      "step": 11000
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007555715766894556,
      "loss": 2.3516,
      "step": 11001
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007554027822675374,
      "loss": 2.3086,
      "step": 11002
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007552339952577182,
      "loss": 2.4609,
      "step": 11003
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.000755065215665113,
      "loss": 1.998,
      "step": 11004
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007548964434948361,
      "loss": 2.1582,
      "step": 11005
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007547276787520024,
      "loss": 2.4141,
      "step": 11006
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007545589214417257,
      "loss": 2.3672,
      "step": 11007
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007543901715691198,
      "loss": 2.1562,
      "step": 11008
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007542214291392983,
      "loss": 2.1699,
      "step": 11009
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007540526941573751,
      "loss": 2.1328,
      "step": 11010
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.000753883966628463,
      "loss": 2.3086,
      "step": 11011
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007537152465576755,
      "loss": 2.1582,
      "step": 11012
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007535465339501244,
      "loss": 2.4648,
      "step": 11013
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007533778288109234,
      "loss": 2.1836,
      "step": 11014
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007532091311451841,
      "loss": 2.248,
      "step": 11015
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007530404409580188,
      "loss": 2.2129,
      "step": 11016
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007528717582545392,
      "loss": 2.25,
      "step": 11017
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007527030830398574,
      "loss": 2.2695,
      "step": 11018
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007525344153190844,
      "loss": 2.1992,
      "step": 11019
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007523657550973313,
      "loss": 2.1777,
      "step": 11020
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007521971023797094,
      "loss": 2.25,
      "step": 11021
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007520284571713295,
      "loss": 2.3789,
      "step": 11022
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007518598194773017,
      "loss": 2.2773,
      "step": 11023
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0007516911893027363,
      "loss": 2.2461,
      "step": 11024
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007515225666527436,
      "loss": 2.3516,
      "step": 11025
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007513539515324334,
      "loss": 2.0938,
      "step": 11026
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007511853439469155,
      "loss": 2.2402,
      "step": 11027
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007510167439012983,
      "loss": 2.1836,
      "step": 11028
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007508481514006921,
      "loss": 2.4492,
      "step": 11029
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007506795664502054,
      "loss": 2.3359,
      "step": 11030
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007505109890549467,
      "loss": 2.125,
      "step": 11031
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007503424192200243,
      "loss": 2.2461,
      "step": 11032
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.000750173856950547,
      "loss": 2.4102,
      "step": 11033
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007500053022516223,
      "loss": 2.2969,
      "step": 11034
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007498367551283584,
      "loss": 2.3008,
      "step": 11035
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007496682155858619,
      "loss": 2.2578,
      "step": 11036
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007494996836292415,
      "loss": 2.4922,
      "step": 11037
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007493311592636032,
      "loss": 2.3789,
      "step": 11038
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007491626424940543,
      "loss": 2.1914,
      "step": 11039
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007489941333257009,
      "loss": 2.1934,
      "step": 11040
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007488256317636501,
      "loss": 2.0059,
      "step": 11041
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.000748657137813008,
      "loss": 2.3203,
      "step": 11042
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007484886514788798,
      "loss": 2.4297,
      "step": 11043
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007483201727663715,
      "loss": 2.1836,
      "step": 11044
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.000748151701680589,
      "loss": 2.543,
      "step": 11045
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007479832382266371,
      "loss": 2.0625,
      "step": 11046
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007478147824096211,
      "loss": 2.3516,
      "step": 11047
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007476463342346451,
      "loss": 2.2266,
      "step": 11048
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007474778937068145,
      "loss": 2.2812,
      "step": 11049
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007473094608312335,
      "loss": 2.3086,
      "step": 11050
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007471410356130055,
      "loss": 2.2695,
      "step": 11051
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007469726180572345,
      "loss": 2.3086,
      "step": 11052
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007468042081690246,
      "loss": 2.3867,
      "step": 11053
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007466358059534788,
      "loss": 2.1582,
      "step": 11054
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007464674114157002,
      "loss": 2.1602,
      "step": 11055
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.000746299024560792,
      "loss": 2.1367,
      "step": 11056
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007461306453938568,
      "loss": 2.1797,
      "step": 11057
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.000745962273919997,
      "loss": 2.457,
      "step": 11058
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007457939101443143,
      "loss": 2.3945,
      "step": 11059
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007456255540719117,
      "loss": 2.1836,
      "step": 11060
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007454572057078902,
      "loss": 2.375,
      "step": 11061
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007452888650573515,
      "loss": 2.3125,
      "step": 11062
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007451205321253966,
      "loss": 2.4961,
      "step": 11063
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007449522069171271,
      "loss": 2.1992,
      "step": 11064
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007447838894376437,
      "loss": 2.3516,
      "step": 11065
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007446155796920465,
      "loss": 1.9492,
      "step": 11066
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.000744447277685436,
      "loss": 2.5,
      "step": 11067
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007442789834229127,
      "loss": 2.2559,
      "step": 11068
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.000744110696909576,
      "loss": 2.3359,
      "step": 11069
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007439424181505259,
      "loss": 2.3438,
      "step": 11070
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007437741471508614,
      "loss": 2.3125,
      "step": 11071
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007436058839156819,
      "loss": 2.3867,
      "step": 11072
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007434376284500868,
      "loss": 2.0977,
      "step": 11073
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007432693807591739,
      "loss": 2.293,
      "step": 11074
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.000743101140848042,
      "loss": 2.1992,
      "step": 11075
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007429329087217896,
      "loss": 2.1641,
      "step": 11076
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007427646843855144,
      "loss": 2.2031,
      "step": 11077
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007425964678443146,
      "loss": 2.1836,
      "step": 11078
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007424282591032866,
      "loss": 2.4297,
      "step": 11079
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007422600581675291,
      "loss": 2.334,
      "step": 11080
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007420918650421382,
      "loss": 2.3516,
      "step": 11081
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.000741923679732211,
      "loss": 2.4062,
      "step": 11082
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007417555022428438,
      "loss": 2.2539,
      "step": 11083
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007415873325791333,
      "loss": 2.1836,
      "step": 11084
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007414191707461757,
      "loss": 2.2148,
      "step": 11085
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007412510167490667,
      "loss": 2.4766,
      "step": 11086
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007410828705929012,
      "loss": 2.3203,
      "step": 11087
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007409147322827757,
      "loss": 2.2656,
      "step": 11088
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007407466018237847,
      "loss": 2.3594,
      "step": 11089
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007405784792210233,
      "loss": 2.2539,
      "step": 11090
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007404103644795861,
      "loss": 2.2227,
      "step": 11091
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007402422576045676,
      "loss": 2.3594,
      "step": 11092
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007400741586010621,
      "loss": 2.3945,
      "step": 11093
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007399060674741629,
      "loss": 2.3086,
      "step": 11094
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007397379842289649,
      "loss": 2.3281,
      "step": 11095
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007395699088705606,
      "loss": 2.127,
      "step": 11096
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007394018414040434,
      "loss": 2.2891,
      "step": 11097
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007392337818345063,
      "loss": 2.3516,
      "step": 11098
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007390657301670425,
      "loss": 2.0684,
      "step": 11099
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.000738897686406744,
      "loss": 2.3164,
      "step": 11100
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007387296505587035,
      "loss": 2.3262,
      "step": 11101
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007385616226280123,
      "loss": 2.043,
      "step": 11102
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007383936026197633,
      "loss": 2.1973,
      "step": 11103
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007382255905390474,
      "loss": 2.3594,
      "step": 11104
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007380575863909557,
      "loss": 2.3477,
      "step": 11105
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007378895901805796,
      "loss": 2.2344,
      "step": 11106
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00073772160191301,
      "loss": 2.2539,
      "step": 11107
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007375536215933376,
      "loss": 2.25,
      "step": 11108
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007373856492266524,
      "loss": 2.2344,
      "step": 11109
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007372176848180443,
      "loss": 2.1094,
      "step": 11110
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007370497283726039,
      "loss": 2.0469,
      "step": 11111
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007368817798954204,
      "loss": 2.3008,
      "step": 11112
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007367138393915833,
      "loss": 2.2031,
      "step": 11113
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007365459068661814,
      "loss": 2.2773,
      "step": 11114
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007363779823243044,
      "loss": 2.0195,
      "step": 11115
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007362100657710405,
      "loss": 2.418,
      "step": 11116
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0007360421572114779,
      "loss": 2.3281,
      "step": 11117
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007358742566507049,
      "loss": 2.3184,
      "step": 11118
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007357063640938095,
      "loss": 2.3477,
      "step": 11119
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007355384795458796,
      "loss": 2.4297,
      "step": 11120
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007353706030120027,
      "loss": 2.2129,
      "step": 11121
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.000735202734497265,
      "loss": 2.2773,
      "step": 11122
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.000735034874006755,
      "loss": 2.2539,
      "step": 11123
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007348670215455584,
      "loss": 2.2969,
      "step": 11124
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007346991771187622,
      "loss": 2.3164,
      "step": 11125
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007345313407314518,
      "loss": 2.3477,
      "step": 11126
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007343635123887143,
      "loss": 2.0801,
      "step": 11127
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007341956920956347,
      "loss": 2.3633,
      "step": 11128
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007340278798572988,
      "loss": 2.1992,
      "step": 11129
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007338600756787919,
      "loss": 2.3984,
      "step": 11130
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.000733692279565199,
      "loss": 2.2793,
      "step": 11131
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007335244915216048,
      "loss": 2.2812,
      "step": 11132
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007333567115530935,
      "loss": 2.0957,
      "step": 11133
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007331889396647499,
      "loss": 2.2109,
      "step": 11134
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.000733021175861658,
      "loss": 2.3633,
      "step": 11135
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007328534201489012,
      "loss": 2.1621,
      "step": 11136
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007326856725315634,
      "loss": 2.4297,
      "step": 11137
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007325179330147278,
      "loss": 2.2383,
      "step": 11138
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007323502016034776,
      "loss": 2.1133,
      "step": 11139
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007321824783028954,
      "loss": 2.334,
      "step": 11140
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007320147631180635,
      "loss": 2.4336,
      "step": 11141
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.000731847056054065,
      "loss": 2.3516,
      "step": 11142
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007316793571159815,
      "loss": 2.4922,
      "step": 11143
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007315116663088949,
      "loss": 2.4062,
      "step": 11144
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007313439836378862,
      "loss": 2.2812,
      "step": 11145
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007311763091080379,
      "loss": 2.3633,
      "step": 11146
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007310086427244302,
      "loss": 2.1484,
      "step": 11147
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007308409844921442,
      "loss": 2.1016,
      "step": 11148
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007306733344162604,
      "loss": 2.3086,
      "step": 11149
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007305056925018593,
      "loss": 2.1328,
      "step": 11150
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007303380587540212,
      "loss": 2.207,
      "step": 11151
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007301704331778258,
      "loss": 2.1133,
      "step": 11152
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.000730002815778352,
      "loss": 2.0938,
      "step": 11153
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007298352065606803,
      "loss": 2.1562,
      "step": 11154
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007296676055298892,
      "loss": 2.0176,
      "step": 11155
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007295000126910576,
      "loss": 2.4844,
      "step": 11156
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.000729332428049264,
      "loss": 2.1582,
      "step": 11157
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.000729164851609587,
      "loss": 2.2422,
      "step": 11158
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.000728997283377105,
      "loss": 2.3477,
      "step": 11159
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007288297233568953,
      "loss": 2.3125,
      "step": 11160
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007286621715540353,
      "loss": 2.2266,
      "step": 11161
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007284946279736031,
      "loss": 2.0508,
      "step": 11162
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007283270926206755,
      "loss": 2.1875,
      "step": 11163
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007281595655003292,
      "loss": 2.1992,
      "step": 11164
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007279920466176413,
      "loss": 2.1719,
      "step": 11165
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007278245359776879,
      "loss": 2.3633,
      "step": 11166
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007276570335855452,
      "loss": 2.1406,
      "step": 11167
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007274895394462884,
      "loss": 2.1035,
      "step": 11168
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007273220535649942,
      "loss": 2.2754,
      "step": 11169
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007271545759467375,
      "loss": 2.2344,
      "step": 11170
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007269871065965933,
      "loss": 2.3086,
      "step": 11171
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007268196455196363,
      "loss": 2.4141,
      "step": 11172
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007266521927209418,
      "loss": 2.2656,
      "step": 11173
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007264847482055836,
      "loss": 2.2617,
      "step": 11174
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.000726317311978636,
      "loss": 2.3086,
      "step": 11175
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007261498840451726,
      "loss": 2.3008,
      "step": 11176
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007259824644102675,
      "loss": 2.1816,
      "step": 11177
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007258150530789938,
      "loss": 2.4336,
      "step": 11178
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007256476500564247,
      "loss": 2.4805,
      "step": 11179
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007254802553476325,
      "loss": 2.3633,
      "step": 11180
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007253128689576908,
      "loss": 2.125,
      "step": 11181
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007251454908916717,
      "loss": 2.2578,
      "step": 11182
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007249781211546467,
      "loss": 2.1152,
      "step": 11183
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007248107597516879,
      "loss": 2.2695,
      "step": 11184
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.000724643406687867,
      "loss": 2.2969,
      "step": 11185
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007244760619682558,
      "loss": 2.1992,
      "step": 11186
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.000724308725597925,
      "loss": 2.3398,
      "step": 11187
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007241413975819447,
      "loss": 2.2852,
      "step": 11188
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007239740779253868,
      "loss": 2.4023,
      "step": 11189
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007238067666333209,
      "loss": 2.2578,
      "step": 11190
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007236394637108172,
      "loss": 2.332,
      "step": 11191
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007234721691629453,
      "loss": 2.3828,
      "step": 11192
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007233048829947753,
      "loss": 2.084,
      "step": 11193
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007231376052113761,
      "loss": 2.4199,
      "step": 11194
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007229703358178172,
      "loss": 2.1875,
      "step": 11195
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007228030748191665,
      "loss": 2.0879,
      "step": 11196
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007226358222204938,
      "loss": 2.1328,
      "step": 11197
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007224685780268666,
      "loss": 2.1387,
      "step": 11198
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007223013422433531,
      "loss": 2.2891,
      "step": 11199
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007221341148750209,
      "loss": 2.127,
      "step": 11200
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007219668959269379,
      "loss": 2.2383,
      "step": 11201
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007217996854041715,
      "loss": 2.2852,
      "step": 11202
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007216324833117879,
      "loss": 2.4492,
      "step": 11203
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.000721465289654855,
      "loss": 2.293,
      "step": 11204
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007212981044384386,
      "loss": 2.3828,
      "step": 11205
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.000721130927667605,
      "loss": 2.2852,
      "step": 11206
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007209637593474201,
      "loss": 2.3477,
      "step": 11207
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007207965994829503,
      "loss": 1.9531,
      "step": 11208
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007206294480792605,
      "loss": 2.2578,
      "step": 11209
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0007204623051414163,
      "loss": 2.1836,
      "step": 11210
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007202951706744821,
      "loss": 2.2129,
      "step": 11211
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007201280446835234,
      "loss": 2.332,
      "step": 11212
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.000719960927173604,
      "loss": 2.2812,
      "step": 11213
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007197938181497885,
      "loss": 2.3672,
      "step": 11214
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007196267176171405,
      "loss": 2.2031,
      "step": 11215
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007194596255807243,
      "loss": 2.3125,
      "step": 11216
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007192925420456027,
      "loss": 2.4648,
      "step": 11217
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007191254670168394,
      "loss": 2.3125,
      "step": 11218
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007189584004994964,
      "loss": 2.5039,
      "step": 11219
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007187913424986378,
      "loss": 2.3945,
      "step": 11220
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007186242930193251,
      "loss": 2.2695,
      "step": 11221
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007184572520666205,
      "loss": 2.3164,
      "step": 11222
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007182902196455857,
      "loss": 2.2031,
      "step": 11223
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007181231957612828,
      "loss": 2.3164,
      "step": 11224
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007179561804187733,
      "loss": 2.252,
      "step": 11225
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007177891736231178,
      "loss": 2.3477,
      "step": 11226
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.000717622175379377,
      "loss": 2.4727,
      "step": 11227
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007174551856926121,
      "loss": 2.2051,
      "step": 11228
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007172882045678832,
      "loss": 2.2812,
      "step": 11229
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007171212320102505,
      "loss": 2.2031,
      "step": 11230
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007169542680247734,
      "loss": 2.3086,
      "step": 11231
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007167873126165119,
      "loss": 2.4141,
      "step": 11232
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007166203657905252,
      "loss": 2.2188,
      "step": 11233
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007164534275518722,
      "loss": 2.2656,
      "step": 11234
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007162864979056114,
      "loss": 2.1016,
      "step": 11235
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007161195768568021,
      "loss": 2.3789,
      "step": 11236
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007159526644105019,
      "loss": 2.1797,
      "step": 11237
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007157857605717692,
      "loss": 2.332,
      "step": 11238
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007156188653456611,
      "loss": 2.375,
      "step": 11239
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007154519787372361,
      "loss": 2.2246,
      "step": 11240
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007152851007515506,
      "loss": 2.2129,
      "step": 11241
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007151182313936615,
      "loss": 2.4023,
      "step": 11242
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.000714951370668626,
      "loss": 2.3281,
      "step": 11243
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007147845185815004,
      "loss": 2.1953,
      "step": 11244
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007146176751373406,
      "loss": 2.25,
      "step": 11245
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007144508403412027,
      "loss": 2.2949,
      "step": 11246
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007142840141981424,
      "loss": 2.3359,
      "step": 11247
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007141171967132152,
      "loss": 2.3594,
      "step": 11248
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007139503878914758,
      "loss": 2.3457,
      "step": 11249
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007137835877379789,
      "loss": 2.2422,
      "step": 11250
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007136167962577798,
      "loss": 2.3828,
      "step": 11251
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007134500134559326,
      "loss": 2.3105,
      "step": 11252
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007132832393374913,
      "loss": 2.252,
      "step": 11253
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007131164739075091,
      "loss": 2.3477,
      "step": 11254
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007129497171710406,
      "loss": 2.2695,
      "step": 11255
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007127829691331386,
      "loss": 2.2031,
      "step": 11256
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007126162297988558,
      "loss": 2.2656,
      "step": 11257
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007124494991732453,
      "loss": 2.3516,
      "step": 11258
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007122827772613596,
      "loss": 2.1348,
      "step": 11259
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007121160640682509,
      "loss": 2.1504,
      "step": 11260
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007119493595989713,
      "loss": 2.1328,
      "step": 11261
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007117826638585717,
      "loss": 2.3008,
      "step": 11262
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007116159768521047,
      "loss": 2.0664,
      "step": 11263
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007114492985846207,
      "loss": 2.2578,
      "step": 11264
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007112826290611707,
      "loss": 2.2969,
      "step": 11265
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007111159682868053,
      "loss": 2.1406,
      "step": 11266
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007109493162665752,
      "loss": 2.1426,
      "step": 11267
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007107826730055305,
      "loss": 2.3828,
      "step": 11268
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007106160385087206,
      "loss": 2.3242,
      "step": 11269
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007104494127811951,
      "loss": 2.2891,
      "step": 11270
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007102827958280038,
      "loss": 2.3984,
      "step": 11271
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007101161876541952,
      "loss": 2.3477,
      "step": 11272
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007099495882648186,
      "loss": 2.1484,
      "step": 11273
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.000709782997664922,
      "loss": 2.207,
      "step": 11274
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.000709616415859554,
      "loss": 2.3281,
      "step": 11275
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007094498428537627,
      "loss": 2.1309,
      "step": 11276
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007092832786525949,
      "loss": 2.3359,
      "step": 11277
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007091167232610993,
      "loss": 2.3906,
      "step": 11278
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007089501766843224,
      "loss": 2.2188,
      "step": 11279
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007087836389273111,
      "loss": 2.0957,
      "step": 11280
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.000708617109995112,
      "loss": 2.5078,
      "step": 11281
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007084505898927717,
      "loss": 2.2441,
      "step": 11282
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007082840786253364,
      "loss": 2.0996,
      "step": 11283
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007081175761978517,
      "loss": 2.2109,
      "step": 11284
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007079510826153629,
      "loss": 2.3555,
      "step": 11285
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007077845978829158,
      "loss": 2.209,
      "step": 11286
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007076181220055553,
      "loss": 2.3945,
      "step": 11287
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007074516549883261,
      "loss": 2.1875,
      "step": 11288
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007072851968362725,
      "loss": 2.2852,
      "step": 11289
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007071187475544393,
      "loss": 2.1406,
      "step": 11290
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007069523071478702,
      "loss": 2.1836,
      "step": 11291
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007067858756216086,
      "loss": 2.2422,
      "step": 11292
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.000706619452980698,
      "loss": 2.2383,
      "step": 11293
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007064530392301818,
      "loss": 2.2949,
      "step": 11294
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007062866343751027,
      "loss": 2.2988,
      "step": 11295
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007061202384205035,
      "loss": 2.3398,
      "step": 11296
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007059538513714261,
      "loss": 2.457,
      "step": 11297
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007057874732329131,
      "loss": 2.2461,
      "step": 11298
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007056211040100063,
      "loss": 2.4023,
      "step": 11299
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007054547437077469,
      "loss": 2.1914,
      "step": 11300
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007052883923311759,
      "loss": 2.2734,
      "step": 11301
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007051220498853351,
      "loss": 2.3242,
      "step": 11302
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0007049557163752647,
      "loss": 2.2656,
      "step": 11303
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007047893918060055,
      "loss": 2.2129,
      "step": 11304
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007046230761825969,
      "loss": 2.3984,
      "step": 11305
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007044567695100799,
      "loss": 2.2812,
      "step": 11306
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007042904717934933,
      "loss": 2.2324,
      "step": 11307
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007041241830378768,
      "loss": 2.2559,
      "step": 11308
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007039579032482692,
      "loss": 2.1738,
      "step": 11309
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00070379163242971,
      "loss": 2.1582,
      "step": 11310
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.000703625370587237,
      "loss": 2.3535,
      "step": 11311
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007034591177258893,
      "loss": 2.1328,
      "step": 11312
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007032928738507036,
      "loss": 2.3711,
      "step": 11313
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007031266389667193,
      "loss": 2.3047,
      "step": 11314
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007029604130789725,
      "loss": 2.375,
      "step": 11315
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007027941961925008,
      "loss": 2.1914,
      "step": 11316
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007026279883123415,
      "loss": 2.2617,
      "step": 11317
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.000702461789443531,
      "loss": 2.2051,
      "step": 11318
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007022955995911057,
      "loss": 1.9961,
      "step": 11319
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007021294187601012,
      "loss": 2.4062,
      "step": 11320
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007019632469555542,
      "loss": 2.1426,
      "step": 11321
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007017970841824996,
      "loss": 2.4023,
      "step": 11322
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.000701630930445973,
      "loss": 2.2227,
      "step": 11323
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007014647857510091,
      "loss": 2.3242,
      "step": 11324
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.000701298650102643,
      "loss": 2.2793,
      "step": 11325
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007011325235059089,
      "loss": 2.1875,
      "step": 11326
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007009664059658414,
      "loss": 2.0703,
      "step": 11327
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007008002974874735,
      "loss": 2.2305,
      "step": 11328
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007006341980758397,
      "loss": 1.9902,
      "step": 11329
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007004681077359731,
      "loss": 2.4531,
      "step": 11330
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007003020264729067,
      "loss": 2.0801,
      "step": 11331
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0007001359542916731,
      "loss": 2.3867,
      "step": 11332
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006999698911973053,
      "loss": 2.25,
      "step": 11333
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006998038371948356,
      "loss": 2.2422,
      "step": 11334
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006996377922892955,
      "loss": 2.1602,
      "step": 11335
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006994717564857167,
      "loss": 2.2812,
      "step": 11336
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.000699305729789131,
      "loss": 2.3945,
      "step": 11337
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006991397122045695,
      "loss": 2.3438,
      "step": 11338
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.000698973703737063,
      "loss": 2.3789,
      "step": 11339
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006988077043916418,
      "loss": 2.0586,
      "step": 11340
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006986417141733367,
      "loss": 2.332,
      "step": 11341
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006984757330871778,
      "loss": 2.4766,
      "step": 11342
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006983097611381945,
      "loss": 2.4453,
      "step": 11343
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006981437983314163,
      "loss": 2.1875,
      "step": 11344
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006979778446718725,
      "loss": 2.1035,
      "step": 11345
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006978119001645924,
      "loss": 2.2734,
      "step": 11346
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006976459648146043,
      "loss": 2.2305,
      "step": 11347
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006974800386269362,
      "loss": 2.2344,
      "step": 11348
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006973141216066172,
      "loss": 2.332,
      "step": 11349
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006971482137586744,
      "loss": 2.1582,
      "step": 11350
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006969823150881352,
      "loss": 2.1289,
      "step": 11351
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006968164256000276,
      "loss": 2.2539,
      "step": 11352
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006966505452993781,
      "loss": 2.3203,
      "step": 11353
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006964846741912134,
      "loss": 2.2812,
      "step": 11354
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006963188122805601,
      "loss": 2.2754,
      "step": 11355
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006961529595724444,
      "loss": 2.3008,
      "step": 11356
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006959871160718923,
      "loss": 2.2109,
      "step": 11357
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006958212817839291,
      "loss": 2.1914,
      "step": 11358
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00069565545671358,
      "loss": 2.2129,
      "step": 11359
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006954896408658704,
      "loss": 2.3125,
      "step": 11360
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006953238342458251,
      "loss": 2.2051,
      "step": 11361
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006951580368584685,
      "loss": 2.082,
      "step": 11362
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.000694992248708824,
      "loss": 2.2969,
      "step": 11363
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006948264698019172,
      "loss": 2.3066,
      "step": 11364
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006946607001427703,
      "loss": 2.2734,
      "step": 11365
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006944949397364072,
      "loss": 2.1113,
      "step": 11366
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006943291885878508,
      "loss": 2.418,
      "step": 11367
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006941634467021243,
      "loss": 2.293,
      "step": 11368
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00069399771408425,
      "loss": 2.1992,
      "step": 11369
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006938319907392502,
      "loss": 2.3203,
      "step": 11370
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006936662766721462,
      "loss": 2.2695,
      "step": 11371
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.000693500571887961,
      "loss": 2.2695,
      "step": 11372
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.000693334876391715,
      "loss": 2.2285,
      "step": 11373
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006931691901884296,
      "loss": 2.2852,
      "step": 11374
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006930035132831254,
      "loss": 2.3203,
      "step": 11375
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006928378456808233,
      "loss": 2.2793,
      "step": 11376
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006926721873865436,
      "loss": 2.3789,
      "step": 11377
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006925065384053062,
      "loss": 2.418,
      "step": 11378
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006923408987421301,
      "loss": 2.1602,
      "step": 11379
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006921752684020361,
      "loss": 2.207,
      "step": 11380
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006920096473900423,
      "loss": 2.2578,
      "step": 11381
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006918440357111679,
      "loss": 2.3828,
      "step": 11382
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006916784333704314,
      "loss": 2.125,
      "step": 11383
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006915128403728512,
      "loss": 2.2305,
      "step": 11384
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006913472567234456,
      "loss": 2.2305,
      "step": 11385
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006911816824272317,
      "loss": 2.2656,
      "step": 11386
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006910161174892269,
      "loss": 2.2324,
      "step": 11387
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006908505619144489,
      "loss": 2.1113,
      "step": 11388
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006906850157079145,
      "loss": 2.3789,
      "step": 11389
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00069051947887464,
      "loss": 2.1211,
      "step": 11390
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006903539514196421,
      "loss": 2.2734,
      "step": 11391
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006901884333479364,
      "loss": 2.4102,
      "step": 11392
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006900229246645393,
      "loss": 2.4102,
      "step": 11393
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006898574253744649,
      "loss": 2.1992,
      "step": 11394
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006896919354827301,
      "loss": 1.9941,
      "step": 11395
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0006895264549943487,
      "loss": 2.457,
      "step": 11396
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006893609839143355,
      "loss": 2.1797,
      "step": 11397
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006891955222477049,
      "loss": 2.3984,
      "step": 11398
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006890300699994708,
      "loss": 2.2188,
      "step": 11399
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006888646271746475,
      "loss": 2.3047,
      "step": 11400
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006886991937782477,
      "loss": 2.0293,
      "step": 11401
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006885337698152847,
      "loss": 2.3477,
      "step": 11402
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006883683552907718,
      "loss": 2.2363,
      "step": 11403
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006882029502097213,
      "loss": 2.3789,
      "step": 11404
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006880375545771457,
      "loss": 2.2734,
      "step": 11405
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006878721683980566,
      "loss": 2.2793,
      "step": 11406
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006877067916774664,
      "loss": 2.457,
      "step": 11407
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006875414244203865,
      "loss": 2.1328,
      "step": 11408
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006873760666318275,
      "loss": 2.1641,
      "step": 11409
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006872107183168004,
      "loss": 2.2461,
      "step": 11410
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006870453794803162,
      "loss": 2.2188,
      "step": 11411
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006868800501273851,
      "loss": 2.3633,
      "step": 11412
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.000686714730263017,
      "loss": 2.1562,
      "step": 11413
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006865494198922212,
      "loss": 2.293,
      "step": 11414
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006863841190200082,
      "loss": 2.2188,
      "step": 11415
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006862188276513863,
      "loss": 2.4062,
      "step": 11416
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006860535457913648,
      "loss": 2.2188,
      "step": 11417
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006858882734449516,
      "loss": 2.3652,
      "step": 11418
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.000685723010617156,
      "loss": 2.252,
      "step": 11419
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006855577573129854,
      "loss": 2.25,
      "step": 11420
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006853925135374479,
      "loss": 2.3027,
      "step": 11421
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006852272792955501,
      "loss": 2.3203,
      "step": 11422
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006850620545923,
      "loss": 2.375,
      "step": 11423
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006848968394327044,
      "loss": 2.1289,
      "step": 11424
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006847316338217692,
      "loss": 2.1562,
      "step": 11425
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006845664377645014,
      "loss": 2.2676,
      "step": 11426
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006844012512659064,
      "loss": 2.2812,
      "step": 11427
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006842360743309905,
      "loss": 2.3789,
      "step": 11428
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006840709069647582,
      "loss": 2.1523,
      "step": 11429
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006839057491722159,
      "loss": 2.3281,
      "step": 11430
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006837406009583674,
      "loss": 2.0781,
      "step": 11431
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006835754623282176,
      "loss": 2.4336,
      "step": 11432
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006834103332867704,
      "loss": 2.3867,
      "step": 11433
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006832452138390302,
      "loss": 2.2266,
      "step": 11434
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006830801039900006,
      "loss": 2.2148,
      "step": 11435
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006829150037446852,
      "loss": 2.2109,
      "step": 11436
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006827499131080859,
      "loss": 2.2305,
      "step": 11437
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.000682584832085207,
      "loss": 2.3281,
      "step": 11438
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006824197606810502,
      "loss": 2.166,
      "step": 11439
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006822546989006178,
      "loss": 2.2891,
      "step": 11440
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006820896467489116,
      "loss": 2.0996,
      "step": 11441
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006819246042309335,
      "loss": 2.3125,
      "step": 11442
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006817595713516851,
      "loss": 2.0977,
      "step": 11443
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006815945481161666,
      "loss": 2.207,
      "step": 11444
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006814295345293791,
      "loss": 2.3281,
      "step": 11445
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006812645305963234,
      "loss": 2.2344,
      "step": 11446
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006810995363219994,
      "loss": 2.332,
      "step": 11447
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006809345517114068,
      "loss": 2.2734,
      "step": 11448
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006807695767695453,
      "loss": 2.0918,
      "step": 11449
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006806046115014144,
      "loss": 2.293,
      "step": 11450
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006804396559120132,
      "loss": 2.2402,
      "step": 11451
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006802747100063399,
      "loss": 2.207,
      "step": 11452
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006801097737893928,
      "loss": 2.2695,
      "step": 11453
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006799448472661707,
      "loss": 2.0508,
      "step": 11454
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.000679779930441671,
      "loss": 2.1426,
      "step": 11455
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006796150233208913,
      "loss": 2.4219,
      "step": 11456
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006794501259088283,
      "loss": 2.1484,
      "step": 11457
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006792852382104802,
      "loss": 2.291,
      "step": 11458
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006791203602308424,
      "loss": 2.4648,
      "step": 11459
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.000678955491974912,
      "loss": 2.2852,
      "step": 11460
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006787906334476844,
      "loss": 2.293,
      "step": 11461
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.000678625784654156,
      "loss": 2.3906,
      "step": 11462
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006784609455993218,
      "loss": 2.1797,
      "step": 11463
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006782961162881771,
      "loss": 2.0723,
      "step": 11464
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006781312967257169,
      "loss": 2.1641,
      "step": 11465
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006779664869169359,
      "loss": 2.3164,
      "step": 11466
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006778016868668281,
      "loss": 2.2773,
      "step": 11467
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006776368965803872,
      "loss": 2.3984,
      "step": 11468
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006774721160626076,
      "loss": 2.4453,
      "step": 11469
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006773073453184822,
      "loss": 2.1094,
      "step": 11470
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006771425843530043,
      "loss": 2.1953,
      "step": 11471
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006769778331711662,
      "loss": 2.2168,
      "step": 11472
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006768130917779613,
      "loss": 2.2695,
      "step": 11473
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006766483601783813,
      "loss": 2.1875,
      "step": 11474
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006764836383774182,
      "loss": 2.2461,
      "step": 11475
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006763189263800631,
      "loss": 2.2344,
      "step": 11476
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006761542241913081,
      "loss": 2.1777,
      "step": 11477
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006759895318161437,
      "loss": 2.1836,
      "step": 11478
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006758248492595613,
      "loss": 2.2383,
      "step": 11479
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00067566017652655,
      "loss": 2.6367,
      "step": 11480
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006754955136221015,
      "loss": 2.3438,
      "step": 11481
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006753308605512045,
      "loss": 2.3672,
      "step": 11482
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006751662173188489,
      "loss": 2.4844,
      "step": 11483
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006750015839300239,
      "loss": 2.1211,
      "step": 11484
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006748369603897185,
      "loss": 1.9434,
      "step": 11485
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006746723467029214,
      "loss": 2.4453,
      "step": 11486
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006745077428746211,
      "loss": 2.2852,
      "step": 11487
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006743431489098046,
      "loss": 2.3359,
      "step": 11488
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0006741785648134611,
      "loss": 2.3066,
      "step": 11489
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006740139905905771,
      "loss": 2.4375,
      "step": 11490
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006738494262461401,
      "loss": 2.4531,
      "step": 11491
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006736848717851365,
      "loss": 2.3906,
      "step": 11492
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006735203272125534,
      "loss": 2.3359,
      "step": 11493
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006733557925333771,
      "loss": 2.3438,
      "step": 11494
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006731912677525928,
      "loss": 2.3027,
      "step": 11495
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006730267528751865,
      "loss": 2.0742,
      "step": 11496
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006728622479061441,
      "loss": 2.1602,
      "step": 11497
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006726977528504498,
      "loss": 2.1914,
      "step": 11498
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006725332677130888,
      "loss": 2.1523,
      "step": 11499
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006723687924990456,
      "loss": 2.2383,
      "step": 11500
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.000672204327213304,
      "loss": 2.1719,
      "step": 11501
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006720398718608485,
      "loss": 2.2305,
      "step": 11502
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006718754264466613,
      "loss": 2.3633,
      "step": 11503
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006717109909757273,
      "loss": 2.2012,
      "step": 11504
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006715465654530283,
      "loss": 2.3594,
      "step": 11505
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006713821498835475,
      "loss": 2.5273,
      "step": 11506
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006712177442722665,
      "loss": 2.1953,
      "step": 11507
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006710533486241683,
      "loss": 2.1426,
      "step": 11508
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006708889629442342,
      "loss": 2.3398,
      "step": 11509
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006707245872374454,
      "loss": 2.2461,
      "step": 11510
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006705602215087832,
      "loss": 2.1484,
      "step": 11511
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006703958657632285,
      "loss": 2.2129,
      "step": 11512
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006702315200057617,
      "loss": 2.3047,
      "step": 11513
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006700671842413632,
      "loss": 2.2461,
      "step": 11514
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006699028584750124,
      "loss": 2.0801,
      "step": 11515
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006697385427116896,
      "loss": 2.1855,
      "step": 11516
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006695742369563739,
      "loss": 2.2148,
      "step": 11517
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006694099412140442,
      "loss": 2.4297,
      "step": 11518
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.000669245655489679,
      "loss": 2.168,
      "step": 11519
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.000669081379788257,
      "loss": 2.252,
      "step": 11520
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006689171141147562,
      "loss": 2.1523,
      "step": 11521
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006687528584741547,
      "loss": 2.3438,
      "step": 11522
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006685886128714289,
      "loss": 2.2539,
      "step": 11523
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006684243773115575,
      "loss": 2.2422,
      "step": 11524
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006682601517995163,
      "loss": 2.2773,
      "step": 11525
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006680959363402822,
      "loss": 2.2227,
      "step": 11526
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006679317309388314,
      "loss": 2.0918,
      "step": 11527
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006677675356001401,
      "loss": 2.1406,
      "step": 11528
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006676033503291836,
      "loss": 2.2812,
      "step": 11529
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006674391751309379,
      "loss": 2.1562,
      "step": 11530
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006672750100103768,
      "loss": 2.166,
      "step": 11531
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006671108549724766,
      "loss": 2.2363,
      "step": 11532
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006669467100222106,
      "loss": 2.2617,
      "step": 11533
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006667825751645536,
      "loss": 2.2305,
      "step": 11534
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006666184504044786,
      "loss": 2.1367,
      "step": 11535
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00066645433574696,
      "loss": 2.293,
      "step": 11536
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006662902311969709,
      "loss": 2.2578,
      "step": 11537
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006661261367594833,
      "loss": 2.1543,
      "step": 11538
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.000665962052439471,
      "loss": 2.2832,
      "step": 11539
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006657979782419056,
      "loss": 2.002,
      "step": 11540
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006656339141717593,
      "loss": 2.0859,
      "step": 11541
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006654698602340036,
      "loss": 2.3945,
      "step": 11542
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006653058164336101,
      "loss": 2.2441,
      "step": 11543
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006651417827755497,
      "loss": 2.0273,
      "step": 11544
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006649777592647937,
      "loss": 1.9805,
      "step": 11545
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006648137459063113,
      "loss": 2.2422,
      "step": 11546
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.000664649742705074,
      "loss": 2.3359,
      "step": 11547
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006644857496660508,
      "loss": 2.375,
      "step": 11548
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006643217667942116,
      "loss": 2.2109,
      "step": 11549
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006641577940945251,
      "loss": 2.4453,
      "step": 11550
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006639938315719611,
      "loss": 2.3027,
      "step": 11551
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006638298792314876,
      "loss": 2.3945,
      "step": 11552
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006636659370780733,
      "loss": 2.4141,
      "step": 11553
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006635020051166851,
      "loss": 2.0742,
      "step": 11554
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006633380833522922,
      "loss": 1.8457,
      "step": 11555
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006631741717898611,
      "loss": 2.2812,
      "step": 11556
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006630102704343589,
      "loss": 2.3711,
      "step": 11557
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006628463792907523,
      "loss": 2.2305,
      "step": 11558
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006626824983640081,
      "loss": 2.0801,
      "step": 11559
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006625186276590924,
      "loss": 2.2773,
      "step": 11560
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006623547671809706,
      "loss": 2.043,
      "step": 11561
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006621909169346083,
      "loss": 2.2207,
      "step": 11562
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006620270769249711,
      "loss": 2.3008,
      "step": 11563
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006618632471570236,
      "loss": 2.332,
      "step": 11564
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006616994276357304,
      "loss": 2.3594,
      "step": 11565
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006615356183660557,
      "loss": 2.3984,
      "step": 11566
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006613718193529636,
      "loss": 2.2383,
      "step": 11567
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006612080306014181,
      "loss": 2.4023,
      "step": 11568
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006610442521163818,
      "loss": 2.2578,
      "step": 11569
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.000660880483902818,
      "loss": 2.291,
      "step": 11570
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006607167259656895,
      "loss": 2.4258,
      "step": 11571
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006605529783099588,
      "loss": 2.0371,
      "step": 11572
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006603892409405881,
      "loss": 2.3828,
      "step": 11573
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006602255138625382,
      "loss": 2.3242,
      "step": 11574
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006600617970807719,
      "loss": 2.3906,
      "step": 11575
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006598980906002499,
      "loss": 2.1973,
      "step": 11576
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006597343944259324,
      "loss": 2.1934,
      "step": 11577
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006595707085627808,
      "loss": 2.2812,
      "step": 11578
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006594070330157549,
      "loss": 2.3906,
      "step": 11579
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006592433677898148,
      "loss": 2.2344,
      "step": 11580
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006590797128899198,
      "loss": 2.1992,
      "step": 11581
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0006589160683210293,
      "loss": 2.3555,
      "step": 11582
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006587524340881028,
      "loss": 2.2617,
      "step": 11583
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006585888101960981,
      "loss": 2.0488,
      "step": 11584
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006584251966499738,
      "loss": 2.2695,
      "step": 11585
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006582615934546883,
      "loss": 2.457,
      "step": 11586
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006580980006151989,
      "loss": 2.2109,
      "step": 11587
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006579344181364636,
      "loss": 2.2422,
      "step": 11588
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006577708460234383,
      "loss": 2.1504,
      "step": 11589
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006576072842810811,
      "loss": 2.2578,
      "step": 11590
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006574437329143478,
      "loss": 2.125,
      "step": 11591
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006572801919281946,
      "loss": 2.4922,
      "step": 11592
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006571166613275769,
      "loss": 2.2969,
      "step": 11593
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006569531411174512,
      "loss": 2.168,
      "step": 11594
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006567896313027722,
      "loss": 2.2656,
      "step": 11595
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006566261318884947,
      "loss": 2.1211,
      "step": 11596
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006564626428795728,
      "loss": 2.2656,
      "step": 11597
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006562991642809619,
      "loss": 2.4414,
      "step": 11598
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006561356960976151,
      "loss": 2.4219,
      "step": 11599
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006559722383344863,
      "loss": 2.2969,
      "step": 11600
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006558087909965285,
      "loss": 2.291,
      "step": 11601
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.000655645354088695,
      "loss": 2.2188,
      "step": 11602
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006554819276159388,
      "loss": 2.207,
      "step": 11603
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006553185115832117,
      "loss": 2.2031,
      "step": 11604
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006551551059954655,
      "loss": 2.3359,
      "step": 11605
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006549917108576526,
      "loss": 2.293,
      "step": 11606
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006548283261747244,
      "loss": 2.3555,
      "step": 11607
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006546649519516315,
      "loss": 2.2539,
      "step": 11608
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006545015881933247,
      "loss": 2.2812,
      "step": 11609
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006543382349047549,
      "loss": 2.2695,
      "step": 11610
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006541748920908723,
      "loss": 2.084,
      "step": 11611
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006540115597566257,
      "loss": 2.207,
      "step": 11612
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006538482379069661,
      "loss": 2.2461,
      "step": 11613
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006536849265468416,
      "loss": 2.1719,
      "step": 11614
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006535216256812015,
      "loss": 2.1348,
      "step": 11615
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006533583353149941,
      "loss": 2.2578,
      "step": 11616
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006531950554531679,
      "loss": 2.2266,
      "step": 11617
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.000653031786100671,
      "loss": 2.1289,
      "step": 11618
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006528685272624504,
      "loss": 2.2383,
      "step": 11619
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006527052789434536,
      "loss": 2.2656,
      "step": 11620
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006525420411486276,
      "loss": 2.2188,
      "step": 11621
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006523788138829193,
      "loss": 2.125,
      "step": 11622
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006522155971512748,
      "loss": 2.1738,
      "step": 11623
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006520523909586398,
      "loss": 2.2578,
      "step": 11624
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006518891953099606,
      "loss": 2.3984,
      "step": 11625
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006517260102101826,
      "loss": 2.0762,
      "step": 11626
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00065156283566425,
      "loss": 2.2148,
      "step": 11627
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.000651399671677108,
      "loss": 2.043,
      "step": 11628
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006512365182537012,
      "loss": 2.3555,
      "step": 11629
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006510733753989735,
      "loss": 2.2969,
      "step": 11630
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006509102431178686,
      "loss": 2.3398,
      "step": 11631
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00065074712141533,
      "loss": 2.1504,
      "step": 11632
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.000650584010296301,
      "loss": 2.4062,
      "step": 11633
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006504209097657243,
      "loss": 2.3945,
      "step": 11634
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006502578198285424,
      "loss": 2.125,
      "step": 11635
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.000650094740489697,
      "loss": 2.3105,
      "step": 11636
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006499316717541306,
      "loss": 2.2969,
      "step": 11637
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006497686136267844,
      "loss": 2.293,
      "step": 11638
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006496055661125999,
      "loss": 2.1973,
      "step": 11639
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006494425292165171,
      "loss": 2.2031,
      "step": 11640
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006492795029434779,
      "loss": 2.3086,
      "step": 11641
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006491164872984214,
      "loss": 2.4688,
      "step": 11642
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006489534822862881,
      "loss": 2.4531,
      "step": 11643
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006487904879120172,
      "loss": 2.1602,
      "step": 11644
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006486275041805483,
      "loss": 2.4102,
      "step": 11645
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006484645310968202,
      "loss": 2.3047,
      "step": 11646
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006483015686657718,
      "loss": 2.1484,
      "step": 11647
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006481386168923404,
      "loss": 2.123,
      "step": 11648
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006479756757814655,
      "loss": 2.1875,
      "step": 11649
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006478127453380837,
      "loss": 2.2305,
      "step": 11650
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006476498255671323,
      "loss": 2.2832,
      "step": 11651
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006474869164735488,
      "loss": 2.3516,
      "step": 11652
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006473240180622697,
      "loss": 2.248,
      "step": 11653
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006471611303382316,
      "loss": 2.4336,
      "step": 11654
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006469982533063696,
      "loss": 2.1855,
      "step": 11655
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006468353869716206,
      "loss": 2.2422,
      "step": 11656
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006466725313389192,
      "loss": 2.2441,
      "step": 11657
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.000646509686413201,
      "loss": 2.3672,
      "step": 11658
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006463468521994,
      "loss": 2.1211,
      "step": 11659
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006461840287024513,
      "loss": 2.4531,
      "step": 11660
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006460212159272888,
      "loss": 2.2695,
      "step": 11661
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006458584138788464,
      "loss": 2.3555,
      "step": 11662
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006456956225620568,
      "loss": 2.2344,
      "step": 11663
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006455328419818541,
      "loss": 2.3945,
      "step": 11664
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006453700721431706,
      "loss": 2.2031,
      "step": 11665
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006452073130509388,
      "loss": 2.2773,
      "step": 11666
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006450445647100904,
      "loss": 2.0762,
      "step": 11667
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006448818271255581,
      "loss": 2.4062,
      "step": 11668
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006447191003022732,
      "loss": 2.0547,
      "step": 11669
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006445563842451663,
      "loss": 2.2578,
      "step": 11670
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006443936789591682,
      "loss": 2.2656,
      "step": 11671
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006442309844492101,
      "loss": 2.3516,
      "step": 11672
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006440683007202216,
      "loss": 2.2812,
      "step": 11673
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006439056277771329,
      "loss": 2.125,
      "step": 11674
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0006437429656248732,
      "loss": 2.4844,
      "step": 11675
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.000643580314268372,
      "loss": 2.2676,
      "step": 11676
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006434176737125584,
      "loss": 2.1387,
      "step": 11677
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006432550439623601,
      "loss": 2.2617,
      "step": 11678
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006430924250227058,
      "loss": 2.0977,
      "step": 11679
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006429298168985236,
      "loss": 2.1484,
      "step": 11680
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006427672195947409,
      "loss": 2.4844,
      "step": 11681
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.000642604633116285,
      "loss": 2.1367,
      "step": 11682
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006424420574680821,
      "loss": 2.2812,
      "step": 11683
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006422794926550599,
      "loss": 2.2969,
      "step": 11684
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.000642116938682144,
      "loss": 2.2969,
      "step": 11685
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006419543955542603,
      "loss": 2.125,
      "step": 11686
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006417918632763347,
      "loss": 2.0566,
      "step": 11687
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006416293418532921,
      "loss": 2.2461,
      "step": 11688
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006414668312900578,
      "loss": 2.4258,
      "step": 11689
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006413043315915561,
      "loss": 2.3379,
      "step": 11690
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006411418427627114,
      "loss": 2.2637,
      "step": 11691
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.000640979364808448,
      "loss": 2.2695,
      "step": 11692
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006408168977336888,
      "loss": 2.168,
      "step": 11693
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006406544415433574,
      "loss": 2.1211,
      "step": 11694
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.000640491996242377,
      "loss": 2.2656,
      "step": 11695
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006403295618356699,
      "loss": 2.0234,
      "step": 11696
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006401671383281589,
      "loss": 2.1562,
      "step": 11697
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006400047257247648,
      "loss": 2.2109,
      "step": 11698
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006398423240304107,
      "loss": 2.123,
      "step": 11699
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006396799332500172,
      "loss": 2.3516,
      "step": 11700
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006395175533885051,
      "loss": 2.3594,
      "step": 11701
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.000639355184450795,
      "loss": 2.2812,
      "step": 11702
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006391928264418079,
      "loss": 2.0879,
      "step": 11703
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006390304793664631,
      "loss": 2.2656,
      "step": 11704
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006388681432296808,
      "loss": 2.4961,
      "step": 11705
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006387058180363793,
      "loss": 2.1992,
      "step": 11706
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006385435037914791,
      "loss": 2.3242,
      "step": 11707
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006383812004998978,
      "loss": 2.293,
      "step": 11708
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.000638218908166554,
      "loss": 2.1992,
      "step": 11709
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006380566267963654,
      "loss": 2.2695,
      "step": 11710
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006378943563942501,
      "loss": 2.1523,
      "step": 11711
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006377320969651255,
      "loss": 2.2129,
      "step": 11712
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006375698485139081,
      "loss": 2.332,
      "step": 11713
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006374076110455143,
      "loss": 2.2344,
      "step": 11714
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006372453845648617,
      "loss": 2.5664,
      "step": 11715
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006370831690768652,
      "loss": 2.3555,
      "step": 11716
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006369209645864409,
      "loss": 2.3711,
      "step": 11717
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006367587710985038,
      "loss": 2.123,
      "step": 11718
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006365965886179693,
      "loss": 2.3203,
      "step": 11719
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.000636434417149752,
      "loss": 2.25,
      "step": 11720
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.000636272256698766,
      "loss": 2.207,
      "step": 11721
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006361101072699252,
      "loss": 2.5059,
      "step": 11722
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006359479688681437,
      "loss": 2.3398,
      "step": 11723
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006357858414983344,
      "loss": 1.9785,
      "step": 11724
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006356237251654104,
      "loss": 2.3398,
      "step": 11725
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006354616198742846,
      "loss": 2.2969,
      "step": 11726
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006352995256298693,
      "loss": 2.3223,
      "step": 11727
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006351374424370764,
      "loss": 2.1895,
      "step": 11728
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.000634975370300817,
      "loss": 2.1992,
      "step": 11729
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006348133092260033,
      "loss": 2.2344,
      "step": 11730
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006346512592175459,
      "loss": 2.375,
      "step": 11731
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006344892202803554,
      "loss": 2.2539,
      "step": 11732
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006343271924193419,
      "loss": 2.2969,
      "step": 11733
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.000634165175639416,
      "loss": 2.2031,
      "step": 11734
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.000634003169945487,
      "loss": 2.4414,
      "step": 11735
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.000633841175342464,
      "loss": 2.0996,
      "step": 11736
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006336791918352561,
      "loss": 2.2266,
      "step": 11737
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006335172194287719,
      "loss": 2.2012,
      "step": 11738
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.00063335525812792,
      "loss": 2.3828,
      "step": 11739
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006331933079376082,
      "loss": 2.3906,
      "step": 11740
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006330313688627437,
      "loss": 2.2773,
      "step": 11741
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006328694409082344,
      "loss": 2.1348,
      "step": 11742
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006327075240789873,
      "loss": 2.2637,
      "step": 11743
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006325456183799084,
      "loss": 2.1758,
      "step": 11744
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.000632383723815904,
      "loss": 2.2812,
      "step": 11745
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006322218403918804,
      "loss": 2.2969,
      "step": 11746
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006320599681127434,
      "loss": 2.2734,
      "step": 11747
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006318981069833983,
      "loss": 2.25,
      "step": 11748
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006317362570087487,
      "loss": 2.1211,
      "step": 11749
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.000631574418193701,
      "loss": 2.3477,
      "step": 11750
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006314125905431585,
      "loss": 2.2656,
      "step": 11751
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006312507740620251,
      "loss": 2.1484,
      "step": 11752
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006310889687552043,
      "loss": 2.166,
      "step": 11753
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006309271746276,
      "loss": 2.0898,
      "step": 11754
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006307653916841143,
      "loss": 2.1055,
      "step": 11755
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006306036199296506,
      "loss": 2.0664,
      "step": 11756
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006304418593691098,
      "loss": 2.2344,
      "step": 11757
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006302801100073952,
      "loss": 2.2578,
      "step": 11758
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006301183718494076,
      "loss": 2.1953,
      "step": 11759
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006299566449000483,
      "loss": 2.543,
      "step": 11760
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006297949291642181,
      "loss": 2.3242,
      "step": 11761
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006296332246468177,
      "loss": 2.2109,
      "step": 11762
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006294715313527473,
      "loss": 2.127,
      "step": 11763
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006293098492869062,
      "loss": 2.1367,
      "step": 11764
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006291481784541948,
      "loss": 2.2559,
      "step": 11765
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006289865188595117,
      "loss": 2.2148,
      "step": 11766
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006288248705077554,
      "loss": 2.1914,
      "step": 11767
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0006286632334038249,
      "loss": 2.3828,
      "step": 11768
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006285016075526184,
      "loss": 2.1875,
      "step": 11769
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006283399929590335,
      "loss": 2.1094,
      "step": 11770
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006281783896279677,
      "loss": 2.2812,
      "step": 11771
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006280167975643176,
      "loss": 2.2285,
      "step": 11772
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006278552167729808,
      "loss": 2.1973,
      "step": 11773
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006276936472588533,
      "loss": 2.123,
      "step": 11774
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006275320890268312,
      "loss": 2.4453,
      "step": 11775
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006273705420818102,
      "loss": 2.3164,
      "step": 11776
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006272090064286859,
      "loss": 2.3086,
      "step": 11777
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006270474820723535,
      "loss": 2.2539,
      "step": 11778
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006268859690177073,
      "loss": 2.1602,
      "step": 11779
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006267244672696417,
      "loss": 2.3672,
      "step": 11780
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.000626562976833051,
      "loss": 2.3711,
      "step": 11781
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006264014977128287,
      "loss": 2.4336,
      "step": 11782
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006262400299138682,
      "loss": 2.043,
      "step": 11783
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006260785734410625,
      "loss": 2.0215,
      "step": 11784
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006259171282993044,
      "loss": 2.3008,
      "step": 11785
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006257556944934861,
      "loss": 2.3008,
      "step": 11786
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006255942720284997,
      "loss": 2.0898,
      "step": 11787
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006254328609092364,
      "loss": 2.3984,
      "step": 11788
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006252714611405879,
      "loss": 2.2285,
      "step": 11789
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006251100727274452,
      "loss": 2.2617,
      "step": 11790
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006249486956746988,
      "loss": 2.3984,
      "step": 11791
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006247873299872383,
      "loss": 2.2383,
      "step": 11792
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006246259756699548,
      "loss": 2.3438,
      "step": 11793
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006244646327277372,
      "loss": 2.2715,
      "step": 11794
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006243033011654746,
      "loss": 2.2383,
      "step": 11795
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.000624141980988056,
      "loss": 2.2344,
      "step": 11796
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006239806722003702,
      "loss": 2.3906,
      "step": 11797
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006238193748073052,
      "loss": 2.3086,
      "step": 11798
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006236580888137485,
      "loss": 2.1914,
      "step": 11799
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006234968142245882,
      "loss": 2.1582,
      "step": 11800
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006233355510447114,
      "loss": 2.3047,
      "step": 11801
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006231742992790044,
      "loss": 2.2227,
      "step": 11802
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006230130589323538,
      "loss": 2.3828,
      "step": 11803
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006228518300096461,
      "loss": 2.1719,
      "step": 11804
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006226906125157668,
      "loss": 2.2891,
      "step": 11805
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006225294064556011,
      "loss": 2.2051,
      "step": 11806
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006223682118340344,
      "loss": 2.1973,
      "step": 11807
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006222070286559514,
      "loss": 1.957,
      "step": 11808
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006220458569262365,
      "loss": 2.1797,
      "step": 11809
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006218846966497735,
      "loss": 2.3867,
      "step": 11810
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006217235478314461,
      "loss": 2.3594,
      "step": 11811
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.000621562410476138,
      "loss": 2.2109,
      "step": 11812
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006214012845887318,
      "loss": 2.543,
      "step": 11813
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006212401701741106,
      "loss": 2.2754,
      "step": 11814
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006210790672371558,
      "loss": 2.3867,
      "step": 11815
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006209179757827505,
      "loss": 2.1426,
      "step": 11816
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006207568958157757,
      "loss": 2.418,
      "step": 11817
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006205958273411125,
      "loss": 2.2461,
      "step": 11818
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006204347703636419,
      "loss": 2.3438,
      "step": 11819
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006202737248882449,
      "loss": 2.25,
      "step": 11820
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006201126909198011,
      "loss": 2.1914,
      "step": 11821
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006199516684631909,
      "loss": 2.3633,
      "step": 11822
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.000619790657523293,
      "loss": 2.2402,
      "step": 11823
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006196296581049877,
      "loss": 2.2266,
      "step": 11824
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.000619468670213153,
      "loss": 2.2363,
      "step": 11825
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006193076938526676,
      "loss": 2.2617,
      "step": 11826
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006191467290284091,
      "loss": 2.3398,
      "step": 11827
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006189857757452563,
      "loss": 2.3594,
      "step": 11828
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006188248340080861,
      "loss": 2.3438,
      "step": 11829
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006186639038217753,
      "loss": 2.3828,
      "step": 11830
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006185029851912007,
      "loss": 2.2539,
      "step": 11831
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006183420781212389,
      "loss": 1.9746,
      "step": 11832
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006181811826167658,
      "loss": 2.2891,
      "step": 11833
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.000618020298682657,
      "loss": 2.3594,
      "step": 11834
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.000617859426323788,
      "loss": 2.1406,
      "step": 11835
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006176985655450335,
      "loss": 2.1875,
      "step": 11836
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006175377163512688,
      "loss": 2.1875,
      "step": 11837
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006173768787473667,
      "loss": 2.2051,
      "step": 11838
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006172160527382027,
      "loss": 2.4805,
      "step": 11839
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006170552383286495,
      "loss": 2.209,
      "step": 11840
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006168944355235805,
      "loss": 2.3477,
      "step": 11841
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006167336443278684,
      "loss": 2.2129,
      "step": 11842
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006165728647463858,
      "loss": 2.2539,
      "step": 11843
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006164120967840052,
      "loss": 2.1836,
      "step": 11844
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006162513404455981,
      "loss": 2.3945,
      "step": 11845
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006160905957360354,
      "loss": 2.3594,
      "step": 11846
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.000615929862660189,
      "loss": 2.0371,
      "step": 11847
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006157691412229295,
      "loss": 2.1953,
      "step": 11848
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.000615608431429127,
      "loss": 2.2168,
      "step": 11849
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006154477332836516,
      "loss": 2.043,
      "step": 11850
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006152870467913731,
      "loss": 2.25,
      "step": 11851
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006151263719571612,
      "loss": 2.127,
      "step": 11852
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006149657087858842,
      "loss": 2.3418,
      "step": 11853
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006148050572824106,
      "loss": 2.2734,
      "step": 11854
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006146444174516094,
      "loss": 2.1602,
      "step": 11855
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006144837892983482,
      "loss": 2.127,
      "step": 11856
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006143231728274947,
      "loss": 2.4297,
      "step": 11857
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006141625680439153,
      "loss": 2.2266,
      "step": 11858
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006140019749524782,
      "loss": 2.2246,
      "step": 11859
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.000613841393558049,
      "loss": 2.3945,
      "step": 11860
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0006136808238654939,
      "loss": 2.4023,
      "step": 11861
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006135202658796787,
      "loss": 2.2969,
      "step": 11862
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006133597196054691,
      "loss": 2.2188,
      "step": 11863
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006131991850477301,
      "loss": 2.123,
      "step": 11864
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006130386622113265,
      "loss": 2.1914,
      "step": 11865
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006128781511011219,
      "loss": 2.2422,
      "step": 11866
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006127176517219816,
      "loss": 2.332,
      "step": 11867
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006125571640787684,
      "loss": 2.418,
      "step": 11868
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006123966881763458,
      "loss": 2.3867,
      "step": 11869
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006122362240195767,
      "loss": 2.2793,
      "step": 11870
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006120757716133237,
      "loss": 2.3164,
      "step": 11871
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006119153309624495,
      "loss": 2.2773,
      "step": 11872
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006117549020718148,
      "loss": 2.3438,
      "step": 11873
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006115944849462825,
      "loss": 2.2617,
      "step": 11874
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006114340795907129,
      "loss": 2.2891,
      "step": 11875
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.000611273686009967,
      "loss": 2.1074,
      "step": 11876
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006111133042089053,
      "loss": 2.2148,
      "step": 11877
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.000610952934192388,
      "loss": 2.1758,
      "step": 11878
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006107925759652748,
      "loss": 2.3359,
      "step": 11879
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006106322295324251,
      "loss": 2.2461,
      "step": 11880
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006104718948986974,
      "loss": 2.3477,
      "step": 11881
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006103115720689513,
      "loss": 2.3008,
      "step": 11882
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006101512610480444,
      "loss": 2.3945,
      "step": 11883
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.000609990961840835,
      "loss": 2.3086,
      "step": 11884
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006098306744521802,
      "loss": 2.2109,
      "step": 11885
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006096703988869379,
      "loss": 1.959,
      "step": 11886
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006095101351499646,
      "loss": 2.25,
      "step": 11887
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006093498832461173,
      "loss": 2.1035,
      "step": 11888
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006091896431802508,
      "loss": 2.3242,
      "step": 11889
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006090294149572227,
      "loss": 2.1738,
      "step": 11890
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006088691985818874,
      "loss": 2.1523,
      "step": 11891
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006087089940591,
      "loss": 2.2969,
      "step": 11892
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006085488013937154,
      "loss": 2.1641,
      "step": 11893
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.000608388620590588,
      "loss": 2.4023,
      "step": 11894
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.000608228451654572,
      "loss": 2.1758,
      "step": 11895
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006080682945905207,
      "loss": 2.3789,
      "step": 11896
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006079081494032872,
      "loss": 2.4844,
      "step": 11897
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006077480160977249,
      "loss": 2.1934,
      "step": 11898
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006075878946786863,
      "loss": 2.168,
      "step": 11899
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006074277851510235,
      "loss": 2.3164,
      "step": 11900
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006072676875195879,
      "loss": 2.1309,
      "step": 11901
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006071076017892319,
      "loss": 2.0762,
      "step": 11902
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006069475279648062,
      "loss": 2.2852,
      "step": 11903
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006067874660511613,
      "loss": 2.1992,
      "step": 11904
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006066274160531475,
      "loss": 2.1523,
      "step": 11905
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006064673779756156,
      "loss": 2.1562,
      "step": 11906
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006063073518234146,
      "loss": 2.2578,
      "step": 11907
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006061473376013945,
      "loss": 2.2754,
      "step": 11908
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.000605987335314403,
      "loss": 2.3516,
      "step": 11909
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006058273449672902,
      "loss": 2.2168,
      "step": 11910
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006056673665649033,
      "loss": 2.3281,
      "step": 11911
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006055074001120904,
      "loss": 2.2734,
      "step": 11912
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006053474456136994,
      "loss": 2.2109,
      "step": 11913
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.000605187503074577,
      "loss": 2.3047,
      "step": 11914
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006050275724995702,
      "loss": 2.1328,
      "step": 11915
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006048676538935251,
      "loss": 2.2773,
      "step": 11916
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006047077472612883,
      "loss": 2.3047,
      "step": 11917
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006045478526077052,
      "loss": 2.3281,
      "step": 11918
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006043879699376214,
      "loss": 2.0762,
      "step": 11919
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.000604228099255881,
      "loss": 2.1719,
      "step": 11920
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006040682405673297,
      "loss": 2.2637,
      "step": 11921
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006039083938768111,
      "loss": 2.3477,
      "step": 11922
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006037485591891694,
      "loss": 2.2773,
      "step": 11923
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006035887365092476,
      "loss": 2.2539,
      "step": 11924
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006034289258418897,
      "loss": 2.1211,
      "step": 11925
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006032691271919377,
      "loss": 2.3438,
      "step": 11926
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006031093405642345,
      "loss": 2.3066,
      "step": 11927
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006029495659636218,
      "loss": 2.209,
      "step": 11928
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006027898033949415,
      "loss": 2.4648,
      "step": 11929
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006026300528630351,
      "loss": 2.2344,
      "step": 11930
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006024703143727435,
      "loss": 2.2266,
      "step": 11931
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006023105879289066,
      "loss": 2.2812,
      "step": 11932
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006021508735363659,
      "loss": 2.5195,
      "step": 11933
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006019911711999602,
      "loss": 2.1328,
      "step": 11934
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006018314809245295,
      "loss": 2.0254,
      "step": 11935
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006016718027149126,
      "loss": 2.0488,
      "step": 11936
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006015121365759488,
      "loss": 2.2617,
      "step": 11937
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006013524825124764,
      "loss": 2.3281,
      "step": 11938
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006011928405293329,
      "loss": 2.2461,
      "step": 11939
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006010332106313563,
      "loss": 2.1641,
      "step": 11940
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006008735928233842,
      "loss": 2.0762,
      "step": 11941
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006007139871102531,
      "loss": 2.2773,
      "step": 11942
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006005543934967999,
      "loss": 2.1172,
      "step": 11943
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006003948119878605,
      "loss": 2.0098,
      "step": 11944
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006002352425882712,
      "loss": 2.2109,
      "step": 11945
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0006000756853028671,
      "loss": 2.1328,
      "step": 11946
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.000599916140136483,
      "loss": 2.4805,
      "step": 11947
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0005997566070939547,
      "loss": 2.3105,
      "step": 11948
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0005995970861801157,
      "loss": 2.3828,
      "step": 11949
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0005994375773998003,
      "loss": 2.1855,
      "step": 11950
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0005992780807578418,
      "loss": 2.166,
      "step": 11951
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0005991185962590737,
      "loss": 2.3867,
      "step": 11952
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0005989591239083294,
      "loss": 2.1953,
      "step": 11953
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0005987996637104409,
      "loss": 2.293,
      "step": 11954
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00059864021567024,
      "loss": 2.2383,
      "step": 11955
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005984807797925593,
      "loss": 2.2188,
      "step": 11956
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00059832135608223,
      "loss": 2.4102,
      "step": 11957
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005981619445440829,
      "loss": 2.2734,
      "step": 11958
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005980025451829486,
      "loss": 2.2539,
      "step": 11959
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005978431580036579,
      "loss": 2.3125,
      "step": 11960
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005976837830110409,
      "loss": 2.3047,
      "step": 11961
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005975244202099264,
      "loss": 2.293,
      "step": 11962
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005973650696051438,
      "loss": 2.4141,
      "step": 11963
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005972057312015225,
      "loss": 2.3125,
      "step": 11964
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005970464050038906,
      "loss": 2.3008,
      "step": 11965
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005968870910170763,
      "loss": 2.1348,
      "step": 11966
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005967277892459068,
      "loss": 2.3672,
      "step": 11967
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005965684996952106,
      "loss": 2.2969,
      "step": 11968
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.000596409222369814,
      "loss": 2.0898,
      "step": 11969
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005962499572745436,
      "loss": 2.4141,
      "step": 11970
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005960907044142254,
      "loss": 2.1582,
      "step": 11971
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005959314637936859,
      "loss": 2.2754,
      "step": 11972
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005957722354177503,
      "loss": 2.3086,
      "step": 11973
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005956130192912441,
      "loss": 2.1758,
      "step": 11974
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.000595453815418991,
      "loss": 2.2441,
      "step": 11975
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005952946238058168,
      "loss": 2.209,
      "step": 11976
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005951354444565447,
      "loss": 2.1406,
      "step": 11977
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005949762773759986,
      "loss": 2.4062,
      "step": 11978
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005948171225690014,
      "loss": 1.9824,
      "step": 11979
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005946579800403765,
      "loss": 2.1562,
      "step": 11980
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005944988497949464,
      "loss": 2.3633,
      "step": 11981
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005943397318375333,
      "loss": 2.3906,
      "step": 11982
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005941806261729582,
      "loss": 2.3555,
      "step": 11983
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005940215328060439,
      "loss": 2.3555,
      "step": 11984
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005938624517416104,
      "loss": 2.2617,
      "step": 11985
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005937033829844784,
      "loss": 2.3008,
      "step": 11986
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005935443265394689,
      "loss": 2.1738,
      "step": 11987
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005933852824114014,
      "loss": 2.1992,
      "step": 11988
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005932262506050956,
      "loss": 2.2383,
      "step": 11989
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00059306723112537,
      "loss": 2.2617,
      "step": 11990
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005929082239770447,
      "loss": 2.1211,
      "step": 11991
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005927492291649372,
      "loss": 2.2422,
      "step": 11992
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005925902466938658,
      "loss": 2.1094,
      "step": 11993
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005924312765686479,
      "loss": 2.3906,
      "step": 11994
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005922723187941013,
      "loss": 2.3203,
      "step": 11995
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005921133733750428,
      "loss": 2.4336,
      "step": 11996
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005919544403162891,
      "loss": 2.2695,
      "step": 11997
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005917955196226557,
      "loss": 2.2227,
      "step": 11998
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005916366112989594,
      "loss": 2.207,
      "step": 11999
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005914777153500151,
      "loss": 2.4062,
      "step": 12000
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005913188317806378,
      "loss": 2.1895,
      "step": 12001
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005911599605956423,
      "loss": 2.3516,
      "step": 12002
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.000591001101799843,
      "loss": 2.3242,
      "step": 12003
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005908422553980541,
      "loss": 2.2637,
      "step": 12004
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005906834213950887,
      "loss": 2.25,
      "step": 12005
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005905245997957598,
      "loss": 2.3555,
      "step": 12006
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.000590365790604881,
      "loss": 2.2129,
      "step": 12007
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005902069938272641,
      "loss": 2.5703,
      "step": 12008
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005900482094677214,
      "loss": 2.332,
      "step": 12009
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005898894375310643,
      "loss": 2.2695,
      "step": 12010
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005897306780221048,
      "loss": 2.4766,
      "step": 12011
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005895719309456536,
      "loss": 1.9043,
      "step": 12012
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005894131963065208,
      "loss": 2.3105,
      "step": 12013
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005892544741095166,
      "loss": 2.2637,
      "step": 12014
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005890957643594513,
      "loss": 2.2031,
      "step": 12015
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005889370670611341,
      "loss": 2.0723,
      "step": 12016
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005887783822193742,
      "loss": 2.4531,
      "step": 12017
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005886197098389793,
      "loss": 2.1562,
      "step": 12018
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005884610499247595,
      "loss": 2.0742,
      "step": 12019
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005883024024815214,
      "loss": 2.1953,
      "step": 12020
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005881437675140725,
      "loss": 2.3984,
      "step": 12021
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005879851450272206,
      "loss": 2.2734,
      "step": 12022
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005878265350257721,
      "loss": 2.2402,
      "step": 12023
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005876679375145336,
      "loss": 2.0918,
      "step": 12024
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005875093524983109,
      "loss": 2.2031,
      "step": 12025
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005873507799819097,
      "loss": 2.1797,
      "step": 12026
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005871922199701358,
      "loss": 2.25,
      "step": 12027
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005870336724677934,
      "loss": 2.2773,
      "step": 12028
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.000586875137479687,
      "loss": 2.2031,
      "step": 12029
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005867166150106211,
      "loss": 2.4805,
      "step": 12030
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005865581050653995,
      "loss": 2.2461,
      "step": 12031
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005863996076488254,
      "loss": 2.0625,
      "step": 12032
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005862411227657014,
      "loss": 2.1074,
      "step": 12033
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005860826504208309,
      "loss": 2.2422,
      "step": 12034
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005859241906190156,
      "loss": 2.4102,
      "step": 12035
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005857657433650575,
      "loss": 2.1973,
      "step": 12036
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005856073086637579,
      "loss": 2.0762,
      "step": 12037
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005854488865199182,
      "loss": 2.5156,
      "step": 12038
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005852904769383389,
      "loss": 2.0254,
      "step": 12039
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005851320799238206,
      "loss": 2.3789,
      "step": 12040
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005849736954811624,
      "loss": 2.2656,
      "step": 12041
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005848153236151653,
      "loss": 2.0684,
      "step": 12042
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005846569643306274,
      "loss": 2.1543,
      "step": 12043
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005844986176323477,
      "loss": 2.3906,
      "step": 12044
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005843402835251247,
      "loss": 2.4238,
      "step": 12045
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005841819620137565,
      "loss": 2.168,
      "step": 12046
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005840236531030412,
      "loss": 2.0586,
      "step": 12047
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005838653567977752,
      "loss": 2.3828,
      "step": 12048
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005837070731027557,
      "loss": 2.3633,
      "step": 12049
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005835488020227793,
      "loss": 2.1758,
      "step": 12050
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005833905435626424,
      "loss": 2.2578,
      "step": 12051
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005832322977271407,
      "loss": 2.4453,
      "step": 12052
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005830740645210689,
      "loss": 2.2539,
      "step": 12053
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005829158439492226,
      "loss": 2.2891,
      "step": 12054
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005827576360163965,
      "loss": 2.1016,
      "step": 12055
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005825994407273842,
      "loss": 2.1777,
      "step": 12056
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00058244125808698,
      "loss": 2.375,
      "step": 12057
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005822830880999777,
      "loss": 2.0977,
      "step": 12058
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00058212493077117,
      "loss": 2.2852,
      "step": 12059
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005819667861053486,
      "loss": 2.375,
      "step": 12060
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005818086541073076,
      "loss": 2.1367,
      "step": 12061
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005816505347818381,
      "loss": 2.3125,
      "step": 12062
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005814924281337311,
      "loss": 2.2793,
      "step": 12063
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005813343341677784,
      "loss": 2.2891,
      "step": 12064
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005811762528887709,
      "loss": 2.168,
      "step": 12065
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005810181843014986,
      "loss": 2.3281,
      "step": 12066
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005808601284107513,
      "loss": 2.2266,
      "step": 12067
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005807020852213189,
      "loss": 2.3203,
      "step": 12068
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.000580544054737991,
      "loss": 2.2734,
      "step": 12069
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005803860369655558,
      "loss": 2.1836,
      "step": 12070
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005802280319088023,
      "loss": 2.2168,
      "step": 12071
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.000580070039572518,
      "loss": 2.1523,
      "step": 12072
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005799120599614909,
      "loss": 1.9746,
      "step": 12073
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005797540930805085,
      "loss": 2.4531,
      "step": 12074
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005795961389343577,
      "loss": 2.2148,
      "step": 12075
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005794381975278243,
      "loss": 2.2988,
      "step": 12076
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005792802688656951,
      "loss": 2.0449,
      "step": 12077
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005791223529527561,
      "loss": 2.2227,
      "step": 12078
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005789644497937922,
      "loss": 2.3008,
      "step": 12079
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005788065593935878,
      "loss": 2.2109,
      "step": 12080
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005786486817569291,
      "loss": 2.1055,
      "step": 12081
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005784908168885993,
      "loss": 2.127,
      "step": 12082
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005783329647933819,
      "loss": 2.2578,
      "step": 12083
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005781751254760607,
      "loss": 2.4453,
      "step": 12084
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005780172989414193,
      "loss": 2.2383,
      "step": 12085
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005778594851942395,
      "loss": 2.3477,
      "step": 12086
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005777016842393043,
      "loss": 2.5,
      "step": 12087
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005775438960813948,
      "loss": 2.3164,
      "step": 12088
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005773861207252935,
      "loss": 2.2441,
      "step": 12089
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005772283581757803,
      "loss": 2.2461,
      "step": 12090
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005770706084376371,
      "loss": 2.3672,
      "step": 12091
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005769128715156434,
      "loss": 2.2461,
      "step": 12092
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005767551474145793,
      "loss": 2.4062,
      "step": 12093
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.000576597436139225,
      "loss": 2.2852,
      "step": 12094
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005764397376943587,
      "loss": 2.3984,
      "step": 12095
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005762820520847598,
      "loss": 1.8457,
      "step": 12096
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005761243793152069,
      "loss": 2.1016,
      "step": 12097
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005759667193904777,
      "loss": 2.3477,
      "step": 12098
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005758090723153492,
      "loss": 2.1641,
      "step": 12099
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005756514380945993,
      "loss": 2.293,
      "step": 12100
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005754938167330051,
      "loss": 2.2578,
      "step": 12101
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005753362082353427,
      "loss": 2.2891,
      "step": 12102
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005751786126063874,
      "loss": 2.4375,
      "step": 12103
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005750210298509162,
      "loss": 2.207,
      "step": 12104
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005748634599737039,
      "loss": 2.3711,
      "step": 12105
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005747059029795249,
      "loss": 2.3105,
      "step": 12106
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005745483588731541,
      "loss": 2.252,
      "step": 12107
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005743908276593658,
      "loss": 2.2695,
      "step": 12108
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.000574233309342933,
      "loss": 2.3555,
      "step": 12109
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005740758039286301,
      "loss": 2.293,
      "step": 12110
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.000573918311421229,
      "loss": 2.2148,
      "step": 12111
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.000573760831825503,
      "loss": 2.0059,
      "step": 12112
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005736033651462235,
      "loss": 2.3125,
      "step": 12113
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005734459113881631,
      "loss": 2.1699,
      "step": 12114
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005732884705560923,
      "loss": 2.3359,
      "step": 12115
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005731310426547824,
      "loss": 2.1367,
      "step": 12116
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005729736276890048,
      "loss": 2.2969,
      "step": 12117
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005728162256635286,
      "loss": 2.3828,
      "step": 12118
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005726588365831238,
      "loss": 2.0898,
      "step": 12119
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00057250146045256,
      "loss": 2.168,
      "step": 12120
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005723440972766065,
      "loss": 2.4336,
      "step": 12121
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005721867470600313,
      "loss": 2.2656,
      "step": 12122
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005720294098076028,
      "loss": 2.2344,
      "step": 12123
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005718720855240896,
      "loss": 2.1836,
      "step": 12124
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005717147742142585,
      "loss": 2.3398,
      "step": 12125
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005715574758828761,
      "loss": 2.1211,
      "step": 12126
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005714001905347094,
      "loss": 2.2266,
      "step": 12127
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005712429181745256,
      "loss": 2.1191,
      "step": 12128
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.000571085658807089,
      "loss": 2.1973,
      "step": 12129
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005709284124371663,
      "loss": 2.5352,
      "step": 12130
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005707711790695218,
      "loss": 2.1484,
      "step": 12131
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005706139587089209,
      "loss": 2.168,
      "step": 12132
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005704567513601271,
      "loss": 2.2344,
      "step": 12133
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005702995570279046,
      "loss": 2.3516,
      "step": 12134
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005701423757170175,
      "loss": 2.3281,
      "step": 12135
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.000569985207432228,
      "loss": 2.2988,
      "step": 12136
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005698280521782997,
      "loss": 2.3672,
      "step": 12137
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.000569670909959994,
      "loss": 2.1445,
      "step": 12138
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005695137807820731,
      "loss": 2.1836,
      "step": 12139
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005693566646492994,
      "loss": 2.293,
      "step": 12140
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005691995615664332,
      "loss": 2.2852,
      "step": 12141
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.000569042471538235,
      "loss": 2.1211,
      "step": 12142
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005688853945694655,
      "loss": 2.5039,
      "step": 12143
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005687283306648851,
      "loss": 2.043,
      "step": 12144
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005685712798292529,
      "loss": 2.2422,
      "step": 12145
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005684142420673273,
      "loss": 2.2168,
      "step": 12146
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005682572173838687,
      "loss": 2.2617,
      "step": 12147
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005681002057836345,
      "loss": 2.2734,
      "step": 12148
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005679432072713825,
      "loss": 2.4648,
      "step": 12149
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005677862218518705,
      "loss": 2.3281,
      "step": 12150
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.000567629249529856,
      "loss": 2.3711,
      "step": 12151
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005674722903100953,
      "loss": 2.2812,
      "step": 12152
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005673153441973451,
      "loss": 2.3555,
      "step": 12153
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.000567158411196361,
      "loss": 2.1816,
      "step": 12154
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005670014913118994,
      "loss": 2.4453,
      "step": 12155
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005668445845487144,
      "loss": 2.2617,
      "step": 12156
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005666876909115616,
      "loss": 2.3672,
      "step": 12157
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.000566530810405195,
      "loss": 2.1465,
      "step": 12158
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005663739430343684,
      "loss": 2.3008,
      "step": 12159
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005662170888038363,
      "loss": 2.2656,
      "step": 12160
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005660602477183512,
      "loss": 2.0273,
      "step": 12161
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005659034197826655,
      "loss": 2.1387,
      "step": 12162
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005657466050015323,
      "loss": 2.3828,
      "step": 12163
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005655898033797038,
      "loss": 2.2559,
      "step": 12164
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005654330149219309,
      "loss": 2.3203,
      "step": 12165
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005652762396329649,
      "loss": 2.3477,
      "step": 12166
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005651194775175573,
      "loss": 2.2969,
      "step": 12167
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.000564962728580458,
      "loss": 2.2734,
      "step": 12168
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005648059928264163,
      "loss": 2.1387,
      "step": 12169
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005646492702601833,
      "loss": 2.2148,
      "step": 12170
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005644925608865075,
      "loss": 2.2285,
      "step": 12171
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005643358647101373,
      "loss": 2.3398,
      "step": 12172
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005641791817358215,
      "loss": 2.3984,
      "step": 12173
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005640225119683083,
      "loss": 2.2969,
      "step": 12174
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005638658554123448,
      "loss": 2.2773,
      "step": 12175
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005637092120726789,
      "loss": 2.2266,
      "step": 12176
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005635525819540566,
      "loss": 2.0469,
      "step": 12177
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.000563395965061225,
      "loss": 2.3516,
      "step": 12178
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005632393613989298,
      "loss": 2.2227,
      "step": 12179
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005630827709719166,
      "loss": 2.3516,
      "step": 12180
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005629261937849304,
      "loss": 2.3438,
      "step": 12181
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005627696298427162,
      "loss": 2.1387,
      "step": 12182
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005626130791500188,
      "loss": 2.3145,
      "step": 12183
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005624565417115819,
      "loss": 2.0586,
      "step": 12184
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005623000175321486,
      "loss": 2.0625,
      "step": 12185
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005621435066164626,
      "loss": 2.3359,
      "step": 12186
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005619870089692671,
      "loss": 2.2656,
      "step": 12187
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005618305245953033,
      "loss": 2.375,
      "step": 12188
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005616740534993142,
      "loss": 2.2227,
      "step": 12189
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005615175956860414,
      "loss": 2.2539,
      "step": 12190
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005613611511602257,
      "loss": 2.2578,
      "step": 12191
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005612047199266077,
      "loss": 2.207,
      "step": 12192
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005610483019899279,
      "loss": 2.2109,
      "step": 12193
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005608918973549271,
      "loss": 2.2969,
      "step": 12194
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005607355060263435,
      "loss": 2.25,
      "step": 12195
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005605791280089174,
      "loss": 2.1152,
      "step": 12196
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005604227633073868,
      "loss": 2.2617,
      "step": 12197
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005602664119264909,
      "loss": 2.1836,
      "step": 12198
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005601100738709667,
      "loss": 2.0859,
      "step": 12199
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005599537491455526,
      "loss": 2.3477,
      "step": 12200
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005597974377549849,
      "loss": 2.3301,
      "step": 12201
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005596411397040009,
      "loss": 2.3789,
      "step": 12202
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005594848549973372,
      "loss": 2.3242,
      "step": 12203
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005593285836397295,
      "loss": 2.1914,
      "step": 12204
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005591723256359124,
      "loss": 2.0742,
      "step": 12205
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005590160809906226,
      "loss": 2.1445,
      "step": 12206
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005588598497085942,
      "loss": 2.2441,
      "step": 12207
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005587036317945608,
      "loss": 2.0996,
      "step": 12208
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005585474272532571,
      "loss": 2.1152,
      "step": 12209
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005583912360894169,
      "loss": 2.125,
      "step": 12210
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005582350583077728,
      "loss": 2.4414,
      "step": 12211
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005580788939130567,
      "loss": 2.2383,
      "step": 12212
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005579227429100026,
      "loss": 2.1719,
      "step": 12213
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005577666053033414,
      "loss": 2.0762,
      "step": 12214
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005576104810978044,
      "loss": 2.1523,
      "step": 12215
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.000557454370298123,
      "loss": 2.1602,
      "step": 12216
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005572982729090284,
      "loss": 2.4141,
      "step": 12217
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005571421889352497,
      "loss": 2.4219,
      "step": 12218
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005569861183815178,
      "loss": 2.1367,
      "step": 12219
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005568300612525614,
      "loss": 2.1387,
      "step": 12220
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005566740175531102,
      "loss": 2.3242,
      "step": 12221
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005565179872878921,
      "loss": 2.3438,
      "step": 12222
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005563619704616363,
      "loss": 2.4141,
      "step": 12223
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005562059670790695,
      "loss": 2.4609,
      "step": 12224
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005560499771449197,
      "loss": 2.3125,
      "step": 12225
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005558940006639144,
      "loss": 2.1484,
      "step": 12226
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005557380376407797,
      "loss": 2.2852,
      "step": 12227
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005555820880802411,
      "loss": 2.3906,
      "step": 12228
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005554261519870254,
      "loss": 2.3398,
      "step": 12229
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005552702293658578,
      "loss": 2.4453,
      "step": 12230
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005551143202214628,
      "loss": 2.1348,
      "step": 12231
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005549584245585653,
      "loss": 2.2168,
      "step": 12232
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005548025423818897,
      "loss": 2.3398,
      "step": 12233
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005546466736961595,
      "loss": 2.4609,
      "step": 12234
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005544908185060975,
      "loss": 2.0957,
      "step": 12235
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005543349768164273,
      "loss": 2.25,
      "step": 12236
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005541791486318715,
      "loss": 2.3477,
      "step": 12237
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005540233339571517,
      "loss": 2.3633,
      "step": 12238
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00055386753279699,
      "loss": 2.3711,
      "step": 12239
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005537117451561071,
      "loss": 2.1621,
      "step": 12240
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005535559710392248,
      "loss": 2.1055,
      "step": 12241
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005534002104510627,
      "loss": 2.3711,
      "step": 12242
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005532444633963416,
      "loss": 2.2578,
      "step": 12243
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005530887298797804,
      "loss": 2.4062,
      "step": 12244
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005529330099060988,
      "loss": 2.2168,
      "step": 12245
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005527773034800156,
      "loss": 2.2891,
      "step": 12246
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005526216106062489,
      "loss": 2.4883,
      "step": 12247
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005524659312895171,
      "loss": 2.0703,
      "step": 12248
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005523102655345379,
      "loss": 2.2539,
      "step": 12249
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005521546133460283,
      "loss": 2.3086,
      "step": 12250
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005519989747287045,
      "loss": 2.2266,
      "step": 12251
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005518433496872835,
      "loss": 2.2812,
      "step": 12252
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005516877382264813,
      "loss": 2.25,
      "step": 12253
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005515321403510134,
      "loss": 2.0781,
      "step": 12254
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005513765560655941,
      "loss": 2.1406,
      "step": 12255
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005512209853749395,
      "loss": 2.3828,
      "step": 12256
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.000551065428283763,
      "loss": 2.2773,
      "step": 12257
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005509098847967785,
      "loss": 2.1523,
      "step": 12258
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005507543549186997,
      "loss": 2.1348,
      "step": 12259
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005505988386542399,
      "loss": 2.1074,
      "step": 12260
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005504433360081112,
      "loss": 2.1699,
      "step": 12261
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005502878469850263,
      "loss": 2.4258,
      "step": 12262
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005501323715896967,
      "loss": 2.2891,
      "step": 12263
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005499769098268343,
      "loss": 2.3125,
      "step": 12264
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005498214617011494,
      "loss": 2.2422,
      "step": 12265
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005496660272173532,
      "loss": 2.4883,
      "step": 12266
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005495106063801554,
      "loss": 2.252,
      "step": 12267
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.000549355199194266,
      "loss": 2.3984,
      "step": 12268
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005491998056643947,
      "loss": 2.2188,
      "step": 12269
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00054904442579525,
      "loss": 2.2617,
      "step": 12270
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005488890595915399,
      "loss": 2.2188,
      "step": 12271
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005487337070579736,
      "loss": 2.3711,
      "step": 12272
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005485783681992587,
      "loss": 2.125,
      "step": 12273
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005484230430201014,
      "loss": 2.2734,
      "step": 12274
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005482677315252094,
      "loss": 2.2344,
      "step": 12275
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005481124337192892,
      "loss": 2.2754,
      "step": 12276
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005479571496070468,
      "loss": 2.3008,
      "step": 12277
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005478018791931871,
      "loss": 2.1875,
      "step": 12278
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005476466224824159,
      "loss": 2.2656,
      "step": 12279
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005474913794794383,
      "loss": 2.2012,
      "step": 12280
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.000547336150188958,
      "loss": 2.2344,
      "step": 12281
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005471809346156792,
      "loss": 2.1953,
      "step": 12282
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005470257327643059,
      "loss": 2.3633,
      "step": 12283
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005468705446395405,
      "loss": 2.1914,
      "step": 12284
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005467153702460863,
      "loss": 2.2109,
      "step": 12285
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.000546560209588645,
      "loss": 2.2227,
      "step": 12286
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005464050626719192,
      "loss": 2.25,
      "step": 12287
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005462499295006098,
      "loss": 2.4297,
      "step": 12288
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.000546094810079418,
      "loss": 2.1777,
      "step": 12289
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005459397044130446,
      "loss": 2.2227,
      "step": 12290
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005457846125061891,
      "loss": 2.3945,
      "step": 12291
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005456295343635526,
      "loss": 2.2773,
      "step": 12292
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005454744699898335,
      "loss": 2.3066,
      "step": 12293
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005453194193897308,
      "loss": 2.1016,
      "step": 12294
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005451643825679431,
      "loss": 2.0898,
      "step": 12295
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005450093595291692,
      "loss": 2.332,
      "step": 12296
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005448543502781057,
      "loss": 2.4922,
      "step": 12297
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005446993548194506,
      "loss": 2.4062,
      "step": 12298
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005445443731579008,
      "loss": 2.293,
      "step": 12299
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005443894052981527,
      "loss": 2.1738,
      "step": 12300
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005442344512449019,
      "loss": 2.2891,
      "step": 12301
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005440795110028443,
      "loss": 2.125,
      "step": 12302
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005439245845766754,
      "loss": 2.2422,
      "step": 12303
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005437696719710894,
      "loss": 2.4414,
      "step": 12304
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005436147731907815,
      "loss": 2.3047,
      "step": 12305
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005434598882404445,
      "loss": 2.4297,
      "step": 12306
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.000543305017124773,
      "loss": 2.3398,
      "step": 12307
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005431501598484592,
      "loss": 2.1641,
      "step": 12308
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005429953164161967,
      "loss": 2.3047,
      "step": 12309
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005428404868326769,
      "loss": 2.0684,
      "step": 12310
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005426856711025919,
      "loss": 2.2852,
      "step": 12311
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005425308692306338,
      "loss": 2.1992,
      "step": 12312
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005423760812214931,
      "loss": 2.2734,
      "step": 12313
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005422213070798594,
      "loss": 2.3047,
      "step": 12314
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005420665468104246,
      "loss": 2.2988,
      "step": 12315
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005419118004178778,
      "loss": 2.207,
      "step": 12316
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005417570679069076,
      "loss": 2.1992,
      "step": 12317
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005416023492822035,
      "loss": 2.0059,
      "step": 12318
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005414476445484546,
      "loss": 2.2852,
      "step": 12319
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005412929537103482,
      "loss": 2.3438,
      "step": 12320
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005411382767725713,
      "loss": 2.3242,
      "step": 12321
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005409836137398125,
      "loss": 2.4727,
      "step": 12322
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005408289646167581,
      "loss": 2.3633,
      "step": 12323
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.000540674329408094,
      "loss": 2.293,
      "step": 12324
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005405197081185065,
      "loss": 2.3633,
      "step": 12325
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005403651007526815,
      "loss": 2.0977,
      "step": 12326
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005402105073153034,
      "loss": 2.4258,
      "step": 12327
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005400559278110577,
      "loss": 2.2148,
      "step": 12328
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005399013622446277,
      "loss": 2.3008,
      "step": 12329
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005397468106206982,
      "loss": 2.3086,
      "step": 12330
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005395922729439518,
      "loss": 2.3242,
      "step": 12331
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005394377492190723,
      "loss": 2.3438,
      "step": 12332
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005392832394507415,
      "loss": 2.4297,
      "step": 12333
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005391287436436418,
      "loss": 2.082,
      "step": 12334
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005389742618024556,
      "loss": 2.4688,
      "step": 12335
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005388197939318636,
      "loss": 2.4102,
      "step": 12336
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005386653400365462,
      "loss": 2.2266,
      "step": 12337
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005385109001211846,
      "loss": 2.3867,
      "step": 12338
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005383564741904587,
      "loss": 2.4102,
      "step": 12339
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.000538202062249048,
      "loss": 2.2773,
      "step": 12340
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005380476643016314,
      "loss": 2.3906,
      "step": 12341
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005378932803528887,
      "loss": 2.3164,
      "step": 12342
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005377389104074975,
      "loss": 2.4062,
      "step": 12343
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005375845544701352,
      "loss": 2.2422,
      "step": 12344
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00053743021254548,
      "loss": 2.3242,
      "step": 12345
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005372758846382091,
      "loss": 2.3164,
      "step": 12346
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005371215707529984,
      "loss": 2.1543,
      "step": 12347
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.000536967270894525,
      "loss": 2.3125,
      "step": 12348
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.000536812985067464,
      "loss": 2.3398,
      "step": 12349
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.000536658713276491,
      "loss": 2.0352,
      "step": 12350
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005365044555262812,
      "loss": 2.3125,
      "step": 12351
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005363502118215091,
      "loss": 2.3203,
      "step": 12352
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005361959821668481,
      "loss": 2.25,
      "step": 12353
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005360417665669723,
      "loss": 2.293,
      "step": 12354
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005358875650265556,
      "loss": 2.1348,
      "step": 12355
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005357333775502696,
      "loss": 2.4141,
      "step": 12356
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005355792041427874,
      "loss": 2.1738,
      "step": 12357
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005354250448087812,
      "loss": 2.3125,
      "step": 12358
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005352708995529221,
      "loss": 2.4062,
      "step": 12359
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.000535116768379881,
      "loss": 2.2812,
      "step": 12360
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005349626512943288,
      "loss": 2.0645,
      "step": 12361
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005348085483009361,
      "loss": 2.4297,
      "step": 12362
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005346544594043723,
      "loss": 2.0664,
      "step": 12363
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005345003846093068,
      "loss": 2.1367,
      "step": 12364
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005343463239204093,
      "loss": 2.293,
      "step": 12365
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005341922773423475,
      "loss": 2.207,
      "step": 12366
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005340382448797896,
      "loss": 2.4219,
      "step": 12367
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005338842265374035,
      "loss": 2.2812,
      "step": 12368
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005337302223198568,
      "loss": 2.1094,
      "step": 12369
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005335762322318154,
      "loss": 2.3477,
      "step": 12370
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005334222562779469,
      "loss": 2.1758,
      "step": 12371
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005332682944629161,
      "loss": 2.2227,
      "step": 12372
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005331143467913894,
      "loss": 2.0781,
      "step": 12373
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005329604132680314,
      "loss": 2.3438,
      "step": 12374
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005328064938975075,
      "loss": 2.2305,
      "step": 12375
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005326525886844809,
      "loss": 2.4297,
      "step": 12376
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005324986976336161,
      "loss": 2.1914,
      "step": 12377
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005323448207495769,
      "loss": 2.2188,
      "step": 12378
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005321909580370257,
      "loss": 2.2891,
      "step": 12379
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005320371095006242,
      "loss": 2.209,
      "step": 12380
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005318832751450365,
      "loss": 2.0703,
      "step": 12381
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.000531729454974923,
      "loss": 2.2852,
      "step": 12382
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.000531575648994945,
      "loss": 2.3281,
      "step": 12383
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005314218572097634,
      "loss": 2.2773,
      "step": 12384
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.000531268079624039,
      "loss": 2.2969,
      "step": 12385
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005311143162424317,
      "loss": 2.332,
      "step": 12386
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005309605670696003,
      "loss": 2.1523,
      "step": 12387
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005308068321102044,
      "loss": 2.3711,
      "step": 12388
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005306531113689032,
      "loss": 1.9766,
      "step": 12389
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.000530499404850354,
      "loss": 2.1152,
      "step": 12390
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005303457125592155,
      "loss": 2.3086,
      "step": 12391
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005301920345001442,
      "loss": 2.1328,
      "step": 12392
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005300383706777974,
      "loss": 2.2695,
      "step": 12393
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005298847210968323,
      "loss": 2.4766,
      "step": 12394
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005297310857619037,
      "loss": 2.25,
      "step": 12395
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005295774646776686,
      "loss": 2.3281,
      "step": 12396
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005294238578487812,
      "loss": 2.1738,
      "step": 12397
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005292702652798969,
      "loss": 2.207,
      "step": 12398
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005291166869756694,
      "loss": 2.1992,
      "step": 12399
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.000528963122940753,
      "loss": 2.2344,
      "step": 12400
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005288095731798017,
      "loss": 2.3008,
      "step": 12401
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005286560376974683,
      "loss": 2.2598,
      "step": 12402
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005285025164984046,
      "loss": 2.3906,
      "step": 12403
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005283490095872635,
      "loss": 2.0449,
      "step": 12404
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005281955169686972,
      "loss": 2.2305,
      "step": 12405
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005280420386473559,
      "loss": 2.1504,
      "step": 12406
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005278885746278913,
      "loss": 2.2344,
      "step": 12407
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.000527735124914954,
      "loss": 2.1465,
      "step": 12408
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005275816895131938,
      "loss": 2.2148,
      "step": 12409
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005274282684272597,
      "loss": 2.2754,
      "step": 12410
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005272748616618015,
      "loss": 2.2891,
      "step": 12411
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005271214692214681,
      "loss": 2.25,
      "step": 12412
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005269680911109072,
      "loss": 2.3398,
      "step": 12413
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005268147273347672,
      "loss": 2.2832,
      "step": 12414
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.000526661377897695,
      "loss": 2.2852,
      "step": 12415
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005265080428043383,
      "loss": 2.2891,
      "step": 12416
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005263547220593428,
      "loss": 2.4297,
      "step": 12417
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005262014156673554,
      "loss": 2.3164,
      "step": 12418
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005260481236330211,
      "loss": 2.5,
      "step": 12419
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005258948459609856,
      "loss": 2.2695,
      "step": 12420
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005257415826558937,
      "loss": 2.166,
      "step": 12421
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00052558833372239,
      "loss": 2.2031,
      "step": 12422
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005254350991651172,
      "loss": 2.0918,
      "step": 12423
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005252818789887206,
      "loss": 2.2539,
      "step": 12424
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005251286731978424,
      "loss": 2.2461,
      "step": 12425
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005249754817971249,
      "loss": 2.2734,
      "step": 12426
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005248223047912106,
      "loss": 2.3281,
      "step": 12427
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005246691421847418,
      "loss": 2.1426,
      "step": 12428
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005245159939823589,
      "loss": 2.334,
      "step": 12429
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005243628601887034,
      "loss": 2.0664,
      "step": 12430
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005242097408084159,
      "loss": 2.2617,
      "step": 12431
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.000524056635846136,
      "loss": 2.2383,
      "step": 12432
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005239035453065033,
      "loss": 2.2324,
      "step": 12433
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005237504691941569,
      "loss": 1.9883,
      "step": 12434
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005235974075137361,
      "loss": 2.3008,
      "step": 12435
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005234443602698782,
      "loss": 2.2812,
      "step": 12436
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005232913274672222,
      "loss": 2.2949,
      "step": 12437
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005231383091104045,
      "loss": 2.3086,
      "step": 12438
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005229853052040627,
      "loss": 2.1484,
      "step": 12439
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005228323157528326,
      "loss": 2.2695,
      "step": 12440
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005226793407613513,
      "loss": 2.2168,
      "step": 12441
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005225263802342534,
      "loss": 2.0059,
      "step": 12442
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005223734341761745,
      "loss": 2.1133,
      "step": 12443
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005222205025917499,
      "loss": 2.2227,
      "step": 12444
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005220675854856136,
      "loss": 2.1445,
      "step": 12445
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005219146828623985,
      "loss": 2.3789,
      "step": 12446
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005217617947267396,
      "loss": 2.2539,
      "step": 12447
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005216089210832696,
      "loss": 2.2305,
      "step": 12448
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00052145606193662,
      "loss": 2.1719,
      "step": 12449
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005213032172914239,
      "loss": 2.2617,
      "step": 12450
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005211503871523129,
      "loss": 2.4414,
      "step": 12451
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005209975715239182,
      "loss": 2.2637,
      "step": 12452
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005208447704108701,
      "loss": 2.1484,
      "step": 12453
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005206919838177992,
      "loss": 2.2559,
      "step": 12454
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005205392117493364,
      "loss": 2.1699,
      "step": 12455
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005203864542101098,
      "loss": 2.3164,
      "step": 12456
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005202337112047495,
      "loss": 2.2598,
      "step": 12457
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005200809827378833,
      "loss": 2.1953,
      "step": 12458
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005199282688141398,
      "loss": 2.166,
      "step": 12459
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.000519775569438147,
      "loss": 2.2656,
      "step": 12460
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.000519622884614532,
      "loss": 2.1914,
      "step": 12461
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005194702143479211,
      "loss": 2.1426,
      "step": 12462
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005193175586429412,
      "loss": 2.209,
      "step": 12463
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005191649175042186,
      "loss": 2.3125,
      "step": 12464
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005190122909363784,
      "loss": 2.0273,
      "step": 12465
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.000518859678944045,
      "loss": 2.4141,
      "step": 12466
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005187070815318445,
      "loss": 2.2129,
      "step": 12467
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005185544987044004,
      "loss": 2.4844,
      "step": 12468
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005184019304663361,
      "loss": 2.2031,
      "step": 12469
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005182493768222753,
      "loss": 2.2676,
      "step": 12470
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005180968377768412,
      "loss": 2.1777,
      "step": 12471
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005179443133346555,
      "loss": 2.375,
      "step": 12472
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005177918035003405,
      "loss": 2.1562,
      "step": 12473
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005176393082785182,
      "loss": 2.3984,
      "step": 12474
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005174868276738094,
      "loss": 2.291,
      "step": 12475
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005173343616908342,
      "loss": 2.293,
      "step": 12476
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005171819103342134,
      "loss": 2.1055,
      "step": 12477
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.000517029473608567,
      "loss": 2.4688,
      "step": 12478
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005168770515185137,
      "loss": 2.1875,
      "step": 12479
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.000516724644068673,
      "loss": 2.3203,
      "step": 12480
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005165722512636628,
      "loss": 2.3047,
      "step": 12481
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005164198731081017,
      "loss": 2.3066,
      "step": 12482
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005162675096066065,
      "loss": 2.2344,
      "step": 12483
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.000516115160763795,
      "loss": 2.0098,
      "step": 12484
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005159628265842835,
      "loss": 2.3594,
      "step": 12485
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005158105070726881,
      "loss": 2.4141,
      "step": 12486
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005156582022336251,
      "loss": 2.0176,
      "step": 12487
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005155059120717098,
      "loss": 2.3242,
      "step": 12488
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005153536365915559,
      "loss": 2.252,
      "step": 12489
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005152013757977796,
      "loss": 2.4492,
      "step": 12490
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005150491296949942,
      "loss": 2.1758,
      "step": 12491
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005148968982878127,
      "loss": 2.4453,
      "step": 12492
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005147446815808484,
      "loss": 2.1855,
      "step": 12493
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005145924795787149,
      "loss": 2.2598,
      "step": 12494
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005144402922860236,
      "loss": 2.3906,
      "step": 12495
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.000514288119707386,
      "loss": 2.1797,
      "step": 12496
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.000514135961847414,
      "loss": 2.3242,
      "step": 12497
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005139838187107187,
      "loss": 2.2891,
      "step": 12498
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005138316903019096,
      "loss": 2.6406,
      "step": 12499
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005136795766255977,
      "loss": 2.1797,
      "step": 12500
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005135274776863917,
      "loss": 2.2949,
      "step": 12501
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005133753934889011,
      "loss": 2.1426,
      "step": 12502
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005132233240377351,
      "loss": 2.3477,
      "step": 12503
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005130712693375008,
      "loss": 2.1543,
      "step": 12504
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.000512919229392807,
      "loss": 2.375,
      "step": 12505
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00051276720420826,
      "loss": 2.1953,
      "step": 12506
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005126151937884677,
      "loss": 2.2168,
      "step": 12507
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005124631981380355,
      "loss": 2.3047,
      "step": 12508
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00051231121726157,
      "loss": 2.2109,
      "step": 12509
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005121592511636768,
      "loss": 2.2402,
      "step": 12510
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005120072998489609,
      "loss": 2.375,
      "step": 12511
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005118553633220259,
      "loss": 2.2324,
      "step": 12512
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005117034415874776,
      "loss": 2.3008,
      "step": 12513
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005115515346499191,
      "loss": 2.1992,
      "step": 12514
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005113996425139531,
      "loss": 2.3594,
      "step": 12515
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005112477651841829,
      "loss": 2.2461,
      "step": 12516
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005110959026652112,
      "loss": 2.1289,
      "step": 12517
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005109440549616398,
      "loss": 2.3867,
      "step": 12518
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005107922220780694,
      "loss": 2.2109,
      "step": 12519
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005106404040191017,
      "loss": 2.3008,
      "step": 12520
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005104886007893376,
      "loss": 2.2305,
      "step": 12521
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005103368123933764,
      "loss": 2.293,
      "step": 12522
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005101850388358187,
      "loss": 2.2227,
      "step": 12523
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005100332801212628,
      "loss": 2.3984,
      "step": 12524
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005098815362543081,
      "loss": 2.3203,
      "step": 12525
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005097298072395531,
      "loss": 2.2969,
      "step": 12526
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005095780930815954,
      "loss": 2.3711,
      "step": 12527
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.000509426393785032,
      "loss": 2.4883,
      "step": 12528
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005092747093544603,
      "loss": 2.4258,
      "step": 12529
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005091230397944773,
      "loss": 2.3789,
      "step": 12530
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005089713851096786,
      "loss": 2.2734,
      "step": 12531
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005088197453046591,
      "loss": 2.1367,
      "step": 12532
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005086681203840156,
      "loss": 2.4453,
      "step": 12533
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.000508516510352342,
      "loss": 2.2773,
      "step": 12534
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.000508364915214232,
      "loss": 2.3711,
      "step": 12535
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005082133349742801,
      "loss": 2.0918,
      "step": 12536
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00050806176963708,
      "loss": 2.2441,
      "step": 12537
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005079102192072235,
      "loss": 2.25,
      "step": 12538
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005077586836893046,
      "loss": 2.1777,
      "step": 12539
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005076071630879139,
      "loss": 2.25,
      "step": 12540
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.000507455657407644,
      "loss": 2.1758,
      "step": 12541
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005073041666530852,
      "loss": 2.2051,
      "step": 12542
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005071526908288287,
      "loss": 2.1074,
      "step": 12543
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005070012299394647,
      "loss": 2.2227,
      "step": 12544
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005068497839895826,
      "loss": 2.2773,
      "step": 12545
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005066983529837723,
      "loss": 2.2969,
      "step": 12546
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.000506546936926622,
      "loss": 2.2285,
      "step": 12547
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005063955358227208,
      "loss": 2.2812,
      "step": 12548
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005062441496766558,
      "loss": 2.1914,
      "step": 12549
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005060927784930154,
      "loss": 2.3789,
      "step": 12550
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005059414222763857,
      "loss": 2.543,
      "step": 12551
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005057900810313538,
      "loss": 2.2148,
      "step": 12552
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005056387547625063,
      "loss": 2.1777,
      "step": 12553
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005054874434744285,
      "loss": 2.5273,
      "step": 12554
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005053361471717046,
      "loss": 2.123,
      "step": 12555
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005051848658589212,
      "loss": 2.0859,
      "step": 12556
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005050335995406616,
      "loss": 2.207,
      "step": 12557
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005048823482215097,
      "loss": 2.0312,
      "step": 12558
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005047311119060487,
      "loss": 2.2617,
      "step": 12559
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005045798905988625,
      "loss": 2.0547,
      "step": 12560
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005044286843045329,
      "loss": 2.3516,
      "step": 12561
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005042774930276415,
      "loss": 2.332,
      "step": 12562
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005041263167727706,
      "loss": 2.1875,
      "step": 12563
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005039751555445014,
      "loss": 2.25,
      "step": 12564
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005038240093474141,
      "loss": 2.2227,
      "step": 12565
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005036728781860894,
      "loss": 2.2031,
      "step": 12566
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005035217620651065,
      "loss": 2.1914,
      "step": 12567
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.000503370660989045,
      "loss": 2.2031,
      "step": 12568
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005032195749624843,
      "loss": 2.1445,
      "step": 12569
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005030685039900023,
      "loss": 2.3066,
      "step": 12570
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005029174480761765,
      "loss": 2.2852,
      "step": 12571
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005027664072255848,
      "loss": 2.127,
      "step": 12572
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005026153814428047,
      "loss": 2.4336,
      "step": 12573
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005024643707324123,
      "loss": 2.4297,
      "step": 12574
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005023133750989832,
      "loss": 2.2559,
      "step": 12575
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005021623945470943,
      "loss": 2.3672,
      "step": 12576
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005020114290813202,
      "loss": 2.1758,
      "step": 12577
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.000501860478706235,
      "loss": 2.3945,
      "step": 12578
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005017095434264138,
      "loss": 2.293,
      "step": 12579
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005015586232464306,
      "loss": 2.3281,
      "step": 12580
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005014077181708579,
      "loss": 2.1172,
      "step": 12581
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005012568282042693,
      "loss": 2.1797,
      "step": 12582
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005011059533512373,
      "loss": 2.207,
      "step": 12583
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005009550936163337,
      "loss": 2.2148,
      "step": 12584
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005008042490041298,
      "loss": 2.1094,
      "step": 12585
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005006534195191967,
      "loss": 2.3125,
      "step": 12586
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005005026051661057,
      "loss": 2.0508,
      "step": 12587
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005003518059494263,
      "loss": 2.3398,
      "step": 12588
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005002010218737287,
      "loss": 2.3262,
      "step": 12589
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0005000502529435814,
      "loss": 2.3047,
      "step": 12590
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0004998994991635537,
      "loss": 2.1602,
      "step": 12591
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0004997487605382144,
      "loss": 2.2734,
      "step": 12592
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0004995980370721308,
      "loss": 1.9883,
      "step": 12593
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0004994473287698701,
      "loss": 2.3242,
      "step": 12594
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0004992966356359994,
      "loss": 2.3711,
      "step": 12595
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0004991459576750859,
      "loss": 2.4258,
      "step": 12596
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0004989952948916951,
      "loss": 2.3906,
      "step": 12597
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0004988446472903917,
      "loss": 2.2227,
      "step": 12598
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0004986940148757425,
      "loss": 2.2773,
      "step": 12599
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0004985433976523114,
      "loss": 2.0605,
      "step": 12600
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0004983927956246621,
      "loss": 2.1621,
      "step": 12601
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0004982422087973587,
      "loss": 2.3242,
      "step": 12602
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0004980916371749651,
      "loss": 2.3555,
      "step": 12603
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.000497941080762043,
      "loss": 2.2539,
      "step": 12604
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0004977905395631559,
      "loss": 2.2383,
      "step": 12605
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004976400135828646,
      "loss": 2.3477,
      "step": 12606
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004974895028257315,
      "loss": 2.375,
      "step": 12607
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004973390072963166,
      "loss": 2.1641,
      "step": 12608
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004971885269991815,
      "loss": 2.1172,
      "step": 12609
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004970380619388851,
      "loss": 2.2168,
      "step": 12610
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004968876121199877,
      "loss": 2.3711,
      "step": 12611
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004967371775470486,
      "loss": 2.1562,
      "step": 12612
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004965867582246261,
      "loss": 2.209,
      "step": 12613
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004964363541572782,
      "loss": 2.2656,
      "step": 12614
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004962859653495627,
      "loss": 2.4453,
      "step": 12615
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004961355918060376,
      "loss": 2.207,
      "step": 12616
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004959852335312587,
      "loss": 2.2422,
      "step": 12617
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004958348905297828,
      "loss": 2.4883,
      "step": 12618
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004956845628061663,
      "loss": 2.2031,
      "step": 12619
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004955342503649641,
      "loss": 2.1719,
      "step": 12620
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004953839532107302,
      "loss": 2.4375,
      "step": 12621
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004952336713480211,
      "loss": 2.1992,
      "step": 12622
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004950834047813897,
      "loss": 2.4219,
      "step": 12623
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004949331535153893,
      "loss": 2.1973,
      "step": 12624
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004947829175545735,
      "loss": 2.2305,
      "step": 12625
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004946326969034953,
      "loss": 2.3477,
      "step": 12626
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004944824915667063,
      "loss": 2.043,
      "step": 12627
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004943323015487577,
      "loss": 2.1816,
      "step": 12628
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004941821268542018,
      "loss": 2.1348,
      "step": 12629
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004940319674875891,
      "loss": 2.2891,
      "step": 12630
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004938818234534694,
      "loss": 2.1055,
      "step": 12631
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004937316947563934,
      "loss": 2.3242,
      "step": 12632
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004935815814009098,
      "loss": 2.0527,
      "step": 12633
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004934314833915677,
      "loss": 2.2305,
      "step": 12634
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.000493281400732916,
      "loss": 2.0527,
      "step": 12635
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004931313334295023,
      "loss": 2.1836,
      "step": 12636
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004929812814858738,
      "loss": 2.293,
      "step": 12637
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004928312449065779,
      "loss": 2.4258,
      "step": 12638
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004926812236961616,
      "loss": 2.4375,
      "step": 12639
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004925312178591706,
      "loss": 2.207,
      "step": 12640
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00049238122740015,
      "loss": 2.2148,
      "step": 12641
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004922312523236464,
      "loss": 2.293,
      "step": 12642
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004920812926342038,
      "loss": 2.3242,
      "step": 12643
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.000491931348336366,
      "loss": 2.125,
      "step": 12644
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004917814194346773,
      "loss": 2.3945,
      "step": 12645
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004916315059336812,
      "loss": 2.2969,
      "step": 12646
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004914816078379202,
      "loss": 2.3809,
      "step": 12647
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004913317251519371,
      "loss": 2.3164,
      "step": 12648
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004911818578802734,
      "loss": 2.1191,
      "step": 12649
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.000491032006027471,
      "loss": 2.2051,
      "step": 12650
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004908821695980704,
      "loss": 2.3555,
      "step": 12651
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004907323485966127,
      "loss": 2.1484,
      "step": 12652
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004905825430276374,
      "loss": 2.291,
      "step": 12653
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004904327528956843,
      "loss": 2.1836,
      "step": 12654
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004902829782052931,
      "loss": 2.1797,
      "step": 12655
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004901332189610016,
      "loss": 2.2969,
      "step": 12656
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004899834751673487,
      "loss": 2.0137,
      "step": 12657
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004898337468288714,
      "loss": 2.3594,
      "step": 12658
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004896840339501078,
      "loss": 2.125,
      "step": 12659
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004895343365355939,
      "loss": 2.0332,
      "step": 12660
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004893846545898664,
      "loss": 2.4492,
      "step": 12661
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004892349881174615,
      "loss": 2.3359,
      "step": 12662
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004890853371229141,
      "loss": 2.2168,
      "step": 12663
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004889357016107587,
      "loss": 2.5859,
      "step": 12664
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004887860815855308,
      "loss": 2.4609,
      "step": 12665
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004886364770517641,
      "loss": 2.2422,
      "step": 12666
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004884868880139914,
      "loss": 2.3574,
      "step": 12667
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004883373144767462,
      "loss": 2.1504,
      "step": 12668
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00048818775644456146,
      "loss": 2.1289,
      "step": 12669
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.000488038213921969,
      "loss": 2.2812,
      "step": 12670
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00048788868691349984,
      "loss": 2.2695,
      "step": 12671
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004877391754236857,
      "loss": 2.3711,
      "step": 12672
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004875896794570577,
      "loss": 2.082,
      "step": 12673
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00048744019901814507,
      "loss": 2.3516,
      "step": 12674
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004872907341114785,
      "loss": 2.3125,
      "step": 12675
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004871412847415865,
      "loss": 2.1484,
      "step": 12676
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00048699185091299825,
      "loss": 2.1426,
      "step": 12677
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004868424326302423,
      "loss": 2.3516,
      "step": 12678
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00048669302989784636,
      "loss": 2.1562,
      "step": 12679
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004865436427203374,
      "loss": 2.1836,
      "step": 12680
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00048639427110224256,
      "loss": 2.1641,
      "step": 12681
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004862449150480888,
      "loss": 2.5195,
      "step": 12682
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00048609557456240126,
      "loss": 2.2773,
      "step": 12683
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00048594624964970603,
      "loss": 2.3555,
      "step": 12684
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00048579694031452826,
      "loss": 2.1211,
      "step": 12685
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004856476465613924,
      "loss": 2.2363,
      "step": 12686
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00048549836839482187,
      "loss": 2.0254,
      "step": 12687
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004853491058193409,
      "loss": 2.3242,
      "step": 12688
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004851998588394729,
      "loss": 2.2383,
      "step": 12689
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004850506274597398,
      "loss": 2.0664,
      "step": 12690
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00048490141168466426,
      "loss": 2.5,
      "step": 12691
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00048475221151876834,
      "loss": 2.2207,
      "step": 12692
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00048460302696657286,
      "loss": 2.2852,
      "step": 12693
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00048445385803259824,
      "loss": 2.1621,
      "step": 12694
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004843047047213652,
      "loss": 2.2227,
      "step": 12695
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00048415556703739404,
      "loss": 2.2344,
      "step": 12696
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0004840064449852032,
      "loss": 2.2773,
      "step": 12697
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00048385733856931237,
      "loss": 2.4375,
      "step": 12698
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004837082477942393,
      "loss": 2.2363,
      "step": 12699
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004835591726645021,
      "loss": 2.0918,
      "step": 12700
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00048341011318461894,
      "loss": 2.2383,
      "step": 12701
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004832610693591062,
      "loss": 2.2188,
      "step": 12702
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00048311204119248,
      "loss": 2.0352,
      "step": 12703
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004829630286892568,
      "loss": 2.168,
      "step": 12704
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00048281403185395266,
      "loss": 2.3242,
      "step": 12705
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00048266505069108226,
      "loss": 2.418,
      "step": 12706
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00048251608520515933,
      "loss": 2.3164,
      "step": 12707
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00048236713540069964,
      "loss": 2.2188,
      "step": 12708
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00048221820128221607,
      "loss": 2.3867,
      "step": 12709
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00048206928285422134,
      "loss": 2.3828,
      "step": 12710
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00048192038012122876,
      "loss": 2.1621,
      "step": 12711
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004817714930877508,
      "loss": 2.0781,
      "step": 12712
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004816226217582985,
      "loss": 2.2207,
      "step": 12713
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004814737661373839,
      "loss": 2.375,
      "step": 12714
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00048132492622951717,
      "loss": 2.2031,
      "step": 12715
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00048117610203920926,
      "loss": 2.3164,
      "step": 12716
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004810272935709692,
      "loss": 2.2852,
      "step": 12717
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004808785008293074,
      "loss": 2.25,
      "step": 12718
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004807297238187317,
      "loss": 2.2695,
      "step": 12719
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004805809625437512,
      "loss": 2.3945,
      "step": 12720
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00048043221700887407,
      "loss": 2.2539,
      "step": 12721
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004802834872186075,
      "loss": 2.2227,
      "step": 12722
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004801347731774579,
      "loss": 2.3164,
      "step": 12723
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047998607488993253,
      "loss": 2.3555,
      "step": 12724
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047983739236053745,
      "loss": 2.4492,
      "step": 12725
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047968872559377775,
      "loss": 2.25,
      "step": 12726
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047954007459415874,
      "loss": 2.1855,
      "step": 12727
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047939143936618543,
      "loss": 2.418,
      "step": 12728
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047924281991436167,
      "loss": 2.1914,
      "step": 12729
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004790942162431903,
      "loss": 2.0742,
      "step": 12730
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004789456283571759,
      "loss": 2.2344,
      "step": 12731
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004787970562608206,
      "loss": 2.0918,
      "step": 12732
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047864849995862623,
      "loss": 2.3242,
      "step": 12733
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004784999594550947,
      "loss": 2.1133,
      "step": 12734
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.000478351434754728,
      "loss": 2.2559,
      "step": 12735
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004782029258620262,
      "loss": 2.2148,
      "step": 12736
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004780544327814894,
      "loss": 2.3594,
      "step": 12737
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004779059555176178,
      "loss": 2.543,
      "step": 12738
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047775749407491107,
      "loss": 2.2617,
      "step": 12739
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004776090484578675,
      "loss": 2.1914,
      "step": 12740
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.000477460618670986,
      "loss": 2.3086,
      "step": 12741
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004773122047187638,
      "loss": 2.2188,
      "step": 12742
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004771638066056987,
      "loss": 2.207,
      "step": 12743
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047701542433628807,
      "loss": 2.1719,
      "step": 12744
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047686705791502804,
      "loss": 2.125,
      "step": 12745
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004767187073464141,
      "loss": 2.2734,
      "step": 12746
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047657037263494216,
      "loss": 2.1758,
      "step": 12747
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004764220537851078,
      "loss": 2.3047,
      "step": 12748
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047627375080140503,
      "loss": 2.3672,
      "step": 12749
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004761254636883272,
      "loss": 2.3008,
      "step": 12750
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047597719245036943,
      "loss": 2.2422,
      "step": 12751
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004758289370920239,
      "loss": 2.0977,
      "step": 12752
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047568069761778323,
      "loss": 2.3516,
      "step": 12753
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004755324740321395,
      "loss": 2.209,
      "step": 12754
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047538426633958507,
      "loss": 2.3633,
      "step": 12755
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047523607454461026,
      "loss": 2.1172,
      "step": 12756
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047508789865170645,
      "loss": 2.2305,
      "step": 12757
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004749397386653632,
      "loss": 2.0664,
      "step": 12758
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047479159459007093,
      "loss": 2.082,
      "step": 12759
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004746434664303183,
      "loss": 2.1406,
      "step": 12760
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004744953541905946,
      "loss": 2.3672,
      "step": 12761
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047434725787538746,
      "loss": 2.332,
      "step": 12762
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047419917748918515,
      "loss": 2.4922,
      "step": 12763
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004740511130364753,
      "loss": 2.2891,
      "step": 12764
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004739030645217439,
      "loss": 2.3711,
      "step": 12765
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004737550319494779,
      "loss": 2.3047,
      "step": 12766
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004736070153241633,
      "loss": 2.0918,
      "step": 12767
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004734590146502853,
      "loss": 2.3516,
      "step": 12768
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047331102993232834,
      "loss": 2.418,
      "step": 12769
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047316306117477724,
      "loss": 2.2852,
      "step": 12770
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047301510838211635,
      "loss": 2.2031,
      "step": 12771
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047286717155882875,
      "loss": 2.4258,
      "step": 12772
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004727192507093966,
      "loss": 2.25,
      "step": 12773
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.000472571345838304,
      "loss": 2.2891,
      "step": 12774
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.000472423456950032,
      "loss": 2.0703,
      "step": 12775
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004722755840490619,
      "loss": 2.1641,
      "step": 12776
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004721277271398751,
      "loss": 2.2383,
      "step": 12777
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004719798862269524,
      "loss": 2.2324,
      "step": 12778
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004718320613147733,
      "loss": 2.1953,
      "step": 12779
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004716842524078181,
      "loss": 2.1074,
      "step": 12780
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.000471536459510565,
      "loss": 2.1465,
      "step": 12781
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004713886826274936,
      "loss": 2.3398,
      "step": 12782
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047124092176308095,
      "loss": 2.334,
      "step": 12783
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004710931769218058,
      "loss": 2.3164,
      "step": 12784
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004709454481081442,
      "loss": 2.3945,
      "step": 12785
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047079773532657346,
      "loss": 2.3125,
      "step": 12786
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047065003858157,
      "loss": 2.3359,
      "step": 12787
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004705023578776092,
      "loss": 2.1836,
      "step": 12788
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004703546932191659,
      "loss": 2.1953,
      "step": 12789
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0004702070446107152,
      "loss": 2.3086,
      "step": 12790
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00047005941205673167,
      "loss": 2.25,
      "step": 12791
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004699117955616883,
      "loss": 2.3281,
      "step": 12792
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046976419513005877,
      "loss": 2.3789,
      "step": 12793
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004696166107663162,
      "loss": 1.9922,
      "step": 12794
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004694690424749326,
      "loss": 2.4219,
      "step": 12795
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004693214902603793,
      "loss": 2.0449,
      "step": 12796
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046917395412712803,
      "loss": 2.1406,
      "step": 12797
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046902643407964993,
      "loss": 2.2266,
      "step": 12798
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004688789301224148,
      "loss": 2.3418,
      "step": 12799
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046873144225989294,
      "loss": 2.2227,
      "step": 12800
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004685839704965532,
      "loss": 2.2383,
      "step": 12801
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004684365148368651,
      "loss": 2.3457,
      "step": 12802
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046828907528529627,
      "loss": 2.3438,
      "step": 12803
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004681416518463152,
      "loss": 2.1309,
      "step": 12804
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046799424452438935,
      "loss": 2.1289,
      "step": 12805
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046784685332398505,
      "loss": 2.373,
      "step": 12806
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046769947824956947,
      "loss": 2.3164,
      "step": 12807
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004675521193056079,
      "loss": 2.1934,
      "step": 12808
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004674047764965661,
      "loss": 2.3398,
      "step": 12809
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046725744982690945,
      "loss": 2.2891,
      "step": 12810
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046711013930110203,
      "loss": 2.2695,
      "step": 12811
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004669628449236074,
      "loss": 2.1777,
      "step": 12812
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046681556669888946,
      "loss": 2.002,
      "step": 12813
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046666830463141173,
      "loss": 2.2891,
      "step": 12814
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046652105872563624,
      "loss": 2.3008,
      "step": 12815
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004663738289860242,
      "loss": 2.3359,
      "step": 12816
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004662266154170389,
      "loss": 2.2266,
      "step": 12817
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046607941802314035,
      "loss": 2.2969,
      "step": 12818
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046593223680878906,
      "loss": 2.1992,
      "step": 12819
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004657850717784452,
      "loss": 2.1094,
      "step": 12820
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046563792293656883,
      "loss": 2.3516,
      "step": 12821
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004654907902876183,
      "loss": 2.1504,
      "step": 12822
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046534367383605293,
      "loss": 2.2598,
      "step": 12823
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046519657358633015,
      "loss": 2.3828,
      "step": 12824
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046504948954290837,
      "loss": 2.2109,
      "step": 12825
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046490242171024377,
      "loss": 2.334,
      "step": 12826
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004647553700927939,
      "loss": 2.3223,
      "step": 12827
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004646083346950142,
      "loss": 2.375,
      "step": 12828
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004644613155213605,
      "loss": 2.168,
      "step": 12829
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046431431257628854,
      "loss": 2.3984,
      "step": 12830
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004641673258642525,
      "loss": 2.3516,
      "step": 12831
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004640203553897061,
      "loss": 2.0762,
      "step": 12832
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046387340115710375,
      "loss": 2.2148,
      "step": 12833
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046372646317089863,
      "loss": 2.0781,
      "step": 12834
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004635795414355429,
      "loss": 2.2188,
      "step": 12835
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004634326359554891,
      "loss": 2.2422,
      "step": 12836
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046328574673518933,
      "loss": 2.2969,
      "step": 12837
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046313887377909447,
      "loss": 2.0801,
      "step": 12838
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004629920170916545,
      "loss": 2.2812,
      "step": 12839
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004628451766773211,
      "loss": 2.375,
      "step": 12840
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046269835254054325,
      "loss": 2.3594,
      "step": 12841
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046255154468576986,
      "loss": 2.1836,
      "step": 12842
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004624047531174501,
      "loss": 2.0371,
      "step": 12843
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004622579778400327,
      "loss": 2.0449,
      "step": 12844
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004621112188579645,
      "loss": 2.1562,
      "step": 12845
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004619644761756936,
      "loss": 2.123,
      "step": 12846
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.000461817749797666,
      "loss": 2.2891,
      "step": 12847
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004616710397283288,
      "loss": 2.1934,
      "step": 12848
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046152434597212714,
      "loss": 2.2227,
      "step": 12849
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046137766853350683,
      "loss": 2.2109,
      "step": 12850
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004612310074169121,
      "loss": 2.1113,
      "step": 12851
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046108436262678765,
      "loss": 2.3086,
      "step": 12852
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046093773416757756,
      "loss": 2.2578,
      "step": 12853
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046079112204372484,
      "loss": 2.3984,
      "step": 12854
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046064452625967203,
      "loss": 2.0684,
      "step": 12855
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004604979468198617,
      "loss": 2.2734,
      "step": 12856
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004603513837287361,
      "loss": 2.1016,
      "step": 12857
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004602048369907358,
      "loss": 2.2812,
      "step": 12858
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00046005830661030215,
      "loss": 2.3477,
      "step": 12859
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00045991179259187567,
      "loss": 2.2422,
      "step": 12860
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004597652949398961,
      "loss": 2.0312,
      "step": 12861
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004596188136588022,
      "loss": 2.0898,
      "step": 12862
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00045947234875303334,
      "loss": 2.2891,
      "step": 12863
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00045932590022702824,
      "loss": 2.3516,
      "step": 12864
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00045917946808522395,
      "loss": 2.1992,
      "step": 12865
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00045903305233205863,
      "loss": 2.5078,
      "step": 12866
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004588866529719684,
      "loss": 2.2324,
      "step": 12867
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00045874027000939057,
      "loss": 2.293,
      "step": 12868
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00045859390344875995,
      "loss": 2.1836,
      "step": 12869
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004584475532945129,
      "loss": 2.0469,
      "step": 12870
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004583012195510835,
      "loss": 2.1855,
      "step": 12871
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004581549022229066,
      "loss": 2.4844,
      "step": 12872
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004580086013144164,
      "loss": 2.0938,
      "step": 12873
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004578623168300458,
      "loss": 2.1855,
      "step": 12874
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004577160487742271,
      "loss": 2.0645,
      "step": 12875
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004575697971513942,
      "loss": 2.2773,
      "step": 12876
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00045742356196597824,
      "loss": 2.2676,
      "step": 12877
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004572773432224102,
      "loss": 2.2969,
      "step": 12878
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00045713114092512145,
      "loss": 2.168,
      "step": 12879
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00045698495507854263,
      "loss": 2.1836,
      "step": 12880
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004568387856871035,
      "loss": 2.0156,
      "step": 12881
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00045669263275523257,
      "loss": 2.1406,
      "step": 12882
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004565464962873602,
      "loss": 2.3613,
      "step": 12883
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0004564003762879142,
      "loss": 2.2168,
      "step": 12884
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.000456254272761322,
      "loss": 2.2285,
      "step": 12885
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004561081857120115,
      "loss": 2.0684,
      "step": 12886
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045596211514440987,
      "loss": 2.0645,
      "step": 12887
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045581606106294284,
      "loss": 2.2559,
      "step": 12888
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004556700234720371,
      "loss": 2.0059,
      "step": 12889
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004555240023761173,
      "loss": 2.2578,
      "step": 12890
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045537799777960907,
      "loss": 2.4023,
      "step": 12891
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004552320096869361,
      "loss": 2.3945,
      "step": 12892
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045508603810252314,
      "loss": 2.3457,
      "step": 12893
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045494008303079283,
      "loss": 2.2969,
      "step": 12894
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004547941444761683,
      "loss": 2.3867,
      "step": 12895
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045464822244307247,
      "loss": 2.3125,
      "step": 12896
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004545023169359269,
      "loss": 2.293,
      "step": 12897
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045435642795915265,
      "loss": 2.1719,
      "step": 12898
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004542105555171709,
      "loss": 2.1836,
      "step": 12899
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045406469961440255,
      "loss": 2.0723,
      "step": 12900
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045391886025526675,
      "loss": 2.0293,
      "step": 12901
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004537730374441832,
      "loss": 2.2734,
      "step": 12902
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045362723118557124,
      "loss": 1.9746,
      "step": 12903
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.000453481441483849,
      "loss": 2.1445,
      "step": 12904
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004533356683434339,
      "loss": 2.0234,
      "step": 12905
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045318991176874357,
      "loss": 2.1211,
      "step": 12906
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045304417176419563,
      "loss": 2.0723,
      "step": 12907
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045289844833420545,
      "loss": 2.2227,
      "step": 12908
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004527527414831899,
      "loss": 2.3555,
      "step": 12909
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045260705121556347,
      "loss": 2.2422,
      "step": 12910
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004524613775357418,
      "loss": 2.1328,
      "step": 12911
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004523157204481386,
      "loss": 2.4453,
      "step": 12912
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045217007995716806,
      "loss": 2.1367,
      "step": 12913
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045202445606724406,
      "loss": 2.2617,
      "step": 12914
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004518788487827786,
      "loss": 2.1172,
      "step": 12915
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004517332581081849,
      "loss": 2.2188,
      "step": 12916
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004515876840478741,
      "loss": 2.5195,
      "step": 12917
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045144212660625785,
      "loss": 2.3281,
      "step": 12918
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004512965857877475,
      "loss": 2.2617,
      "step": 12919
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004511510615967529,
      "loss": 2.3125,
      "step": 12920
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004510055540376837,
      "loss": 2.2559,
      "step": 12921
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045086006311494955,
      "loss": 2.4727,
      "step": 12922
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045071458883295956,
      "loss": 2.2148,
      "step": 12923
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045056913119612195,
      "loss": 2.0957,
      "step": 12924
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045042369020884367,
      "loss": 2.4961,
      "step": 12925
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00045027826587553364,
      "loss": 2.332,
      "step": 12926
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004501328582005978,
      "loss": 2.1445,
      "step": 12927
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004499874671884422,
      "loss": 2.2969,
      "step": 12928
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004498420928434731,
      "loss": 2.3398,
      "step": 12929
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.000449696735170096,
      "loss": 2.2383,
      "step": 12930
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044955139417271516,
      "loss": 2.1973,
      "step": 12931
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044940606985573563,
      "loss": 2.3164,
      "step": 12932
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044926076222356025,
      "loss": 2.4141,
      "step": 12933
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044911547128059337,
      "loss": 2.1289,
      "step": 12934
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044897019703123685,
      "loss": 2.2656,
      "step": 12935
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004488249394798938,
      "loss": 2.0234,
      "step": 12936
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044867969863096515,
      "loss": 2.1875,
      "step": 12937
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044853447448885256,
      "loss": 2.084,
      "step": 12938
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044838926705795734,
      "loss": 2.293,
      "step": 12939
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004482440763426792,
      "loss": 2.3438,
      "step": 12940
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044809890234741724,
      "loss": 2.2695,
      "step": 12941
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004479537450765722,
      "loss": 2.2344,
      "step": 12942
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044780860453454195,
      "loss": 2.2246,
      "step": 12943
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044766348072572447,
      "loss": 1.9199,
      "step": 12944
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044751837365451796,
      "loss": 2.3359,
      "step": 12945
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004473732833253198,
      "loss": 2.2246,
      "step": 12946
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044722820974252644,
      "loss": 2.3438,
      "step": 12947
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004470831529105337,
      "loss": 2.1484,
      "step": 12948
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044693811283373776,
      "loss": 2.5352,
      "step": 12949
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044679308951653396,
      "loss": 2.457,
      "step": 12950
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004466480829633164,
      "loss": 2.375,
      "step": 12951
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004465030931784796,
      "loss": 2.2305,
      "step": 12952
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004463581201664175,
      "loss": 2.2031,
      "step": 12953
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044621316393152264,
      "loss": 2.3633,
      "step": 12954
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004460682244781884,
      "loss": 2.1035,
      "step": 12955
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004459233018108061,
      "loss": 2.1758,
      "step": 12956
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004457783959337681,
      "loss": 2.2812,
      "step": 12957
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044563350685146495,
      "loss": 2.1484,
      "step": 12958
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004454886345682879,
      "loss": 2.3359,
      "step": 12959
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044534377908862636,
      "loss": 2.2656,
      "step": 12960
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044519894041687014,
      "loss": 2.1152,
      "step": 12961
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044505411855740886,
      "loss": 2.0176,
      "step": 12962
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004449093135146307,
      "loss": 2.3438,
      "step": 12963
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004447645252929233,
      "loss": 2.2793,
      "step": 12964
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044461975389667463,
      "loss": 2.3828,
      "step": 12965
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004444749993302721,
      "loss": 2.0469,
      "step": 12966
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004443302615981015,
      "loss": 2.2617,
      "step": 12967
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004441855407045493,
      "loss": 2.3516,
      "step": 12968
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044404083665400143,
      "loss": 2.2734,
      "step": 12969
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004438961494508422,
      "loss": 2.166,
      "step": 12970
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004437514790994561,
      "loss": 2.0703,
      "step": 12971
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004436068256042274,
      "loss": 2.1289,
      "step": 12972
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004434621889695397,
      "loss": 2.1289,
      "step": 12973
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004433175691997756,
      "loss": 2.1211,
      "step": 12974
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044317296629931815,
      "loss": 2.127,
      "step": 12975
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00044302838027254846,
      "loss": 2.1445,
      "step": 12976
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0004428838111238487,
      "loss": 2.1797,
      "step": 12977
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00044273925885759914,
      "loss": 2.2559,
      "step": 12978
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004425947234781809,
      "loss": 2.418,
      "step": 12979
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004424502049899731,
      "loss": 2.3652,
      "step": 12980
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00044230570339735565,
      "loss": 2.2539,
      "step": 12981
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004421612187047076,
      "loss": 2.3047,
      "step": 12982
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.000442016750916407,
      "loss": 2.125,
      "step": 12983
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004418723000368311,
      "loss": 2.1875,
      "step": 12984
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00044172786607035854,
      "loss": 2.1582,
      "step": 12985
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004415834490213654,
      "loss": 1.9883,
      "step": 12986
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004414390488942277,
      "loss": 2.3633,
      "step": 12987
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00044129466569332155,
      "loss": 2.2188,
      "step": 12988
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00044115029942302263,
      "loss": 2.2363,
      "step": 12989
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004410059500877055,
      "loss": 2.293,
      "step": 12990
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00044086161769174337,
      "loss": 2.3516,
      "step": 12991
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00044071730223951166,
      "loss": 2.1855,
      "step": 12992
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004405730037353829,
      "loss": 2.1367,
      "step": 12993
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004404287221837293,
      "loss": 2.1348,
      "step": 12994
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00044028445758892355,
      "loss": 2.2891,
      "step": 12995
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00044014020995533767,
      "loss": 2.0508,
      "step": 12996
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.000439995979287342,
      "loss": 2.248,
      "step": 12997
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043985176558930815,
      "loss": 2.1875,
      "step": 12998
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043970756886560535,
      "loss": 2.3477,
      "step": 12999
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043956338912060403,
      "loss": 2.2852,
      "step": 13000
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004394192263586726,
      "loss": 2.3555,
      "step": 13001
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004392750805841803,
      "loss": 2.2598,
      "step": 13002
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043913095180149464,
      "loss": 2.1777,
      "step": 13003
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043898684001498356,
      "loss": 2.3008,
      "step": 13004
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043884274522901435,
      "loss": 2.2656,
      "step": 13005
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004386986674479533,
      "loss": 2.4062,
      "step": 13006
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043855460667616586,
      "loss": 2.0352,
      "step": 13007
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043841056291801827,
      "loss": 2.3555,
      "step": 13008
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043826653617787557,
      "loss": 2.2734,
      "step": 13009
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043812252646010174,
      "loss": 2.2852,
      "step": 13010
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043797853376906096,
      "loss": 2.2598,
      "step": 13011
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004378345581091171,
      "loss": 2.1914,
      "step": 13012
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043769059948463285,
      "loss": 2.1602,
      "step": 13013
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043754665789997005,
      "loss": 2.3594,
      "step": 13014
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004374027333594911,
      "loss": 2.5,
      "step": 13015
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004372588258675576,
      "loss": 2.2734,
      "step": 13016
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043711493542853,
      "loss": 2.0625,
      "step": 13017
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043697106204676906,
      "loss": 2.2617,
      "step": 13018
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043682720572663406,
      "loss": 2.2363,
      "step": 13019
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004366833664724846,
      "loss": 2.252,
      "step": 13020
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043653954428867994,
      "loss": 2.2188,
      "step": 13021
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043639573917957796,
      "loss": 2.084,
      "step": 13022
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004362519511495361,
      "loss": 2.1504,
      "step": 13023
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004361081802029118,
      "loss": 2.3867,
      "step": 13024
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004359644263440623,
      "loss": 2.2969,
      "step": 13025
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004358206895773431,
      "loss": 2.3125,
      "step": 13026
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043567696990711027,
      "loss": 2.2734,
      "step": 13027
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043553326733771923,
      "loss": 2.3086,
      "step": 13028
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004353895818735244,
      "loss": 2.3281,
      "step": 13029
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043524591351887953,
      "loss": 2.1875,
      "step": 13030
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043510226227813853,
      "loss": 2.3359,
      "step": 13031
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043495862815565503,
      "loss": 2.4062,
      "step": 13032
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004348150111557807,
      "loss": 2.4414,
      "step": 13033
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043467141128286814,
      "loss": 2.3477,
      "step": 13034
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043452782854126905,
      "loss": 2.1133,
      "step": 13035
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043438426293533427,
      "loss": 2.3125,
      "step": 13036
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043424071446941393,
      "loss": 2.0312,
      "step": 13037
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004340971831478584,
      "loss": 2.3125,
      "step": 13038
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004339536689750174,
      "loss": 2.3906,
      "step": 13039
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004338101719552392,
      "loss": 2.252,
      "step": 13040
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.000433666692092873,
      "loss": 2.3906,
      "step": 13041
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.000433523229392266,
      "loss": 2.2773,
      "step": 13042
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004333797838577662,
      "loss": 2.3047,
      "step": 13043
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043323635549372,
      "loss": 2.2012,
      "step": 13044
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004330929443044741,
      "loss": 2.2539,
      "step": 13045
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004329495502943739,
      "loss": 2.0918,
      "step": 13046
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.000432806173467765,
      "loss": 2.3984,
      "step": 13047
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043266281382899253,
      "loss": 2.3906,
      "step": 13048
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004325194713824003,
      "loss": 2.1953,
      "step": 13049
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043237614613233155,
      "loss": 2.5352,
      "step": 13050
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043223283808313073,
      "loss": 2.0527,
      "step": 13051
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043208954723913994,
      "loss": 2.3359,
      "step": 13052
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043194627360470107,
      "loss": 2.3555,
      "step": 13053
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004318030171841559,
      "loss": 2.1602,
      "step": 13054
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004316597779818463,
      "loss": 2.1094,
      "step": 13055
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043151655600211214,
      "loss": 1.9473,
      "step": 13056
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043137335124929346,
      "loss": 1.9922,
      "step": 13057
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043123016372772994,
      "loss": 1.9434,
      "step": 13058
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043108699344176127,
      "loss": 2.0762,
      "step": 13059
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.000430943840395725,
      "loss": 2.2422,
      "step": 13060
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043080070459396,
      "loss": 2.1875,
      "step": 13061
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043065758604080294,
      "loss": 2.4727,
      "step": 13062
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004305144847405913,
      "loss": 2.3477,
      "step": 13063
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043037140069766177,
      "loss": 2.293,
      "step": 13064
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00043022833391634954,
      "loss": 2.2324,
      "step": 13065
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004300852844009907,
      "loss": 2.4355,
      "step": 13066
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0004299422521559195,
      "loss": 2.4258,
      "step": 13067
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.000429799237185471,
      "loss": 2.1758,
      "step": 13068
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00042965623949397814,
      "loss": 2.1934,
      "step": 13069
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00042951325908577477,
      "loss": 2.0879,
      "step": 13070
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042937029596519386,
      "loss": 2.1211,
      "step": 13071
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042922735013656743,
      "loss": 2.2969,
      "step": 13072
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004290844216042269,
      "loss": 2.3398,
      "step": 13073
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004289415103725036,
      "loss": 2.4492,
      "step": 13074
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004287986164457288,
      "loss": 2.2617,
      "step": 13075
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042865573982823194,
      "loss": 2.3398,
      "step": 13076
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042851288052434276,
      "loss": 2.3984,
      "step": 13077
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.000428370038538391,
      "loss": 2.002,
      "step": 13078
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042822721387470467,
      "loss": 2.0898,
      "step": 13079
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004280844065376116,
      "loss": 2.207,
      "step": 13080
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004279416165314397,
      "loss": 2.3672,
      "step": 13081
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042779884386051625,
      "loss": 2.3164,
      "step": 13082
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.000427656088529167,
      "loss": 2.0918,
      "step": 13083
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042751335054171867,
      "loss": 2.4023,
      "step": 13084
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.000427370629902496,
      "loss": 2.0078,
      "step": 13085
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042722792661582456,
      "loss": 2.2344,
      "step": 13086
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042708524068602803,
      "loss": 2.3711,
      "step": 13087
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042694257211743105,
      "loss": 2.3984,
      "step": 13088
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042679992091435617,
      "loss": 2.1895,
      "step": 13089
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004266572870811264,
      "loss": 2.1367,
      "step": 13090
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004265146706220646,
      "loss": 2.293,
      "step": 13091
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042637207154149213,
      "loss": 2.1953,
      "step": 13092
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042622948984372936,
      "loss": 2.0918,
      "step": 13093
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042608692553309846,
      "loss": 2.2617,
      "step": 13094
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.000425944378613919,
      "loss": 2.1133,
      "step": 13095
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004258018490905101,
      "loss": 2.4766,
      "step": 13096
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004256593369671913,
      "loss": 2.1094,
      "step": 13097
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042551684224828156,
      "loss": 2.1758,
      "step": 13098
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004253743649380982,
      "loss": 2.2617,
      "step": 13099
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004252319050409592,
      "loss": 2.2656,
      "step": 13100
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042508946256118187,
      "loss": 2.1484,
      "step": 13101
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004249470375030822,
      "loss": 2.3555,
      "step": 13102
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004248046298709758,
      "loss": 2.2031,
      "step": 13103
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004246622396691786,
      "loss": 2.0918,
      "step": 13104
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042451986690200585,
      "loss": 2.3438,
      "step": 13105
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.000424377511573771,
      "loss": 2.5156,
      "step": 13106
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042423517368878885,
      "loss": 2.252,
      "step": 13107
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004240928532513717,
      "loss": 2.2031,
      "step": 13108
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004239505502658333,
      "loss": 2.2441,
      "step": 13109
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042380826473648503,
      "loss": 2.3184,
      "step": 13110
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042366599666763936,
      "loss": 2.0547,
      "step": 13111
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042352374606360687,
      "loss": 2.2422,
      "step": 13112
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004233815129286984,
      "loss": 2.3008,
      "step": 13113
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042323929726722457,
      "loss": 2.2891,
      "step": 13114
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004230970990834946,
      "loss": 2.1387,
      "step": 13115
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004229549183818168,
      "loss": 2.1953,
      "step": 13116
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004228127551665012,
      "loss": 2.1797,
      "step": 13117
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004226706094418551,
      "loss": 2.1289,
      "step": 13118
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004225284812121855,
      "loss": 2.1758,
      "step": 13119
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004223863704817998,
      "loss": 2.3594,
      "step": 13120
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004222442772550048,
      "loss": 2.2656,
      "step": 13121
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004221022015361061,
      "loss": 2.207,
      "step": 13122
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004219601433294086,
      "loss": 2.3008,
      "step": 13123
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004218181026392174,
      "loss": 2.4531,
      "step": 13124
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042167607946983735,
      "loss": 2.293,
      "step": 13125
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004215340738255714,
      "loss": 2.207,
      "step": 13126
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004213920857107235,
      "loss": 2.2891,
      "step": 13127
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042125011512959576,
      "loss": 2.3516,
      "step": 13128
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004211081620864905,
      "loss": 2.1172,
      "step": 13129
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042096622658570993,
      "loss": 2.3008,
      "step": 13130
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042082430863155465,
      "loss": 2.1914,
      "step": 13131
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004206824082283249,
      "loss": 2.1699,
      "step": 13132
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004205405253803212,
      "loss": 2.3164,
      "step": 13133
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004203986600918434,
      "loss": 2.1875,
      "step": 13134
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00042025681236718994,
      "loss": 2.2129,
      "step": 13135
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004201149822106588,
      "loss": 2.3145,
      "step": 13136
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004199731696265492,
      "loss": 2.1172,
      "step": 13137
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00041983137461915776,
      "loss": 2.375,
      "step": 13138
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00041968959719278123,
      "loss": 2.1602,
      "step": 13139
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.000419547837351716,
      "loss": 2.2129,
      "step": 13140
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004194060951002583,
      "loss": 2.207,
      "step": 13141
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004192643704427027,
      "loss": 2.2402,
      "step": 13142
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00041912266338334437,
      "loss": 2.2422,
      "step": 13143
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004189809739264777,
      "loss": 2.0469,
      "step": 13144
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004188393020763961,
      "loss": 2.3555,
      "step": 13145
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004186976478373923,
      "loss": 2.2402,
      "step": 13146
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004185560112137592,
      "loss": 2.1387,
      "step": 13147
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00041841439220978926,
      "loss": 2.1875,
      "step": 13148
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004182727908297733,
      "loss": 2.3086,
      "step": 13149
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.000418131207078003,
      "loss": 2.2969,
      "step": 13150
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.000417989640958768,
      "loss": 2.0801,
      "step": 13151
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004178480924763591,
      "loss": 1.9961,
      "step": 13152
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00041770656163506495,
      "loss": 2.3516,
      "step": 13153
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.000417565048439175,
      "loss": 2.3828,
      "step": 13154
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00041742355289297694,
      "loss": 2.1797,
      "step": 13155
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00041728207500075885,
      "loss": 2.1836,
      "step": 13156
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004171406147668084,
      "loss": 2.4688,
      "step": 13157
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00041699917219541183,
      "loss": 2.2656,
      "step": 13158
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004168577472908548,
      "loss": 2.3027,
      "step": 13159
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004167163400574241,
      "loss": 2.3242,
      "step": 13160
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004165749504994044,
      "loss": 2.3555,
      "step": 13161
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0004164335786210798,
      "loss": 2.0254,
      "step": 13162
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00041629222442673454,
      "loss": 2.25,
      "step": 13163
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004161508879206527,
      "loss": 2.3086,
      "step": 13164
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041600956910711675,
      "loss": 2.2285,
      "step": 13165
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004158682679904088,
      "loss": 2.5078,
      "step": 13166
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041572698457481105,
      "loss": 2.2715,
      "step": 13167
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004155857188646054,
      "loss": 2.3242,
      "step": 13168
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041544447086407164,
      "loss": 2.2051,
      "step": 13169
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041530324057749104,
      "loss": 2.0059,
      "step": 13170
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004151620280091424,
      "loss": 2.1816,
      "step": 13171
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041502083316330554,
      "loss": 2.1992,
      "step": 13172
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041487965604425917,
      "loss": 2.2695,
      "step": 13173
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041473849665628093,
      "loss": 2.2852,
      "step": 13174
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041459735500364915,
      "loss": 2.1895,
      "step": 13175
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041445623109064,
      "loss": 2.1426,
      "step": 13176
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004143151249215309,
      "loss": 2.041,
      "step": 13177
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041417403650059693,
      "loss": 2.2656,
      "step": 13178
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041403296583211404,
      "loss": 2.1836,
      "step": 13179
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004138919129203573,
      "loss": 2.3555,
      "step": 13180
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.000413750877769601,
      "loss": 2.0938,
      "step": 13181
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041360986038411807,
      "loss": 2.1934,
      "step": 13182
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041346886076818324,
      "loss": 2.3164,
      "step": 13183
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004133278789260686,
      "loss": 2.1836,
      "step": 13184
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041318691486204594,
      "loss": 2.3984,
      "step": 13185
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041304596858038735,
      "loss": 2.1641,
      "step": 13186
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004129050400853643,
      "loss": 2.3223,
      "step": 13187
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041276412938124707,
      "loss": 2.2461,
      "step": 13188
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041262323647230526,
      "loss": 2.2617,
      "step": 13189
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004124823613628088,
      "loss": 2.3555,
      "step": 13190
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041234150405702706,
      "loss": 2.2988,
      "step": 13191
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004122006645592278,
      "loss": 2.3789,
      "step": 13192
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004120598428736795,
      "loss": 2.1113,
      "step": 13193
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004119190390046489,
      "loss": 2.2305,
      "step": 13194
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004117782529564031,
      "loss": 2.1855,
      "step": 13195
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041163748473320883,
      "loss": 2.3359,
      "step": 13196
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041149673433933144,
      "loss": 2.2188,
      "step": 13197
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004113560017790358,
      "loss": 2.3125,
      "step": 13198
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004112152870565868,
      "loss": 2.0254,
      "step": 13199
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041107459017624906,
      "loss": 2.1133,
      "step": 13200
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041093391114228574,
      "loss": 2.1445,
      "step": 13201
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004107932499589592,
      "loss": 2.2188,
      "step": 13202
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041065260663053325,
      "loss": 2.1152,
      "step": 13203
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004105119811612693,
      "loss": 2.2656,
      "step": 13204
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004103713735554282,
      "loss": 2.2148,
      "step": 13205
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041023078381727143,
      "loss": 2.125,
      "step": 13206
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00041009021195105946,
      "loss": 2.3125,
      "step": 13207
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040994965796105153,
      "loss": 2.2031,
      "step": 13208
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004098091218515074,
      "loss": 2.2266,
      "step": 13209
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040966860362668533,
      "loss": 2.2031,
      "step": 13210
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.000409528103290844,
      "loss": 2.3555,
      "step": 13211
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004093876208482403,
      "loss": 2.2461,
      "step": 13212
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004092471563031318,
      "loss": 2.3359,
      "step": 13213
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040910670965977534,
      "loss": 2.2188,
      "step": 13214
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040896628092242614,
      "loss": 2.0273,
      "step": 13215
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004088258700953404,
      "loss": 2.3828,
      "step": 13216
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004086854771827725,
      "loss": 2.2852,
      "step": 13217
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040854510218897724,
      "loss": 2.0527,
      "step": 13218
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004084047451182078,
      "loss": 2.1914,
      "step": 13219
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040826440597471823,
      "loss": 2.293,
      "step": 13220
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040812408476276066,
      "loss": 2.1562,
      "step": 13221
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004079837814865874,
      "loss": 2.2246,
      "step": 13222
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004078434961504507,
      "loss": 2.1992,
      "step": 13223
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.000407703228758601,
      "loss": 2.2578,
      "step": 13224
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004075629793152885,
      "loss": 2.0801,
      "step": 13225
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004074227478247644,
      "loss": 2.3262,
      "step": 13226
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004072825342912776,
      "loss": 2.2734,
      "step": 13227
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004071423387190766,
      "loss": 2.3477,
      "step": 13228
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040700216111241004,
      "loss": 2.2871,
      "step": 13229
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040686200147552643,
      "loss": 2.5547,
      "step": 13230
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004067218598126724,
      "loss": 2.1094,
      "step": 13231
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040658173612809456,
      "loss": 2.3594,
      "step": 13232
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040644163042603934,
      "loss": 2.1797,
      "step": 13233
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004063015427107527,
      "loss": 2.2578,
      "step": 13234
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040616147298647935,
      "loss": 2.1074,
      "step": 13235
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004060214212574642,
      "loss": 2.3223,
      "step": 13236
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004058813875279508,
      "loss": 2.1953,
      "step": 13237
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040574137180218294,
      "loss": 2.0957,
      "step": 13238
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040560137408440376,
      "loss": 2.3398,
      "step": 13239
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040546139437885566,
      "loss": 2.125,
      "step": 13240
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004053214326897797,
      "loss": 2.332,
      "step": 13241
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004051814890214178,
      "loss": 2.2578,
      "step": 13242
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004050415633780111,
      "loss": 2.1621,
      "step": 13243
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004049016557637992,
      "loss": 2.1035,
      "step": 13244
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004047617661830213,
      "loss": 2.3047,
      "step": 13245
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040462189463991784,
      "loss": 2.1738,
      "step": 13246
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040448204113872666,
      "loss": 2.2109,
      "step": 13247
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004043422056836855,
      "loss": 2.3711,
      "step": 13248
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.000404202388279032,
      "loss": 2.3945,
      "step": 13249
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004040625889290037,
      "loss": 2.1074,
      "step": 13250
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004039228076378361,
      "loss": 2.2617,
      "step": 13251
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004037830444097654,
      "loss": 2.1367,
      "step": 13252
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040364329924902733,
      "loss": 2.1426,
      "step": 13253
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004035035721598561,
      "loss": 2.2305,
      "step": 13254
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00040336386314648577,
      "loss": 2.0234,
      "step": 13255
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0004032241722131501,
      "loss": 2.1758,
      "step": 13256
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00040308449936408275,
      "loss": 2.3047,
      "step": 13257
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00040294484460351546,
      "loss": 2.1445,
      "step": 13258
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0004028052079356809,
      "loss": 2.3281,
      "step": 13259
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0004026655893648099,
      "loss": 2.2383,
      "step": 13260
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0004025259888951337,
      "loss": 2.0332,
      "step": 13261
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00040238640653088287,
      "loss": 2.25,
      "step": 13262
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00040224684227628706,
      "loss": 2.1855,
      "step": 13263
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00040210729613557506,
      "loss": 2.127,
      "step": 13264
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.000401967768112976,
      "loss": 2.25,
      "step": 13265
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0004018282582127183,
      "loss": 2.3203,
      "step": 13266
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0004016887664390293,
      "loss": 2.2656,
      "step": 13267
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00040154929279613517,
      "loss": 2.2207,
      "step": 13268
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0004014098372882641,
      "loss": 2.1367,
      "step": 13269
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0004012703999196412,
      "loss": 2.2441,
      "step": 13270
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0004011309806944915,
      "loss": 2.2969,
      "step": 13271
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00040099157961704025,
      "loss": 2.375,
      "step": 13272
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0004008521966915122,
      "loss": 2.1113,
      "step": 13273
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00040071283192213026,
      "loss": 2.3516,
      "step": 13274
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00040057348531311846,
      "loss": 2.1367,
      "step": 13275
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00040043415686869855,
      "loss": 2.0371,
      "step": 13276
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0004002948465930937,
      "loss": 2.4648,
      "step": 13277
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0004001555544905244,
      "loss": 2.1133,
      "step": 13278
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00040001628056521266,
      "loss": 2.4609,
      "step": 13279
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.000399877024821378,
      "loss": 2.2656,
      "step": 13280
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003997377872632408,
      "loss": 2.291,
      "step": 13281
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003995985678950208,
      "loss": 2.0645,
      "step": 13282
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003994593667209363,
      "loss": 2.3828,
      "step": 13283
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003993201837452054,
      "loss": 2.2695,
      "step": 13284
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039918101897204597,
      "loss": 2.418,
      "step": 13285
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003990418724056757,
      "loss": 2.3828,
      "step": 13286
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039890274405031027,
      "loss": 2.1113,
      "step": 13287
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003987636339101662,
      "loss": 2.4023,
      "step": 13288
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003986245419894594,
      "loss": 2.125,
      "step": 13289
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003984854682924043,
      "loss": 2.3633,
      "step": 13290
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003983464128232147,
      "loss": 2.1992,
      "step": 13291
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039820737558610576,
      "loss": 2.2344,
      "step": 13292
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039806835658529017,
      "loss": 2.2969,
      "step": 13293
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039792935582498026,
      "loss": 2.3086,
      "step": 13294
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039779037330938863,
      "loss": 2.3516,
      "step": 13295
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.000397651409042727,
      "loss": 2.2812,
      "step": 13296
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039751246302920643,
      "loss": 2.3867,
      "step": 13297
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003973735352730369,
      "loss": 2.3164,
      "step": 13298
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039723462577842875,
      "loss": 2.2656,
      "step": 13299
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003970957345495917,
      "loss": 2.2109,
      "step": 13300
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039695686159073394,
      "loss": 2.2852,
      "step": 13301
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003968180069060646,
      "loss": 2.2031,
      "step": 13302
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039667917049979065,
      "loss": 2.3633,
      "step": 13303
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003965403523761196,
      "loss": 2.2812,
      "step": 13304
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003964015525392585,
      "loss": 2.1797,
      "step": 13305
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039626277099341303,
      "loss": 2.3828,
      "step": 13306
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039612400774278843,
      "loss": 2.3594,
      "step": 13307
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039598526279159,
      "loss": 2.3203,
      "step": 13308
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039584653614402256,
      "loss": 2.3164,
      "step": 13309
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003957078278042896,
      "loss": 2.1289,
      "step": 13310
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039556913777659365,
      "loss": 2.4492,
      "step": 13311
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003954304660651391,
      "loss": 2.0664,
      "step": 13312
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003952918126741273,
      "loss": 2.1953,
      "step": 13313
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003951531776077595,
      "loss": 2.1582,
      "step": 13314
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039501456087023725,
      "loss": 2.3828,
      "step": 13315
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039487596246576143,
      "loss": 2.1172,
      "step": 13316
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003947373823985313,
      "loss": 1.9609,
      "step": 13317
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.000394598820672747,
      "loss": 2.3828,
      "step": 13318
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003944602772926067,
      "loss": 2.4023,
      "step": 13319
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039432175226230946,
      "loss": 2.4102,
      "step": 13320
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039418324558605235,
      "loss": 2.1094,
      "step": 13321
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039404475726803324,
      "loss": 2.1914,
      "step": 13322
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039390628731244805,
      "loss": 2.0859,
      "step": 13323
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003937678357234933,
      "loss": 2.0957,
      "step": 13324
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003936294025053647,
      "loss": 2.3262,
      "step": 13325
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039349098766225675,
      "loss": 2.3516,
      "step": 13326
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039335259119836454,
      "loss": 2.3594,
      "step": 13327
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003932142131178812,
      "loss": 2.1973,
      "step": 13328
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039307585342500064,
      "loss": 2.1152,
      "step": 13329
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039293751212391505,
      "loss": 2.293,
      "step": 13330
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003927991892188169,
      "loss": 2.1719,
      "step": 13331
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039266088471389814,
      "loss": 2.0625,
      "step": 13332
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003925225986133497,
      "loss": 2.1426,
      "step": 13333
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003923843309213613,
      "loss": 2.1895,
      "step": 13334
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039224608164212417,
      "loss": 2.2832,
      "step": 13335
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003921078507798271,
      "loss": 2.3359,
      "step": 13336
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003919696383386586,
      "loss": 2.375,
      "step": 13337
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039183144432280737,
      "loss": 2.0723,
      "step": 13338
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003916932687364615,
      "loss": 2.1562,
      "step": 13339
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039155511158380776,
      "loss": 2.4688,
      "step": 13340
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003914169728690323,
      "loss": 2.2422,
      "step": 13341
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039127885259632167,
      "loss": 2.3008,
      "step": 13342
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039114075076986175,
      "loss": 2.3281,
      "step": 13343
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003910026673938367,
      "loss": 2.0566,
      "step": 13344
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039086460247243163,
      "loss": 2.3633,
      "step": 13345
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039072655600982963,
      "loss": 2.2188,
      "step": 13346
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039058852801021436,
      "loss": 2.3867,
      "step": 13347
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003904505184777688,
      "loss": 2.2227,
      "step": 13348
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00039031252741667476,
      "loss": 2.2852,
      "step": 13349
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00039017455483111353,
      "loss": 2.3711,
      "step": 13350
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003900366007252665,
      "loss": 2.1543,
      "step": 13351
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003898986651033144,
      "loss": 2.3164,
      "step": 13352
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003897607479694364,
      "loss": 2.2734,
      "step": 13353
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038962284932781235,
      "loss": 2.4141,
      "step": 13354
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003894849691826212,
      "loss": 2.207,
      "step": 13355
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038934710753804093,
      "loss": 2.1855,
      "step": 13356
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003892092643982489,
      "loss": 2.2031,
      "step": 13357
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003890714397674224,
      "loss": 2.2422,
      "step": 13358
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003889336336497384,
      "loss": 2.0898,
      "step": 13359
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038879584604937237,
      "loss": 2.2422,
      "step": 13360
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003886580769704997,
      "loss": 2.1699,
      "step": 13361
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038852032641729586,
      "loss": 2.1855,
      "step": 13362
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038838259439393473,
      "loss": 2.0039,
      "step": 13363
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038824488090458966,
      "loss": 2.1367,
      "step": 13364
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003881071859534342,
      "loss": 2.2539,
      "step": 13365
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003879695095446414,
      "loss": 2.3984,
      "step": 13366
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038783185168238233,
      "loss": 2.3906,
      "step": 13367
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003876942123708295,
      "loss": 2.2148,
      "step": 13368
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003875565916141529,
      "loss": 2.2852,
      "step": 13369
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003874189894165234,
      "loss": 2.2246,
      "step": 13370
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038728140578211115,
      "loss": 2.3047,
      "step": 13371
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003871438407150849,
      "loss": 2.2656,
      "step": 13372
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.000387006294219613,
      "loss": 2.2891,
      "step": 13373
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.000386868766299864,
      "loss": 2.2617,
      "step": 13374
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038673125696000565,
      "loss": 2.2598,
      "step": 13375
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003865937662042048,
      "loss": 2.2129,
      "step": 13376
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038645629403662705,
      "loss": 2.1836,
      "step": 13377
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003863188404614396,
      "loss": 2.2891,
      "step": 13378
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038618140548280725,
      "loss": 2.2344,
      "step": 13379
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038604398910489416,
      "loss": 2.1211,
      "step": 13380
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003859065913318649,
      "loss": 2.3438,
      "step": 13381
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003857692121678834,
      "loss": 1.998,
      "step": 13382
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003856318516171121,
      "loss": 2.4141,
      "step": 13383
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038549450968371413,
      "loss": 2.3125,
      "step": 13384
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003853571863718508,
      "loss": 2.3516,
      "step": 13385
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003852198816856839,
      "loss": 2.0625,
      "step": 13386
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038508259562937376,
      "loss": 2.3086,
      "step": 13387
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003849453282070812,
      "loss": 2.0742,
      "step": 13388
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038480807942296516,
      "loss": 2.2324,
      "step": 13389
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038467084928118513,
      "loss": 2.0938,
      "step": 13390
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003845336377859,
      "loss": 2.2188,
      "step": 13391
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003843964449412672,
      "loss": 2.2695,
      "step": 13392
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003842592707514441,
      "loss": 2.2148,
      "step": 13393
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003841221152205875,
      "loss": 2.293,
      "step": 13394
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038398497835285427,
      "loss": 2.4336,
      "step": 13395
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003838478601523994,
      "loss": 2.3047,
      "step": 13396
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003837107606233782,
      "loss": 2.1602,
      "step": 13397
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038357367976994575,
      "loss": 2.1738,
      "step": 13398
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003834366175962557,
      "loss": 2.3711,
      "step": 13399
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038329957410646064,
      "loss": 2.1992,
      "step": 13400
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038316254930471493,
      "loss": 2.1875,
      "step": 13401
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038302554319517027,
      "loss": 2.1699,
      "step": 13402
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003828885557819778,
      "loss": 2.2539,
      "step": 13403
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038275158706928925,
      "loss": 2.2734,
      "step": 13404
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038261463706125556,
      "loss": 2.2578,
      "step": 13405
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038247770576202634,
      "loss": 2.2129,
      "step": 13406
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038234079317575067,
      "loss": 2.2148,
      "step": 13407
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038220389930657784,
      "loss": 2.373,
      "step": 13408
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038206702415865667,
      "loss": 2.3242,
      "step": 13409
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003819301677361341,
      "loss": 2.2969,
      "step": 13410
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038179333004315796,
      "loss": 2.0859,
      "step": 13411
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038165651108387424,
      "loss": 2.4297,
      "step": 13412
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038151971086242944,
      "loss": 2.2188,
      "step": 13413
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003813829293829694,
      "loss": 2.2441,
      "step": 13414
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003812461666496385,
      "loss": 2.4023,
      "step": 13415
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.000381109422666581,
      "loss": 2.3789,
      "step": 13416
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003809726974379408,
      "loss": 2.0566,
      "step": 13417
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003808359909678617,
      "loss": 2.2266,
      "step": 13418
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038069930326048597,
      "loss": 2.3828,
      "step": 13419
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003805626343199549,
      "loss": 2.2148,
      "step": 13420
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003804259841504113,
      "loss": 2.1582,
      "step": 13421
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00038028935275599566,
      "loss": 2.2305,
      "step": 13422
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.000380152740140848,
      "loss": 2.127,
      "step": 13423
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003800161463091083,
      "loss": 2.3477,
      "step": 13424
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00037987957126491624,
      "loss": 2.3164,
      "step": 13425
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003797430150124098,
      "loss": 1.8535,
      "step": 13426
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00037960647755572787,
      "loss": 2.2539,
      "step": 13427
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.000379469958899007,
      "loss": 2.3047,
      "step": 13428
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00037933345904638525,
      "loss": 2.2773,
      "step": 13429
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00037919697800199806,
      "loss": 2.2461,
      "step": 13430
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003790605157699819,
      "loss": 2.4141,
      "step": 13431
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003789240723544716,
      "loss": 2.2695,
      "step": 13432
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00037878764775960193,
      "loss": 2.0938,
      "step": 13433
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003786512419895074,
      "loss": 2.2871,
      "step": 13434
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003785148550483209,
      "loss": 2.375,
      "step": 13435
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00037837848694017586,
      "loss": 2.3789,
      "step": 13436
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003782421376692049,
      "loss": 2.1758,
      "step": 13437
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003781058072395395,
      "loss": 2.2578,
      "step": 13438
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003779694956553106,
      "loss": 2.1758,
      "step": 13439
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00037783320292064925,
      "loss": 1.9941,
      "step": 13440
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003776969290396859,
      "loss": 2.1367,
      "step": 13441
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003775606740165497,
      "loss": 2.3828,
      "step": 13442
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00037742443785536894,
      "loss": 2.3203,
      "step": 13443
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003772882205602736,
      "loss": 1.9551,
      "step": 13444
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003771520221353905,
      "loss": 2.4062,
      "step": 13445
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003770158425848468,
      "loss": 2.0352,
      "step": 13446
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00037687968191276946,
      "loss": 2.1055,
      "step": 13447
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00037674354012328493,
      "loss": 2.2383,
      "step": 13448
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00037660741722051806,
      "loss": 2.2148,
      "step": 13449
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003764713132085945,
      "loss": 2.1699,
      "step": 13450
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.000376335228091638,
      "loss": 2.2461,
      "step": 13451
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00037619916187377303,
      "loss": 2.2988,
      "step": 13452
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003760631145591222,
      "loss": 2.2852,
      "step": 13453
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003759270861518089,
      "loss": 2.0938,
      "step": 13454
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003757910766559545,
      "loss": 2.0215,
      "step": 13455
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003756550860756808,
      "loss": 2.3828,
      "step": 13456
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003755191144151092,
      "loss": 2.3984,
      "step": 13457
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00037538316167835985,
      "loss": 2.2852,
      "step": 13458
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.000375247227869552,
      "loss": 2.2031,
      "step": 13459
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003751113129928053,
      "loss": 2.0508,
      "step": 13460
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00037497541705223893,
      "loss": 2.2773,
      "step": 13461
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00037483954005197007,
      "loss": 2.2734,
      "step": 13462
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003747036819961167,
      "loss": 2.3164,
      "step": 13463
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003745678428887961,
      "loss": 2.1367,
      "step": 13464
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003744320227341244,
      "loss": 2.2676,
      "step": 13465
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00037429622153621676,
      "loss": 2.2773,
      "step": 13466
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.000374160439299189,
      "loss": 2.0527,
      "step": 13467
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00037402467602715595,
      "loss": 2.418,
      "step": 13468
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003738889317242312,
      "loss": 2.3418,
      "step": 13469
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003737532063945288,
      "loss": 2.2812,
      "step": 13470
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.000373617500042161,
      "loss": 2.207,
      "step": 13471
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003734818126712408,
      "loss": 2.2227,
      "step": 13472
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00037334614428587935,
      "loss": 2.1836,
      "step": 13473
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003732104948901882,
      "loss": 1.9355,
      "step": 13474
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003730748644882782,
      "loss": 2.3281,
      "step": 13475
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003729392530842588,
      "loss": 2.2344,
      "step": 13476
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00037280366068224025,
      "loss": 2.25,
      "step": 13477
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003726680872863306,
      "loss": 2.3438,
      "step": 13478
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003725325329006386,
      "loss": 2.1836,
      "step": 13479
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00037239699752927223,
      "loss": 2.1953,
      "step": 13480
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003722614811763384,
      "loss": 2.1934,
      "step": 13481
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003721259838459434,
      "loss": 1.9922,
      "step": 13482
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003719905055421936,
      "loss": 2.2383,
      "step": 13483
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003718550462691946,
      "loss": 2.2773,
      "step": 13484
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00037171960603105104,
      "loss": 2.3242,
      "step": 13485
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003715841848318665,
      "loss": 2.3047,
      "step": 13486
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00037144878267574623,
      "loss": 2.1523,
      "step": 13487
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003713133995667923,
      "loss": 2.1836,
      "step": 13488
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003711780355091073,
      "loss": 1.9336,
      "step": 13489
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00037104269050679327,
      "loss": 2.25,
      "step": 13490
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003709073645639521,
      "loss": 2.4297,
      "step": 13491
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.000370772057684684,
      "loss": 2.1035,
      "step": 13492
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003706367698730897,
      "loss": 2.1367,
      "step": 13493
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003705015011332683,
      "loss": 2.1738,
      "step": 13494
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00037036625146931945,
      "loss": 2.3906,
      "step": 13495
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003702310208853411,
      "loss": 2.3555,
      "step": 13496
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00037009580938543186,
      "loss": 2.2422,
      "step": 13497
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003699606169736884,
      "loss": 2.1875,
      "step": 13498
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003698254436542078,
      "loss": 2.2344,
      "step": 13499
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003696902894310865,
      "loss": 2.2422,
      "step": 13500
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036955515430842,
      "loss": 2.1172,
      "step": 13501
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003694200382903028,
      "loss": 2.2539,
      "step": 13502
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003692849413808298,
      "loss": 2.1133,
      "step": 13503
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036914986358409517,
      "loss": 2.4531,
      "step": 13504
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003690148049041916,
      "loss": 2.1855,
      "step": 13505
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003688797653452121,
      "loss": 2.3203,
      "step": 13506
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003687447449112492,
      "loss": 2.4766,
      "step": 13507
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.000368609743606394,
      "loss": 2.2031,
      "step": 13508
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003684747614347369,
      "loss": 2.2246,
      "step": 13509
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036833979840036966,
      "loss": 2.2871,
      "step": 13510
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036820485450738137,
      "loss": 2.25,
      "step": 13511
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036806992975986106,
      "loss": 2.1582,
      "step": 13512
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003679350241618976,
      "loss": 2.4648,
      "step": 13513
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036780013771757947,
      "loss": 1.9844,
      "step": 13514
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003676652704309935,
      "loss": 2.1035,
      "step": 13515
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036753042230622723,
      "loss": 2.1855,
      "step": 13516
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036739559334736637,
      "loss": 2.3047,
      "step": 13517
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036726078355849744,
      "loss": 2.1758,
      "step": 13518
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036712599294370474,
      "loss": 2.3047,
      "step": 13519
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036699122150707375,
      "loss": 2.2676,
      "step": 13520
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003668564692526877,
      "loss": 2.2969,
      "step": 13521
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036672173618463043,
      "loss": 2.1367,
      "step": 13522
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036658702230698507,
      "loss": 1.9297,
      "step": 13523
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003664523276238335,
      "loss": 2.5938,
      "step": 13524
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036631765213925716,
      "loss": 2.3789,
      "step": 13525
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003661829958573376,
      "loss": 2.168,
      "step": 13526
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036604835878215546,
      "loss": 2.3008,
      "step": 13527
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036591374091779017,
      "loss": 2.127,
      "step": 13528
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003657791422683213,
      "loss": 2.3047,
      "step": 13529
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003656445628378282,
      "loss": 2.1035,
      "step": 13530
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036551000263038846,
      "loss": 2.1602,
      "step": 13531
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003653754616500795,
      "loss": 2.3164,
      "step": 13532
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036524093990097874,
      "loss": 2.418,
      "step": 13533
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00036510643738716286,
      "loss": 2.4727,
      "step": 13534
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003649719541127071,
      "loss": 2.2598,
      "step": 13535
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00036483749008168743,
      "loss": 2.2031,
      "step": 13536
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003647030452981778,
      "loss": 2.1934,
      "step": 13537
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003645686197662531,
      "loss": 2.2812,
      "step": 13538
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003644342134899862,
      "loss": 2.2031,
      "step": 13539
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003642998264734506,
      "loss": 2.1504,
      "step": 13540
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00036416545872071816,
      "loss": 2.2754,
      "step": 13541
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00036403111023586076,
      "loss": 2.2578,
      "step": 13542
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003638967810229502,
      "loss": 2.1406,
      "step": 13543
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003637624710860568,
      "loss": 2.2344,
      "step": 13544
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003636281804292495,
      "loss": 2.3379,
      "step": 13545
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003634939090565995,
      "loss": 2.5273,
      "step": 13546
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003633596569721749,
      "loss": 2.1738,
      "step": 13547
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003632254241800436,
      "loss": 2.375,
      "step": 13548
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00036309121068427353,
      "loss": 2.2734,
      "step": 13549
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003629570164889323,
      "loss": 2.2109,
      "step": 13550
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.000362822841598086,
      "loss": 2.3438,
      "step": 13551
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00036268868601579995,
      "loss": 2.5469,
      "step": 13552
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003625545497461409,
      "loss": 2.1719,
      "step": 13553
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00036242043279317274,
      "loss": 2.2539,
      "step": 13554
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00036228633516095955,
      "loss": 2.3281,
      "step": 13555
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00036215225685356513,
      "loss": 2.3242,
      "step": 13556
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00036201819787505296,
      "loss": 2.2539,
      "step": 13557
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003618841582294846,
      "loss": 2.2461,
      "step": 13558
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003617501379209227,
      "loss": 2.2227,
      "step": 13559
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00036161613695342786,
      "loss": 2.1328,
      "step": 13560
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003614821553310613,
      "loss": 2.2441,
      "step": 13561
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00036134819305788256,
      "loss": 2.1777,
      "step": 13562
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00036121425013795186,
      "loss": 2.2109,
      "step": 13563
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00036108032657532717,
      "loss": 2.0176,
      "step": 13564
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00036094642237406737,
      "loss": 2.4062,
      "step": 13565
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003608125375382305,
      "loss": 2.0996,
      "step": 13566
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003606786720718733,
      "loss": 2.2344,
      "step": 13567
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00036054482597905205,
      "loss": 2.2188,
      "step": 13568
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00036041099926382314,
      "loss": 2.207,
      "step": 13569
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003602771919302421,
      "loss": 2.4336,
      "step": 13570
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00036014340398236324,
      "loss": 2.2383,
      "step": 13571
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00036000963542424106,
      "loss": 2.2773,
      "step": 13572
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003598758862599295,
      "loss": 2.207,
      "step": 13573
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003597421564934813,
      "loss": 2.418,
      "step": 13574
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003596084461289485,
      "loss": 2.207,
      "step": 13575
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003594747551703834,
      "loss": 2.2441,
      "step": 13576
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003593410836218375,
      "loss": 2.1328,
      "step": 13577
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035920743148736093,
      "loss": 2.4141,
      "step": 13578
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003590737987710043,
      "loss": 2.2617,
      "step": 13579
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003589401854768166,
      "loss": 2.252,
      "step": 13580
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035880659160884745,
      "loss": 2.3203,
      "step": 13581
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035867301717114433,
      "loss": 2.1641,
      "step": 13582
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035853946216775546,
      "loss": 2.252,
      "step": 13583
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003584059266027284,
      "loss": 2.2344,
      "step": 13584
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003582724104801088,
      "loss": 2.1855,
      "step": 13585
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035813891380394357,
      "loss": 2.2734,
      "step": 13586
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003580054365782772,
      "loss": 2.3711,
      "step": 13587
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035787197880715496,
      "loss": 2.2148,
      "step": 13588
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003577385404946214,
      "loss": 2.2266,
      "step": 13589
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003576051216447198,
      "loss": 2.1758,
      "step": 13590
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035747172226149274,
      "loss": 2.1992,
      "step": 13591
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003573383423489831,
      "loss": 2.3516,
      "step": 13592
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035720498191123306,
      "loss": 2.3164,
      "step": 13593
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035707164095228315,
      "loss": 2.3828,
      "step": 13594
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003569383194761745,
      "loss": 2.4531,
      "step": 13595
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003568050174869474,
      "loss": 2.3984,
      "step": 13596
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035667173498864105,
      "loss": 2.1777,
      "step": 13597
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.000356538471985294,
      "loss": 2.3984,
      "step": 13598
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003564052284809449,
      "loss": 2.0918,
      "step": 13599
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003562720044796318,
      "loss": 2.0938,
      "step": 13600
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003561387999853911,
      "loss": 2.1094,
      "step": 13601
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035600561500226017,
      "loss": 2.2734,
      "step": 13602
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003558724495342741,
      "loss": 2.3516,
      "step": 13603
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035573930358546893,
      "loss": 2.4102,
      "step": 13604
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035560617715987885,
      "loss": 2.3438,
      "step": 13605
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035547307026153864,
      "loss": 2.0449,
      "step": 13606
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003553399828944812,
      "loss": 2.2148,
      "step": 13607
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035520691506273994,
      "loss": 2.25,
      "step": 13608
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035507386677034747,
      "loss": 2.0352,
      "step": 13609
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035494083802133525,
      "loss": 2.0527,
      "step": 13610
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035480782881973393,
      "loss": 2.3008,
      "step": 13611
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035467483916957543,
      "loss": 2.1602,
      "step": 13612
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003545418690748889,
      "loss": 2.2539,
      "step": 13613
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003544089185397038,
      "loss": 2.2598,
      "step": 13614
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.000354275987568049,
      "loss": 2.2539,
      "step": 13615
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035414307616395325,
      "loss": 2.2422,
      "step": 13616
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003540101843314438,
      "loss": 2.2109,
      "step": 13617
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003538773120745473,
      "loss": 2.25,
      "step": 13618
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035374445939729074,
      "loss": 2.1152,
      "step": 13619
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035361162630370024,
      "loss": 2.3242,
      "step": 13620
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035347881279780037,
      "loss": 2.2246,
      "step": 13621
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035334601888361607,
      "loss": 2.5078,
      "step": 13622
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003532132445651719,
      "loss": 2.4062,
      "step": 13623
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035308048984649076,
      "loss": 2.2715,
      "step": 13624
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.000352947754731596,
      "loss": 2.2852,
      "step": 13625
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003528150392245094,
      "loss": 2.1836,
      "step": 13626
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0003526823433292534,
      "loss": 2.1094,
      "step": 13627
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00035254966704984837,
      "loss": 2.3828,
      "step": 13628
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003524170103903155,
      "loss": 2.3672,
      "step": 13629
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.000352284373354674,
      "loss": 2.3242,
      "step": 13630
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003521517559469437,
      "loss": 2.3555,
      "step": 13631
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003520191581711435,
      "loss": 2.3633,
      "step": 13632
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003518865800312914,
      "loss": 2.1777,
      "step": 13633
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00035175402153140445,
      "loss": 2.3125,
      "step": 13634
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003516214826755,
      "loss": 2.1543,
      "step": 13635
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003514889634675947,
      "loss": 2.1777,
      "step": 13636
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00035135646391170385,
      "loss": 2.2871,
      "step": 13637
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003512239840118427,
      "loss": 2.2188,
      "step": 13638
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00035109152377202645,
      "loss": 2.2578,
      "step": 13639
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003509590831962685,
      "loss": 2.2578,
      "step": 13640
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003508266622885818,
      "loss": 2.3516,
      "step": 13641
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003506942610529799,
      "loss": 2.1426,
      "step": 13642
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00035056187949347484,
      "loss": 2.2363,
      "step": 13643
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00035042951761407793,
      "loss": 2.0645,
      "step": 13644
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003502971754188006,
      "loss": 2.041,
      "step": 13645
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003501648529116527,
      "loss": 2.1035,
      "step": 13646
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003500325500966447,
      "loss": 2.1211,
      "step": 13647
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003499002669777851,
      "loss": 2.2266,
      "step": 13648
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003497680035590831,
      "loss": 2.1934,
      "step": 13649
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034963575984454633,
      "loss": 2.0137,
      "step": 13650
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003495035358381823,
      "loss": 2.3242,
      "step": 13651
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034937133154399816,
      "loss": 2.2812,
      "step": 13652
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003492391469659999,
      "loss": 2.2051,
      "step": 13653
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003491069821081925,
      "loss": 2.4297,
      "step": 13654
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003489748369745821,
      "loss": 2.3242,
      "step": 13655
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003488427115691728,
      "loss": 2.125,
      "step": 13656
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003487106058959678,
      "loss": 2.0977,
      "step": 13657
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034857851995897095,
      "loss": 2.3477,
      "step": 13658
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.000348446453762185,
      "loss": 2.3359,
      "step": 13659
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003483144073096117,
      "loss": 2.0918,
      "step": 13660
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034818238060525195,
      "loss": 2.3477,
      "step": 13661
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003480503736531078,
      "loss": 2.0098,
      "step": 13662
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034791838645717877,
      "loss": 2.3047,
      "step": 13663
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034778641902146433,
      "loss": 2.2383,
      "step": 13664
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034765447134996376,
      "loss": 2.2227,
      "step": 13665
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.000347522543446676,
      "loss": 2.2773,
      "step": 13666
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034739063531559787,
      "loss": 2.3906,
      "step": 13667
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003472587469607277,
      "loss": 2.2617,
      "step": 13668
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034712687838606127,
      "loss": 2.0859,
      "step": 13669
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034699502959559524,
      "loss": 2.0645,
      "step": 13670
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034686320059332465,
      "loss": 2.4453,
      "step": 13671
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034673139138324474,
      "loss": 2.3984,
      "step": 13672
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034659960196934916,
      "loss": 2.2461,
      "step": 13673
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034646783235563194,
      "loss": 2.5977,
      "step": 13674
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003463360825460865,
      "loss": 2.0527,
      "step": 13675
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034620435254470493,
      "loss": 2.3242,
      "step": 13676
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034607264235547844,
      "loss": 2.1133,
      "step": 13677
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003459409519823995,
      "loss": 2.3945,
      "step": 13678
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003458092814294581,
      "loss": 2.4648,
      "step": 13679
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003456776307006442,
      "loss": 2.2578,
      "step": 13680
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034554599979994737,
      "loss": 2.2266,
      "step": 13681
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003454143887313568,
      "loss": 2.3008,
      "step": 13682
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003452827974988604,
      "loss": 2.1992,
      "step": 13683
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034515122610644555,
      "loss": 2.4648,
      "step": 13684
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034501967455809966,
      "loss": 2.3398,
      "step": 13685
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034488814285780947,
      "loss": 2.207,
      "step": 13686
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034475663100956,
      "loss": 2.0938,
      "step": 13687
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003446251390173374,
      "loss": 2.1992,
      "step": 13688
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003444936668851255,
      "loss": 2.3359,
      "step": 13689
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034436221461690874,
      "loss": 2.0527,
      "step": 13690
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034423078221667094,
      "loss": 2.25,
      "step": 13691
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034409936968839437,
      "loss": 2.1836,
      "step": 13692
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003439679770360611,
      "loss": 2.168,
      "step": 13693
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034383660426365304,
      "loss": 2.3359,
      "step": 13694
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034370525137515163,
      "loss": 2.2812,
      "step": 13695
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034357391837453653,
      "loss": 2.3828,
      "step": 13696
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003434426052657881,
      "loss": 2.3359,
      "step": 13697
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034331131205288555,
      "loss": 2.2695,
      "step": 13698
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034318003873980743,
      "loss": 2.0938,
      "step": 13699
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034304878533053117,
      "loss": 2.1562,
      "step": 13700
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003429175518290348,
      "loss": 2.125,
      "step": 13701
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003427863382392954,
      "loss": 2.1719,
      "step": 13702
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003426551445652883,
      "loss": 2.1914,
      "step": 13703
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003425239708109897,
      "loss": 2.1992,
      "step": 13704
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034239281698037475,
      "loss": 2.2305,
      "step": 13705
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034226168307741755,
      "loss": 2.2227,
      "step": 13706
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003421305691060915,
      "loss": 2.1992,
      "step": 13707
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003419994750703703,
      "loss": 2.1836,
      "step": 13708
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034186840097422664,
      "loss": 2.293,
      "step": 13709
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034173734682163207,
      "loss": 2.0059,
      "step": 13710
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003416063126165584,
      "loss": 2.3789,
      "step": 13711
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034147529836297587,
      "loss": 2.1738,
      "step": 13712
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034134430406485515,
      "loss": 2.168,
      "step": 13713
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034121332972616536,
      "loss": 2.2617,
      "step": 13714
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034108237535087596,
      "loss": 2.1797,
      "step": 13715
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003409514409429547,
      "loss": 2.2734,
      "step": 13716
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003408205265063696,
      "loss": 2.0703,
      "step": 13717
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034068963204508817,
      "loss": 2.2695,
      "step": 13718
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034055875756307653,
      "loss": 2.2617,
      "step": 13719
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034042790306430007,
      "loss": 2.0742,
      "step": 13720
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034029706855272533,
      "loss": 2.4141,
      "step": 13721
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003401662540323165,
      "loss": 2.0664,
      "step": 13722
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00034003545950703727,
      "loss": 2.0801,
      "step": 13723
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003399046849808515,
      "loss": 2.1777,
      "step": 13724
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003397739304577222,
      "loss": 2.0879,
      "step": 13725
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033964319594161177,
      "loss": 2.207,
      "step": 13726
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033951248143648116,
      "loss": 2.1484,
      "step": 13727
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033938178694629197,
      "loss": 2.2695,
      "step": 13728
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033925111247500494,
      "loss": 2.3438,
      "step": 13729
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033912045802657933,
      "loss": 2.2891,
      "step": 13730
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003389898236049751,
      "loss": 2.1172,
      "step": 13731
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033885920921415013,
      "loss": 2.0879,
      "step": 13732
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033872861485806285,
      "loss": 2.1797,
      "step": 13733
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.000338598040540671,
      "loss": 2.0605,
      "step": 13734
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003384674862659307,
      "loss": 2.1484,
      "step": 13735
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.000338336952037799,
      "loss": 2.3242,
      "step": 13736
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033820643786023073,
      "loss": 1.9688,
      "step": 13737
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033807594373718163,
      "loss": 2.2656,
      "step": 13738
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003379454696726054,
      "loss": 2.1016,
      "step": 13739
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033781501567045613,
      "loss": 2.2168,
      "step": 13740
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033768458173468743,
      "loss": 2.1875,
      "step": 13741
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033755416786925143,
      "loss": 2.1875,
      "step": 13742
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033742377407809974,
      "loss": 2.3633,
      "step": 13743
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003372934003651843,
      "loss": 2.4453,
      "step": 13744
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033716304673445585,
      "loss": 2.3047,
      "step": 13745
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003370327131898642,
      "loss": 2.3047,
      "step": 13746
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033690239973535894,
      "loss": 2.1875,
      "step": 13747
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003367721063748895,
      "loss": 2.1328,
      "step": 13748
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003366418331124038,
      "loss": 2.3281,
      "step": 13749
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033651157995184935,
      "loss": 2.3945,
      "step": 13750
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003363813468971733,
      "loss": 2.2285,
      "step": 13751
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003362511339523226,
      "loss": 2.2441,
      "step": 13752
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003361209411212427,
      "loss": 2.2129,
      "step": 13753
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033599076840787925,
      "loss": 2.1875,
      "step": 13754
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003358606158161762,
      "loss": 2.2578,
      "step": 13755
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003357304833500785,
      "loss": 2.1191,
      "step": 13756
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003356003710135288,
      "loss": 2.084,
      "step": 13757
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003354702788104706,
      "loss": 2.043,
      "step": 13758
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003353402067448456,
      "loss": 2.3086,
      "step": 13759
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003352101548205955,
      "loss": 2.0703,
      "step": 13760
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003350801230416618,
      "loss": 2.1836,
      "step": 13761
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003349501114119844,
      "loss": 2.1348,
      "step": 13762
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033482011993550266,
      "loss": 2.0566,
      "step": 13763
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003346901486161569,
      "loss": 2.1797,
      "step": 13764
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.000334560197457885,
      "loss": 2.2734,
      "step": 13765
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003344302664646246,
      "loss": 2.2578,
      "step": 13766
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033430035564031347,
      "loss": 2.3359,
      "step": 13767
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003341704649888886,
      "loss": 2.4258,
      "step": 13768
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033404059451428537,
      "loss": 2.2148,
      "step": 13769
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033391074422043976,
      "loss": 2.1484,
      "step": 13770
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003337809141112869,
      "loss": 2.4219,
      "step": 13771
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033365110419076075,
      "loss": 2.1445,
      "step": 13772
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033352131446279454,
      "loss": 2.293,
      "step": 13773
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033339154493132185,
      "loss": 2.3945,
      "step": 13774
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033326179560027523,
      "loss": 2.2031,
      "step": 13775
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033313206647358617,
      "loss": 2.457,
      "step": 13776
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033300235755518625,
      "loss": 2.166,
      "step": 13777
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003328726688490056,
      "loss": 2.293,
      "step": 13778
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033274300035897466,
      "loss": 2.3398,
      "step": 13779
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033261335208902243,
      "loss": 2.1621,
      "step": 13780
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033248372404307816,
      "loss": 2.1152,
      "step": 13781
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033235411622506927,
      "loss": 2.0469,
      "step": 13782
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003322245286389239,
      "loss": 2.0469,
      "step": 13783
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003320949612885691,
      "loss": 2.2109,
      "step": 13784
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003319654141779309,
      "loss": 2.3711,
      "step": 13785
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003318358873109344,
      "loss": 2.1816,
      "step": 13786
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033170638069150596,
      "loss": 2.4414,
      "step": 13787
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003315768943235694,
      "loss": 2.1289,
      "step": 13788
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033144742821104823,
      "loss": 2.1992,
      "step": 13789
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033131798235786603,
      "loss": 2.3359,
      "step": 13790
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033118855676794593,
      "loss": 2.2227,
      "step": 13791
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033105915144520927,
      "loss": 2.1582,
      "step": 13792
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033092976639357755,
      "loss": 2.3281,
      "step": 13793
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033080040161697147,
      "loss": 2.2402,
      "step": 13794
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003306710571193119,
      "loss": 2.207,
      "step": 13795
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003305417329045175,
      "loss": 2.1387,
      "step": 13796
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033041242897650794,
      "loss": 2.1875,
      "step": 13797
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.000330283145339201,
      "loss": 2.1992,
      "step": 13798
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00033015388199651464,
      "loss": 2.291,
      "step": 13799
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003300246389523662,
      "loss": 2.2676,
      "step": 13800
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00032989541621067207,
      "loss": 2.1309,
      "step": 13801
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00032976621377534763,
      "loss": 2.2305,
      "step": 13802
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00032963703165030843,
      "loss": 2.2773,
      "step": 13803
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003295078698394697,
      "loss": 2.2383,
      "step": 13804
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00032937872834674475,
      "loss": 2.2148,
      "step": 13805
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003292496071760467,
      "loss": 2.3398,
      "step": 13806
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003291205063312893,
      "loss": 2.2539,
      "step": 13807
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003289914258163844,
      "loss": 2.2031,
      "step": 13808
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003288623656352431,
      "loss": 2.4023,
      "step": 13809
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00032873332579177675,
      "loss": 2.3125,
      "step": 13810
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003286043062898958,
      "loss": 2.125,
      "step": 13811
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003284753071335095,
      "loss": 2.1152,
      "step": 13812
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00032834632832652724,
      "loss": 2.2109,
      "step": 13813
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00032821736987285777,
      "loss": 2.3047,
      "step": 13814
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032808843177640866,
      "loss": 2.3203,
      "step": 13815
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032795951404108694,
      "loss": 2.3945,
      "step": 13816
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032783061667079937,
      "loss": 1.9219,
      "step": 13817
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003277017396694525,
      "loss": 2.1719,
      "step": 13818
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003275728830409509,
      "loss": 2.5781,
      "step": 13819
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032744404678920004,
      "loss": 2.1133,
      "step": 13820
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032731523091810344,
      "loss": 2.2695,
      "step": 13821
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032718643543156535,
      "loss": 2.4062,
      "step": 13822
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032705766033348804,
      "loss": 2.3398,
      "step": 13823
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003269289056277744,
      "loss": 2.2773,
      "step": 13824
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003268001713183255,
      "loss": 2.2734,
      "step": 13825
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032667145740904283,
      "loss": 2.2363,
      "step": 13826
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.000326542763903827,
      "loss": 2.3242,
      "step": 13827
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032641409080657756,
      "loss": 2.2266,
      "step": 13828
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032628543812119313,
      "loss": 2.5,
      "step": 13829
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003261568058515736,
      "loss": 2.2695,
      "step": 13830
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032602819400161633,
      "loss": 2.3555,
      "step": 13831
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032589960257521834,
      "loss": 2.3359,
      "step": 13832
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003257710315762766,
      "loss": 2.1758,
      "step": 13833
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032564248100868775,
      "loss": 2.1855,
      "step": 13834
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032551395087634683,
      "loss": 2.1191,
      "step": 13835
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003253854411831485,
      "loss": 2.3047,
      "step": 13836
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003252569519329872,
      "loss": 2.3438,
      "step": 13837
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032512848312975695,
      "loss": 2.2852,
      "step": 13838
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003250000347773502,
      "loss": 2.3477,
      "step": 13839
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032487160687966,
      "loss": 2.4766,
      "step": 13840
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003247431994405774,
      "loss": 2.0801,
      "step": 13841
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032461481246399396,
      "loss": 2.1211,
      "step": 13842
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003244864459538005,
      "loss": 2.0098,
      "step": 13843
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003243580999138864,
      "loss": 2.1875,
      "step": 13844
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003242297743481416,
      "loss": 2.2617,
      "step": 13845
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032410146926045404,
      "loss": 2.2305,
      "step": 13846
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003239731846547124,
      "loss": 2.3906,
      "step": 13847
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032384492053480366,
      "loss": 2.3359,
      "step": 13848
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003237166769046148,
      "loss": 2.2031,
      "step": 13849
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032358845376803246,
      "loss": 2.2734,
      "step": 13850
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032346025112894183,
      "loss": 2.25,
      "step": 13851
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032333206899122735,
      "loss": 2.2461,
      "step": 13852
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003232039073587745,
      "loss": 2.4023,
      "step": 13853
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032307576623546633,
      "loss": 2.2852,
      "step": 13854
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032294764562518577,
      "loss": 2.1191,
      "step": 13855
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003228195455318155,
      "loss": 2.3555,
      "step": 13856
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003226914659592376,
      "loss": 2.1484,
      "step": 13857
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032256340691133324,
      "loss": 2.0918,
      "step": 13858
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003224353683919826,
      "loss": 2.1367,
      "step": 13859
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.000322307350405066,
      "loss": 2.0996,
      "step": 13860
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.000322179352954463,
      "loss": 1.959,
      "step": 13861
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032205137604405186,
      "loss": 2.1816,
      "step": 13862
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003219234196777112,
      "loss": 2.4414,
      "step": 13863
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.000321795483859318,
      "loss": 2.127,
      "step": 13864
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032166756859274947,
      "loss": 2.0508,
      "step": 13865
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003215396738818821,
      "loss": 2.2891,
      "step": 13866
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032141179973059123,
      "loss": 2.4844,
      "step": 13867
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032128394614275145,
      "loss": 2.1719,
      "step": 13868
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032115611312223756,
      "loss": 2.2539,
      "step": 13869
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003210283006729238,
      "loss": 2.0977,
      "step": 13870
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003209005087986827,
      "loss": 2.2773,
      "step": 13871
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003207727375033862,
      "loss": 2.2246,
      "step": 13872
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003206449867909076,
      "loss": 2.2734,
      "step": 13873
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003205172566651174,
      "loss": 2.2773,
      "step": 13874
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032038954712988613,
      "loss": 2.3164,
      "step": 13875
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032026185818908383,
      "loss": 2.4238,
      "step": 13876
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00032013418984658037,
      "loss": 2.125,
      "step": 13877
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003200065421062439,
      "loss": 2.3789,
      "step": 13878
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003198789149719432,
      "loss": 2.4844,
      "step": 13879
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003197513084475451,
      "loss": 2.3516,
      "step": 13880
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003196237225369172,
      "loss": 2.084,
      "step": 13881
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.000319496157243925,
      "loss": 2.2812,
      "step": 13882
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00031936861257243456,
      "loss": 2.3379,
      "step": 13883
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003192410885263113,
      "loss": 2.2344,
      "step": 13884
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003191135851094189,
      "loss": 1.9668,
      "step": 13885
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00031898610232562177,
      "loss": 2.0215,
      "step": 13886
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003188586401787823,
      "loss": 2.1875,
      "step": 13887
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003187311986727639,
      "loss": 2.0586,
      "step": 13888
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00031860377781142766,
      "loss": 2.3125,
      "step": 13889
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00031847637759863556,
      "loss": 2.3438,
      "step": 13890
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00031834899803824757,
      "loss": 2.3711,
      "step": 13891
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003182216391341239,
      "loss": 2.5078,
      "step": 13892
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003180943008901246,
      "loss": 2.2422,
      "step": 13893
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00031796698331010775,
      "loss": 2.0938,
      "step": 13894
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00031783968639793116,
      "loss": 2.1777,
      "step": 13895
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00031771241015745335,
      "loss": 2.041,
      "step": 13896
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003175851545925308,
      "loss": 2.2656,
      "step": 13897
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003174579197070193,
      "loss": 2.2695,
      "step": 13898
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003173307055047748,
      "loss": 2.2305,
      "step": 13899
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00031720351198965283,
      "loss": 2.3398,
      "step": 13900
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00031707633916550716,
      "loss": 2.0605,
      "step": 13901
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00031694918703619135,
      "loss": 2.2656,
      "step": 13902
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00031682205560555897,
      "loss": 2.3633,
      "step": 13903
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00031669494487746264,
      "loss": 2.1914,
      "step": 13904
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003165678548557538,
      "loss": 2.2461,
      "step": 13905
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003164407855442841,
      "loss": 2.2344,
      "step": 13906
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003163137369469038,
      "loss": 2.332,
      "step": 13907
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031618670906746293,
      "loss": 2.2383,
      "step": 13908
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031605970190981124,
      "loss": 2.1797,
      "step": 13909
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031593271547779734,
      "loss": 2.3398,
      "step": 13910
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003158057497752688,
      "loss": 2.3594,
      "step": 13911
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031567880480607346,
      "loss": 2.1875,
      "step": 13912
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003155518805740586,
      "loss": 2.3867,
      "step": 13913
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031542497708306996,
      "loss": 2.2188,
      "step": 13914
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003152980943369527,
      "loss": 2.252,
      "step": 13915
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003151712323395528,
      "loss": 2.3008,
      "step": 13916
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031504439109471407,
      "loss": 2.1953,
      "step": 13917
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031491757060628,
      "loss": 2.2734,
      "step": 13918
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031479077087809396,
      "loss": 2.1406,
      "step": 13919
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031466399191399855,
      "loss": 2.1172,
      "step": 13920
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031453723371783506,
      "loss": 2.3047,
      "step": 13921
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003144104962934451,
      "loss": 2.0273,
      "step": 13922
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031428377964466935,
      "loss": 2.25,
      "step": 13923
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003141570837753476,
      "loss": 2.0508,
      "step": 13924
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031403040868931874,
      "loss": 2.3867,
      "step": 13925
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031390375439042175,
      "loss": 2.0938,
      "step": 13926
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003137771208824951,
      "loss": 2.2227,
      "step": 13927
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031365050816937535,
      "loss": 2.1738,
      "step": 13928
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003135239162549002,
      "loss": 2.1211,
      "step": 13929
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031339734514290485,
      "loss": 2.3672,
      "step": 13930
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031327079483722543,
      "loss": 2.3125,
      "step": 13931
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003131442653416969,
      "loss": 2.2051,
      "step": 13932
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031301775666015344,
      "loss": 2.1641,
      "step": 13933
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031289126879642813,
      "loss": 2.0879,
      "step": 13934
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003127648017543545,
      "loss": 2.2383,
      "step": 13935
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003126383555377651,
      "loss": 2.3438,
      "step": 13936
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003125119301504914,
      "loss": 2.2852,
      "step": 13937
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003123855255963638,
      "loss": 2.1836,
      "step": 13938
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003122591418792141,
      "loss": 2.168,
      "step": 13939
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003121327790028715,
      "loss": 2.2715,
      "step": 13940
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003120064369711648,
      "loss": 2.1719,
      "step": 13941
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003118801157879232,
      "loss": 2.2617,
      "step": 13942
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003117538154569746,
      "loss": 2.3145,
      "step": 13943
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003116275359821459,
      "loss": 2.4336,
      "step": 13944
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003115012773672643,
      "loss": 2.3281,
      "step": 13945
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003113750396161552,
      "loss": 2.1094,
      "step": 13946
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003112488227326449,
      "loss": 2.3047,
      "step": 13947
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003111226267205572,
      "loss": 2.2598,
      "step": 13948
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031099645158371716,
      "loss": 2.2246,
      "step": 13949
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031087029732594754,
      "loss": 2.1992,
      "step": 13950
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031074416395107153,
      "loss": 2.1621,
      "step": 13951
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031061805146291176,
      "loss": 2.3984,
      "step": 13952
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031049195986528955,
      "loss": 2.1992,
      "step": 13953
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003103658891620256,
      "loss": 2.3398,
      "step": 13954
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003102398393569404,
      "loss": 2.293,
      "step": 13955
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00031011381045385425,
      "loss": 2.4492,
      "step": 13956
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003099878024565853,
      "loss": 2.1465,
      "step": 13957
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003098618153689526,
      "loss": 2.1797,
      "step": 13958
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003097358491947743,
      "loss": 2.0371,
      "step": 13959
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003096099039378669,
      "loss": 2.3926,
      "step": 13960
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00030948397960204677,
      "loss": 2.3477,
      "step": 13961
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00030935807619113074,
      "loss": 1.9746,
      "step": 13962
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00030923219370893387,
      "loss": 2.1094,
      "step": 13963
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003091063321592701,
      "loss": 2.3711,
      "step": 13964
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003089804915459539,
      "loss": 2.2402,
      "step": 13965
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00030885467187279905,
      "loss": 2.2305,
      "step": 13966
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003087288731436179,
      "loss": 2.2812,
      "step": 13967
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003086030953622222,
      "loss": 2.3945,
      "step": 13968
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00030847733853242386,
      "loss": 2.4102,
      "step": 13969
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003083516026580341,
      "loss": 2.168,
      "step": 13970
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003082258877428623,
      "loss": 2.2305,
      "step": 13971
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003081001937907187,
      "loss": 2.1797,
      "step": 13972
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003079745208054118,
      "loss": 2.2773,
      "step": 13973
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00030784886879075,
      "loss": 2.2852,
      "step": 13974
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00030772323775054146,
      "loss": 2.2266,
      "step": 13975
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003075976276885928,
      "loss": 2.1992,
      "step": 13976
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003074720386087101,
      "loss": 2.4102,
      "step": 13977
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003073464705146994,
      "loss": 2.0781,
      "step": 13978
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003072209234103663,
      "loss": 2.1133,
      "step": 13979
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00030709539729951475,
      "loss": 2.3477,
      "step": 13980
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00030696989218594815,
      "loss": 2.4238,
      "step": 13981
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003068444080734709,
      "loss": 2.4336,
      "step": 13982
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00030671894496588504,
      "loss": 2.1152,
      "step": 13983
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00030659350286699205,
      "loss": 2.4102,
      "step": 13984
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003064680817805937,
      "loss": 2.1504,
      "step": 13985
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003063426817104908,
      "loss": 2.209,
      "step": 13986
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00030621730266048295,
      "loss": 2.1875,
      "step": 13987
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00030609194463437006,
      "loss": 2.2891,
      "step": 13988
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003059666076359503,
      "loss": 2.1543,
      "step": 13989
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00030584129166902243,
      "loss": 2.1562,
      "step": 13990
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00030571599673738325,
      "loss": 2.1016,
      "step": 13991
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003055907228448299,
      "loss": 2.1621,
      "step": 13992
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003054654699951591,
      "loss": 2.2207,
      "step": 13993
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003053402381921656,
      "loss": 2.2266,
      "step": 13994
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.000305215027439645,
      "loss": 2.168,
      "step": 13995
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.000305089837741391,
      "loss": 2.1816,
      "step": 13996
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003049646691011979,
      "loss": 2.0332,
      "step": 13997
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003048395215228581,
      "loss": 2.3516,
      "step": 13998
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00030471439501016453,
      "loss": 2.1445,
      "step": 13999
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00030458928956690834,
      "loss": 2.2383,
      "step": 14000
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00030446420519688103,
      "loss": 2.2246,
      "step": 14001
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00030433914190387324,
      "loss": 2.2148,
      "step": 14002
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003042140996916746,
      "loss": 2.1113,
      "step": 14003
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00030408907856407366,
      "loss": 2.0762,
      "step": 14004
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00030396407852486016,
      "loss": 2.2695,
      "step": 14005
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003038390995778214,
      "loss": 2.3945,
      "step": 14006
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003037141417267445,
      "loss": 2.3281,
      "step": 14007
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003035892049754162,
      "loss": 2.0625,
      "step": 14008
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003034642893276228,
      "loss": 2.1484,
      "step": 14009
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00030333939478714955,
      "loss": 2.2656,
      "step": 14010
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003032145213577806,
      "loss": 2.1719,
      "step": 14011
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003030896690433005,
      "loss": 2.3203,
      "step": 14012
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00030296483784749296,
      "loss": 2.3086,
      "step": 14013
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003028400277741402,
      "loss": 2.1602,
      "step": 14014
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003027152388270249,
      "loss": 2.2188,
      "step": 14015
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003025904710099281,
      "loss": 2.2305,
      "step": 14016
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00030246572432663076,
      "loss": 2.1992,
      "step": 14017
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003023409987809136,
      "loss": 2.2305,
      "step": 14018
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00030221629437655585,
      "loss": 2.2891,
      "step": 14019
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003020916111173361,
      "loss": 2.2754,
      "step": 14020
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00030196694900703314,
      "loss": 2.3008,
      "step": 14021
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003018423080494247,
      "loss": 2.3047,
      "step": 14022
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003017176882482875,
      "loss": 2.3867,
      "step": 14023
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00030159308960739796,
      "loss": 2.332,
      "step": 14024
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00030146851213053226,
      "loss": 2.2227,
      "step": 14025
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00030134395582146525,
      "loss": 2.1484,
      "step": 14026
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003012194206839709,
      "loss": 2.248,
      "step": 14027
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003010949067218235,
      "loss": 2.2383,
      "step": 14028
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00030097041393879656,
      "loss": 2.2109,
      "step": 14029
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003008459423386619,
      "loss": 2.168,
      "step": 14030
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003007214919251918,
      "loss": 2.332,
      "step": 14031
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003005970627021578,
      "loss": 2.3398,
      "step": 14032
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003004726546733303,
      "loss": 2.1074,
      "step": 14033
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003003482678424787,
      "loss": 2.4102,
      "step": 14034
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00030022390221337293,
      "loss": 2.2695,
      "step": 14035
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0003000995577897818,
      "loss": 2.2266,
      "step": 14036
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029997523457547283,
      "loss": 2.3672,
      "step": 14037
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029985093257421403,
      "loss": 2.2793,
      "step": 14038
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029972665178977146,
      "loss": 2.2168,
      "step": 14039
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002996023922259116,
      "loss": 2.1426,
      "step": 14040
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002994781538864003,
      "loss": 2.2031,
      "step": 14041
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.000299353936775002,
      "loss": 2.3789,
      "step": 14042
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029922974089548047,
      "loss": 2.1426,
      "step": 14043
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002991055662515999,
      "loss": 1.9785,
      "step": 14044
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002989814128471232,
      "loss": 2.3398,
      "step": 14045
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002988572806858123,
      "loss": 2.3672,
      "step": 14046
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002987331697714284,
      "loss": 2.1641,
      "step": 14047
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029860908010773357,
      "loss": 2.4336,
      "step": 14048
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029848501169848764,
      "loss": 2.1738,
      "step": 14049
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002983609645474498,
      "loss": 2.168,
      "step": 14050
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029823693865837955,
      "loss": 2.3125,
      "step": 14051
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029811293403503547,
      "loss": 2.3867,
      "step": 14052
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002979889506811747,
      "loss": 2.2871,
      "step": 14053
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002978649886005551,
      "loss": 2.2852,
      "step": 14054
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029774104779693234,
      "loss": 2.2617,
      "step": 14055
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029761712827406294,
      "loss": 2.1934,
      "step": 14056
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002974932300357015,
      "loss": 2.3008,
      "step": 14057
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002973693530856031,
      "loss": 2.3008,
      "step": 14058
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029724549742752096,
      "loss": 2.0293,
      "step": 14059
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002971216630652086,
      "loss": 2.2559,
      "step": 14060
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029699785000241905,
      "loss": 2.2031,
      "step": 14061
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002968740582429039,
      "loss": 2.1445,
      "step": 14062
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029675028779041403,
      "loss": 2.3555,
      "step": 14063
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002966265386487006,
      "loss": 2.2246,
      "step": 14064
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029650281082151364,
      "loss": 2.3516,
      "step": 14065
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029637910431260217,
      "loss": 2.1016,
      "step": 14066
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002962554191257151,
      "loss": 2.3203,
      "step": 14067
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002961317552646008,
      "loss": 2.2539,
      "step": 14068
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002960081127330064,
      "loss": 2.375,
      "step": 14069
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.000295884491534678,
      "loss": 2.1465,
      "step": 14070
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002957608916733631,
      "loss": 2.2305,
      "step": 14071
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002956373131528064,
      "loss": 2.1875,
      "step": 14072
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029551375597675246,
      "loss": 2.291,
      "step": 14073
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002953902201489459,
      "loss": 2.1836,
      "step": 14074
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002952667056731304,
      "loss": 2.2344,
      "step": 14075
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029514321255304866,
      "loss": 2.3359,
      "step": 14076
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002950197407924426,
      "loss": 2.3672,
      "step": 14077
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029489629039505414,
      "loss": 2.2793,
      "step": 14078
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029477286136462454,
      "loss": 2.2734,
      "step": 14079
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002946494537048935,
      "loss": 2.1914,
      "step": 14080
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002945260674196012,
      "loss": 2.4492,
      "step": 14081
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029440270251248615,
      "loss": 2.4531,
      "step": 14082
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002942793589872869,
      "loss": 2.2812,
      "step": 14083
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002941560368477415,
      "loss": 2.1094,
      "step": 14084
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029403273609758686,
      "loss": 2.2695,
      "step": 14085
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002939094567405589,
      "loss": 2.2422,
      "step": 14086
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002937861987803938,
      "loss": 2.123,
      "step": 14087
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029366296222082687,
      "loss": 2.2285,
      "step": 14088
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002935397470655925,
      "loss": 2.3164,
      "step": 14089
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029341655331842375,
      "loss": 2.1953,
      "step": 14090
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.000293293380983055,
      "loss": 2.2168,
      "step": 14091
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0002931702300632182,
      "loss": 2.168,
      "step": 14092
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029304710056264496,
      "loss": 2.168,
      "step": 14093
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00029292399248506673,
      "loss": 2.1074,
      "step": 14094
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00029280090583421446,
      "loss": 2.293,
      "step": 14095
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002926778406138175,
      "loss": 2.5195,
      "step": 14096
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002925547968276057,
      "loss": 2.0684,
      "step": 14097
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.000292431774479307,
      "loss": 2.3633,
      "step": 14098
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002923087735726501,
      "loss": 2.2422,
      "step": 14099
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002921857941113617,
      "loss": 2.1914,
      "step": 14100
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00029206283609916906,
      "loss": 2.1973,
      "step": 14101
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002919398995397976,
      "loss": 2.0371,
      "step": 14102
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00029181698443697305,
      "loss": 2.375,
      "step": 14103
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00029169409079442043,
      "loss": 2.0078,
      "step": 14104
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002915712186158632,
      "loss": 2.2656,
      "step": 14105
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00029144836790502505,
      "loss": 2.2969,
      "step": 14106
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002913255386656292,
      "loss": 2.3086,
      "step": 14107
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00029120273090139736,
      "loss": 2.2344,
      "step": 14108
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002910799446160507,
      "loss": 2.2695,
      "step": 14109
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002909571798133104,
      "loss": 2.2891,
      "step": 14110
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.000290834436496897,
      "loss": 2.2305,
      "step": 14111
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002907117146705296,
      "loss": 2.3945,
      "step": 14112
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002905890143379264,
      "loss": 2.3711,
      "step": 14113
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002904663355028071,
      "loss": 2.3359,
      "step": 14114
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00029034367816888854,
      "loss": 2.0195,
      "step": 14115
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002902210423398872,
      "loss": 2.1621,
      "step": 14116
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002900984280195198,
      "loss": 2.0957,
      "step": 14117
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028997583521150216,
      "loss": 2.2109,
      "step": 14118
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028985326391954883,
      "loss": 2.1484,
      "step": 14119
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002897307141473745,
      "loss": 2.1992,
      "step": 14120
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028960818589869245,
      "loss": 2.2344,
      "step": 14121
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002894856791772161,
      "loss": 2.3164,
      "step": 14122
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028936319398665725,
      "loss": 2.1777,
      "step": 14123
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002892407303307283,
      "loss": 2.082,
      "step": 14124
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028911828821313954,
      "loss": 2.041,
      "step": 14125
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028899586763760175,
      "loss": 2.4141,
      "step": 14126
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028887346860782505,
      "loss": 2.3359,
      "step": 14127
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002887510911275182,
      "loss": 2.3086,
      "step": 14128
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028862873520038926,
      "loss": 2.127,
      "step": 14129
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028850640083014637,
      "loss": 2.3125,
      "step": 14130
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028838408802049685,
      "loss": 2.2266,
      "step": 14131
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028826179677514683,
      "loss": 2.4297,
      "step": 14132
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028813952709780223,
      "loss": 2.1484,
      "step": 14133
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028801727899216867,
      "loss": 2.2539,
      "step": 14134
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028789505246195013,
      "loss": 2.1309,
      "step": 14135
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028777284751085045,
      "loss": 2.1113,
      "step": 14136
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.000287650664142573,
      "loss": 2.1016,
      "step": 14137
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028752850236082064,
      "loss": 2.3477,
      "step": 14138
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002874063621692947,
      "loss": 2.1367,
      "step": 14139
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.000287284243571697,
      "loss": 2.375,
      "step": 14140
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028716214657172756,
      "loss": 2.166,
      "step": 14141
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028704007117308697,
      "loss": 2.1172,
      "step": 14142
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002869180173794738,
      "loss": 2.3242,
      "step": 14143
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028679598519458705,
      "loss": 2.2578,
      "step": 14144
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028667397462212496,
      "loss": 2.0977,
      "step": 14145
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028655198566578436,
      "loss": 2.1426,
      "step": 14146
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028643001832926243,
      "loss": 2.3008,
      "step": 14147
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028630807261625446,
      "loss": 2.4688,
      "step": 14148
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028618614853045634,
      "loss": 2.1914,
      "step": 14149
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002860642460755629,
      "loss": 2.2734,
      "step": 14150
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028594236525526806,
      "loss": 2.1211,
      "step": 14151
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002858205060732647,
      "loss": 2.2734,
      "step": 14152
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.000285698668533246,
      "loss": 2.0254,
      "step": 14153
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002855768526389042,
      "loss": 2.3086,
      "step": 14154
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002854550583939306,
      "loss": 2.2461,
      "step": 14155
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002853332858020152,
      "loss": 2.2852,
      "step": 14156
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002852115348668495,
      "loss": 2.1836,
      "step": 14157
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002850898055921222,
      "loss": 2.0488,
      "step": 14158
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002849680979815217,
      "loss": 2.2695,
      "step": 14159
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028484641203873674,
      "loss": 2.1699,
      "step": 14160
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002847247477674548,
      "loss": 2.3438,
      "step": 14161
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028460310517136237,
      "loss": 2.2383,
      "step": 14162
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.000284481484254146,
      "loss": 2.2695,
      "step": 14163
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002843598850194907,
      "loss": 2.2969,
      "step": 14164
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028423830747108204,
      "loss": 2.1699,
      "step": 14165
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028411675161260343,
      "loss": 2.1895,
      "step": 14166
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028399521744773917,
      "loss": 2.1914,
      "step": 14167
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028387370498017127,
      "loss": 2.1953,
      "step": 14168
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028375221421358254,
      "loss": 2.2969,
      "step": 14169
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002836307451516549,
      "loss": 2.3555,
      "step": 14170
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002835092977980687,
      "loss": 2.0391,
      "step": 14171
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.000283387872156504,
      "loss": 2.2773,
      "step": 14172
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028326646823064063,
      "loss": 2.1699,
      "step": 14173
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.000283145086024158,
      "loss": 2.25,
      "step": 14174
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028302372554073375,
      "loss": 2.2734,
      "step": 14175
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002829023867840457,
      "loss": 2.3203,
      "step": 14176
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002827810697577711,
      "loss": 2.2695,
      "step": 14177
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.000282659774465586,
      "loss": 2.1426,
      "step": 14178
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002825385009111655,
      "loss": 2.1152,
      "step": 14179
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002824172490981858,
      "loss": 2.4297,
      "step": 14180
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028229601903032053,
      "loss": 2.2129,
      "step": 14181
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002821748107112432,
      "loss": 2.1309,
      "step": 14182
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00028205362414462687,
      "loss": 2.1094,
      "step": 14183
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002819324593341445,
      "loss": 2.2305,
      "step": 14184
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002818113162834669,
      "loss": 2.1953,
      "step": 14185
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002816901949962658,
      "loss": 2.1875,
      "step": 14186
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002815690954762111,
      "loss": 2.332,
      "step": 14187
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00028144801772697305,
      "loss": 2.1367,
      "step": 14188
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00028132696175221995,
      "loss": 2.3555,
      "step": 14189
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00028120592755562094,
      "loss": 2.1562,
      "step": 14190
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002810849151408432,
      "loss": 2.1016,
      "step": 14191
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00028096392451155397,
      "loss": 2.1465,
      "step": 14192
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00028084295567142004,
      "loss": 2.1348,
      "step": 14193
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002807220086241068,
      "loss": 2.2109,
      "step": 14194
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00028060108337327915,
      "loss": 2.1953,
      "step": 14195
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00028048017992260177,
      "loss": 2.1445,
      "step": 14196
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002803592982757387,
      "loss": 2.2129,
      "step": 14197
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002802384384363525,
      "loss": 2.4609,
      "step": 14198
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00028011760040810586,
      "loss": 2.4297,
      "step": 14199
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002799967841946609,
      "loss": 2.1152,
      "step": 14200
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027987598979967854,
      "loss": 2.2168,
      "step": 14201
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027975521722681875,
      "loss": 2.2539,
      "step": 14202
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002796344664797418,
      "loss": 2.0625,
      "step": 14203
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002795137375621071,
      "loss": 2.2383,
      "step": 14204
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027939303047757246,
      "loss": 2.0996,
      "step": 14205
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027927234522979636,
      "loss": 2.1738,
      "step": 14206
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002791516818224353,
      "loss": 2.1191,
      "step": 14207
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002790310402591465,
      "loss": 2.3359,
      "step": 14208
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002789104205435852,
      "loss": 2.2695,
      "step": 14209
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.000278789822679407,
      "loss": 2.1426,
      "step": 14210
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002786692466702659,
      "loss": 2.0547,
      "step": 14211
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027854869251981606,
      "loss": 2.0254,
      "step": 14212
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027842816023171104,
      "loss": 2.1895,
      "step": 14213
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.000278307649809603,
      "loss": 2.3945,
      "step": 14214
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027818716125714305,
      "loss": 2.1797,
      "step": 14215
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002780666945779838,
      "loss": 2.3359,
      "step": 14216
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002779462497757752,
      "loss": 1.7891,
      "step": 14217
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027782582685416667,
      "loss": 2.0996,
      "step": 14218
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002777054258168078,
      "loss": 2.3203,
      "step": 14219
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002775850466673474,
      "loss": 2.332,
      "step": 14220
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027746468940943313,
      "loss": 2.2617,
      "step": 14221
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027734435404671155,
      "loss": 2.123,
      "step": 14222
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027722404058283046,
      "loss": 2.0586,
      "step": 14223
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002771037490214351,
      "loss": 2.2637,
      "step": 14224
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002769834793661703,
      "loss": 2.3203,
      "step": 14225
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027686323162068115,
      "loss": 2.1484,
      "step": 14226
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027674300578861175,
      "loss": 2.0781,
      "step": 14227
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027662280187360476,
      "loss": 2.0527,
      "step": 14228
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027650261987930335,
      "loss": 2.3086,
      "step": 14229
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027638245980934873,
      "loss": 2.166,
      "step": 14230
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002762623216673829,
      "loss": 2.25,
      "step": 14231
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002761422054570457,
      "loss": 2.5156,
      "step": 14232
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027602211118197775,
      "loss": 2.3145,
      "step": 14233
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027590203884581764,
      "loss": 2.2266,
      "step": 14234
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027578198845220426,
      "loss": 2.1914,
      "step": 14235
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027566196000477583,
      "loss": 2.1719,
      "step": 14236
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027554195350716935,
      "loss": 2.1953,
      "step": 14237
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002754219689630212,
      "loss": 2.0352,
      "step": 14238
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027530200637596736,
      "loss": 2.3047,
      "step": 14239
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027518206574964353,
      "loss": 2.2402,
      "step": 14240
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027506214708768374,
      "loss": 2.0508,
      "step": 14241
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002749422503937221,
      "loss": 2.3594,
      "step": 14242
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027482237567139236,
      "loss": 2.2051,
      "step": 14243
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002747025229243266,
      "loss": 2.3164,
      "step": 14244
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002745826921561566,
      "loss": 2.3027,
      "step": 14245
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027446288337051395,
      "loss": 2.4023,
      "step": 14246
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002743430965710294,
      "loss": 2.209,
      "step": 14247
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002742233317613324,
      "loss": 2.5156,
      "step": 14248
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002741035889450528,
      "loss": 2.2012,
      "step": 14249
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027398386812581857,
      "loss": 2.4023,
      "step": 14250
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027386416930725823,
      "loss": 2.1484,
      "step": 14251
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002737444924929985,
      "loss": 2.2539,
      "step": 14252
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002736248376866662,
      "loss": 2.3164,
      "step": 14253
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002735052048918878,
      "loss": 2.1348,
      "step": 14254
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002733855941122877,
      "loss": 2.4688,
      "step": 14255
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027326600535149115,
      "loss": 2.3828,
      "step": 14256
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002731464386131215,
      "loss": 2.2656,
      "step": 14257
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002730268939008024,
      "loss": 2.2109,
      "step": 14258
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027290737121815666,
      "loss": 2.3008,
      "step": 14259
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027278787056880593,
      "loss": 2.2129,
      "step": 14260
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027266839195637117,
      "loss": 2.1582,
      "step": 14261
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002725489353844732,
      "loss": 2.3359,
      "step": 14262
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002724295008567325,
      "loss": 2.1621,
      "step": 14263
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002723100883767674,
      "loss": 2.2266,
      "step": 14264
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002721906979481971,
      "loss": 2.2852,
      "step": 14265
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027207132957463953,
      "loss": 2.0918,
      "step": 14266
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002719519832597118,
      "loss": 2.1484,
      "step": 14267
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027183265900703027,
      "loss": 2.3203,
      "step": 14268
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027171335682021094,
      "loss": 2.3203,
      "step": 14269
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027159407670286964,
      "loss": 2.1719,
      "step": 14270
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027147481865862,
      "loss": 2.4023,
      "step": 14271
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027135558269107685,
      "loss": 2.2109,
      "step": 14272
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002712363688038526,
      "loss": 1.7949,
      "step": 14273
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002711171770005606,
      "loss": 2.3203,
      "step": 14274
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027099800728481207,
      "loss": 2.1328,
      "step": 14275
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002708788596602189,
      "loss": 2.1328,
      "step": 14276
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002707597341303909,
      "loss": 2.4414,
      "step": 14277
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002706406306989384,
      "loss": 2.0957,
      "step": 14278
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00027052154936947094,
      "loss": 2.1875,
      "step": 14279
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002704024901455967,
      "loss": 2.2734,
      "step": 14280
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00027028345303092307,
      "loss": 2.1543,
      "step": 14281
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002701644380290583,
      "loss": 2.1758,
      "step": 14282
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002700454451436085,
      "loss": 2.2852,
      "step": 14283
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002699264743781792,
      "loss": 2.2598,
      "step": 14284
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026980752573637577,
      "loss": 2.1582,
      "step": 14285
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002696885992218032,
      "loss": 2.1836,
      "step": 14286
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026956969483806506,
      "loss": 2.1816,
      "step": 14287
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026945081258876403,
      "loss": 2.3203,
      "step": 14288
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002693319524775032,
      "loss": 2.3516,
      "step": 14289
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026921311450788465,
      "loss": 2.4258,
      "step": 14290
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026909429868350886,
      "loss": 2.4102,
      "step": 14291
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026897550500797675,
      "loss": 2.3008,
      "step": 14292
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002688567334848885,
      "loss": 2.3242,
      "step": 14293
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026873798411784246,
      "loss": 2.1133,
      "step": 14294
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026861925691043785,
      "loss": 2.0645,
      "step": 14295
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.000268500551866272,
      "loss": 2.127,
      "step": 14296
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002683818689889425,
      "loss": 2.2969,
      "step": 14297
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002682632082820453,
      "loss": 2.3555,
      "step": 14298
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026814456974917677,
      "loss": 2.2383,
      "step": 14299
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026802595339393153,
      "loss": 1.9668,
      "step": 14300
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026790735921990426,
      "loss": 2.3945,
      "step": 14301
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002677887872306891,
      "loss": 2.1367,
      "step": 14302
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026767023742987894,
      "loss": 2.0547,
      "step": 14303
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002675517098210658,
      "loss": 2.1992,
      "step": 14304
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002674332044078418,
      "loss": 2.2656,
      "step": 14305
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002673147211937984,
      "loss": 2.207,
      "step": 14306
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002671962601825253,
      "loss": 2.1484,
      "step": 14307
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026707782137761263,
      "loss": 2.2051,
      "step": 14308
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026695940478264977,
      "loss": 2.3242,
      "step": 14309
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.000266841010401225,
      "loss": 2.4727,
      "step": 14310
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026672263823692544,
      "loss": 2.1738,
      "step": 14311
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026660428829333873,
      "loss": 2.1758,
      "step": 14312
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002664859605740513,
      "loss": 2.2754,
      "step": 14313
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002663676550826486,
      "loss": 2.1484,
      "step": 14314
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026624937182271593,
      "loss": 2.127,
      "step": 14315
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026613111079783734,
      "loss": 2.0938,
      "step": 14316
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.000266012872011597,
      "loss": 2.2168,
      "step": 14317
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002658946554675773,
      "loss": 2.1562,
      "step": 14318
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002657764611693612,
      "loss": 2.3672,
      "step": 14319
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002656582891205299,
      "loss": 2.4062,
      "step": 14320
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002655401393246646,
      "loss": 2.1797,
      "step": 14321
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002654220117853459,
      "loss": 2.2031,
      "step": 14322
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026530390650615323,
      "loss": 2.4141,
      "step": 14323
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002651858234906649,
      "loss": 2.3711,
      "step": 14324
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026506776274246035,
      "loss": 2.2891,
      "step": 14325
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002649497242651169,
      "loss": 2.1719,
      "step": 14326
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002648317080622108,
      "loss": 2.0508,
      "step": 14327
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.000264713714137319,
      "loss": 2.0352,
      "step": 14328
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002645957424940172,
      "loss": 2.1523,
      "step": 14329
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026447779313588005,
      "loss": 2.1074,
      "step": 14330
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002643598660664812,
      "loss": 2.0,
      "step": 14331
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002642419612893954,
      "loss": 2.4414,
      "step": 14332
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002641240788081951,
      "loss": 2.3398,
      "step": 14333
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.000264006218626452,
      "loss": 2.4609,
      "step": 14334
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026388838074773823,
      "loss": 2.0527,
      "step": 14335
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002637705651756247,
      "loss": 2.4141,
      "step": 14336
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002636527719136812,
      "loss": 2.3301,
      "step": 14337
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026353500096547766,
      "loss": 2.0645,
      "step": 14338
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002634172523345826,
      "loss": 2.1094,
      "step": 14339
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026329952602456444,
      "loss": 2.375,
      "step": 14340
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026318182203899034,
      "loss": 2.2031,
      "step": 14341
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002630641403814277,
      "loss": 2.2754,
      "step": 14342
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026294648105544197,
      "loss": 2.1641,
      "step": 14343
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002628288440645988,
      "loss": 2.1348,
      "step": 14344
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026271122941246363,
      "loss": 2.0723,
      "step": 14345
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002625936371026,
      "loss": 2.2227,
      "step": 14346
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026247606713857073,
      "loss": 2.2461,
      "step": 14347
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026235851952393995,
      "loss": 2.2031,
      "step": 14348
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.000262240994262269,
      "loss": 2.2461,
      "step": 14349
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.000262123491357119,
      "loss": 2.2695,
      "step": 14350
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.000262006010812051,
      "loss": 2.2402,
      "step": 14351
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002618885526306254,
      "loss": 2.3398,
      "step": 14352
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002617711168164012,
      "loss": 2.209,
      "step": 14353
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002616537033729367,
      "loss": 2.5391,
      "step": 14354
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002615363123037904,
      "loss": 2.2207,
      "step": 14355
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026141894361251985,
      "loss": 2.2578,
      "step": 14356
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002613015973026811,
      "loss": 2.252,
      "step": 14357
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002611842733778307,
      "loss": 2.1914,
      "step": 14358
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002610669718415234,
      "loss": 2.2891,
      "step": 14359
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002609496926973142,
      "loss": 2.1074,
      "step": 14360
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026083243594875703,
      "loss": 2.2188,
      "step": 14361
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002607152015994053,
      "loss": 2.168,
      "step": 14362
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026059798965281103,
      "loss": 2.2363,
      "step": 14363
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002604808001125264,
      "loss": 2.1641,
      "step": 14364
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.000260363632982103,
      "loss": 2.2148,
      "step": 14365
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002602464882650908,
      "loss": 2.2539,
      "step": 14366
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00026012936596504,
      "loss": 2.4062,
      "step": 14367
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002600122660855,
      "loss": 2.0195,
      "step": 14368
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00025989518863001905,
      "loss": 2.0137,
      "step": 14369
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00025977813360214476,
      "loss": 2.1484,
      "step": 14370
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002596611010054244,
      "loss": 2.2012,
      "step": 14371
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002595440908434049,
      "loss": 2.1953,
      "step": 14372
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0002594271031196315,
      "loss": 2.4141,
      "step": 14373
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025931013783764945,
      "loss": 2.2695,
      "step": 14374
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002591931950010035,
      "loss": 2.0742,
      "step": 14375
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002590762746132371,
      "loss": 2.3711,
      "step": 14376
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025895937667789326,
      "loss": 2.1543,
      "step": 14377
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002588425011985144,
      "loss": 2.2129,
      "step": 14378
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002587256481786425,
      "loss": 2.2812,
      "step": 14379
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002586088176218182,
      "loss": 2.457,
      "step": 14380
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025849200953158237,
      "loss": 2.2461,
      "step": 14381
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025837522391147403,
      "loss": 2.1328,
      "step": 14382
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002582584607650329,
      "loss": 2.3047,
      "step": 14383
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002581417200957965,
      "loss": 2.1914,
      "step": 14384
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025802500190730314,
      "loss": 2.1992,
      "step": 14385
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025790830620308914,
      "loss": 2.0703,
      "step": 14386
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025779163298669116,
      "loss": 2.2617,
      "step": 14387
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025767498226164496,
      "loss": 2.2734,
      "step": 14388
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002575583540314853,
      "loss": 2.2695,
      "step": 14389
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025744174829974554,
      "loss": 2.1816,
      "step": 14390
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002573251650699606,
      "loss": 2.1914,
      "step": 14391
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025720860434566285,
      "loss": 2.2656,
      "step": 14392
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025709206613038394,
      "loss": 2.2871,
      "step": 14393
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025697555042765566,
      "loss": 2.1016,
      "step": 14394
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002568590572410092,
      "loss": 2.2383,
      "step": 14395
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002567425865739744,
      "loss": 2.1719,
      "step": 14396
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025662613843008053,
      "loss": 2.1367,
      "step": 14397
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002565097128128564,
      "loss": 2.2148,
      "step": 14398
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025639330972583043,
      "loss": 2.4258,
      "step": 14399
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025627692917252955,
      "loss": 2.332,
      "step": 14400
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025616057115648096,
      "loss": 1.9844,
      "step": 14401
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025604423568121015,
      "loss": 2.0566,
      "step": 14402
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002559279227502428,
      "loss": 2.2715,
      "step": 14403
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002558116323671038,
      "loss": 2.3398,
      "step": 14404
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002556953645353166,
      "loss": 2.2812,
      "step": 14405
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025557911925840494,
      "loss": 2.3672,
      "step": 14406
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002554628965398911,
      "loss": 2.2266,
      "step": 14407
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002553466963832973,
      "loss": 2.1719,
      "step": 14408
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025523051879214445,
      "loss": 2.1523,
      "step": 14409
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002551143637699532,
      "loss": 2.3984,
      "step": 14410
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002549982313202439,
      "loss": 2.0645,
      "step": 14411
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025488212144653545,
      "loss": 2.1543,
      "step": 14412
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002547660341523459,
      "loss": 2.1309,
      "step": 14413
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002546499694411936,
      "loss": 2.2656,
      "step": 14414
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002545339273165956,
      "loss": 2.5195,
      "step": 14415
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002544179077820682,
      "loss": 2.1797,
      "step": 14416
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002543019108411273,
      "loss": 2.2305,
      "step": 14417
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002541859364972883,
      "loss": 2.1055,
      "step": 14418
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002540699847540652,
      "loss": 2.2734,
      "step": 14419
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002539540556149714,
      "loss": 2.375,
      "step": 14420
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025383814908352053,
      "loss": 2.3555,
      "step": 14421
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025372226516322494,
      "loss": 2.2383,
      "step": 14422
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025360640385759583,
      "loss": 2.1387,
      "step": 14423
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002534905651701448,
      "loss": 2.4219,
      "step": 14424
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002533747491043814,
      "loss": 2.4102,
      "step": 14425
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025325895566381595,
      "loss": 2.0488,
      "step": 14426
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025314318485195677,
      "loss": 2.0918,
      "step": 14427
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025302743667231253,
      "loss": 2.3047,
      "step": 14428
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002529117111283905,
      "loss": 2.1582,
      "step": 14429
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002527960082236975,
      "loss": 2.3164,
      "step": 14430
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025268032796174037,
      "loss": 2.4492,
      "step": 14431
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002525646703460239,
      "loss": 2.293,
      "step": 14432
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002524490353800527,
      "loss": 2.293,
      "step": 14433
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025233342306733175,
      "loss": 2.3828,
      "step": 14434
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025221783341136406,
      "loss": 2.3203,
      "step": 14435
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025210226641565216,
      "loss": 2.2539,
      "step": 14436
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002519867220836981,
      "loss": 2.3945,
      "step": 14437
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002518712004190039,
      "loss": 2.2207,
      "step": 14438
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025175570142506933,
      "loss": 2.1953,
      "step": 14439
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025164022510539496,
      "loss": 2.4258,
      "step": 14440
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025152477146348027,
      "loss": 2.1523,
      "step": 14441
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002514093405028236,
      "loss": 2.3164,
      "step": 14442
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025129393222692254,
      "loss": 2.1738,
      "step": 14443
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025117854663927477,
      "loss": 2.3438,
      "step": 14444
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.000251063183743377,
      "loss": 2.4023,
      "step": 14445
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002509478435427246,
      "loss": 2.2793,
      "step": 14446
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025083252604081343,
      "loss": 2.1445,
      "step": 14447
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002507172312411372,
      "loss": 2.2539,
      "step": 14448
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002506019591471904,
      "loss": 2.207,
      "step": 14449
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025048670976246556,
      "loss": 2.125,
      "step": 14450
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00025037148309045576,
      "loss": 2.3516,
      "step": 14451
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002502562791346521,
      "loss": 2.3594,
      "step": 14452
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.000250141097898546,
      "loss": 2.375,
      "step": 14453
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.000250025939385628,
      "loss": 2.4883,
      "step": 14454
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00024991080359938755,
      "loss": 2.207,
      "step": 14455
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002497956905433131,
      "loss": 2.209,
      "step": 14456
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002496806002208941,
      "loss": 2.168,
      "step": 14457
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00024956553263561756,
      "loss": 2.2031,
      "step": 14458
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002494504877909701,
      "loss": 2.4219,
      "step": 14459
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002493354656904383,
      "loss": 2.25,
      "step": 14460
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002492204663375081,
      "loss": 2.0859,
      "step": 14461
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002491054897356637,
      "loss": 2.2539,
      "step": 14462
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00024899053588838937,
      "loss": 2.332,
      "step": 14463
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002488756047991686,
      "loss": 2.0547,
      "step": 14464
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002487606964714847,
      "loss": 2.1113,
      "step": 14465
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002486458109088191,
      "loss": 2.1641,
      "step": 14466
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002485309481146537,
      "loss": 2.1641,
      "step": 14467
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024841610809246873,
      "loss": 2.0918,
      "step": 14468
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002483012908457445,
      "loss": 2.0703,
      "step": 14469
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024818649637796067,
      "loss": 2.1992,
      "step": 14470
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024807172469259553,
      "loss": 2.1875,
      "step": 14471
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002479569757931268,
      "loss": 2.2148,
      "step": 14472
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.000247842249683032,
      "loss": 2.3242,
      "step": 14473
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002477275463657881,
      "loss": 2.4062,
      "step": 14474
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024761286584487055,
      "loss": 2.2598,
      "step": 14475
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.000247498208123754,
      "loss": 2.2383,
      "step": 14476
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002473835732059142,
      "loss": 2.1523,
      "step": 14477
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002472689610948242,
      "loss": 2.293,
      "step": 14478
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002471543717939572,
      "loss": 2.2695,
      "step": 14479
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002470398053067855,
      "loss": 2.0312,
      "step": 14480
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002469252616367814,
      "loss": 2.1348,
      "step": 14481
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002468107407874153,
      "loss": 2.332,
      "step": 14482
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024669624276215784,
      "loss": 2.1797,
      "step": 14483
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024658176756447894,
      "loss": 2.3047,
      "step": 14484
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024646731519784737,
      "loss": 2.1504,
      "step": 14485
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.000246352885665731,
      "loss": 2.0527,
      "step": 14486
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002462384789715978,
      "loss": 2.1465,
      "step": 14487
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.000246124095118915,
      "loss": 2.4609,
      "step": 14488
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.000246009734111148,
      "loss": 2.1348,
      "step": 14489
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024589539595176323,
      "loss": 2.2305,
      "step": 14490
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002457810806442248,
      "loss": 2.4375,
      "step": 14491
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002456667881919973,
      "loss": 2.293,
      "step": 14492
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024555251859854357,
      "loss": 2.2402,
      "step": 14493
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024543827186732716,
      "loss": 2.1211,
      "step": 14494
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002453240480018094,
      "loss": 2.0859,
      "step": 14495
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002452098470054519,
      "loss": 2.2773,
      "step": 14496
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002450956688817158,
      "loss": 2.2754,
      "step": 14497
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024498151363406054,
      "loss": 2.0137,
      "step": 14498
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002448673812659449,
      "loss": 2.2793,
      "step": 14499
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024475327178082864,
      "loss": 2.2031,
      "step": 14500
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002446391851821692,
      "loss": 2.3633,
      "step": 14501
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024452512147342333,
      "loss": 2.2227,
      "step": 14502
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024441108065804783,
      "loss": 2.332,
      "step": 14503
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002442970627394988,
      "loss": 2.2422,
      "step": 14504
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002441830677212312,
      "loss": 2.1074,
      "step": 14505
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002440690956066991,
      "loss": 2.3438,
      "step": 14506
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024395514639935644,
      "loss": 2.5898,
      "step": 14507
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024384122010265652,
      "loss": 2.0527,
      "step": 14508
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024372731672005134,
      "loss": 2.2852,
      "step": 14509
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024361343625499288,
      "loss": 2.2969,
      "step": 14510
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024349957871093155,
      "loss": 2.2227,
      "step": 14511
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002433857440913181,
      "loss": 2.3613,
      "step": 14512
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002432719323996021,
      "loss": 2.2461,
      "step": 14513
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024315814363923196,
      "loss": 2.3281,
      "step": 14514
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002430443778136564,
      "loss": 2.3984,
      "step": 14515
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002429306349263225,
      "loss": 2.3672,
      "step": 14516
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024281691498067738,
      "loss": 2.0391,
      "step": 14517
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002427032179801667,
      "loss": 2.0723,
      "step": 14518
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024258954392823606,
      "loss": 2.3242,
      "step": 14519
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002424758928283305,
      "loss": 2.2656,
      "step": 14520
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024236226468389365,
      "loss": 2.1953,
      "step": 14521
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024224865949836838,
      "loss": 2.2383,
      "step": 14522
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024213507727519835,
      "loss": 2.1328,
      "step": 14523
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002420215180178249,
      "loss": 2.2617,
      "step": 14524
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024190798172968897,
      "loss": 2.3242,
      "step": 14525
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024179446841423135,
      "loss": 2.2461,
      "step": 14526
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024168097807489232,
      "loss": 2.3203,
      "step": 14527
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024156751071511051,
      "loss": 2.3672,
      "step": 14528
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024145406633832413,
      "loss": 2.1504,
      "step": 14529
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024134064494797113,
      "loss": 2.3242,
      "step": 14530
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024122724654748908,
      "loss": 2.4453,
      "step": 14531
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024111387114031358,
      "loss": 2.2148,
      "step": 14532
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024100051872988083,
      "loss": 2.2812,
      "step": 14533
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024088718931962518,
      "loss": 2.3008,
      "step": 14534
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002407738829129813,
      "loss": 2.293,
      "step": 14535
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024066059951338294,
      "loss": 2.1152,
      "step": 14536
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024054733912426274,
      "loss": 2.0898,
      "step": 14537
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024043410174905255,
      "loss": 2.0977,
      "step": 14538
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024032088739118408,
      "loss": 2.2012,
      "step": 14539
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024020769605408843,
      "loss": 2.2852,
      "step": 14540
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00024009452774119533,
      "loss": 2.2012,
      "step": 14541
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002399813824559336,
      "loss": 2.2715,
      "step": 14542
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00023986826020173303,
      "loss": 2.1582,
      "step": 14543
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00023975516098202122,
      "loss": 2.3008,
      "step": 14544
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00023964208480022487,
      "loss": 2.2617,
      "step": 14545
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.000239529031659771,
      "loss": 2.0801,
      "step": 14546
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00023941600156408583,
      "loss": 2.1094,
      "step": 14547
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00023930299451659377,
      "loss": 2.1816,
      "step": 14548
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00023919001052072008,
      "loss": 2.2559,
      "step": 14549
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00023907704957988797,
      "loss": 2.2305,
      "step": 14550
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00023896411169752098,
      "loss": 2.207,
      "step": 14551
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00023885119687704092,
      "loss": 2.3125,
      "step": 14552
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00023873830512186989,
      "loss": 2.3398,
      "step": 14553
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00023862543643542912,
      "loss": 2.2656,
      "step": 14554
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00023851259082113818,
      "loss": 2.1406,
      "step": 14555
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002383997682824175,
      "loss": 2.1602,
      "step": 14556
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00023828696882268518,
      "loss": 2.1602,
      "step": 14557
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002381741924453602,
      "loss": 2.3047,
      "step": 14558
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00023806143915385924,
      "loss": 2.2695,
      "step": 14559
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023794870895159982,
      "loss": 2.3086,
      "step": 14560
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002378360018419974,
      "loss": 2.2773,
      "step": 14561
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002377233178284677,
      "loss": 2.1465,
      "step": 14562
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023761065691442574,
      "loss": 2.2676,
      "step": 14563
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023749801910328517,
      "loss": 2.2207,
      "step": 14564
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023738540439845868,
      "loss": 2.2188,
      "step": 14565
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023727281280336,
      "loss": 2.2773,
      "step": 14566
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002371602443214006,
      "loss": 2.1582,
      "step": 14567
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002370476989559912,
      "loss": 2.168,
      "step": 14568
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023693517671054276,
      "loss": 2.0508,
      "step": 14569
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023682267758846532,
      "loss": 2.3926,
      "step": 14570
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002367102015931676,
      "loss": 2.3945,
      "step": 14571
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023659774872805762,
      "loss": 2.1289,
      "step": 14572
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023648531899654357,
      "loss": 2.4219,
      "step": 14573
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023637291240203274,
      "loss": 2.1719,
      "step": 14574
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023626052894793059,
      "loss": 2.0859,
      "step": 14575
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023614816863764355,
      "loss": 2.3945,
      "step": 14576
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023603583147457574,
      "loss": 2.1797,
      "step": 14577
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023592351746213182,
      "loss": 2.1602,
      "step": 14578
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023581122660371533,
      "loss": 2.1074,
      "step": 14579
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023569895890272895,
      "loss": 2.293,
      "step": 14580
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002355867143625744,
      "loss": 2.2422,
      "step": 14581
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023547449298665346,
      "loss": 2.2715,
      "step": 14582
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002353622947783669,
      "loss": 2.3594,
      "step": 14583
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023525011974111443,
      "loss": 2.1113,
      "step": 14584
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023513796787829488,
      "loss": 2.1562,
      "step": 14585
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002350258391933079,
      "loss": 2.1309,
      "step": 14586
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023491373368955082,
      "loss": 2.4102,
      "step": 14587
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023480165137042041,
      "loss": 2.1641,
      "step": 14588
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023468959223931364,
      "loss": 2.1602,
      "step": 14589
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002345775562996263,
      "loss": 2.1328,
      "step": 14590
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002344655435547529,
      "loss": 2.1914,
      "step": 14591
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023435355400808834,
      "loss": 2.2734,
      "step": 14592
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023424158766302628,
      "loss": 2.2285,
      "step": 14593
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002341296445229595,
      "loss": 2.3281,
      "step": 14594
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002340177245912799,
      "loss": 2.2266,
      "step": 14595
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023390582787137949,
      "loss": 2.3438,
      "step": 14596
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023379395436664907,
      "loss": 2.1465,
      "step": 14597
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023368210408047853,
      "loss": 2.1641,
      "step": 14598
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023357027701625767,
      "loss": 2.2422,
      "step": 14599
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023345847317737478,
      "loss": 2.2207,
      "step": 14600
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023334669256721796,
      "loss": 2.2227,
      "step": 14601
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023323493518917504,
      "loss": 2.2461,
      "step": 14602
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023312320104663232,
      "loss": 2.3398,
      "step": 14603
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002330114901429753,
      "loss": 2.3047,
      "step": 14604
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002328998024815895,
      "loss": 2.3555,
      "step": 14605
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023278813806585974,
      "loss": 2.0449,
      "step": 14606
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002326764968991696,
      "loss": 2.3398,
      "step": 14607
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023256487898490154,
      "loss": 2.0957,
      "step": 14608
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023245328432643908,
      "loss": 2.3379,
      "step": 14609
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023234171292716333,
      "loss": 2.1914,
      "step": 14610
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023223016479045512,
      "loss": 2.2461,
      "step": 14611
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023211863991969472,
      "loss": 2.1562,
      "step": 14612
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023200713831826226,
      "loss": 2.2734,
      "step": 14613
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023189565998953598,
      "loss": 2.1328,
      "step": 14614
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023178420493689446,
      "loss": 2.002,
      "step": 14615
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002316727731637147,
      "loss": 2.4883,
      "step": 14616
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023156136467337407,
      "loss": 2.5,
      "step": 14617
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023144997946924795,
      "loss": 2.3086,
      "step": 14618
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002313386175547123,
      "loss": 2.0918,
      "step": 14619
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002312272789331411,
      "loss": 2.2383,
      "step": 14620
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023111596360790866,
      "loss": 2.3164,
      "step": 14621
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023100467158238848,
      "loss": 2.2188,
      "step": 14622
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023089340285995265,
      "loss": 2.1484,
      "step": 14623
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002307821574439729,
      "loss": 2.2734,
      "step": 14624
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023067093533782047,
      "loss": 2.0898,
      "step": 14625
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023055973654486606,
      "loss": 2.25,
      "step": 14626
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023044856106847888,
      "loss": 2.1445,
      "step": 14627
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023033740891202805,
      "loss": 2.1699,
      "step": 14628
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023022628007888225,
      "loss": 2.248,
      "step": 14629
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023011517457240872,
      "loss": 2.1582,
      "step": 14630
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00023000409239597375,
      "loss": 2.1602,
      "step": 14631
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00022989303355294466,
      "loss": 2.2617,
      "step": 14632
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002297819980466863,
      "loss": 2.2012,
      "step": 14633
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00022967098588056313,
      "loss": 2.1172,
      "step": 14634
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002295599970579395,
      "loss": 2.1582,
      "step": 14635
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.000229449031582179,
      "loss": 2.3359,
      "step": 14636
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002293380894566439,
      "loss": 2.2461,
      "step": 14637
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002292271706846959,
      "loss": 2.1152,
      "step": 14638
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00022911627526969646,
      "loss": 2.2773,
      "step": 14639
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0002290054032150064,
      "loss": 2.3164,
      "step": 14640
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00022889455452398488,
      "loss": 2.3203,
      "step": 14641
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00022878372919999158,
      "loss": 2.3789,
      "step": 14642
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00022867292724638432,
      "loss": 2.123,
      "step": 14643
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00022856214866652104,
      "loss": 2.2344,
      "step": 14644
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00022845139346375898,
      "loss": 2.3555,
      "step": 14645
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00022834066164145405,
      "loss": 2.2773,
      "step": 14646
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00022822995320296148,
      "loss": 2.0723,
      "step": 14647
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00022811926815163652,
      "loss": 2.207,
      "step": 14648
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00022800860649083355,
      "loss": 2.3594,
      "step": 14649
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00022789796822390553,
      "loss": 2.2969,
      "step": 14650
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00022778735335420475,
      "loss": 2.2383,
      "step": 14651
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00022767676188508435,
      "loss": 2.2324,
      "step": 14652
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022756619381989496,
      "loss": 2.4141,
      "step": 14653
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002274556491619869,
      "loss": 2.3672,
      "step": 14654
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002273451279147104,
      "loss": 2.3398,
      "step": 14655
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022723463008141476,
      "loss": 2.1426,
      "step": 14656
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022712415566544797,
      "loss": 2.1211,
      "step": 14657
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022701370467015836,
      "loss": 2.0469,
      "step": 14658
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022690327709889226,
      "loss": 2.1367,
      "step": 14659
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002267928729549966,
      "loss": 2.1992,
      "step": 14660
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022668249224181648,
      "loss": 2.2969,
      "step": 14661
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022657213496269702,
      "loss": 2.3984,
      "step": 14662
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002264618011209827,
      "loss": 2.2891,
      "step": 14663
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022635149072001648,
      "loss": 2.1582,
      "step": 14664
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002262412037631416,
      "loss": 2.3281,
      "step": 14665
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022613094025369975,
      "loss": 2.293,
      "step": 14666
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022602070019503263,
      "loss": 2.373,
      "step": 14667
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002259104835904804,
      "loss": 2.3281,
      "step": 14668
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022580029044338347,
      "loss": 2.2188,
      "step": 14669
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022569012075708062,
      "loss": 2.127,
      "step": 14670
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022557997453491054,
      "loss": 2.2285,
      "step": 14671
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002254698517802114,
      "loss": 2.3477,
      "step": 14672
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002253597524963198,
      "loss": 2.2305,
      "step": 14673
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002252496766865718,
      "loss": 2.1602,
      "step": 14674
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022513962435430403,
      "loss": 2.2422,
      "step": 14675
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022502959550285096,
      "loss": 1.9961,
      "step": 14676
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002249195901355464,
      "loss": 2.2734,
      "step": 14677
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022480960825572427,
      "loss": 2.3359,
      "step": 14678
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022469964986671776,
      "loss": 2.3945,
      "step": 14679
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002245897149718582,
      "loss": 2.2188,
      "step": 14680
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002244798035744776,
      "loss": 1.9004,
      "step": 14681
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002243699156779062,
      "loss": 2.2676,
      "step": 14682
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022426005128547432,
      "loss": 2.3281,
      "step": 14683
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022415021040051087,
      "loss": 2.2109,
      "step": 14684
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022404039302634482,
      "loss": 2.2148,
      "step": 14685
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022393059916630344,
      "loss": 2.2383,
      "step": 14686
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022382082882371412,
      "loss": 2.2383,
      "step": 14687
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022371108200190359,
      "loss": 1.998,
      "step": 14688
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022360135870419718,
      "loss": 2.2266,
      "step": 14689
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022349165893391975,
      "loss": 2.2988,
      "step": 14690
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002233819826943957,
      "loss": 2.166,
      "step": 14691
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022327232998894887,
      "loss": 2.0996,
      "step": 14692
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002231627008209016,
      "loss": 2.4648,
      "step": 14693
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002230530951935762,
      "loss": 2.0586,
      "step": 14694
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022294351311029448,
      "loss": 2.3281,
      "step": 14695
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002228339545743767,
      "loss": 2.2207,
      "step": 14696
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002227244195891428,
      "loss": 2.1875,
      "step": 14697
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022261490815791206,
      "loss": 2.2188,
      "step": 14698
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022250542028400355,
      "loss": 2.1016,
      "step": 14699
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022239595597073436,
      "loss": 2.3164,
      "step": 14700
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022228651522142206,
      "loss": 2.1094,
      "step": 14701
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022217709803938325,
      "loss": 2.2695,
      "step": 14702
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022206770442793333,
      "loss": 2.1211,
      "step": 14703
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022195833439038703,
      "loss": 2.2305,
      "step": 14704
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022184898793005904,
      "loss": 2.0273,
      "step": 14705
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002217396650502629,
      "loss": 2.293,
      "step": 14706
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022163036575431117,
      "loss": 2.1055,
      "step": 14707
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022152109004551645,
      "loss": 2.4297,
      "step": 14708
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022141183792718955,
      "loss": 2.3047,
      "step": 14709
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022130260940264146,
      "loss": 2.25,
      "step": 14710
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022119340447518244,
      "loss": 2.2676,
      "step": 14711
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022108422314812148,
      "loss": 2.123,
      "step": 14712
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022097506542476697,
      "loss": 2.1113,
      "step": 14713
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002208659313084269,
      "loss": 2.0918,
      "step": 14714
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022075682080240866,
      "loss": 2.3359,
      "step": 14715
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022064773391001835,
      "loss": 2.3789,
      "step": 14716
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022053867063456133,
      "loss": 2.0879,
      "step": 14717
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022042963097934344,
      "loss": 2.1992,
      "step": 14718
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022032061494766842,
      "loss": 2.1699,
      "step": 14719
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00022021162254283965,
      "loss": 2.4805,
      "step": 14720
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002201026537681602,
      "loss": 2.043,
      "step": 14721
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021999370862693237,
      "loss": 2.0742,
      "step": 14722
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021988478712245708,
      "loss": 2.0801,
      "step": 14723
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002197758892580356,
      "loss": 2.4062,
      "step": 14724
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021966701503696716,
      "loss": 2.4141,
      "step": 14725
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021955816446255183,
      "loss": 2.3125,
      "step": 14726
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021944933753808738,
      "loss": 2.0,
      "step": 14727
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021934053426687217,
      "loss": 2.3672,
      "step": 14728
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0002192317546522029,
      "loss": 2.2129,
      "step": 14729
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021912299869737616,
      "loss": 2.2656,
      "step": 14730
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021901426640568778,
      "loss": 2.2461,
      "step": 14731
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021890555778043263,
      "loss": 2.1172,
      "step": 14732
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021879687282490447,
      "loss": 2.2578,
      "step": 14733
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021868821154239716,
      "loss": 2.0195,
      "step": 14734
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021857957393620376,
      "loss": 2.332,
      "step": 14735
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021847096000961587,
      "loss": 2.2656,
      "step": 14736
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021836236976592504,
      "loss": 2.457,
      "step": 14737
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021825380320842226,
      "loss": 2.1738,
      "step": 14738
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021814526034039705,
      "loss": 2.2324,
      "step": 14739
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021803674116513817,
      "loss": 2.2617,
      "step": 14740
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021792824568593526,
      "loss": 2.1211,
      "step": 14741
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021781977390607544,
      "loss": 2.2461,
      "step": 14742
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021771132582884545,
      "loss": 2.2754,
      "step": 14743
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021760290145753192,
      "loss": 2.1191,
      "step": 14744
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00021749450079542088,
      "loss": 2.0723,
      "step": 14745
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002173861238457968,
      "loss": 2.125,
      "step": 14746
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021727777061194366,
      "loss": 1.9531,
      "step": 14747
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002171694410971451,
      "loss": 1.9824,
      "step": 14748
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021706113530468418,
      "loss": 2.0723,
      "step": 14749
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021695285323784254,
      "loss": 2.2695,
      "step": 14750
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021684459489990172,
      "loss": 2.207,
      "step": 14751
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021673636029414202,
      "loss": 2.2656,
      "step": 14752
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021662814942384346,
      "loss": 2.2617,
      "step": 14753
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021651996229228544,
      "loss": 1.9668,
      "step": 14754
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021641179890274608,
      "loss": 2.3301,
      "step": 14755
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021630365925850303,
      "loss": 2.2168,
      "step": 14756
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021619554336283332,
      "loss": 2.3047,
      "step": 14757
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021608745121901352,
      "loss": 2.1289,
      "step": 14758
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021597938283031903,
      "loss": 2.0625,
      "step": 14759
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021587133820002402,
      "loss": 2.3633,
      "step": 14760
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021576331733140375,
      "loss": 2.1562,
      "step": 14761
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021565532022773092,
      "loss": 2.4844,
      "step": 14762
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021554734689227818,
      "loss": 2.0391,
      "step": 14763
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002154393973283175,
      "loss": 2.2734,
      "step": 14764
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021533147153912058,
      "loss": 2.1094,
      "step": 14765
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002152235695279573,
      "loss": 2.2852,
      "step": 14766
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021511569129809783,
      "loss": 2.1562,
      "step": 14767
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.000215007836852811,
      "loss": 2.2422,
      "step": 14768
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021490000619536542,
      "loss": 1.9766,
      "step": 14769
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021479219932902838,
      "loss": 2.4102,
      "step": 14770
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021468441625706715,
      "loss": 2.3281,
      "step": 14771
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021457665698274743,
      "loss": 1.9414,
      "step": 14772
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021446892150933506,
      "loss": 2.041,
      "step": 14773
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002143612098400949,
      "loss": 2.2383,
      "step": 14774
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002142535219782905,
      "loss": 2.2285,
      "step": 14775
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021414585792718543,
      "loss": 2.3008,
      "step": 14776
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002140382176900425,
      "loss": 2.4141,
      "step": 14777
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021393060127012332,
      "loss": 2.1992,
      "step": 14778
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002138230086706887,
      "loss": 2.2812,
      "step": 14779
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021371543989499942,
      "loss": 2.2754,
      "step": 14780
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021360789494631526,
      "loss": 2.0254,
      "step": 14781
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021350037382789522,
      "loss": 2.3906,
      "step": 14782
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021339287654299665,
      "loss": 2.3281,
      "step": 14783
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021328540309487843,
      "loss": 2.2168,
      "step": 14784
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002131779534867966,
      "loss": 2.1367,
      "step": 14785
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002130705277220071,
      "loss": 2.3398,
      "step": 14786
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021296312580376553,
      "loss": 2.2246,
      "step": 14787
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021285574773532678,
      "loss": 2.3555,
      "step": 14788
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021274839351994424,
      "loss": 2.2266,
      "step": 14789
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021264106316087162,
      "loss": 2.3398,
      "step": 14790
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021253375666136087,
      "loss": 2.3301,
      "step": 14791
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002124264740246642,
      "loss": 2.2109,
      "step": 14792
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002123192152540322,
      "loss": 2.1895,
      "step": 14793
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002122119803527155,
      "loss": 2.332,
      "step": 14794
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021210476932396338,
      "loss": 2.2227,
      "step": 14795
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021199758217102472,
      "loss": 2.1504,
      "step": 14796
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002118904188971481,
      "loss": 2.375,
      "step": 14797
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021178327950558052,
      "loss": 2.2852,
      "step": 14798
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021167616399956856,
      "loss": 2.1484,
      "step": 14799
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021156907238235824,
      "loss": 2.0801,
      "step": 14800
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002114620046571951,
      "loss": 2.4531,
      "step": 14801
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002113549608273232,
      "loss": 2.3477,
      "step": 14802
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021124794089598652,
      "loss": 2.1641,
      "step": 14803
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021114094486642844,
      "loss": 2.3125,
      "step": 14804
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021103397274189095,
      "loss": 2.2109,
      "step": 14805
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021092702452561542,
      "loss": 2.3281,
      "step": 14806
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002108201002208431,
      "loss": 2.1973,
      "step": 14807
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021071319983081415,
      "loss": 2.2383,
      "step": 14808
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021060632335876772,
      "loss": 2.1074,
      "step": 14809
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021049947080794296,
      "loss": 2.1543,
      "step": 14810
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021039264218157728,
      "loss": 2.2383,
      "step": 14811
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021028583748290865,
      "loss": 2.0801,
      "step": 14812
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002101790567151728,
      "loss": 2.2109,
      "step": 14813
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00021007229988160604,
      "loss": 2.2812,
      "step": 14814
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00020996556698544357,
      "loss": 2.2891,
      "step": 14815
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00020985885802991922,
      "loss": 2.168,
      "step": 14816
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002097521730182673,
      "loss": 2.293,
      "step": 14817
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00020964551195372006,
      "loss": 2.2734,
      "step": 14818
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00020953887483950983,
      "loss": 2.3164,
      "step": 14819
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00020943226167886863,
      "loss": 2.2578,
      "step": 14820
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00020932567247502676,
      "loss": 2.3945,
      "step": 14821
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00020921910723121394,
      "loss": 2.1875,
      "step": 14822
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00020911256595065975,
      "loss": 2.0938,
      "step": 14823
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002090060486365929,
      "loss": 2.3262,
      "step": 14824
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00020889955529224114,
      "loss": 2.2227,
      "step": 14825
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002087930859208309,
      "loss": 2.2773,
      "step": 14826
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002086866405255897,
      "loss": 2.2363,
      "step": 14827
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00020858021910974257,
      "loss": 2.1797,
      "step": 14828
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002084738216765142,
      "loss": 2.4844,
      "step": 14829
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00020836744822912902,
      "loss": 2.1758,
      "step": 14830
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002082610987708108,
      "loss": 2.1953,
      "step": 14831
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00020815477330478173,
      "loss": 2.2383,
      "step": 14832
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00020804847183426435,
      "loss": 2.2734,
      "step": 14833
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00020794219436247942,
      "loss": 2.2617,
      "step": 14834
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00020783594089264802,
      "loss": 2.2969,
      "step": 14835
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00020772971142798947,
      "loss": 2.3359,
      "step": 14836
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002076235059717234,
      "loss": 2.1992,
      "step": 14837
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00020751732452706763,
      "loss": 2.1797,
      "step": 14838
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020741116709724005,
      "loss": 2.1914,
      "step": 14839
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020730503368545796,
      "loss": 2.168,
      "step": 14840
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020719892429493713,
      "loss": 2.1914,
      "step": 14841
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020709283892889286,
      "loss": 2.4531,
      "step": 14842
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020698677759054007,
      "loss": 2.082,
      "step": 14843
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020688074028309312,
      "loss": 2.375,
      "step": 14844
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020677472700976474,
      "loss": 2.3828,
      "step": 14845
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020666873777376772,
      "loss": 2.2969,
      "step": 14846
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020656277257831413,
      "loss": 2.2422,
      "step": 14847
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020645683142661486,
      "loss": 2.2656,
      "step": 14848
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020635091432187958,
      "loss": 2.291,
      "step": 14849
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020624502126731926,
      "loss": 2.2109,
      "step": 14850
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020613915226614212,
      "loss": 2.3906,
      "step": 14851
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.000206033307321556,
      "loss": 2.4844,
      "step": 14852
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020592748643676872,
      "loss": 2.1035,
      "step": 14853
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020582168961498726,
      "loss": 2.3047,
      "step": 14854
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020571591685941703,
      "loss": 2.3008,
      "step": 14855
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020561016817326395,
      "loss": 2.3086,
      "step": 14856
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020550444355973185,
      "loss": 2.3008,
      "step": 14857
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0002053987430220251,
      "loss": 2.3086,
      "step": 14858
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020529306656334633,
      "loss": 2.2812,
      "step": 14859
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020518741418689847,
      "loss": 2.166,
      "step": 14860
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020508178589588233,
      "loss": 2.2559,
      "step": 14861
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0002049761816934994,
      "loss": 2.3789,
      "step": 14862
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020487060158294978,
      "loss": 2.0918,
      "step": 14863
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020476504556743292,
      "loss": 2.1211,
      "step": 14864
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.000204659513650147,
      "loss": 2.25,
      "step": 14865
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0002045540058342904,
      "loss": 2.375,
      "step": 14866
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020444852212306053,
      "loss": 2.0664,
      "step": 14867
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020434306251965352,
      "loss": 2.0762,
      "step": 14868
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020423762702726522,
      "loss": 2.3555,
      "step": 14869
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020413221564909102,
      "loss": 2.1113,
      "step": 14870
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020402682838832498,
      "loss": 2.2773,
      "step": 14871
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020392146524816037,
      "loss": 2.1836,
      "step": 14872
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020381612623179035,
      "loss": 2.2656,
      "step": 14873
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0002037108113424072,
      "loss": 2.1641,
      "step": 14874
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020360552058320202,
      "loss": 2.0762,
      "step": 14875
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0002035002539573657,
      "loss": 2.2812,
      "step": 14876
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0002033950114680878,
      "loss": 2.1562,
      "step": 14877
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0002032897931185581,
      "loss": 2.1523,
      "step": 14878
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0002031845989119644,
      "loss": 2.2969,
      "step": 14879
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0002030794288514949,
      "loss": 2.1328,
      "step": 14880
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020297428294033625,
      "loss": 2.1836,
      "step": 14881
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020286916118167497,
      "loss": 2.2773,
      "step": 14882
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0002027640635786967,
      "loss": 2.1543,
      "step": 14883
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020265899013458612,
      "loss": 1.9746,
      "step": 14884
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020255394085252665,
      "loss": 2.123,
      "step": 14885
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0002024489157357029,
      "loss": 2.2383,
      "step": 14886
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020234391478729662,
      "loss": 2.2031,
      "step": 14887
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020223893801048977,
      "loss": 2.3281,
      "step": 14888
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0002021339854084635,
      "loss": 2.375,
      "step": 14889
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020202905698439867,
      "loss": 2.3203,
      "step": 14890
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020192415274147447,
      "loss": 2.5234,
      "step": 14891
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020181927268286948,
      "loss": 2.2188,
      "step": 14892
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020171441681176306,
      "loss": 2.2793,
      "step": 14893
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020160958513133187,
      "loss": 2.2891,
      "step": 14894
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0002015047776447526,
      "loss": 2.2344,
      "step": 14895
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0002013999943552014,
      "loss": 2.3008,
      "step": 14896
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020129523526585402,
      "loss": 2.209,
      "step": 14897
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0002011905003798843,
      "loss": 2.3086,
      "step": 14898
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020108578970046655,
      "loss": 2.2969,
      "step": 14899
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020098110323077346,
      "loss": 2.4102,
      "step": 14900
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020087644097397772,
      "loss": 2.1895,
      "step": 14901
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0002007718029332507,
      "loss": 2.3086,
      "step": 14902
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020066718911176352,
      "loss": 2.1602,
      "step": 14903
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020056259951268585,
      "loss": 2.0684,
      "step": 14904
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0002004580341391875,
      "loss": 2.0273,
      "step": 14905
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020035349299443728,
      "loss": 2.168,
      "step": 14906
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020024897608160298,
      "loss": 2.2266,
      "step": 14907
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00020014448340385137,
      "loss": 2.1504,
      "step": 14908
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0002000400149643493,
      "loss": 2.1387,
      "step": 14909
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0001999355707662629,
      "loss": 2.0566,
      "step": 14910
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00019983115081275639,
      "loss": 2.5547,
      "step": 14911
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00019972675510699435,
      "loss": 2.084,
      "step": 14912
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0001996223836521407,
      "loss": 2.0859,
      "step": 14913
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00019951803645135792,
      "loss": 2.0742,
      "step": 14914
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0001994137135078078,
      "loss": 2.3789,
      "step": 14915
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00019930941482465192,
      "loss": 2.2168,
      "step": 14916
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00019920514040505123,
      "loss": 2.3672,
      "step": 14917
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00019910089025216494,
      "loss": 2.2539,
      "step": 14918
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00019899666436915266,
      "loss": 2.2031,
      "step": 14919
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0001988924627591724,
      "loss": 2.4102,
      "step": 14920
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00019878828542538229,
      "loss": 2.1602,
      "step": 14921
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00019868413237093864,
      "loss": 2.1797,
      "step": 14922
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00019858000359899798,
      "loss": 2.2812,
      "step": 14923
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00019847589911271601,
      "loss": 2.1602,
      "step": 14924
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00019837181891524681,
      "loss": 2.1602,
      "step": 14925
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00019826776300974503,
      "loss": 2.1094,
      "step": 14926
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00019816373139936328,
      "loss": 2.1484,
      "step": 14927
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00019805972408725426,
      "loss": 2.3047,
      "step": 14928
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0001979557410765702,
      "loss": 2.2129,
      "step": 14929
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00019785178237046176,
      "loss": 2.3047,
      "step": 14930
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0001977478479720789,
      "loss": 2.1074,
      "step": 14931
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019764393788457147,
      "loss": 2.4258,
      "step": 14932
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019754005211108862,
      "loss": 2.0547,
      "step": 14933
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001974361906547778,
      "loss": 2.3828,
      "step": 14934
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019733235351878677,
      "loss": 2.209,
      "step": 14935
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001972285407062623,
      "loss": 2.082,
      "step": 14936
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019712475222034986,
      "loss": 2.0488,
      "step": 14937
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019702098806419454,
      "loss": 2.2188,
      "step": 14938
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019691724824094092,
      "loss": 2.2812,
      "step": 14939
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019681353275373292,
      "loss": 2.1211,
      "step": 14940
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019670984160571293,
      "loss": 2.4004,
      "step": 14941
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019660617480002363,
      "loss": 2.3691,
      "step": 14942
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019650253233980598,
      "loss": 2.1641,
      "step": 14943
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019639891422820123,
      "loss": 2.4883,
      "step": 14944
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019629532046834875,
      "loss": 2.3359,
      "step": 14945
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019619175106338837,
      "loss": 2.4219,
      "step": 14946
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019608820601645804,
      "loss": 1.9863,
      "step": 14947
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001959846853306957,
      "loss": 2.2168,
      "step": 14948
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019588118900923878,
      "loss": 2.2188,
      "step": 14949
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019577771705522307,
      "loss": 1.9863,
      "step": 14950
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001956742694717839,
      "loss": 2.3066,
      "step": 14951
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001955708462620568,
      "loss": 2.1523,
      "step": 14952
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019546744742917556,
      "loss": 2.1523,
      "step": 14953
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019536407297627312,
      "loss": 2.1504,
      "step": 14954
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019526072290648234,
      "loss": 2.3242,
      "step": 14955
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019515739722293524,
      "loss": 2.0527,
      "step": 14956
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019505409592876288,
      "loss": 2.2344,
      "step": 14957
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019495081902709522,
      "loss": 2.1738,
      "step": 14958
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019484756652106205,
      "loss": 2.1953,
      "step": 14959
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001947443384137928,
      "loss": 2.3633,
      "step": 14960
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019464113470841492,
      "loss": 2.4062,
      "step": 14961
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019453795540805608,
      "loss": 2.3516,
      "step": 14962
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019443480051584329,
      "loss": 2.1836,
      "step": 14963
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001943316700349018,
      "loss": 2.3164,
      "step": 14964
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019422856396835754,
      "loss": 2.125,
      "step": 14965
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019412548231933425,
      "loss": 2.207,
      "step": 14966
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019402242509095635,
      "loss": 2.3438,
      "step": 14967
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019391939228634615,
      "loss": 2.2578,
      "step": 14968
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019381638390862644,
      "loss": 2.2656,
      "step": 14969
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019371339996091818,
      "loss": 2.1211,
      "step": 14970
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019361044044634247,
      "loss": 2.3438,
      "step": 14971
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019350750536801942,
      "loss": 2.0352,
      "step": 14972
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019340459472906823,
      "loss": 2.293,
      "step": 14973
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.000193301708532607,
      "loss": 2.0137,
      "step": 14974
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019319884678175382,
      "loss": 2.2285,
      "step": 14975
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019309600947962615,
      "loss": 2.127,
      "step": 14976
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019299319662933957,
      "loss": 2.168,
      "step": 14977
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019289040823400994,
      "loss": 2.207,
      "step": 14978
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019278764429675254,
      "loss": 2.2539,
      "step": 14979
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001926849048206809,
      "loss": 2.4023,
      "step": 14980
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001925821898089084,
      "loss": 2.1641,
      "step": 14981
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019247949926454766,
      "loss": 2.252,
      "step": 14982
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019237683319071097,
      "loss": 2.457,
      "step": 14983
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019227419159050885,
      "loss": 2.0566,
      "step": 14984
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019217157446705226,
      "loss": 2.2637,
      "step": 14985
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019206898182345022,
      "loss": 2.2246,
      "step": 14986
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019196641366281221,
      "loss": 2.2539,
      "step": 14987
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001918638699882458,
      "loss": 2.1328,
      "step": 14988
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019176135080285894,
      "loss": 2.2773,
      "step": 14989
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019165885610975786,
      "loss": 2.1758,
      "step": 14990
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001915563859120486,
      "loss": 2.1328,
      "step": 14991
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001914539402128368,
      "loss": 2.1484,
      "step": 14992
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019135151901522653,
      "loss": 2.3984,
      "step": 14993
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019124912232232094,
      "loss": 2.0605,
      "step": 14994
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019114675013722404,
      "loss": 2.252,
      "step": 14995
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019104440246303756,
      "loss": 2.1445,
      "step": 14996
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019094207930286266,
      "loss": 2.1309,
      "step": 14997
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019083978065980033,
      "loss": 2.2129,
      "step": 14998
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019073750653695088,
      "loss": 2.2891,
      "step": 14999
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019063525693741325,
      "loss": 2.1328,
      "step": 15000
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001905330318642855,
      "loss": 2.4883,
      "step": 15001
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001904308313206663,
      "loss": 2.3184,
      "step": 15002
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019032865530965216,
      "loss": 2.2383,
      "step": 15003
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019022650383433915,
      "loss": 2.1191,
      "step": 15004
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001901243768978229,
      "loss": 2.2441,
      "step": 15005
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019002227450319877,
      "loss": 2.1875,
      "step": 15006
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00018992019665355997,
      "loss": 2.2363,
      "step": 15007
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00018981814335200054,
      "loss": 2.3789,
      "step": 15008
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001897161146016123,
      "loss": 2.3672,
      "step": 15009
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001896141104054877,
      "loss": 2.1484,
      "step": 15010
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00018951213076671725,
      "loss": 2.3203,
      "step": 15011
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001894101756883918,
      "loss": 2.2383,
      "step": 15012
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00018930824517360035,
      "loss": 2.3242,
      "step": 15013
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00018920633922543217,
      "loss": 2.3125,
      "step": 15014
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001891044578469754,
      "loss": 2.2773,
      "step": 15015
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00018900260104131716,
      "loss": 2.2715,
      "step": 15016
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001889007688115436,
      "loss": 2.1602,
      "step": 15017
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00018879896116074158,
      "loss": 2.1387,
      "step": 15018
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001886971780919956,
      "loss": 2.2402,
      "step": 15019
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001885954196083899,
      "loss": 2.1465,
      "step": 15020
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001884936857130083,
      "loss": 2.3398,
      "step": 15021
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001883919764089339,
      "loss": 2.4219,
      "step": 15022
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00018829029169924871,
      "loss": 2.2734,
      "step": 15023
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001881886315870336,
      "loss": 2.3027,
      "step": 15024
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001880869960753696,
      "loss": 2.1504,
      "step": 15025
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018798538516733699,
      "loss": 2.3281,
      "step": 15026
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018788379886601416,
      "loss": 2.3164,
      "step": 15027
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018778223717448006,
      "loss": 2.1055,
      "step": 15028
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018768070009581207,
      "loss": 2.2812,
      "step": 15029
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018757918763308702,
      "loss": 2.0703,
      "step": 15030
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018747769978938157,
      "loss": 2.4727,
      "step": 15031
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001873762365677708,
      "loss": 2.3184,
      "step": 15032
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018727479797132907,
      "loss": 2.1113,
      "step": 15033
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018717338400313068,
      "loss": 2.2812,
      "step": 15034
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018707199466624891,
      "loss": 2.2324,
      "step": 15035
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001869706299637558,
      "loss": 2.4102,
      "step": 15036
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018686928989872332,
      "loss": 2.3477,
      "step": 15037
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018676797447422243,
      "loss": 2.1602,
      "step": 15038
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001866666836933234,
      "loss": 2.248,
      "step": 15039
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018656541755909518,
      "loss": 2.3984,
      "step": 15040
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018646417607460675,
      "loss": 2.1992,
      "step": 15041
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018636295924292633,
      "loss": 2.2949,
      "step": 15042
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018626176706712072,
      "loss": 2.3438,
      "step": 15043
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018616059955025644,
      "loss": 2.2852,
      "step": 15044
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001860594566953996,
      "loss": 2.2383,
      "step": 15045
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018595833850561493,
      "loss": 2.2305,
      "step": 15046
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018585724498396627,
      "loss": 2.1602,
      "step": 15047
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018575617613351736,
      "loss": 2.207,
      "step": 15048
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001856551319573312,
      "loss": 2.2344,
      "step": 15049
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018555411245846931,
      "loss": 2.1543,
      "step": 15050
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001854531176399934,
      "loss": 2.25,
      "step": 15051
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018535214750496333,
      "loss": 2.5234,
      "step": 15052
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018525120205643942,
      "loss": 2.3711,
      "step": 15053
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018515028129748013,
      "loss": 2.25,
      "step": 15054
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001850493852311441,
      "loss": 2.3262,
      "step": 15055
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001849485138604885,
      "loss": 2.3711,
      "step": 15056
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018484766718857026,
      "loss": 2.2734,
      "step": 15057
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018474684521844554,
      "loss": 2.2266,
      "step": 15058
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001846460479531693,
      "loss": 2.2305,
      "step": 15059
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018454527539579568,
      "loss": 2.3281,
      "step": 15060
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018444452754937934,
      "loss": 2.1406,
      "step": 15061
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018434380441697274,
      "loss": 2.3984,
      "step": 15062
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018424310600162786,
      "loss": 2.3672,
      "step": 15063
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018414243230639637,
      "loss": 2.1738,
      "step": 15064
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018404178333432953,
      "loss": 2.2891,
      "step": 15065
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018394115908847687,
      "loss": 2.1289,
      "step": 15066
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001838405595718874,
      "loss": 2.2305,
      "step": 15067
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018373998478761,
      "loss": 2.0918,
      "step": 15068
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018363943473869248,
      "loss": 1.9082,
      "step": 15069
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001835389094281814,
      "loss": 2.3398,
      "step": 15070
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018343840885912366,
      "loss": 2.3477,
      "step": 15071
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018333793303456402,
      "loss": 2.3711,
      "step": 15072
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018323748195754762,
      "loss": 2.2344,
      "step": 15073
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001831370556311187,
      "loss": 2.0938,
      "step": 15074
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018303665405831993,
      "loss": 2.1816,
      "step": 15075
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018293627724219442,
      "loss": 2.0137,
      "step": 15076
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001828359251857834,
      "loss": 2.2383,
      "step": 15077
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018273559789212823,
      "loss": 2.1504,
      "step": 15078
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018263529536426883,
      "loss": 2.1191,
      "step": 15079
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001825350176052447,
      "loss": 2.3184,
      "step": 15080
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018243476461809517,
      "loss": 2.2891,
      "step": 15081
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018233453640585783,
      "loss": 2.2266,
      "step": 15082
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018223433297156954,
      "loss": 2.2852,
      "step": 15083
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018213415431826729,
      "loss": 2.0312,
      "step": 15084
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018203400044898688,
      "loss": 2.3242,
      "step": 15085
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018193387136676288,
      "loss": 2.2734,
      "step": 15086
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018183376707462973,
      "loss": 2.2773,
      "step": 15087
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018173368757562125,
      "loss": 2.3633,
      "step": 15088
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001816336328727699,
      "loss": 2.0918,
      "step": 15089
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018153360296910737,
      "loss": 2.2539,
      "step": 15090
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018143359786766523,
      "loss": 2.1816,
      "step": 15091
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018133361757147404,
      "loss": 2.2324,
      "step": 15092
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018123366208356329,
      "loss": 2.3164,
      "step": 15093
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018113373140696222,
      "loss": 2.293,
      "step": 15094
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018103382554469872,
      "loss": 2.2676,
      "step": 15095
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018093394449980073,
      "loss": 2.209,
      "step": 15096
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018083408827529435,
      "loss": 2.0996,
      "step": 15097
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001807342568742062,
      "loss": 2.1738,
      "step": 15098
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018063445029956095,
      "loss": 2.332,
      "step": 15099
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018053466855438328,
      "loss": 2.3125,
      "step": 15100
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018043491164169723,
      "loss": 2.2148,
      "step": 15101
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001803351795645255,
      "loss": 2.2363,
      "step": 15102
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018023547232588966,
      "loss": 2.207,
      "step": 15103
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001801357899288124,
      "loss": 2.3262,
      "step": 15104
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00018003613237631378,
      "loss": 2.3281,
      "step": 15105
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00017993649967141346,
      "loss": 2.2109,
      "step": 15106
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00017983689181713103,
      "loss": 2.0742,
      "step": 15107
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001797373088164851,
      "loss": 2.293,
      "step": 15108
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00017963775067249277,
      "loss": 2.248,
      "step": 15109
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00017953821738817143,
      "loss": 2.1094,
      "step": 15110
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00017943870896653736,
      "loss": 2.2656,
      "step": 15111
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00017933922541060588,
      "loss": 2.3984,
      "step": 15112
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00017923976672339128,
      "loss": 2.1367,
      "step": 15113
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00017914033290790775,
      "loss": 2.2148,
      "step": 15114
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00017904092396716875,
      "loss": 2.1855,
      "step": 15115
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00017894153990418628,
      "loss": 2.1953,
      "step": 15116
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00017884218072197235,
      "loss": 2.2305,
      "step": 15117
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017874284642353745,
      "loss": 2.1289,
      "step": 15118
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001786435370118923,
      "loss": 2.1094,
      "step": 15119
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017854425249004568,
      "loss": 2.3008,
      "step": 15120
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001784449928610068,
      "loss": 2.2461,
      "step": 15121
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017834575812778296,
      "loss": 2.3945,
      "step": 15122
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001782465482933817,
      "loss": 2.293,
      "step": 15123
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017814736336080962,
      "loss": 2.2578,
      "step": 15124
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001780482033330719,
      "loss": 2.0781,
      "step": 15125
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017794906821317326,
      "loss": 2.2695,
      "step": 15126
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017784995800411852,
      "loss": 2.3789,
      "step": 15127
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017775087270891066,
      "loss": 2.375,
      "step": 15128
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017765181233055205,
      "loss": 2.4336,
      "step": 15129
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017755277687204484,
      "loss": 2.1562,
      "step": 15130
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001774537663363903,
      "loss": 2.1953,
      "step": 15131
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001773547807265885,
      "loss": 2.1836,
      "step": 15132
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001772558200456389,
      "loss": 2.2422,
      "step": 15133
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001771568842965404,
      "loss": 2.4277,
      "step": 15134
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017705797348229157,
      "loss": 2.2852,
      "step": 15135
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017695908760588896,
      "loss": 2.1543,
      "step": 15136
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017686022667032987,
      "loss": 2.0898,
      "step": 15137
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017676139067860952,
      "loss": 2.0566,
      "step": 15138
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017666257963372322,
      "loss": 2.2148,
      "step": 15139
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017656379353866547,
      "loss": 2.3789,
      "step": 15140
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017646503239642964,
      "loss": 2.2617,
      "step": 15141
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017636629621000822,
      "loss": 2.5156,
      "step": 15142
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017626758498239358,
      "loss": 2.2324,
      "step": 15143
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017616889871657705,
      "loss": 2.0918,
      "step": 15144
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017607023741554907,
      "loss": 2.2227,
      "step": 15145
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017597160108229882,
      "loss": 2.332,
      "step": 15146
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017587298971981637,
      "loss": 2.4141,
      "step": 15147
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001757744033310894,
      "loss": 2.125,
      "step": 15148
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017567584191910523,
      "loss": 2.0645,
      "step": 15149
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001755773054868508,
      "loss": 2.0918,
      "step": 15150
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017547879403731226,
      "loss": 2.2129,
      "step": 15151
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017538030757347444,
      "loss": 2.1523,
      "step": 15152
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001752818460983221,
      "loss": 2.3047,
      "step": 15153
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017518340961483902,
      "loss": 2.2852,
      "step": 15154
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017508499812600808,
      "loss": 2.2578,
      "step": 15155
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.000174986611634811,
      "loss": 2.3047,
      "step": 15156
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001748882501442297,
      "loss": 2.1504,
      "step": 15157
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017478991365724495,
      "loss": 2.1953,
      "step": 15158
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017469160217683632,
      "loss": 2.3984,
      "step": 15159
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017459331570598323,
      "loss": 2.125,
      "step": 15160
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017449505424766389,
      "loss": 2.3301,
      "step": 15161
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017439681780485617,
      "loss": 2.1387,
      "step": 15162
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017429860638053663,
      "loss": 2.2305,
      "step": 15163
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017420041997768176,
      "loss": 2.2656,
      "step": 15164
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017410225859926666,
      "loss": 2.1836,
      "step": 15165
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017400412224826588,
      "loss": 2.2148,
      "step": 15166
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017390601092765379,
      "loss": 2.3438,
      "step": 15167
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017380792464040306,
      "loss": 2.3379,
      "step": 15168
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017370986338948558,
      "loss": 2.2539,
      "step": 15169
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017361182717787405,
      "loss": 2.041,
      "step": 15170
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017351381600853855,
      "loss": 2.2422,
      "step": 15171
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017341582988444914,
      "loss": 2.084,
      "step": 15172
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017331786880857525,
      "loss": 2.2168,
      "step": 15173
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001732199327838856,
      "loss": 2.084,
      "step": 15174
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017312202181334779,
      "loss": 2.3086,
      "step": 15175
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001730241358999287,
      "loss": 2.2402,
      "step": 15176
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017292627504659474,
      "loss": 2.168,
      "step": 15177
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017282843925631164,
      "loss": 2.166,
      "step": 15178
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001727306285320437,
      "loss": 2.1465,
      "step": 15179
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001726328428767554,
      "loss": 2.2578,
      "step": 15180
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017253508229340942,
      "loss": 2.3008,
      "step": 15181
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017243734678496847,
      "loss": 2.125,
      "step": 15182
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017233963635439464,
      "loss": 2.1641,
      "step": 15183
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017224195100464825,
      "loss": 2.1895,
      "step": 15184
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017214429073868998,
      "loss": 2.0508,
      "step": 15185
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017204665555947885,
      "loss": 2.4805,
      "step": 15186
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001719490454699739,
      "loss": 2.4375,
      "step": 15187
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001718514604731327,
      "loss": 2.0488,
      "step": 15188
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017175390057191253,
      "loss": 2.2969,
      "step": 15189
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017165636576927013,
      "loss": 2.3516,
      "step": 15190
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017155885606816068,
      "loss": 2.1797,
      "step": 15191
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017146137147153873,
      "loss": 2.1777,
      "step": 15192
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017136391198235924,
      "loss": 1.9824,
      "step": 15193
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017126647760357517,
      "loss": 2.0879,
      "step": 15194
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017116906833813885,
      "loss": 2.0508,
      "step": 15195
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017107168418900232,
      "loss": 2.1289,
      "step": 15196
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017097432515911682,
      "loss": 2.1816,
      "step": 15197
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017087699125143253,
      "loss": 2.3633,
      "step": 15198
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017077968246889853,
      "loss": 2.334,
      "step": 15199
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017068239881446414,
      "loss": 2.1992,
      "step": 15200
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001705851402910774,
      "loss": 2.2773,
      "step": 15201
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017048790690168513,
      "loss": 2.2383,
      "step": 15202
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017039069864923428,
      "loss": 2.2344,
      "step": 15203
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017029351553667017,
      "loss": 2.0859,
      "step": 15204
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017019635756693795,
      "loss": 2.4805,
      "step": 15205
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017009922474298212,
      "loss": 2.2617,
      "step": 15206
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001700021170677458,
      "loss": 2.1699,
      "step": 15207
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001699050345441715,
      "loss": 2.3672,
      "step": 15208
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00016980797717520136,
      "loss": 2.2617,
      "step": 15209
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00016971094496377672,
      "loss": 2.1211,
      "step": 15210
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016961393791283785,
      "loss": 2.1602,
      "step": 15211
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001695169560253238,
      "loss": 2.1445,
      "step": 15212
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001694199993041745,
      "loss": 2.2344,
      "step": 15213
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001693230677523274,
      "loss": 2.3574,
      "step": 15214
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016922616137271984,
      "loss": 2.0898,
      "step": 15215
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016912928016828854,
      "loss": 2.2305,
      "step": 15216
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016903242414196952,
      "loss": 2.0879,
      "step": 15217
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016893559329669727,
      "loss": 2.1914,
      "step": 15218
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016883878763540683,
      "loss": 2.4141,
      "step": 15219
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016874200716103093,
      "loss": 2.0664,
      "step": 15220
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016864525187650314,
      "loss": 2.1875,
      "step": 15221
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016854852178475478,
      "loss": 2.3125,
      "step": 15222
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016845181688871725,
      "loss": 2.2266,
      "step": 15223
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016835513719132145,
      "loss": 2.3359,
      "step": 15224
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001682584826954966,
      "loss": 2.2266,
      "step": 15225
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016816185340417212,
      "loss": 2.2539,
      "step": 15226
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016806524932027556,
      "loss": 2.375,
      "step": 15227
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016796867044673492,
      "loss": 2.3047,
      "step": 15228
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016787211678647652,
      "loss": 2.3047,
      "step": 15229
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016777558834242645,
      "loss": 2.418,
      "step": 15230
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016767908511750962,
      "loss": 2.3203,
      "step": 15231
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016758260711465046,
      "loss": 2.1543,
      "step": 15232
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016748615433677294,
      "loss": 2.3672,
      "step": 15233
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016738972678679955,
      "loss": 2.2422,
      "step": 15234
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016729332446765188,
      "loss": 2.334,
      "step": 15235
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016719694738225234,
      "loss": 2.2852,
      "step": 15236
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016710059553352085,
      "loss": 2.2812,
      "step": 15237
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016700426892437705,
      "loss": 2.2852,
      "step": 15238
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016690796755774006,
      "loss": 2.3711,
      "step": 15239
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016681169143652842,
      "loss": 2.2734,
      "step": 15240
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001667154405636594,
      "loss": 2.168,
      "step": 15241
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016661921494204958,
      "loss": 2.3438,
      "step": 15242
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016652301457461494,
      "loss": 2.4023,
      "step": 15243
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016642683946427105,
      "loss": 2.1992,
      "step": 15244
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016633068961393184,
      "loss": 2.4375,
      "step": 15245
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016623456502651136,
      "loss": 2.2578,
      "step": 15246
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016613846570492208,
      "loss": 2.4844,
      "step": 15247
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016604239165207636,
      "loss": 2.1543,
      "step": 15248
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016594634287088583,
      "loss": 2.3555,
      "step": 15249
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016585031936426086,
      "loss": 2.3008,
      "step": 15250
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001657543211351109,
      "loss": 2.3945,
      "step": 15251
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001656583481863454,
      "loss": 2.1953,
      "step": 15252
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001655624005208729,
      "loss": 2.1328,
      "step": 15253
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016546647814160055,
      "loss": 2.4297,
      "step": 15254
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016537058105143477,
      "loss": 2.3867,
      "step": 15255
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016527470925328246,
      "loss": 2.1426,
      "step": 15256
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016517886275004833,
      "loss": 2.2832,
      "step": 15257
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016508304154463671,
      "loss": 2.3438,
      "step": 15258
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016498724563995137,
      "loss": 2.2129,
      "step": 15259
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001648914750388957,
      "loss": 2.2422,
      "step": 15260
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016479572974437118,
      "loss": 2.2617,
      "step": 15261
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016470000975927956,
      "loss": 2.3086,
      "step": 15262
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016460431508652173,
      "loss": 2.332,
      "step": 15263
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016450864572899727,
      "loss": 2.2852,
      "step": 15264
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016441300168960505,
      "loss": 2.1484,
      "step": 15265
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016431738297124354,
      "loss": 2.457,
      "step": 15266
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016422178957681066,
      "loss": 2.2422,
      "step": 15267
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016412622150920264,
      "loss": 2.3477,
      "step": 15268
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016403067877131616,
      "loss": 2.2715,
      "step": 15269
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001639351613660458,
      "loss": 2.2031,
      "step": 15270
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016383966929628635,
      "loss": 2.0293,
      "step": 15271
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016374420256493172,
      "loss": 2.3125,
      "step": 15272
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016364876117487483,
      "loss": 2.2031,
      "step": 15273
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016355334512900744,
      "loss": 2.3242,
      "step": 15274
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016345795443022126,
      "loss": 2.2031,
      "step": 15275
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016336258908140723,
      "loss": 2.1504,
      "step": 15276
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016326724908545488,
      "loss": 2.2109,
      "step": 15277
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001631719344452529,
      "loss": 2.1523,
      "step": 15278
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016307664516369057,
      "loss": 2.1699,
      "step": 15279
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016298138124365514,
      "loss": 2.1621,
      "step": 15280
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016288614268803305,
      "loss": 2.2227,
      "step": 15281
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016279092949971052,
      "loss": 2.3906,
      "step": 15282
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001626957416815732,
      "loss": 2.4648,
      "step": 15283
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016260057923650495,
      "loss": 2.0938,
      "step": 15284
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016250544216739015,
      "loss": 2.1914,
      "step": 15285
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001624103304771113,
      "loss": 2.3984,
      "step": 15286
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016231524416855092,
      "loss": 2.0918,
      "step": 15287
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001622201832445901,
      "loss": 2.1426,
      "step": 15288
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016212514770810982,
      "loss": 2.248,
      "step": 15289
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001620301375619896,
      "loss": 2.2891,
      "step": 15290
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016193515280910886,
      "loss": 2.207,
      "step": 15291
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016184019345234603,
      "loss": 2.2148,
      "step": 15292
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016174525949457863,
      "loss": 2.0371,
      "step": 15293
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001616503509386831,
      "loss": 2.1758,
      "step": 15294
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016155546778753572,
      "loss": 2.0801,
      "step": 15295
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.000161460610044012,
      "loss": 2.1758,
      "step": 15296
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016136577771098604,
      "loss": 2.2188,
      "step": 15297
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001612709707913318,
      "loss": 2.293,
      "step": 15298
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016117618928792243,
      "loss": 2.1992,
      "step": 15299
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016108143320362988,
      "loss": 1.9785,
      "step": 15300
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001609867025413251,
      "loss": 2.0742,
      "step": 15301
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016089199730387983,
      "loss": 2.4453,
      "step": 15302
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016079731749416316,
      "loss": 2.2539,
      "step": 15303
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00016070266311504433,
      "loss": 2.1309,
      "step": 15304
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00016060803416939162,
      "loss": 2.3008,
      "step": 15305
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00016051343066007296,
      "loss": 2.0781,
      "step": 15306
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00016041885258995502,
      "loss": 2.3125,
      "step": 15307
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00016032429996190334,
      "loss": 2.0781,
      "step": 15308
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00016022977277878358,
      "loss": 2.0801,
      "step": 15309
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001601352710434605,
      "loss": 2.3398,
      "step": 15310
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00016004079475879718,
      "loss": 2.0898,
      "step": 15311
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015994634392765716,
      "loss": 2.2266,
      "step": 15312
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015985191855290214,
      "loss": 2.2578,
      "step": 15313
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015975751863739362,
      "loss": 2.3281,
      "step": 15314
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015966314418399265,
      "loss": 2.0195,
      "step": 15315
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015956879519555867,
      "loss": 2.1562,
      "step": 15316
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015947447167495067,
      "loss": 2.1445,
      "step": 15317
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001593801736250272,
      "loss": 2.3164,
      "step": 15318
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015928590104864594,
      "loss": 2.0781,
      "step": 15319
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001591916539486634,
      "loss": 2.332,
      "step": 15320
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015909743232793517,
      "loss": 2.2305,
      "step": 15321
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015900323618931757,
      "loss": 2.1348,
      "step": 15322
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001589090655356642,
      "loss": 2.1152,
      "step": 15323
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015881492036982892,
      "loss": 2.3281,
      "step": 15324
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015872080069466454,
      "loss": 2.1289,
      "step": 15325
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015862670651302369,
      "loss": 2.1641,
      "step": 15326
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015853263782775707,
      "loss": 2.1289,
      "step": 15327
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015843859464171594,
      "loss": 2.25,
      "step": 15328
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015834457695774939,
      "loss": 2.332,
      "step": 15329
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015825058477870712,
      "loss": 2.2812,
      "step": 15330
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015815661810743688,
      "loss": 2.1328,
      "step": 15331
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015806267694678643,
      "loss": 2.207,
      "step": 15332
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015796876129960268,
      "loss": 2.1797,
      "step": 15333
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015787487116873122,
      "loss": 2.3398,
      "step": 15334
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015778100655701756,
      "loss": 2.3164,
      "step": 15335
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001576871674673056,
      "loss": 2.1953,
      "step": 15336
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015759335390243967,
      "loss": 2.1875,
      "step": 15337
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015749956586526192,
      "loss": 2.2617,
      "step": 15338
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001574058033586151,
      "loss": 2.2773,
      "step": 15339
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015731206638534002,
      "loss": 2.2695,
      "step": 15340
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001572183549482773,
      "loss": 2.2715,
      "step": 15341
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.000157124669050267,
      "loss": 2.5352,
      "step": 15342
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.000157031008694148,
      "loss": 2.3633,
      "step": 15343
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015693737388275785,
      "loss": 2.1504,
      "step": 15344
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015684376461893524,
      "loss": 2.3828,
      "step": 15345
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015675018090551595,
      "loss": 2.3359,
      "step": 15346
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015665662274533598,
      "loss": 2.4453,
      "step": 15347
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001565630901412306,
      "loss": 2.1133,
      "step": 15348
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001564695830960342,
      "loss": 2.2852,
      "step": 15349
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001563761016125802,
      "loss": 2.0391,
      "step": 15350
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015628264569370165,
      "loss": 2.0664,
      "step": 15351
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015618921534223007,
      "loss": 2.1992,
      "step": 15352
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001560958105609973,
      "loss": 2.2109,
      "step": 15353
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001560024313528333,
      "loss": 2.2188,
      "step": 15354
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001559090777205683,
      "loss": 2.1797,
      "step": 15355
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001558157496670306,
      "loss": 2.4805,
      "step": 15356
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001557224471950488,
      "loss": 2.3164,
      "step": 15357
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015562917030745028,
      "loss": 2.1445,
      "step": 15358
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015553591900706144,
      "loss": 2.168,
      "step": 15359
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015544269329670801,
      "loss": 2.4023,
      "step": 15360
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001553494931792152,
      "loss": 2.2402,
      "step": 15361
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015525631865740742,
      "loss": 2.1465,
      "step": 15362
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001551631697341078,
      "loss": 2.2285,
      "step": 15363
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001550700464121393,
      "loss": 2.125,
      "step": 15364
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.000154976948694324,
      "loss": 2.252,
      "step": 15365
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001548838765834829,
      "loss": 2.2324,
      "step": 15366
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015479083008243622,
      "loss": 2.3242,
      "step": 15367
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015469780919400366,
      "loss": 2.082,
      "step": 15368
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015460481392100446,
      "loss": 2.2227,
      "step": 15369
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015451184426625608,
      "loss": 2.0879,
      "step": 15370
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001544189002325761,
      "loss": 2.3242,
      "step": 15371
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015432598182278125,
      "loss": 2.1016,
      "step": 15372
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.000154233089039687,
      "loss": 2.0195,
      "step": 15373
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001541402218861081,
      "loss": 2.1641,
      "step": 15374
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015404738036485898,
      "loss": 2.2051,
      "step": 15375
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015395456447875322,
      "loss": 2.0449,
      "step": 15376
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015386177423060311,
      "loss": 2.123,
      "step": 15377
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001537690096232208,
      "loss": 2.2461,
      "step": 15378
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015367627065941702,
      "loss": 2.2227,
      "step": 15379
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015358355734200224,
      "loss": 2.1016,
      "step": 15380
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015349086967378622,
      "loss": 2.2617,
      "step": 15381
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001533982076575775,
      "loss": 2.1211,
      "step": 15382
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001533055712961837,
      "loss": 1.9648,
      "step": 15383
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001532129605924124,
      "loss": 2.1191,
      "step": 15384
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001531203755490701,
      "loss": 2.2402,
      "step": 15385
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015302781616896233,
      "loss": 2.1836,
      "step": 15386
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001529352824548933,
      "loss": 2.2617,
      "step": 15387
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001528427744096682,
      "loss": 2.3164,
      "step": 15388
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001527502920360898,
      "loss": 2.1328,
      "step": 15389
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015265783533696033,
      "loss": 2.2461,
      "step": 15390
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001525654043150818,
      "loss": 2.2773,
      "step": 15391
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001524729989732555,
      "loss": 2.0,
      "step": 15392
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015238061931428104,
      "loss": 2.1543,
      "step": 15393
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015228826534095818,
      "loss": 2.3672,
      "step": 15394
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015219593705608536,
      "loss": 2.1758,
      "step": 15395
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00015210363446246068,
      "loss": 2.1953,
      "step": 15396
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00015201135756288088,
      "loss": 2.3301,
      "step": 15397
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00015191910636014262,
      "loss": 2.4277,
      "step": 15398
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.000151826880857041,
      "loss": 2.3594,
      "step": 15399
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00015173468105637102,
      "loss": 2.209,
      "step": 15400
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00015164250696092675,
      "loss": 2.3477,
      "step": 15401
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001515503585735013,
      "loss": 2.2383,
      "step": 15402
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00015145823589688667,
      "loss": 2.123,
      "step": 15403
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00015136613893387474,
      "loss": 2.4219,
      "step": 15404
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00015127406768725683,
      "loss": 2.2734,
      "step": 15405
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00015118202215982213,
      "loss": 2.2695,
      "step": 15406
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00015109000235436043,
      "loss": 2.2617,
      "step": 15407
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001509980082736605,
      "loss": 2.2305,
      "step": 15408
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00015090603992050966,
      "loss": 2.3711,
      "step": 15409
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00015081409729769435,
      "loss": 2.0488,
      "step": 15410
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001507221804080019,
      "loss": 2.3359,
      "step": 15411
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00015063028925421705,
      "loss": 2.4023,
      "step": 15412
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001505384238391243,
      "loss": 2.0352,
      "step": 15413
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001504465841655075,
      "loss": 2.2617,
      "step": 15414
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00015035477023615017,
      "loss": 2.1855,
      "step": 15415
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00015026298205383416,
      "loss": 2.2695,
      "step": 15416
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00015017121962134083,
      "loss": 2.0586,
      "step": 15417
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00015007948294145103,
      "loss": 2.1504,
      "step": 15418
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014998777201694492,
      "loss": 2.1523,
      "step": 15419
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001498960868506013,
      "loss": 2.3066,
      "step": 15420
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014980442744519886,
      "loss": 2.2656,
      "step": 15421
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014971279380351476,
      "loss": 2.3379,
      "step": 15422
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014962118592832608,
      "loss": 2.2305,
      "step": 15423
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014952960382240898,
      "loss": 2.3867,
      "step": 15424
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014943804748853863,
      "loss": 2.1953,
      "step": 15425
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014934651692948898,
      "loss": 2.2051,
      "step": 15426
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014925501214803417,
      "loss": 2.2871,
      "step": 15427
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001491635331469473,
      "loss": 2.3438,
      "step": 15428
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014907207992900017,
      "loss": 2.3125,
      "step": 15429
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001489806524969637,
      "loss": 2.1562,
      "step": 15430
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014888925085360937,
      "loss": 2.2773,
      "step": 15431
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001487978750017065,
      "loss": 2.2344,
      "step": 15432
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014870652494402382,
      "loss": 2.2812,
      "step": 15433
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014861520068332968,
      "loss": 2.1465,
      "step": 15434
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014852390222239186,
      "loss": 1.9492,
      "step": 15435
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014843262956397663,
      "loss": 2.4004,
      "step": 15436
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014834138271085007,
      "loss": 2.2559,
      "step": 15437
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014825016166577698,
      "loss": 2.0078,
      "step": 15438
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014815896643152193,
      "loss": 2.3711,
      "step": 15439
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014806779701084826,
      "loss": 2.0293,
      "step": 15440
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014797665340651888,
      "loss": 2.25,
      "step": 15441
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014788553562129558,
      "loss": 2.2812,
      "step": 15442
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001477944436579395,
      "loss": 2.1582,
      "step": 15443
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014770337751921126,
      "loss": 2.2695,
      "step": 15444
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014761233720787014,
      "loss": 2.0645,
      "step": 15445
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014752132272667507,
      "loss": 2.1191,
      "step": 15446
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014743033407838447,
      "loss": 2.3242,
      "step": 15447
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014733937126575525,
      "loss": 2.2461,
      "step": 15448
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014724843429154367,
      "loss": 2.1797,
      "step": 15449
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014715752315850572,
      "loss": 2.2422,
      "step": 15450
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014706663786939644,
      "loss": 2.3594,
      "step": 15451
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014697577842696973,
      "loss": 2.1719,
      "step": 15452
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001468849448339785,
      "loss": 2.25,
      "step": 15453
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014679413709317623,
      "loss": 2.2227,
      "step": 15454
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014670335520731415,
      "loss": 2.1191,
      "step": 15455
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014661259917914316,
      "loss": 2.3398,
      "step": 15456
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014652186901141363,
      "loss": 2.2383,
      "step": 15457
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014643116470687524,
      "loss": 2.3594,
      "step": 15458
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014634048626827612,
      "loss": 2.1641,
      "step": 15459
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014624983369836465,
      "loss": 2.2734,
      "step": 15460
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014615920699988726,
      "loss": 1.957,
      "step": 15461
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014606860617559094,
      "loss": 2.4219,
      "step": 15462
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014597803122822062,
      "loss": 2.1562,
      "step": 15463
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001458874821605215,
      "loss": 2.0742,
      "step": 15464
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014579695897523704,
      "loss": 2.3164,
      "step": 15465
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014570646167511047,
      "loss": 2.2148,
      "step": 15466
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014561599026288475,
      "loss": 2.1836,
      "step": 15467
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014552554474130087,
      "loss": 2.375,
      "step": 15468
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014543512511309953,
      "loss": 2.3086,
      "step": 15469
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014534473138102112,
      "loss": 2.457,
      "step": 15470
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014525436354780486,
      "loss": 2.2734,
      "step": 15471
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001451640216161888,
      "loss": 1.9023,
      "step": 15472
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014507370558891088,
      "loss": 2.168,
      "step": 15473
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001449834154687082,
      "loss": 2.3047,
      "step": 15474
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014489315125831658,
      "loss": 2.1797,
      "step": 15475
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014480291296047122,
      "loss": 2.1445,
      "step": 15476
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014471270057790663,
      "loss": 2.3633,
      "step": 15477
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001446225141133569,
      "loss": 2.2031,
      "step": 15478
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014453235356955463,
      "loss": 2.1699,
      "step": 15479
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014444221894923214,
      "loss": 2.2617,
      "step": 15480
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014435211025512075,
      "loss": 2.1836,
      "step": 15481
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001442620274899511,
      "loss": 2.2656,
      "step": 15482
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014417197065645282,
      "loss": 2.3516,
      "step": 15483
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014408193975735506,
      "loss": 2.3359,
      "step": 15484
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001439919347953862,
      "loss": 2.1504,
      "step": 15485
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014390195577327337,
      "loss": 2.3809,
      "step": 15486
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001438120026937436,
      "loss": 2.1641,
      "step": 15487
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014372207555952244,
      "loss": 2.3672,
      "step": 15488
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00014363217437333498,
      "loss": 2.2539,
      "step": 15489
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014354229913790596,
      "loss": 2.3711,
      "step": 15490
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014345244985595852,
      "loss": 2.0723,
      "step": 15491
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014336262653021526,
      "loss": 2.2969,
      "step": 15492
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014327282916339824,
      "loss": 2.2969,
      "step": 15493
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014318305775822893,
      "loss": 2.1992,
      "step": 15494
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014309331231742752,
      "loss": 2.2344,
      "step": 15495
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.000143003592843713,
      "loss": 2.3438,
      "step": 15496
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014291389933980515,
      "loss": 2.2012,
      "step": 15497
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014282423180842152,
      "loss": 2.1758,
      "step": 15498
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001427345902522791,
      "loss": 1.9766,
      "step": 15499
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014264497467409454,
      "loss": 2.2188,
      "step": 15500
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014255538507658373,
      "loss": 2.2734,
      "step": 15501
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.000142465821462461,
      "loss": 2.2617,
      "step": 15502
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014237628383444102,
      "loss": 2.1055,
      "step": 15503
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014228677219523656,
      "loss": 2.3633,
      "step": 15504
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014219728654756047,
      "loss": 2.2285,
      "step": 15505
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014210782689412415,
      "loss": 2.1797,
      "step": 15506
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014201839323763898,
      "loss": 2.1113,
      "step": 15507
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014192898558081446,
      "loss": 2.2109,
      "step": 15508
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001418396039263603,
      "loss": 2.3047,
      "step": 15509
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014175024827698535,
      "loss": 2.3828,
      "step": 15510
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.000141660918635397,
      "loss": 2.1914,
      "step": 15511
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014157161500430205,
      "loss": 2.2031,
      "step": 15512
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001414823373864069,
      "loss": 2.2109,
      "step": 15513
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014139308578441735,
      "loss": 2.3594,
      "step": 15514
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014130386020103737,
      "loss": 2.0547,
      "step": 15515
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014121466063897104,
      "loss": 2.123,
      "step": 15516
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014112548710092167,
      "loss": 2.1699,
      "step": 15517
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014103633958959127,
      "loss": 2.2656,
      "step": 15518
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014094721810768097,
      "loss": 2.3008,
      "step": 15519
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014085812265789212,
      "loss": 2.1875,
      "step": 15520
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014076905324292432,
      "loss": 2.2109,
      "step": 15521
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014068000986547634,
      "loss": 2.3164,
      "step": 15522
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001405909925282469,
      "loss": 2.3711,
      "step": 15523
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014050200123393353,
      "loss": 1.9902,
      "step": 15524
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014041303598523247,
      "loss": 1.9629,
      "step": 15525
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014032409678484036,
      "loss": 2.0625,
      "step": 15526
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014023518363545174,
      "loss": 2.0859,
      "step": 15527
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001401462965397614,
      "loss": 2.1875,
      "step": 15528
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00014005743550046256,
      "loss": 2.4141,
      "step": 15529
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001399686005202484,
      "loss": 2.3398,
      "step": 15530
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013987979160181042,
      "loss": 2.3613,
      "step": 15531
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013979100874784013,
      "loss": 2.1387,
      "step": 15532
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013970225196102804,
      "loss": 2.4453,
      "step": 15533
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001396135212440637,
      "loss": 2.2617,
      "step": 15534
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013952481659963568,
      "loss": 2.3242,
      "step": 15535
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013943613803043208,
      "loss": 2.459,
      "step": 15536
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013934748553914066,
      "loss": 2.0879,
      "step": 15537
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013925885912844716,
      "loss": 2.1797,
      "step": 15538
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013917025880103774,
      "loss": 2.1777,
      "step": 15539
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013908168455959723,
      "loss": 2.1758,
      "step": 15540
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013899313640680966,
      "loss": 2.2031,
      "step": 15541
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013890461434535817,
      "loss": 2.1699,
      "step": 15542
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001388161183779253,
      "loss": 2.1836,
      "step": 15543
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001387276485071931,
      "loss": 2.252,
      "step": 15544
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013863920473584213,
      "loss": 2.2734,
      "step": 15545
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013855078706655278,
      "loss": 2.25,
      "step": 15546
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013846239550200412,
      "loss": 2.2188,
      "step": 15547
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013837403004487504,
      "loss": 2.1855,
      "step": 15548
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013828569069784292,
      "loss": 2.1992,
      "step": 15549
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001381973774635852,
      "loss": 2.3496,
      "step": 15550
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013810909034477748,
      "loss": 2.4141,
      "step": 15551
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013802082934409555,
      "loss": 2.2344,
      "step": 15552
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013793259446421413,
      "loss": 2.3555,
      "step": 15553
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001378443857078069,
      "loss": 2.3047,
      "step": 15554
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001377562030775462,
      "loss": 2.25,
      "step": 15555
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013766804657610544,
      "loss": 2.3359,
      "step": 15556
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001375799162061554,
      "loss": 2.2656,
      "step": 15557
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013749181197036654,
      "loss": 2.1953,
      "step": 15558
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013740373387140903,
      "loss": 2.0137,
      "step": 15559
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013731568191195198,
      "loss": 2.2812,
      "step": 15560
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001372276560946636,
      "loss": 2.3477,
      "step": 15561
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001371396564222107,
      "loss": 2.0527,
      "step": 15562
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001370516828972611,
      "loss": 2.207,
      "step": 15563
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001369637355224802,
      "loss": 2.2891,
      "step": 15564
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013687581430053274,
      "loss": 2.2949,
      "step": 15565
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013678791923408328,
      "loss": 2.2773,
      "step": 15566
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013670005032579558,
      "loss": 2.2852,
      "step": 15567
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013661220757833192,
      "loss": 2.2891,
      "step": 15568
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013652439099435466,
      "loss": 2.1484,
      "step": 15569
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013643660057652442,
      "loss": 2.3047,
      "step": 15570
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013634883632750205,
      "loss": 2.252,
      "step": 15571
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013626109824994671,
      "loss": 2.2695,
      "step": 15572
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013617338634651753,
      "loss": 2.1504,
      "step": 15573
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013608570061987202,
      "loss": 2.0898,
      "step": 15574
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013599804107266756,
      "loss": 2.3359,
      "step": 15575
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001359104077075608,
      "loss": 2.1582,
      "step": 15576
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001358228005272071,
      "loss": 2.2148,
      "step": 15577
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013573521953426083,
      "loss": 2.3027,
      "step": 15578
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013564766473137647,
      "loss": 2.332,
      "step": 15579
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013556013612120722,
      "loss": 2.1211,
      "step": 15580
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013547263370640528,
      "loss": 2.3008,
      "step": 15581
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013538515748962222,
      "loss": 2.3398,
      "step": 15582
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013529770747350934,
      "loss": 2.3086,
      "step": 15583
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001352102836607162,
      "loss": 2.168,
      "step": 15584
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001351228860538919,
      "loss": 2.1895,
      "step": 15585
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013503551465568519,
      "loss": 2.1172,
      "step": 15586
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013494816946874378,
      "loss": 2.3672,
      "step": 15587
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013486085049571416,
      "loss": 2.4062,
      "step": 15588
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013477355773924282,
      "loss": 2.2324,
      "step": 15589
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001346862912019746,
      "loss": 2.0898,
      "step": 15590
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013459905088655433,
      "loss": 2.3438,
      "step": 15591
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013451183679562528,
      "loss": 2.0957,
      "step": 15592
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013442464893183048,
      "loss": 2.3906,
      "step": 15593
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013433748729781237,
      "loss": 2.1934,
      "step": 15594
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001342503518962117,
      "loss": 2.1699,
      "step": 15595
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001341632427296694,
      "loss": 2.0918,
      "step": 15596
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013407615980082476,
      "loss": 2.2168,
      "step": 15597
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013398910311231683,
      "loss": 2.25,
      "step": 15598
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.000133902072666784,
      "loss": 2.1875,
      "step": 15599
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001338150684668633,
      "loss": 2.1836,
      "step": 15600
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013372809051519108,
      "loss": 2.2773,
      "step": 15601
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001336411388144032,
      "loss": 2.2695,
      "step": 15602
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013355421336713502,
      "loss": 2.4609,
      "step": 15603
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013346731417601988,
      "loss": 2.207,
      "step": 15604
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013338044124369165,
      "loss": 2.2031,
      "step": 15605
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001332935945727829,
      "loss": 2.2344,
      "step": 15606
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013320677416592518,
      "loss": 2.3125,
      "step": 15607
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001331199800257492,
      "loss": 2.1875,
      "step": 15608
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001330332121548855,
      "loss": 2.0586,
      "step": 15609
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013294647055596344,
      "loss": 2.1738,
      "step": 15610
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001328597552316111,
      "loss": 2.252,
      "step": 15611
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013277306618445696,
      "loss": 2.2422,
      "step": 15612
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013268640341712723,
      "loss": 2.2734,
      "step": 15613
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013259976693224873,
      "loss": 2.041,
      "step": 15614
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013251315673244634,
      "loss": 2.2461,
      "step": 15615
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013242657282034497,
      "loss": 2.0156,
      "step": 15616
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001323400151985681,
      "loss": 2.1602,
      "step": 15617
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001322534838697388,
      "loss": 2.2949,
      "step": 15618
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013216697883647967,
      "loss": 2.1309,
      "step": 15619
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013208050010141159,
      "loss": 2.2656,
      "step": 15620
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013199404766715494,
      "loss": 2.2539,
      "step": 15621
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013190762153633041,
      "loss": 2.0957,
      "step": 15622
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001318212217115563,
      "loss": 2.0957,
      "step": 15623
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013173484819545088,
      "loss": 2.3047,
      "step": 15624
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013164850099063152,
      "loss": 2.3828,
      "step": 15625
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013156218009971533,
      "loss": 2.2363,
      "step": 15626
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013147588552531763,
      "loss": 2.0918,
      "step": 15627
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001313896172700534,
      "loss": 2.293,
      "step": 15628
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001313033753365369,
      "loss": 2.2891,
      "step": 15629
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001312171597273818,
      "loss": 2.3672,
      "step": 15630
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013113097044520038,
      "loss": 2.0195,
      "step": 15631
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001310448074926047,
      "loss": 2.4023,
      "step": 15632
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001309586708722059,
      "loss": 2.3594,
      "step": 15633
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013087256058661378,
      "loss": 2.1836,
      "step": 15634
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013078647663843811,
      "loss": 2.3457,
      "step": 15635
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013070041903028728,
      "loss": 2.1328,
      "step": 15636
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001306143877647694,
      "loss": 2.3086,
      "step": 15637
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001305283828444912,
      "loss": 2.2617,
      "step": 15638
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013044240427205922,
      "loss": 2.0488,
      "step": 15639
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001303564520500785,
      "loss": 2.1094,
      "step": 15640
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013027052618115386,
      "loss": 2.2852,
      "step": 15641
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013018462666788944,
      "loss": 2.3164,
      "step": 15642
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013009875351288803,
      "loss": 2.4062,
      "step": 15643
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013001290671875166,
      "loss": 2.0957,
      "step": 15644
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001299270862880818,
      "loss": 2.3281,
      "step": 15645
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012984129222347963,
      "loss": 2.2031,
      "step": 15646
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012975552452754434,
      "loss": 2.1016,
      "step": 15647
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012966978320287526,
      "loss": 2.1797,
      "step": 15648
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001295840682520708,
      "loss": 2.3164,
      "step": 15649
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012949837967772825,
      "loss": 2.1602,
      "step": 15650
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012941271748244398,
      "loss": 2.2109,
      "step": 15651
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012932708166881412,
      "loss": 2.1855,
      "step": 15652
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012924147223943383,
      "loss": 2.3906,
      "step": 15653
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012915588919689701,
      "loss": 2.1035,
      "step": 15654
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012907033254379763,
      "loss": 2.1758,
      "step": 15655
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012898480228272768,
      "loss": 2.0801,
      "step": 15656
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012889929841627956,
      "loss": 2.293,
      "step": 15657
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012881382094704396,
      "loss": 2.127,
      "step": 15658
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012872836987761139,
      "loss": 2.3555,
      "step": 15659
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012864294521057097,
      "loss": 2.293,
      "step": 15660
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012855754694851164,
      "loss": 2.2617,
      "step": 15661
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001284721750940213,
      "loss": 2.166,
      "step": 15662
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012838682964968684,
      "loss": 2.1914,
      "step": 15663
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012830151061809413,
      "loss": 2.2109,
      "step": 15664
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012821621800182949,
      "loss": 2.418,
      "step": 15665
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.000128130951803477,
      "loss": 2.2871,
      "step": 15666
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012804571202562043,
      "loss": 2.2617,
      "step": 15667
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012796049867084302,
      "loss": 2.2422,
      "step": 15668
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012787531174172716,
      "loss": 2.082,
      "step": 15669
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012779015124085414,
      "loss": 2.3633,
      "step": 15670
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012770501717080407,
      "loss": 1.9375,
      "step": 15671
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001276199095341578,
      "loss": 2.3516,
      "step": 15672
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012753482833349384,
      "loss": 2.0254,
      "step": 15673
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001274497735713903,
      "loss": 2.1836,
      "step": 15674
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00012736474525042475,
      "loss": 2.1914,
      "step": 15675
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012727974337317405,
      "loss": 2.3125,
      "step": 15676
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012719476794221363,
      "loss": 2.2656,
      "step": 15677
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012710981896011907,
      "loss": 2.1152,
      "step": 15678
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001270248964294639,
      "loss": 2.2461,
      "step": 15679
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012694000035282226,
      "loss": 2.1973,
      "step": 15680
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001268551307327662,
      "loss": 2.1836,
      "step": 15681
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012677028757186794,
      "loss": 2.0684,
      "step": 15682
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012668547087269822,
      "loss": 2.0625,
      "step": 15683
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012660068063782736,
      "loss": 2.125,
      "step": 15684
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001265159168698251,
      "loss": 2.2695,
      "step": 15685
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001264311795712597,
      "loss": 2.3027,
      "step": 15686
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012634646874469868,
      "loss": 2.1445,
      "step": 15687
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012626178439270995,
      "loss": 2.3906,
      "step": 15688
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012617712651785917,
      "loss": 2.252,
      "step": 15689
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012609249512271148,
      "loss": 2.0898,
      "step": 15690
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012600789020983193,
      "loss": 2.2246,
      "step": 15691
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001259233117817844,
      "loss": 2.3789,
      "step": 15692
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001258387598411317,
      "loss": 2.1816,
      "step": 15693
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012575423439043577,
      "loss": 2.3984,
      "step": 15694
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012566973543225824,
      "loss": 2.1367,
      "step": 15695
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012558526296916006,
      "loss": 2.3672,
      "step": 15696
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001255008170037004,
      "loss": 2.2227,
      "step": 15697
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012541639753843882,
      "loss": 2.4805,
      "step": 15698
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012533200457593297,
      "loss": 2.3008,
      "step": 15699
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001252476381187405,
      "loss": 2.1074,
      "step": 15700
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012516329816941819,
      "loss": 2.0137,
      "step": 15701
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012507898473052172,
      "loss": 2.2695,
      "step": 15702
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001249946978046056,
      "loss": 2.2148,
      "step": 15703
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012491043739422449,
      "loss": 2.166,
      "step": 15704
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012482620350193175,
      "loss": 2.3125,
      "step": 15705
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001247419961302796,
      "loss": 2.168,
      "step": 15706
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012465781528182008,
      "loss": 2.3242,
      "step": 15707
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012457366095910426,
      "loss": 2.25,
      "step": 15708
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012448953316468225,
      "loss": 2.2148,
      "step": 15709
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012440543190110297,
      "loss": 2.2773,
      "step": 15710
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001243213571709152,
      "loss": 2.2148,
      "step": 15711
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012423730897666708,
      "loss": 2.3242,
      "step": 15712
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012415328732090492,
      "loss": 2.25,
      "step": 15713
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012406929220617514,
      "loss": 2.1523,
      "step": 15714
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012398532363502336,
      "loss": 2.4883,
      "step": 15715
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012390138160999376,
      "loss": 2.2383,
      "step": 15716
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012381746613362987,
      "loss": 2.2441,
      "step": 15717
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001237335772084749,
      "loss": 2.4141,
      "step": 15718
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001236497148370711,
      "loss": 2.1602,
      "step": 15719
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012356587902195937,
      "loss": 2.2188,
      "step": 15720
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012348206976568065,
      "loss": 2.0215,
      "step": 15721
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012339828707077418,
      "loss": 2.1367,
      "step": 15722
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001233145309397793,
      "loss": 2.0664,
      "step": 15723
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001232308013752337,
      "loss": 2.2949,
      "step": 15724
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012314709837967498,
      "loss": 2.2578,
      "step": 15725
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012306342195563924,
      "loss": 2.2266,
      "step": 15726
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012297977210566248,
      "loss": 2.1055,
      "step": 15727
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012289614883227961,
      "loss": 2.1504,
      "step": 15728
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012281255213802468,
      "loss": 2.2031,
      "step": 15729
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012272898202543025,
      "loss": 2.2812,
      "step": 15730
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001226454384970298,
      "loss": 2.1797,
      "step": 15731
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001225619215553545,
      "loss": 2.2793,
      "step": 15732
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012247843120293501,
      "loss": 2.1367,
      "step": 15733
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001223949674423015,
      "loss": 2.3516,
      "step": 15734
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012231153027598353,
      "loss": 2.1387,
      "step": 15735
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012222811970650916,
      "loss": 2.4023,
      "step": 15736
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012214473573640583,
      "loss": 2.332,
      "step": 15737
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012206137836820063,
      "loss": 2.1719,
      "step": 15738
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012197804760441977,
      "loss": 2.0703,
      "step": 15739
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012189474344758799,
      "loss": 2.3086,
      "step": 15740
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012181146590022995,
      "loss": 2.3398,
      "step": 15741
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001217282149648693,
      "loss": 2.3066,
      "step": 15742
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012164499064402845,
      "loss": 2.2578,
      "step": 15743
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012156179294022995,
      "loss": 2.3125,
      "step": 15744
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012147862185599434,
      "loss": 2.125,
      "step": 15745
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012139547739384249,
      "loss": 2.0488,
      "step": 15746
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012131235955629349,
      "loss": 2.25,
      "step": 15747
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012122926834586646,
      "loss": 2.209,
      "step": 15748
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012114620376507912,
      "loss": 2.2461,
      "step": 15749
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001210631658164486,
      "loss": 2.1016,
      "step": 15750
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012098015450249155,
      "loss": 2.457,
      "step": 15751
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012089716982572319,
      "loss": 2.0156,
      "step": 15752
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012081421178865803,
      "loss": 2.1328,
      "step": 15753
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001207312803938102,
      "loss": 2.1953,
      "step": 15754
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012064837564369313,
      "loss": 2.1777,
      "step": 15755
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012056549754081846,
      "loss": 2.1016,
      "step": 15756
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001204826460876981,
      "loss": 2.0273,
      "step": 15757
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012039982128684268,
      "loss": 1.7891,
      "step": 15758
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001203170231407621,
      "loss": 2.0176,
      "step": 15759
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012023425165196511,
      "loss": 2.1406,
      "step": 15760
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012015150682296006,
      "loss": 2.2383,
      "step": 15761
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00012006878865625481,
      "loss": 2.3008,
      "step": 15762
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00011998609715435537,
      "loss": 2.1992,
      "step": 15763
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00011990343231976809,
      "loss": 2.1816,
      "step": 15764
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00011982079415499758,
      "loss": 2.3398,
      "step": 15765
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00011973818266254821,
      "loss": 2.207,
      "step": 15766
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00011965559784492364,
      "loss": 2.293,
      "step": 15767
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00011957303970462619,
      "loss": 2.418,
      "step": 15768
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011949050824415741,
      "loss": 2.1055,
      "step": 15769
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011940800346601866,
      "loss": 2.0547,
      "step": 15770
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011932552537271013,
      "loss": 2.2969,
      "step": 15771
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011924307396673096,
      "loss": 2.125,
      "step": 15772
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011916064925057945,
      "loss": 2.1719,
      "step": 15773
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011907825122675408,
      "loss": 2.1602,
      "step": 15774
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0001189958798977513,
      "loss": 2.3555,
      "step": 15775
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011891353526606707,
      "loss": 2.1816,
      "step": 15776
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.000118831217334197,
      "loss": 2.2051,
      "step": 15777
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011874892610463561,
      "loss": 2.2891,
      "step": 15778
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011866666157987638,
      "loss": 2.0645,
      "step": 15779
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0001185844237624123,
      "loss": 2.2207,
      "step": 15780
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0001185022126547356,
      "loss": 2.1777,
      "step": 15781
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0001184200282593375,
      "loss": 2.2344,
      "step": 15782
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011833787057870815,
      "loss": 2.2598,
      "step": 15783
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011825573961533743,
      "loss": 2.4531,
      "step": 15784
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011817363537171433,
      "loss": 2.3672,
      "step": 15785
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011809155785032643,
      "loss": 2.0566,
      "step": 15786
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011800950705366154,
      "loss": 2.1602,
      "step": 15787
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011792748298420552,
      "loss": 2.3242,
      "step": 15788
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011784548564444441,
      "loss": 2.5859,
      "step": 15789
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011776351503686266,
      "loss": 2.3164,
      "step": 15790
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011768157116394451,
      "loss": 2.1797,
      "step": 15791
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011759965402817275,
      "loss": 2.4062,
      "step": 15792
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011751776363203004,
      "loss": 2.1738,
      "step": 15793
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011743589997799808,
      "loss": 2.293,
      "step": 15794
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011735406306855744,
      "loss": 2.2422,
      "step": 15795
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0001172722529061876,
      "loss": 2.4062,
      "step": 15796
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011719046949336853,
      "loss": 2.5039,
      "step": 15797
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011710871283257796,
      "loss": 2.1953,
      "step": 15798
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011702698292629343,
      "loss": 2.3398,
      "step": 15799
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011694527977699165,
      "loss": 2.3125,
      "step": 15800
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011686360338714885,
      "loss": 2.2461,
      "step": 15801
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011678195375923972,
      "loss": 2.2305,
      "step": 15802
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011670033089573851,
      "loss": 2.2812,
      "step": 15803
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011661873479911855,
      "loss": 2.1719,
      "step": 15804
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.000116537165471853,
      "loss": 2.1504,
      "step": 15805
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0001164556229164131,
      "loss": 2.3555,
      "step": 15806
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011637410713527042,
      "loss": 2.3086,
      "step": 15807
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011629261813089454,
      "loss": 2.2461,
      "step": 15808
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011621115590575504,
      "loss": 2.4551,
      "step": 15809
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011612972046232096,
      "loss": 2.5078,
      "step": 15810
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011604831180305963,
      "loss": 2.1523,
      "step": 15811
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011596692993043778,
      "loss": 2.2695,
      "step": 15812
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011588557484692197,
      "loss": 2.1641,
      "step": 15813
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011580424655497757,
      "loss": 2.1328,
      "step": 15814
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011572294505706882,
      "loss": 2.1152,
      "step": 15815
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0001156416703556592,
      "loss": 2.2422,
      "step": 15816
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0001155604224532123,
      "loss": 2.2988,
      "step": 15817
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011547920135218981,
      "loss": 2.2656,
      "step": 15818
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011539800705505277,
      "loss": 2.1797,
      "step": 15819
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011531683956426187,
      "loss": 2.3262,
      "step": 15820
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011523569888227703,
      "loss": 2.3398,
      "step": 15821
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011515458501155651,
      "loss": 2.1367,
      "step": 15822
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011507349795455868,
      "loss": 2.3047,
      "step": 15823
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0001149924377137408,
      "loss": 2.2188,
      "step": 15824
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011491140429155921,
      "loss": 2.0215,
      "step": 15825
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011483039769046911,
      "loss": 2.1797,
      "step": 15826
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0001147494179129257,
      "loss": 2.1328,
      "step": 15827
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011466846496138295,
      "loss": 2.3281,
      "step": 15828
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011458753883829365,
      "loss": 2.0684,
      "step": 15829
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011450663954611052,
      "loss": 2.334,
      "step": 15830
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011442576708728481,
      "loss": 2.2891,
      "step": 15831
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011434492146426733,
      "loss": 2.418,
      "step": 15832
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011426410267950782,
      "loss": 2.4336,
      "step": 15833
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011418331073545562,
      "loss": 2.2148,
      "step": 15834
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0001141025456345588,
      "loss": 2.1426,
      "step": 15835
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0001140218073792647,
      "loss": 2.1543,
      "step": 15836
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011394109597202029,
      "loss": 2.2168,
      "step": 15837
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011386041141527126,
      "loss": 2.1016,
      "step": 15838
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0001137797537114622,
      "loss": 2.3672,
      "step": 15839
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011369912286303807,
      "loss": 2.4297,
      "step": 15840
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0001136185188724418,
      "loss": 2.3711,
      "step": 15841
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011353794174211584,
      "loss": 2.0371,
      "step": 15842
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011345739147450207,
      "loss": 1.9688,
      "step": 15843
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011337686807204161,
      "loss": 2.1289,
      "step": 15844
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011329637153717454,
      "loss": 2.1328,
      "step": 15845
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011321590187233977,
      "loss": 2.123,
      "step": 15846
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011313545907997614,
      "loss": 1.9707,
      "step": 15847
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011305504316252158,
      "loss": 2.4375,
      "step": 15848
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011297465412241226,
      "loss": 2.0527,
      "step": 15849
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011289429196208501,
      "loss": 2.2344,
      "step": 15850
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011281395668397442,
      "loss": 2.2734,
      "step": 15851
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011273364829051514,
      "loss": 2.293,
      "step": 15852
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011265336678414107,
      "loss": 2.3047,
      "step": 15853
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0001125731121672845,
      "loss": 2.3164,
      "step": 15854
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011249288444237782,
      "loss": 2.2461,
      "step": 15855
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011241268361185197,
      "loss": 2.3047,
      "step": 15856
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011233250967813746,
      "loss": 2.1562,
      "step": 15857
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011225236264366356,
      "loss": 2.1758,
      "step": 15858
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011217224251085911,
      "loss": 2.2656,
      "step": 15859
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011209214928215239,
      "loss": 2.0234,
      "step": 15860
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00011201208295997001,
      "loss": 2.0645,
      "step": 15861
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011193204354673803,
      "loss": 2.3438,
      "step": 15862
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011185203104488273,
      "loss": 2.2266,
      "step": 15863
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011177204545682817,
      "loss": 2.4219,
      "step": 15864
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0001116920867849982,
      "loss": 2.2949,
      "step": 15865
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011161215503181588,
      "loss": 2.3906,
      "step": 15866
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0001115322501997036,
      "loss": 2.2695,
      "step": 15867
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011145237229108262,
      "loss": 2.2656,
      "step": 15868
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011137252130837328,
      "loss": 2.0254,
      "step": 15869
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011129269725399548,
      "loss": 2.3301,
      "step": 15870
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011121290013036844,
      "loss": 2.1953,
      "step": 15871
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011113312993990987,
      "loss": 2.3242,
      "step": 15872
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011105338668503728,
      "loss": 2.1172,
      "step": 15873
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011097367036816697,
      "loss": 2.1797,
      "step": 15874
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011089398099171476,
      "loss": 2.2109,
      "step": 15875
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011081431855809565,
      "loss": 2.1582,
      "step": 15876
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011073468306972345,
      "loss": 2.2969,
      "step": 15877
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011065507452901125,
      "loss": 1.9785,
      "step": 15878
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011057549293837166,
      "loss": 2.2461,
      "step": 15879
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011049593830021642,
      "loss": 2.2734,
      "step": 15880
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011041641061695607,
      "loss": 2.3984,
      "step": 15881
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0001103369098910002,
      "loss": 2.2773,
      "step": 15882
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011025743612475869,
      "loss": 1.9609,
      "step": 15883
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011017798932063949,
      "loss": 2.2695,
      "step": 15884
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011009856948105002,
      "loss": 2.2637,
      "step": 15885
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00011001917660839699,
      "loss": 2.2969,
      "step": 15886
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010993981070508652,
      "loss": 2.2344,
      "step": 15887
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010986047177352321,
      "loss": 2.3438,
      "step": 15888
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010978115981611181,
      "loss": 2.3789,
      "step": 15889
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010970187483525529,
      "loss": 2.2539,
      "step": 15890
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010962261683335661,
      "loss": 2.4141,
      "step": 15891
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010954338581281708,
      "loss": 2.3555,
      "step": 15892
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010946418177603801,
      "loss": 2.3359,
      "step": 15893
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010938500472541968,
      "loss": 2.2227,
      "step": 15894
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010930585466336095,
      "loss": 2.2852,
      "step": 15895
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010922673159226083,
      "loss": 2.2188,
      "step": 15896
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010914763551451656,
      "loss": 2.3438,
      "step": 15897
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010906856643252539,
      "loss": 2.1758,
      "step": 15898
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010898952434868304,
      "loss": 2.0801,
      "step": 15899
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010891050926538515,
      "loss": 2.418,
      "step": 15900
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0001088315211850256,
      "loss": 2.4062,
      "step": 15901
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010875256010999824,
      "loss": 2.1855,
      "step": 15902
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010867362604269615,
      "loss": 2.0449,
      "step": 15903
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0001085947189855111,
      "loss": 2.0938,
      "step": 15904
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0001085158389408336,
      "loss": 2.3008,
      "step": 15905
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010843698591105511,
      "loss": 2.1465,
      "step": 15906
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010835815989856446,
      "loss": 2.2422,
      "step": 15907
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010827936090575019,
      "loss": 2.2734,
      "step": 15908
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010820058893500051,
      "loss": 2.3965,
      "step": 15909
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010812184398870251,
      "loss": 2.2148,
      "step": 15910
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010804312606924238,
      "loss": 2.2578,
      "step": 15911
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010796443517900512,
      "loss": 2.2266,
      "step": 15912
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0001078857713203757,
      "loss": 2.1543,
      "step": 15913
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0001078071344957381,
      "loss": 2.3203,
      "step": 15914
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010772852470747474,
      "loss": 2.2852,
      "step": 15915
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010764994195796818,
      "loss": 2.2422,
      "step": 15916
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010757138624959939,
      "loss": 2.0586,
      "step": 15917
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010749285758474914,
      "loss": 2.166,
      "step": 15918
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010741435596579719,
      "loss": 2.1191,
      "step": 15919
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010733588139512219,
      "loss": 2.0156,
      "step": 15920
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.000107257433875102,
      "loss": 2.0977,
      "step": 15921
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0001071790134081141,
      "loss": 2.2891,
      "step": 15922
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010710061999653498,
      "loss": 2.3281,
      "step": 15923
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010702225364274021,
      "loss": 2.2539,
      "step": 15924
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010694391434910389,
      "loss": 2.3145,
      "step": 15925
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0001068656021180009,
      "loss": 2.2422,
      "step": 15926
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010678731695180399,
      "loss": 2.1602,
      "step": 15927
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010670905885288518,
      "loss": 2.2051,
      "step": 15928
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010663082782361622,
      "loss": 2.3496,
      "step": 15929
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010655262386636789,
      "loss": 2.4609,
      "step": 15930
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010647444698350961,
      "loss": 2.2461,
      "step": 15931
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010639629717741073,
      "loss": 2.1797,
      "step": 15932
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010631817445043956,
      "loss": 2.4023,
      "step": 15933
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010624007880496322,
      "loss": 2.4531,
      "step": 15934
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010616201024334815,
      "loss": 2.3711,
      "step": 15935
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010608396876796034,
      "loss": 2.3145,
      "step": 15936
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010600595438116467,
      "loss": 2.3262,
      "step": 15937
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010592796708532503,
      "loss": 2.0527,
      "step": 15938
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0001058500068828051,
      "loss": 2.3555,
      "step": 15939
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010577207377596687,
      "loss": 2.2031,
      "step": 15940
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010569416776717211,
      "loss": 2.2539,
      "step": 15941
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010561628885878195,
      "loss": 2.1035,
      "step": 15942
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010553843705315614,
      "loss": 2.168,
      "step": 15943
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010546061235265358,
      "loss": 2.1133,
      "step": 15944
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010538281475963285,
      "loss": 2.2578,
      "step": 15945
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010530504427645171,
      "loss": 2.4609,
      "step": 15946
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0001052273009054665,
      "loss": 2.3633,
      "step": 15947
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010514958464903301,
      "loss": 2.3164,
      "step": 15948
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0001050718955095068,
      "loss": 2.3438,
      "step": 15949
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010499423348924186,
      "loss": 2.2988,
      "step": 15950
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010491659859059144,
      "loss": 2.1504,
      "step": 15951
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0001048389908159082,
      "loss": 2.2617,
      "step": 15952
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010476141016754414,
      "loss": 2.418,
      "step": 15953
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010468385664784985,
      "loss": 2.0469,
      "step": 15954
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010460633025917588,
      "loss": 2.1738,
      "step": 15955
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010452883100387112,
      "loss": 2.2031,
      "step": 15956
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010445135888428436,
      "loss": 2.3086,
      "step": 15957
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010437391390276308,
      "loss": 2.2422,
      "step": 15958
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010429649606165426,
      "loss": 2.2227,
      "step": 15959
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010421910536330358,
      "loss": 2.2812,
      "step": 15960
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010414174181005653,
      "loss": 2.2422,
      "step": 15961
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010406440540425766,
      "loss": 2.1934,
      "step": 15962
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010398709614825019,
      "loss": 2.2363,
      "step": 15963
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010390981404437683,
      "loss": 2.0938,
      "step": 15964
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010383255909497957,
      "loss": 2.1152,
      "step": 15965
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010375533130239967,
      "loss": 2.2852,
      "step": 15966
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010367813066897703,
      "loss": 2.2695,
      "step": 15967
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010360095719705131,
      "loss": 1.9648,
      "step": 15968
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010352381088896123,
      "loss": 2.2383,
      "step": 15969
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010344669174704457,
      "loss": 2.1914,
      "step": 15970
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010336959977363758,
      "loss": 2.0293,
      "step": 15971
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010329253497107749,
      "loss": 2.2773,
      "step": 15972
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010321549734169911,
      "loss": 2.3438,
      "step": 15973
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010313848688783666,
      "loss": 2.4258,
      "step": 15974
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010306150361182409,
      "loss": 2.5195,
      "step": 15975
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010298454751599451,
      "loss": 2.1074,
      "step": 15976
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010290761860267962,
      "loss": 2.2422,
      "step": 15977
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010283071687421041,
      "loss": 2.332,
      "step": 15978
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010275384233291762,
      "loss": 2.293,
      "step": 15979
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010267699498113082,
      "loss": 1.9336,
      "step": 15980
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010260017482117834,
      "loss": 2.252,
      "step": 15981
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010252338185538868,
      "loss": 2.0449,
      "step": 15982
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0001024466160860883,
      "loss": 2.0723,
      "step": 15983
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010236987751560378,
      "loss": 2.2891,
      "step": 15984
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010229316614626072,
      "loss": 2.127,
      "step": 15985
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010221648198038347,
      "loss": 2.1582,
      "step": 15986
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010213982502029573,
      "loss": 2.1289,
      "step": 15987
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010206319526832053,
      "loss": 2.1855,
      "step": 15988
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010198659272678035,
      "loss": 2.1797,
      "step": 15989
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010191001739799611,
      "loss": 2.4805,
      "step": 15990
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010183346928428805,
      "loss": 2.0039,
      "step": 15991
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010175694838797656,
      "loss": 2.2773,
      "step": 15992
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0001016804547113801,
      "loss": 2.2344,
      "step": 15993
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010160398825681649,
      "loss": 2.1621,
      "step": 15994
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0001015275490266031,
      "loss": 2.1738,
      "step": 15995
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010145113702305653,
      "loss": 2.3633,
      "step": 15996
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010137475224849179,
      "loss": 2.457,
      "step": 15997
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010129839470522406,
      "loss": 2.1113,
      "step": 15998
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010122206439556691,
      "loss": 2.2344,
      "step": 15999
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010114576132183361,
      "loss": 2.3906,
      "step": 16000
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010106948548633621,
      "loss": 2.2812,
      "step": 16001
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010099323689138617,
      "loss": 2.3438,
      "step": 16002
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010091701553929433,
      "loss": 2.1562,
      "step": 16003
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010084082143237006,
      "loss": 2.4844,
      "step": 16004
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010076465457292261,
      "loss": 2.293,
      "step": 16005
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010068851496325981,
      "loss": 2.2148,
      "step": 16006
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010061240260568927,
      "loss": 2.2734,
      "step": 16007
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010053631750251702,
      "loss": 2.2559,
      "step": 16008
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0001004602596560491,
      "loss": 2.2656,
      "step": 16009
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010038422906858991,
      "loss": 2.2812,
      "step": 16010
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010030822574244369,
      "loss": 2.1992,
      "step": 16011
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010023224967991373,
      "loss": 2.2539,
      "step": 16012
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010015630088330218,
      "loss": 1.9824,
      "step": 16013
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0001000803793549101,
      "loss": 2.3867,
      "step": 16014
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010000448509703908,
      "loss": 2.4414,
      "step": 16015
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.992861811198839e-05,
      "loss": 1.9902,
      "step": 16016
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.985277840205698e-05,
      "loss": 2.1367,
      "step": 16017
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.977696596954311e-05,
      "loss": 2.2852,
      "step": 16018
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.970118081674451e-05,
      "loss": 2.166,
      "step": 16019
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.962542294595722e-05,
      "loss": 2.3203,
      "step": 16020
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.954969235947741e-05,
      "loss": 2.2539,
      "step": 16021
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.947398905959948e-05,
      "loss": 2.0566,
      "step": 16022
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.939831304861791e-05,
      "loss": 2.3203,
      "step": 16023
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.932266432882564e-05,
      "loss": 2.3281,
      "step": 16024
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.924704290251541e-05,
      "loss": 2.2969,
      "step": 16025
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.917144877197825e-05,
      "loss": 2.293,
      "step": 16026
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.909588193950537e-05,
      "loss": 2.2188,
      "step": 16027
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.902034240738666e-05,
      "loss": 2.084,
      "step": 16028
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.894483017791123e-05,
      "loss": 1.9863,
      "step": 16029
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.8869345253367e-05,
      "loss": 2.375,
      "step": 16030
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.879388763604157e-05,
      "loss": 2.25,
      "step": 16031
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.871845732822194e-05,
      "loss": 2.125,
      "step": 16032
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.864305433219334e-05,
      "loss": 2.4414,
      "step": 16033
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.856767865024107e-05,
      "loss": 2.1035,
      "step": 16034
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.849233028464933e-05,
      "loss": 2.1406,
      "step": 16035
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.841700923770114e-05,
      "loss": 2.0898,
      "step": 16036
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.834171551167903e-05,
      "loss": 2.1953,
      "step": 16037
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.826644910886473e-05,
      "loss": 2.3203,
      "step": 16038
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.81912100315392e-05,
      "loss": 2.3359,
      "step": 16039
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.811599828198203e-05,
      "loss": 2.2539,
      "step": 16040
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.804081386247266e-05,
      "loss": 2.4609,
      "step": 16041
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.796565677528956e-05,
      "loss": 2.2188,
      "step": 16042
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.789052702271017e-05,
      "loss": 2.3203,
      "step": 16043
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.781542460701076e-05,
      "loss": 2.3555,
      "step": 16044
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.774034953046762e-05,
      "loss": 2.1934,
      "step": 16045
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.766530179535571e-05,
      "loss": 2.0625,
      "step": 16046
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.759028140394899e-05,
      "loss": 2.2188,
      "step": 16047
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.751528835852119e-05,
      "loss": 2.3789,
      "step": 16048
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.74403226613445e-05,
      "loss": 2.0605,
      "step": 16049
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.736538431469067e-05,
      "loss": 2.3516,
      "step": 16050
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.729047332083096e-05,
      "loss": 2.3789,
      "step": 16051
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.721558968203515e-05,
      "loss": 2.0742,
      "step": 16052
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.714073340057217e-05,
      "loss": 2.1895,
      "step": 16053
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.706590447871078e-05,
      "loss": 2.2031,
      "step": 16054
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.69911029187186e-05,
      "loss": 2.1797,
      "step": 16055
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.691632872286215e-05,
      "loss": 2.1543,
      "step": 16056
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.684158189340708e-05,
      "loss": 2.1836,
      "step": 16057
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.676686243261912e-05,
      "loss": 2.2207,
      "step": 16058
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.669217034276224e-05,
      "loss": 2.0215,
      "step": 16059
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.661750562609961e-05,
      "loss": 2.3203,
      "step": 16060
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.65428682848939e-05,
      "loss": 2.207,
      "step": 16061
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.646825832140726e-05,
      "loss": 2.3125,
      "step": 16062
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.639367573790015e-05,
      "loss": 2.1641,
      "step": 16063
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.631912053663295e-05,
      "loss": 2.3203,
      "step": 16064
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.624459271986463e-05,
      "loss": 2.1445,
      "step": 16065
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.617009228985407e-05,
      "loss": 1.998,
      "step": 16066
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.609561924885835e-05,
      "loss": 2.3281,
      "step": 16067
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.602117359913476e-05,
      "loss": 1.9746,
      "step": 16068
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.594675534293873e-05,
      "loss": 2.2773,
      "step": 16069
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.587236448252579e-05,
      "loss": 2.1152,
      "step": 16070
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.579800102015024e-05,
      "loss": 2.4219,
      "step": 16071
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.57236649580654e-05,
      "loss": 2.2285,
      "step": 16072
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.564935629852368e-05,
      "loss": 2.2441,
      "step": 16073
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.557507504377705e-05,
      "loss": 2.3574,
      "step": 16074
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.550082119607673e-05,
      "loss": 2.3789,
      "step": 16075
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.542659475767246e-05,
      "loss": 2.1719,
      "step": 16076
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.535239573081367e-05,
      "loss": 2.0215,
      "step": 16077
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.527822411774912e-05,
      "loss": 2.2891,
      "step": 16078
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.520407992072621e-05,
      "loss": 2.3047,
      "step": 16079
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.51299631419914e-05,
      "loss": 2.4023,
      "step": 16080
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.505587378379132e-05,
      "loss": 2.1016,
      "step": 16081
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.498181184837096e-05,
      "loss": 2.2324,
      "step": 16082
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.49077773379743e-05,
      "loss": 2.3555,
      "step": 16083
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.483377025484496e-05,
      "loss": 2.3125,
      "step": 16084
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.475979060122586e-05,
      "loss": 2.2148,
      "step": 16085
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.468583837935874e-05,
      "loss": 2.1562,
      "step": 16086
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.461191359148425e-05,
      "loss": 2.3574,
      "step": 16087
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.453801623984281e-05,
      "loss": 2.1641,
      "step": 16088
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.4464146326674e-05,
      "loss": 2.3398,
      "step": 16089
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.439030385421587e-05,
      "loss": 1.9453,
      "step": 16090
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.431648882470644e-05,
      "loss": 2.2344,
      "step": 16091
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.424270124038226e-05,
      "loss": 2.1348,
      "step": 16092
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.41689411034794e-05,
      "loss": 2.1602,
      "step": 16093
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.409520841623331e-05,
      "loss": 2.0781,
      "step": 16094
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.40215031808781e-05,
      "loss": 2.1367,
      "step": 16095
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.394782539964719e-05,
      "loss": 2.2617,
      "step": 16096
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.387417507477337e-05,
      "loss": 2.1836,
      "step": 16097
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.380055220848871e-05,
      "loss": 2.1016,
      "step": 16098
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.37269568030239e-05,
      "loss": 2.3672,
      "step": 16099
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.365338886060892e-05,
      "loss": 2.1934,
      "step": 16100
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.357984838347388e-05,
      "loss": 2.1621,
      "step": 16101
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.350633537384679e-05,
      "loss": 2.0996,
      "step": 16102
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.343284983395517e-05,
      "loss": 2.2617,
      "step": 16103
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.335939176602615e-05,
      "loss": 2.2207,
      "step": 16104
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.328596117228583e-05,
      "loss": 2.3828,
      "step": 16105
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.32125580549592e-05,
      "loss": 2.1523,
      "step": 16106
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.313918241627073e-05,
      "loss": 2.4297,
      "step": 16107
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.306583425844384e-05,
      "loss": 2.0645,
      "step": 16108
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.299251358370143e-05,
      "loss": 2.1719,
      "step": 16109
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.291922039426493e-05,
      "loss": 2.207,
      "step": 16110
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.28459546923559e-05,
      "loss": 2.4453,
      "step": 16111
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.277271648019414e-05,
      "loss": 2.3516,
      "step": 16112
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.269950575999908e-05,
      "loss": 2.1055,
      "step": 16113
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.262632253398939e-05,
      "loss": 2.3555,
      "step": 16114
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.255316680438264e-05,
      "loss": 2.1953,
      "step": 16115
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.248003857339571e-05,
      "loss": 2.2344,
      "step": 16116
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.240693784324472e-05,
      "loss": 2.002,
      "step": 16117
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.23338646161449e-05,
      "loss": 2.25,
      "step": 16118
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.226081889431026e-05,
      "loss": 2.2773,
      "step": 16119
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.218780067995458e-05,
      "loss": 2.0742,
      "step": 16120
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.211480997529065e-05,
      "loss": 2.25,
      "step": 16121
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.204184678253025e-05,
      "loss": 2.0957,
      "step": 16122
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.196891110388405e-05,
      "loss": 2.2969,
      "step": 16123
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.189600294156286e-05,
      "loss": 2.2363,
      "step": 16124
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.182312229777567e-05,
      "loss": 2.2461,
      "step": 16125
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.175026917473095e-05,
      "loss": 2.2715,
      "step": 16126
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.167744357463659e-05,
      "loss": 2.1914,
      "step": 16127
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.160464549969939e-05,
      "loss": 2.1289,
      "step": 16128
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.153187495212523e-05,
      "loss": 2.4062,
      "step": 16129
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.145913193411959e-05,
      "loss": 2.4883,
      "step": 16130
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.138641644788637e-05,
      "loss": 2.1543,
      "step": 16131
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.131372849562958e-05,
      "loss": 2.4375,
      "step": 16132
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.124106807955157e-05,
      "loss": 2.1426,
      "step": 16133
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.116843520185436e-05,
      "loss": 2.293,
      "step": 16134
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.109582986473885e-05,
      "loss": 2.2246,
      "step": 16135
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.102325207040518e-05,
      "loss": 2.2852,
      "step": 16136
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.095070182105303e-05,
      "loss": 2.5352,
      "step": 16137
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.087817911888064e-05,
      "loss": 2.1328,
      "step": 16138
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.080568396608546e-05,
      "loss": 2.2227,
      "step": 16139
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.073321636486465e-05,
      "loss": 2.1914,
      "step": 16140
    },
    {
      "epoch": 1.74,
      "learning_rate": 9.066077631741431e-05,
      "loss": 2.2031,
      "step": 16141
    },
    {
      "epoch": 1.74,
      "learning_rate": 9.058836382592939e-05,
      "loss": 2.2344,
      "step": 16142
    },
    {
      "epoch": 1.74,
      "learning_rate": 9.05159788926042e-05,
      "loss": 2.2031,
      "step": 16143
    },
    {
      "epoch": 1.74,
      "learning_rate": 9.044362151963247e-05,
      "loss": 2.2422,
      "step": 16144
    },
    {
      "epoch": 1.74,
      "learning_rate": 9.037129170920678e-05,
      "loss": 2.1523,
      "step": 16145
    },
    {
      "epoch": 1.74,
      "learning_rate": 9.029898946351867e-05,
      "loss": 2.2402,
      "step": 16146
    },
    {
      "epoch": 1.74,
      "learning_rate": 9.022671478475942e-05,
      "loss": 2.2461,
      "step": 16147
    },
    {
      "epoch": 1.74,
      "learning_rate": 9.015446767511937e-05,
      "loss": 2.1562,
      "step": 16148
    },
    {
      "epoch": 1.74,
      "learning_rate": 9.008224813678745e-05,
      "loss": 2.2969,
      "step": 16149
    },
    {
      "epoch": 1.74,
      "learning_rate": 9.001005617195234e-05,
      "loss": 2.3125,
      "step": 16150
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.993789178280165e-05,
      "loss": 2.0957,
      "step": 16151
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.986575497152239e-05,
      "loss": 2.2773,
      "step": 16152
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.979364574030014e-05,
      "loss": 2.4609,
      "step": 16153
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.972156409132026e-05,
      "loss": 2.3301,
      "step": 16154
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.964951002676725e-05,
      "loss": 2.293,
      "step": 16155
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.957748354882422e-05,
      "loss": 2.168,
      "step": 16156
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.950548465967423e-05,
      "loss": 2.3203,
      "step": 16157
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.943351336149875e-05,
      "loss": 1.9629,
      "step": 16158
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.93615696564788e-05,
      "loss": 2.0859,
      "step": 16159
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.928965354679464e-05,
      "loss": 2.1641,
      "step": 16160
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.921776503462564e-05,
      "loss": 2.1328,
      "step": 16161
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.914590412214984e-05,
      "loss": 2.166,
      "step": 16162
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.907407081154517e-05,
      "loss": 2.0898,
      "step": 16163
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.900226510498843e-05,
      "loss": 2.2812,
      "step": 16164
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.893048700465567e-05,
      "loss": 2.0762,
      "step": 16165
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.885873651272136e-05,
      "loss": 2.3086,
      "step": 16166
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.878701363136077e-05,
      "loss": 2.1055,
      "step": 16167
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.871531836274671e-05,
      "loss": 2.2285,
      "step": 16168
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.864365070905178e-05,
      "loss": 2.4102,
      "step": 16169
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.85720106724478e-05,
      "loss": 2.2539,
      "step": 16170
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.850039825510592e-05,
      "loss": 2.2852,
      "step": 16171
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.842881345919596e-05,
      "loss": 2.2227,
      "step": 16172
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.835725628688751e-05,
      "loss": 2.0234,
      "step": 16173
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.828572674034851e-05,
      "loss": 2.3398,
      "step": 16174
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.821422482174701e-05,
      "loss": 2.3125,
      "step": 16175
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.814275053324938e-05,
      "loss": 2.2188,
      "step": 16176
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.80713038770219e-05,
      "loss": 2.2441,
      "step": 16177
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.799988485522914e-05,
      "loss": 2.1465,
      "step": 16178
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.792849347003562e-05,
      "loss": 2.3535,
      "step": 16179
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.785712972360505e-05,
      "loss": 2.2539,
      "step": 16180
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.778579361809946e-05,
      "loss": 2.0762,
      "step": 16181
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.771448515568081e-05,
      "loss": 2.2793,
      "step": 16182
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.76432043385098e-05,
      "loss": 2.3047,
      "step": 16183
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.757195116874684e-05,
      "loss": 2.0879,
      "step": 16184
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.750072564855071e-05,
      "loss": 2.25,
      "step": 16185
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.742952778007995e-05,
      "loss": 2.2305,
      "step": 16186
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.735835756549238e-05,
      "loss": 2.1035,
      "step": 16187
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.728721500694437e-05,
      "loss": 2.1465,
      "step": 16188
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.721610010659153e-05,
      "loss": 2.25,
      "step": 16189
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.714501286658949e-05,
      "loss": 2.1914,
      "step": 16190
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.707395328909218e-05,
      "loss": 1.9609,
      "step": 16191
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.700292137625266e-05,
      "loss": 2.1582,
      "step": 16192
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.693191713022353e-05,
      "loss": 2.1738,
      "step": 16193
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.686094055315685e-05,
      "loss": 2.2012,
      "step": 16194
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.678999164720303e-05,
      "loss": 2.293,
      "step": 16195
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.671907041451232e-05,
      "loss": 2.1035,
      "step": 16196
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.664817685723348e-05,
      "loss": 2.3887,
      "step": 16197
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.657731097751531e-05,
      "loss": 2.3203,
      "step": 16198
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.650647277750489e-05,
      "loss": 2.1035,
      "step": 16199
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.643566225934907e-05,
      "loss": 2.2656,
      "step": 16200
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.636487942519345e-05,
      "loss": 2.3359,
      "step": 16201
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.62941242771832e-05,
      "loss": 2.0762,
      "step": 16202
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.622339681746238e-05,
      "loss": 2.2812,
      "step": 16203
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.61526970481743e-05,
      "loss": 2.0137,
      "step": 16204
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.608202497146101e-05,
      "loss": 2.1289,
      "step": 16205
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.601138058946457e-05,
      "loss": 2.0195,
      "step": 16206
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.594076390432571e-05,
      "loss": 2.1797,
      "step": 16207
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.587017491818394e-05,
      "loss": 2.2891,
      "step": 16208
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.579961363317868e-05,
      "loss": 2.2383,
      "step": 16209
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.57290800514483e-05,
      "loss": 2.3125,
      "step": 16210
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.565857417513001e-05,
      "loss": 2.1406,
      "step": 16211
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.558809600636008e-05,
      "loss": 2.1191,
      "step": 16212
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.551764554727459e-05,
      "loss": 2.3633,
      "step": 16213
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.54472228000085e-05,
      "loss": 2.2852,
      "step": 16214
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.537682776669552e-05,
      "loss": 2.2148,
      "step": 16215
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.530646044946922e-05,
      "loss": 2.1641,
      "step": 16216
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.523612085046162e-05,
      "loss": 2.2129,
      "step": 16217
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.516580897180448e-05,
      "loss": 2.3164,
      "step": 16218
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.509552481562821e-05,
      "loss": 2.2969,
      "step": 16219
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.502526838406299e-05,
      "loss": 2.0957,
      "step": 16220
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.495503967923757e-05,
      "loss": 2.2539,
      "step": 16221
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.488483870328012e-05,
      "loss": 2.3281,
      "step": 16222
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.481466545831828e-05,
      "loss": 2.1152,
      "step": 16223
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.474451994647825e-05,
      "loss": 2.2656,
      "step": 16224
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.467440216988531e-05,
      "loss": 2.2383,
      "step": 16225
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.4604312130665e-05,
      "loss": 2.1328,
      "step": 16226
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.453424983094105e-05,
      "loss": 2.2266,
      "step": 16227
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.446421527283609e-05,
      "loss": 2.1953,
      "step": 16228
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.43942084584729e-05,
      "loss": 2.0527,
      "step": 16229
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.432422938997297e-05,
      "loss": 2.0371,
      "step": 16230
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.425427806945674e-05,
      "loss": 2.2305,
      "step": 16231
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.418435449904349e-05,
      "loss": 2.0469,
      "step": 16232
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.411445868085299e-05,
      "loss": 2.3164,
      "step": 16233
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.404459061700287e-05,
      "loss": 2.1719,
      "step": 16234
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.397475030961021e-05,
      "loss": 2.0645,
      "step": 16235
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.390493776079167e-05,
      "loss": 2.3867,
      "step": 16236
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.383515297266275e-05,
      "loss": 2.418,
      "step": 16237
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.376539594733801e-05,
      "loss": 2.3594,
      "step": 16238
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.369566668693163e-05,
      "loss": 2.2969,
      "step": 16239
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.362596519355625e-05,
      "loss": 2.1387,
      "step": 16240
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.355629146932442e-05,
      "loss": 2.1152,
      "step": 16241
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.34866455163471e-05,
      "loss": 2.2188,
      "step": 16242
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.341702733673517e-05,
      "loss": 2.4609,
      "step": 16243
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.334743693259794e-05,
      "loss": 2.2793,
      "step": 16244
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.327787430604439e-05,
      "loss": 2.1445,
      "step": 16245
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.320833945918271e-05,
      "loss": 2.25,
      "step": 16246
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.31388323941199e-05,
      "loss": 2.0273,
      "step": 16247
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.306935311296193e-05,
      "loss": 2.2227,
      "step": 16248
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.299990161781445e-05,
      "loss": 2.2383,
      "step": 16249
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.293047791078234e-05,
      "loss": 2.2539,
      "step": 16250
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.286108199396902e-05,
      "loss": 2.3008,
      "step": 16251
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.279171386947747e-05,
      "loss": 1.998,
      "step": 16252
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.272237353941003e-05,
      "loss": 2.2188,
      "step": 16253
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.265306100586778e-05,
      "loss": 2.1953,
      "step": 16254
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.258377627095093e-05,
      "loss": 2.3906,
      "step": 16255
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.251451933675913e-05,
      "loss": 2.2441,
      "step": 16256
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.244529020539148e-05,
      "loss": 2.2031,
      "step": 16257
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.23760888789452e-05,
      "loss": 2.1348,
      "step": 16258
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.230691535951795e-05,
      "loss": 2.2637,
      "step": 16259
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.223776964920527e-05,
      "loss": 2.0684,
      "step": 16260
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.216865175010314e-05,
      "loss": 2.123,
      "step": 16261
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.209956166430555e-05,
      "loss": 1.9668,
      "step": 16262
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.20304993939064e-05,
      "loss": 2.3477,
      "step": 16263
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.196146494099865e-05,
      "loss": 2.3672,
      "step": 16264
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.189245830767388e-05,
      "loss": 2.1719,
      "step": 16265
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.182347949602365e-05,
      "loss": 2.1641,
      "step": 16266
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.175452850813781e-05,
      "loss": 2.248,
      "step": 16267
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.168560534610603e-05,
      "loss": 2.2734,
      "step": 16268
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.161671001201709e-05,
      "loss": 2.1055,
      "step": 16269
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.154784250795855e-05,
      "loss": 2.2812,
      "step": 16270
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.147900283601717e-05,
      "loss": 2.127,
      "step": 16271
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.141019099827906e-05,
      "loss": 2.1699,
      "step": 16272
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.134140699682991e-05,
      "loss": 2.2246,
      "step": 16273
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.127265083375346e-05,
      "loss": 2.1719,
      "step": 16274
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.120392251113351e-05,
      "loss": 2.1133,
      "step": 16275
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.113522203105294e-05,
      "loss": 2.3281,
      "step": 16276
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.106654939559355e-05,
      "loss": 2.248,
      "step": 16277
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.099790460683598e-05,
      "loss": 2.418,
      "step": 16278
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.092928766686058e-05,
      "loss": 2.3125,
      "step": 16279
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.086069857774702e-05,
      "loss": 2.3281,
      "step": 16280
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.079213734157332e-05,
      "loss": 2.3086,
      "step": 16281
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.072360396041745e-05,
      "loss": 2.1934,
      "step": 16282
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.065509843635577e-05,
      "loss": 2.1426,
      "step": 16283
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.058662077146473e-05,
      "loss": 2.3555,
      "step": 16284
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.0518170967819e-05,
      "loss": 2.2559,
      "step": 16285
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.044974902749313e-05,
      "loss": 2.3516,
      "step": 16286
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.038135495256027e-05,
      "loss": 2.0078,
      "step": 16287
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.031298874509319e-05,
      "loss": 2.1602,
      "step": 16288
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.024465040716366e-05,
      "loss": 2.3672,
      "step": 16289
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.01763399408425e-05,
      "loss": 2.2695,
      "step": 16290
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.010805734819925e-05,
      "loss": 2.1367,
      "step": 16291
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.003980263130395e-05,
      "loss": 2.3242,
      "step": 16292
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.997157579222447e-05,
      "loss": 2.3164,
      "step": 16293
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.990337683302817e-05,
      "loss": 2.2773,
      "step": 16294
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.983520575578196e-05,
      "loss": 2.0215,
      "step": 16295
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.976706256255173e-05,
      "loss": 2.293,
      "step": 16296
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.969894725540227e-05,
      "loss": 2.2578,
      "step": 16297
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.963085983639762e-05,
      "loss": 2.209,
      "step": 16298
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.95628003076011e-05,
      "loss": 2.2129,
      "step": 16299
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.949476867107541e-05,
      "loss": 2.2578,
      "step": 16300
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.942676492888168e-05,
      "loss": 2.1836,
      "step": 16301
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.935878908308092e-05,
      "loss": 2.0996,
      "step": 16302
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.929084113573315e-05,
      "loss": 2.1133,
      "step": 16303
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.922292108889706e-05,
      "loss": 2.0117,
      "step": 16304
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.915502894463122e-05,
      "loss": 2.1758,
      "step": 16305
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.908716470499267e-05,
      "loss": 2.1875,
      "step": 16306
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.901932837203818e-05,
      "loss": 2.2812,
      "step": 16307
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.895151994782313e-05,
      "loss": 2.2012,
      "step": 16308
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.888373943440263e-05,
      "loss": 2.2852,
      "step": 16309
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.881598683383029e-05,
      "loss": 2.2227,
      "step": 16310
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.874826214815956e-05,
      "loss": 2.1953,
      "step": 16311
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.868056537944279e-05,
      "loss": 2.3477,
      "step": 16312
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.861289652973124e-05,
      "loss": 2.375,
      "step": 16313
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.854525560107529e-05,
      "loss": 2.3516,
      "step": 16314
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.847764259552504e-05,
      "loss": 2.3398,
      "step": 16315
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.841005751512931e-05,
      "loss": 2.2207,
      "step": 16316
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.834250036193592e-05,
      "loss": 2.1504,
      "step": 16317
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.82749711379922e-05,
      "loss": 2.043,
      "step": 16318
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.820746984534476e-05,
      "loss": 2.3555,
      "step": 16319
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.813999648603887e-05,
      "loss": 2.2812,
      "step": 16320
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.807255106211908e-05,
      "loss": 2.332,
      "step": 16321
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.800513357562933e-05,
      "loss": 2.125,
      "step": 16322
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.793774402861275e-05,
      "loss": 2.2148,
      "step": 16323
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.787038242311128e-05,
      "loss": 2.2578,
      "step": 16324
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.780304876116629e-05,
      "loss": 2.2305,
      "step": 16325
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.7735743044818e-05,
      "loss": 2.3086,
      "step": 16326
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.766846527610638e-05,
      "loss": 2.1914,
      "step": 16327
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.760121545706978e-05,
      "loss": 2.2031,
      "step": 16328
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.753399358974633e-05,
      "loss": 2.1055,
      "step": 16329
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.746679967617298e-05,
      "loss": 2.2539,
      "step": 16330
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.739963371838588e-05,
      "loss": 2.207,
      "step": 16331
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.73324957184206e-05,
      "loss": 2.0879,
      "step": 16332
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.726538567831143e-05,
      "loss": 2.0703,
      "step": 16333
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.719830360009183e-05,
      "loss": 2.4336,
      "step": 16334
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.71312494857952e-05,
      "loss": 2.1367,
      "step": 16335
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.706422333745311e-05,
      "loss": 2.0645,
      "step": 16336
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.699722515709651e-05,
      "loss": 2.1289,
      "step": 16337
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.693025494675598e-05,
      "loss": 2.3047,
      "step": 16338
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.686331270846092e-05,
      "loss": 2.3848,
      "step": 16339
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.679639844423991e-05,
      "loss": 2.2578,
      "step": 16340
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.672951215612012e-05,
      "loss": 2.2422,
      "step": 16341
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.666265384612925e-05,
      "loss": 2.1641,
      "step": 16342
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.659582351629302e-05,
      "loss": 2.3516,
      "step": 16343
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.652902116863635e-05,
      "loss": 2.1289,
      "step": 16344
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.646224680518377e-05,
      "loss": 2.1992,
      "step": 16345
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.639550042795884e-05,
      "loss": 2.166,
      "step": 16346
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.632878203898409e-05,
      "loss": 2.0781,
      "step": 16347
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.626209164028142e-05,
      "loss": 2.2441,
      "step": 16348
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.619542923387147e-05,
      "loss": 2.1641,
      "step": 16349
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.612879482177471e-05,
      "loss": 2.3906,
      "step": 16350
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.606218840601009e-05,
      "loss": 2.2578,
      "step": 16351
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.599560998859622e-05,
      "loss": 2.1465,
      "step": 16352
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.592905957155049e-05,
      "loss": 2.1621,
      "step": 16353
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.586253715688962e-05,
      "loss": 2.1504,
      "step": 16354
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.579604274662955e-05,
      "loss": 2.2148,
      "step": 16355
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.572957634278532e-05,
      "loss": 2.1719,
      "step": 16356
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.566313794737067e-05,
      "loss": 2.1875,
      "step": 16357
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.559672756239943e-05,
      "loss": 2.2637,
      "step": 16358
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.553034518988388e-05,
      "loss": 2.1758,
      "step": 16359
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.546399083183542e-05,
      "loss": 2.2383,
      "step": 16360
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.539766449026497e-05,
      "loss": 2.0117,
      "step": 16361
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.533136616718261e-05,
      "loss": 2.1152,
      "step": 16362
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.526509586459729e-05,
      "loss": 2.1836,
      "step": 16363
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.519885358451684e-05,
      "loss": 2.2578,
      "step": 16364
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.513263932894898e-05,
      "loss": 2.2695,
      "step": 16365
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.506645309990035e-05,
      "loss": 1.9707,
      "step": 16366
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.50002948993762e-05,
      "loss": 2.2031,
      "step": 16367
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.493416472938174e-05,
      "loss": 2.2031,
      "step": 16368
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.486806259192058e-05,
      "loss": 2.2617,
      "step": 16369
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.4801988488996e-05,
      "loss": 2.2109,
      "step": 16370
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.47359424226105e-05,
      "loss": 2.1523,
      "step": 16371
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.466992439476528e-05,
      "loss": 2.1367,
      "step": 16372
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.46039344074606e-05,
      "loss": 2.1191,
      "step": 16373
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.453797246269656e-05,
      "loss": 2.1543,
      "step": 16374
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.447203856247198e-05,
      "loss": 2.0938,
      "step": 16375
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.440613270878471e-05,
      "loss": 2.1113,
      "step": 16376
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.434025490363205e-05,
      "loss": 2.4062,
      "step": 16377
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.427440514901041e-05,
      "loss": 2.2891,
      "step": 16378
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.420858344691516e-05,
      "loss": 2.3398,
      "step": 16379
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.414278979934064e-05,
      "loss": 2.1719,
      "step": 16380
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.4077024208281e-05,
      "loss": 2.1953,
      "step": 16381
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.401128667572898e-05,
      "loss": 2.2871,
      "step": 16382
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.394557720367667e-05,
      "loss": 2.125,
      "step": 16383
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.387989579411514e-05,
      "loss": 2.2617,
      "step": 16384
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.381424244903524e-05,
      "loss": 2.3242,
      "step": 16385
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.374861717042602e-05,
      "loss": 2.2188,
      "step": 16386
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.368301996027605e-05,
      "loss": 2.127,
      "step": 16387
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.361745082057347e-05,
      "loss": 2.3477,
      "step": 16388
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.355190975330517e-05,
      "loss": 2.041,
      "step": 16389
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.34863967604571e-05,
      "loss": 2.123,
      "step": 16390
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.342091184401478e-05,
      "loss": 2.25,
      "step": 16391
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.33554550059623e-05,
      "loss": 2.0293,
      "step": 16392
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.329002624828363e-05,
      "loss": 2.2773,
      "step": 16393
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.322462557296095e-05,
      "loss": 2.1172,
      "step": 16394
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.315925298197667e-05,
      "loss": 2.2578,
      "step": 16395
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.309390847731123e-05,
      "loss": 2.2109,
      "step": 16396
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.302859206094514e-05,
      "loss": 2.3047,
      "step": 16397
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.296330373485782e-05,
      "loss": 2.2461,
      "step": 16398
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.289804350102747e-05,
      "loss": 2.3555,
      "step": 16399
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.283281136143149e-05,
      "loss": 2.0117,
      "step": 16400
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.276760731804721e-05,
      "loss": 2.3086,
      "step": 16401
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.270243137285026e-05,
      "loss": 2.2578,
      "step": 16402
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.26372835278154e-05,
      "loss": 2.3906,
      "step": 16403
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.257216378491705e-05,
      "loss": 2.4375,
      "step": 16404
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.250707214612873e-05,
      "loss": 2.1953,
      "step": 16405
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.244200861342276e-05,
      "loss": 2.2168,
      "step": 16406
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.237697318877067e-05,
      "loss": 2.248,
      "step": 16407
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.231196587414335e-05,
      "loss": 2.3008,
      "step": 16408
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.224698667151086e-05,
      "loss": 2.2148,
      "step": 16409
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.218203558284198e-05,
      "loss": 2.3516,
      "step": 16410
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.211711261010523e-05,
      "loss": 2.0703,
      "step": 16411
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.205221775526794e-05,
      "loss": 2.1328,
      "step": 16412
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.198735102029652e-05,
      "loss": 2.084,
      "step": 16413
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.192251240715675e-05,
      "loss": 2.2969,
      "step": 16414
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.185770191781338e-05,
      "loss": 2.0312,
      "step": 16415
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.179291955423051e-05,
      "loss": 2.3984,
      "step": 16416
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.172816531837101e-05,
      "loss": 2.0781,
      "step": 16417
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.166343921219742e-05,
      "loss": 2.2422,
      "step": 16418
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.159874123767096e-05,
      "loss": 2.2969,
      "step": 16419
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.153407139675217e-05,
      "loss": 2.0605,
      "step": 16420
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.146942969140102e-05,
      "loss": 2.2383,
      "step": 16421
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.14048161235763e-05,
      "loss": 2.3301,
      "step": 16422
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.134023069523565e-05,
      "loss": 2.2969,
      "step": 16423
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.127567340833651e-05,
      "loss": 2.1289,
      "step": 16424
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.121114426483522e-05,
      "loss": 2.2559,
      "step": 16425
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.114664326668707e-05,
      "loss": 2.2539,
      "step": 16426
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.108217041584675e-05,
      "loss": 2.1367,
      "step": 16427
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.101772571426813e-05,
      "loss": 2.3125,
      "step": 16428
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.095330916390397e-05,
      "loss": 2.3477,
      "step": 16429
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.088892076670617e-05,
      "loss": 2.3789,
      "step": 16430
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.082456052462594e-05,
      "loss": 2.3984,
      "step": 16431
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.076022843961383e-05,
      "loss": 2.2852,
      "step": 16432
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.069592451361906e-05,
      "loss": 2.2227,
      "step": 16433
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.063164874859051e-05,
      "loss": 2.1641,
      "step": 16434
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.056740114647565e-05,
      "loss": 2.3789,
      "step": 16435
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.050318170922155e-05,
      "loss": 2.3438,
      "step": 16436
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.043899043877444e-05,
      "loss": 2.2578,
      "step": 16437
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.037482733707934e-05,
      "loss": 2.2695,
      "step": 16438
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.031069240608045e-05,
      "loss": 2.3516,
      "step": 16439
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.024658564772146e-05,
      "loss": 2.2148,
      "step": 16440
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.018250706394514e-05,
      "loss": 2.0527,
      "step": 16441
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.011845665669303e-05,
      "loss": 2.1914,
      "step": 16442
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.005443442790594e-05,
      "loss": 2.0684,
      "step": 16443
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.999044037952451e-05,
      "loss": 2.3086,
      "step": 16444
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.992647451348755e-05,
      "loss": 2.2188,
      "step": 16445
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.986253683173349e-05,
      "loss": 2.1797,
      "step": 16446
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.979862733619979e-05,
      "loss": 2.1211,
      "step": 16447
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.973474602882345e-05,
      "loss": 2.2285,
      "step": 16448
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.967089291153983e-05,
      "loss": 2.3008,
      "step": 16449
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.960706798628414e-05,
      "loss": 2.3145,
      "step": 16450
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.95432712549906e-05,
      "loss": 2.2773,
      "step": 16451
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.947950271959236e-05,
      "loss": 2.3867,
      "step": 16452
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.941576238202153e-05,
      "loss": 2.3555,
      "step": 16453
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.935205024420998e-05,
      "loss": 2.1074,
      "step": 16454
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.928836630808844e-05,
      "loss": 2.4375,
      "step": 16455
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.922471057558644e-05,
      "loss": 2.0762,
      "step": 16456
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.916108304863322e-05,
      "loss": 2.082,
      "step": 16457
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.90974837291567e-05,
      "loss": 2.293,
      "step": 16458
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.903391261908443e-05,
      "loss": 2.1543,
      "step": 16459
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.897036972034254e-05,
      "loss": 2.2246,
      "step": 16460
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.890685503485684e-05,
      "loss": 2.3164,
      "step": 16461
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.884336856455165e-05,
      "loss": 2.1016,
      "step": 16462
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.877991031135123e-05,
      "loss": 2.2109,
      "step": 16463
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.871648027717836e-05,
      "loss": 2.3672,
      "step": 16464
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.865307846395541e-05,
      "loss": 2.207,
      "step": 16465
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.858970487360305e-05,
      "loss": 2.2617,
      "step": 16466
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.852635950804253e-05,
      "loss": 2.1426,
      "step": 16467
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.846304236919299e-05,
      "loss": 2.2656,
      "step": 16468
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.839975345897298e-05,
      "loss": 2.3516,
      "step": 16469
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.833649277930065e-05,
      "loss": 2.2461,
      "step": 16470
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.827326033209303e-05,
      "loss": 2.2773,
      "step": 16471
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.821005611926623e-05,
      "loss": 2.3555,
      "step": 16472
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.814688014273529e-05,
      "loss": 2.1406,
      "step": 16473
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.80837324044149e-05,
      "loss": 2.1016,
      "step": 16474
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.802061290621863e-05,
      "loss": 2.2539,
      "step": 16475
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.795752165005909e-05,
      "loss": 2.125,
      "step": 16476
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.789445863784837e-05,
      "loss": 2.2031,
      "step": 16477
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.78314238714971e-05,
      "loss": 2.5352,
      "step": 16478
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.776841735291584e-05,
      "loss": 2.0078,
      "step": 16479
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.770543908401373e-05,
      "loss": 2.3242,
      "step": 16480
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.764248906669934e-05,
      "loss": 1.9688,
      "step": 16481
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.757956730287995e-05,
      "loss": 2.2539,
      "step": 16482
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.751667379446247e-05,
      "loss": 2.1504,
      "step": 16483
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.745380854335303e-05,
      "loss": 2.2031,
      "step": 16484
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.739097155145635e-05,
      "loss": 2.2422,
      "step": 16485
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.732816282067645e-05,
      "loss": 2.1289,
      "step": 16486
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.726538235291712e-05,
      "loss": 2.2852,
      "step": 16487
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.720263015008055e-05,
      "loss": 2.0684,
      "step": 16488
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.713990621406818e-05,
      "loss": 2.2734,
      "step": 16489
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.707721054678096e-05,
      "loss": 2.1875,
      "step": 16490
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.70145431501189e-05,
      "loss": 2.168,
      "step": 16491
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.695190402598072e-05,
      "loss": 2.3125,
      "step": 16492
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.688929317626468e-05,
      "loss": 2.2891,
      "step": 16493
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.682671060286827e-05,
      "loss": 2.0723,
      "step": 16494
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.676415630768796e-05,
      "loss": 2.0977,
      "step": 16495
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.670163029261889e-05,
      "loss": 2.2344,
      "step": 16496
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.663913255955622e-05,
      "loss": 2.3691,
      "step": 16497
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.65766631103939e-05,
      "loss": 2.1641,
      "step": 16498
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.651422194702472e-05,
      "loss": 2.3867,
      "step": 16499
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.645180907134096e-05,
      "loss": 2.0859,
      "step": 16500
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.638942448523389e-05,
      "loss": 2.1953,
      "step": 16501
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.632706819059408e-05,
      "loss": 2.332,
      "step": 16502
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.626474018931083e-05,
      "loss": 2.0859,
      "step": 16503
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.620244048327328e-05,
      "loss": 2.2812,
      "step": 16504
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.614016907436903e-05,
      "loss": 2.1094,
      "step": 16505
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.607792596448514e-05,
      "loss": 2.2324,
      "step": 16506
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.601571115550808e-05,
      "loss": 2.2539,
      "step": 16507
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.595352464932291e-05,
      "loss": 2.3008,
      "step": 16508
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.58913664478138e-05,
      "loss": 2.1699,
      "step": 16509
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.582923655286488e-05,
      "loss": 2.1914,
      "step": 16510
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.576713496635878e-05,
      "loss": 2.1484,
      "step": 16511
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.570506169017709e-05,
      "loss": 2.4492,
      "step": 16512
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.564301672620099e-05,
      "loss": 2.3906,
      "step": 16513
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.558100007631085e-05,
      "loss": 2.1836,
      "step": 16514
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.551901174238573e-05,
      "loss": 2.2734,
      "step": 16515
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.5457051726304e-05,
      "loss": 2.2188,
      "step": 16516
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.539512002994342e-05,
      "loss": 2.418,
      "step": 16517
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.533321665518088e-05,
      "loss": 2.209,
      "step": 16518
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.527134160389192e-05,
      "loss": 2.1875,
      "step": 16519
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.52094948779518e-05,
      "loss": 2.0547,
      "step": 16520
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.514767647923459e-05,
      "loss": 2.0332,
      "step": 16521
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.508588640961344e-05,
      "loss": 2.3086,
      "step": 16522
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.50241246709612e-05,
      "loss": 2.3008,
      "step": 16523
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.496239126514903e-05,
      "loss": 2.2285,
      "step": 16524
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.490068619404788e-05,
      "loss": 2.25,
      "step": 16525
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.483900945952747e-05,
      "loss": 2.2422,
      "step": 16526
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.477736106345711e-05,
      "loss": 2.2539,
      "step": 16527
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.471574100770461e-05,
      "loss": 2.1992,
      "step": 16528
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.465414929413727e-05,
      "loss": 1.9922,
      "step": 16529
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.45925859246218e-05,
      "loss": 2.1289,
      "step": 16530
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.453105090102373e-05,
      "loss": 2.1191,
      "step": 16531
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.446954422520723e-05,
      "loss": 2.1113,
      "step": 16532
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.440806589903692e-05,
      "loss": 2.1953,
      "step": 16533
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.434661592437552e-05,
      "loss": 2.2402,
      "step": 16534
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.428519430308488e-05,
      "loss": 2.2852,
      "step": 16535
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.422380103702652e-05,
      "loss": 2.418,
      "step": 16536
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.416243612806094e-05,
      "loss": 2.3555,
      "step": 16537
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.410109957804766e-05,
      "loss": 2.1211,
      "step": 16538
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.403979138884508e-05,
      "loss": 2.3438,
      "step": 16539
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.397851156231138e-05,
      "loss": 2.0723,
      "step": 16540
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.391726010030352e-05,
      "loss": 2.1758,
      "step": 16541
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.385603700467735e-05,
      "loss": 2.2461,
      "step": 16542
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.379484227728849e-05,
      "loss": 2.3086,
      "step": 16543
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.373367591999102e-05,
      "loss": 2.293,
      "step": 16544
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.367253793463867e-05,
      "loss": 2.1191,
      "step": 16545
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.361142832308419e-05,
      "loss": 2.1992,
      "step": 16546
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.355034708717932e-05,
      "loss": 2.1172,
      "step": 16547
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.348929422877481e-05,
      "loss": 2.2539,
      "step": 16548
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.342826974972094e-05,
      "loss": 2.3789,
      "step": 16549
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.336727365186712e-05,
      "loss": 2.3594,
      "step": 16550
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.330630593706155e-05,
      "loss": 2.1523,
      "step": 16551
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.324536660715152e-05,
      "loss": 2.0781,
      "step": 16552
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.318445566398423e-05,
      "loss": 2.3125,
      "step": 16553
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.312357310940509e-05,
      "loss": 2.3477,
      "step": 16554
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.306271894525905e-05,
      "loss": 2.3086,
      "step": 16555
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.300189317339034e-05,
      "loss": 2.2891,
      "step": 16556
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.294109579564222e-05,
      "loss": 2.2773,
      "step": 16557
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.288032681385691e-05,
      "loss": 2.2383,
      "step": 16558
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.281958622987604e-05,
      "loss": 2.1523,
      "step": 16559
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.275887404554004e-05,
      "loss": 2.1367,
      "step": 16560
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.269819026268885e-05,
      "loss": 2.1777,
      "step": 16561
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.263753488316126e-05,
      "loss": 2.1504,
      "step": 16562
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.257690790879555e-05,
      "loss": 2.1113,
      "step": 16563
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.251630934142882e-05,
      "loss": 2.1562,
      "step": 16564
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.245573918289715e-05,
      "loss": 2.2949,
      "step": 16565
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.239519743503652e-05,
      "loss": 2.1367,
      "step": 16566
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.233468409968112e-05,
      "loss": 1.9902,
      "step": 16567
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.227419917866494e-05,
      "loss": 2.3281,
      "step": 16568
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.221374267382063e-05,
      "loss": 1.9766,
      "step": 16569
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.215331458698047e-05,
      "loss": 2.2227,
      "step": 16570
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.209291491997538e-05,
      "loss": 2.293,
      "step": 16571
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.203254367463585e-05,
      "loss": 2.3281,
      "step": 16572
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.197220085279143e-05,
      "loss": 2.3711,
      "step": 16573
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.191188645627066e-05,
      "loss": 2.1973,
      "step": 16574
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.185160048690075e-05,
      "loss": 2.1641,
      "step": 16575
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.179134294650934e-05,
      "loss": 2.3047,
      "step": 16576
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.173111383692209e-05,
      "loss": 2.1602,
      "step": 16577
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.167091315996387e-05,
      "loss": 2.3789,
      "step": 16578
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.161074091745933e-05,
      "loss": 2.3262,
      "step": 16579
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.15505971112319e-05,
      "loss": 2.3555,
      "step": 16580
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.149048174310401e-05,
      "loss": 2.3711,
      "step": 16581
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.14303948148971e-05,
      "loss": 2.3691,
      "step": 16582
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.137033632843237e-05,
      "loss": 2.3867,
      "step": 16583
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.131030628552981e-05,
      "loss": 2.0684,
      "step": 16584
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.125030468800818e-05,
      "loss": 2.3398,
      "step": 16585
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.119033153768605e-05,
      "loss": 2.1289,
      "step": 16586
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.113038683638062e-05,
      "loss": 2.2324,
      "step": 16587
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.107047058590843e-05,
      "loss": 2.2344,
      "step": 16588
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.1010582788085355e-05,
      "loss": 2.0625,
      "step": 16589
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.0950723444725964e-05,
      "loss": 2.1211,
      "step": 16590
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.089089255764424e-05,
      "loss": 2.3477,
      "step": 16591
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.083109012865318e-05,
      "loss": 2.3867,
      "step": 16592
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.0771316159565214e-05,
      "loss": 2.1641,
      "step": 16593
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.071157065219157e-05,
      "loss": 2.293,
      "step": 16594
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.0651853608342355e-05,
      "loss": 2.2383,
      "step": 16595
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.0592165029828004e-05,
      "loss": 2.3789,
      "step": 16596
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.0532504918456745e-05,
      "loss": 2.3867,
      "step": 16597
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.047287327603634e-05,
      "loss": 2.1367,
      "step": 16598
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.041327010437414e-05,
      "loss": 2.3125,
      "step": 16599
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.0353695405276355e-05,
      "loss": 2.25,
      "step": 16600
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.029414918054798e-05,
      "loss": 2.2734,
      "step": 16601
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.023463143199359e-05,
      "loss": 2.3516,
      "step": 16602
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.0175142161417064e-05,
      "loss": 2.1543,
      "step": 16603
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.0115681370620844e-05,
      "loss": 2.2773,
      "step": 16604
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.005624906140672e-05,
      "loss": 1.9551,
      "step": 16605
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.999684523557569e-05,
      "loss": 2.0664,
      "step": 16606
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.993746989492821e-05,
      "loss": 2.1016,
      "step": 16607
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.9878123041263164e-05,
      "loss": 2.1445,
      "step": 16608
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.9818804676379235e-05,
      "loss": 2.3516,
      "step": 16609
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.9759514802073646e-05,
      "loss": 2.1973,
      "step": 16610
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.970025342014329e-05,
      "loss": 2.2422,
      "step": 16611
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.9641020532384184e-05,
      "loss": 2.127,
      "step": 16612
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.958181614059099e-05,
      "loss": 2.4141,
      "step": 16613
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.952264024655773e-05,
      "loss": 2.125,
      "step": 16614
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.946349285207775e-05,
      "loss": 2.4062,
      "step": 16615
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.940437395894349e-05,
      "loss": 2.0234,
      "step": 16616
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.934528356894653e-05,
      "loss": 2.0625,
      "step": 16617
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.9286221683876986e-05,
      "loss": 2.3203,
      "step": 16618
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.9227188305525314e-05,
      "loss": 2.2207,
      "step": 16619
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.9168183435679976e-05,
      "loss": 2.2734,
      "step": 16620
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.9109207076129104e-05,
      "loss": 2.0684,
      "step": 16621
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.905025922865992e-05,
      "loss": 2.2812,
      "step": 16622
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.899133989505878e-05,
      "loss": 2.2734,
      "step": 16623
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.893244907711104e-05,
      "loss": 2.4336,
      "step": 16624
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.887358677660137e-05,
      "loss": 2.2734,
      "step": 16625
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.8814752995313356e-05,
      "loss": 2.2969,
      "step": 16626
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.875594773503001e-05,
      "loss": 2.1562,
      "step": 16627
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.8697170997533133e-05,
      "loss": 2.0527,
      "step": 16628
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.8638422784604184e-05,
      "loss": 2.1797,
      "step": 16629
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.857970309802308e-05,
      "loss": 2.25,
      "step": 16630
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.852101193956927e-05,
      "loss": 2.3867,
      "step": 16631
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.8462349311021565e-05,
      "loss": 2.2578,
      "step": 16632
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.840371521415744e-05,
      "loss": 2.2363,
      "step": 16633
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.834510965075357e-05,
      "loss": 2.3105,
      "step": 16634
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.828653262258599e-05,
      "loss": 2.4141,
      "step": 16635
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.8227984131430045e-05,
      "loss": 2.248,
      "step": 16636
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.816946417905955e-05,
      "loss": 2.1387,
      "step": 16637
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.811097276724797e-05,
      "loss": 2.2148,
      "step": 16638
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.805250989776811e-05,
      "loss": 2.0312,
      "step": 16639
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.799407557239123e-05,
      "loss": 2.1465,
      "step": 16640
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.793566979288789e-05,
      "loss": 2.3984,
      "step": 16641
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.787729256102858e-05,
      "loss": 2.3809,
      "step": 16642
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.781894387858189e-05,
      "loss": 2.1875,
      "step": 16643
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.7760623747316055e-05,
      "loss": 2.082,
      "step": 16644
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.770233216899834e-05,
      "loss": 2.0996,
      "step": 16645
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.7644069145395436e-05,
      "loss": 2.2109,
      "step": 16646
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.758583467827261e-05,
      "loss": 2.2754,
      "step": 16647
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.752762876939455e-05,
      "loss": 2.2461,
      "step": 16648
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.7469451420525175e-05,
      "loss": 2.2773,
      "step": 16649
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.741130263342764e-05,
      "loss": 2.1797,
      "step": 16650
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.735318240986365e-05,
      "loss": 2.2734,
      "step": 16651
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.729509075159489e-05,
      "loss": 2.3594,
      "step": 16652
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.723702766038119e-05,
      "loss": 2.2852,
      "step": 16653
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.717899313798247e-05,
      "loss": 2.3047,
      "step": 16654
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.7120987186157325e-05,
      "loss": 2.2539,
      "step": 16655
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.7063009806663456e-05,
      "loss": 2.1406,
      "step": 16656
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.700506100125768e-05,
      "loss": 2.084,
      "step": 16657
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.6947140771696046e-05,
      "loss": 2.0801,
      "step": 16658
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.6889249119734034e-05,
      "loss": 2.1914,
      "step": 16659
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.683138604712557e-05,
      "loss": 2.2188,
      "step": 16660
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.677355155562403e-05,
      "loss": 2.2129,
      "step": 16661
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.6715745646982454e-05,
      "loss": 2.2617,
      "step": 16662
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.6657968322952336e-05,
      "loss": 2.3555,
      "step": 16663
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.6600219585284275e-05,
      "loss": 2.1719,
      "step": 16664
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.6542499435728534e-05,
      "loss": 2.1914,
      "step": 16665
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.648480787603416e-05,
      "loss": 2.207,
      "step": 16666
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.6427144907949315e-05,
      "loss": 2.1172,
      "step": 16667
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.636951053322159e-05,
      "loss": 2.3789,
      "step": 16668
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.631190475359715e-05,
      "loss": 2.1836,
      "step": 16669
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.625432757082205e-05,
      "loss": 2.2422,
      "step": 16670
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.6196778986640664e-05,
      "loss": 2.0703,
      "step": 16671
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.613925900279704e-05,
      "loss": 2.0918,
      "step": 16672
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.608176762103445e-05,
      "loss": 2.2852,
      "step": 16673
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.602430484309484e-05,
      "loss": 2.1523,
      "step": 16674
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.5966870670719596e-05,
      "loss": 2.127,
      "step": 16675
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.590946510564909e-05,
      "loss": 2.4531,
      "step": 16676
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.585208814962295e-05,
      "loss": 2.3125,
      "step": 16677
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.579473980437988e-05,
      "loss": 2.1797,
      "step": 16678
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.573742007165783e-05,
      "loss": 2.3984,
      "step": 16679
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.5680128953193524e-05,
      "loss": 2.1113,
      "step": 16680
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.562286645072323e-05,
      "loss": 2.1836,
      "step": 16681
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.556563256598224e-05,
      "loss": 2.1992,
      "step": 16682
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.5508427300704935e-05,
      "loss": 2.0508,
      "step": 16683
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.5451250656624486e-05,
      "loss": 2.0977,
      "step": 16684
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.5394102635474174e-05,
      "loss": 2.3945,
      "step": 16685
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.533698323898529e-05,
      "loss": 2.2266,
      "step": 16686
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.527989246888876e-05,
      "loss": 2.2852,
      "step": 16687
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.522283032691466e-05,
      "loss": 2.2637,
      "step": 16688
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.516579681479239e-05,
      "loss": 2.2383,
      "step": 16689
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.510879193424989e-05,
      "loss": 2.1445,
      "step": 16690
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.505181568701501e-05,
      "loss": 2.2012,
      "step": 16691
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.499486807481391e-05,
      "loss": 2.3203,
      "step": 16692
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.493794909937255e-05,
      "loss": 2.1289,
      "step": 16693
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.488105876241556e-05,
      "loss": 2.1738,
      "step": 16694
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.482419706566721e-05,
      "loss": 2.2305,
      "step": 16695
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.476736401085025e-05,
      "loss": 2.3672,
      "step": 16696
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.4710559599687074e-05,
      "loss": 2.2617,
      "step": 16697
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.465378383389918e-05,
      "loss": 2.1133,
      "step": 16698
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.459703671520699e-05,
      "loss": 2.3906,
      "step": 16699
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.454031824532979e-05,
      "loss": 2.2734,
      "step": 16700
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.448362842598664e-05,
      "loss": 2.0898,
      "step": 16701
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.442696725889562e-05,
      "loss": 2.0859,
      "step": 16702
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.4370334745773245e-05,
      "loss": 2.3398,
      "step": 16703
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.431373088833602e-05,
      "loss": 2.0781,
      "step": 16704
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.4257155688299254e-05,
      "loss": 2.0625,
      "step": 16705
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.4200609147377345e-05,
      "loss": 2.3555,
      "step": 16706
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.414409126728348e-05,
      "loss": 2.1387,
      "step": 16707
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.408760204973073e-05,
      "loss": 2.2969,
      "step": 16708
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.403114149643085e-05,
      "loss": 2.252,
      "step": 16709
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.397470960909456e-05,
      "loss": 2.2578,
      "step": 16710
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.391830638943207e-05,
      "loss": 2.4297,
      "step": 16711
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.386193183915278e-05,
      "loss": 2.4023,
      "step": 16712
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.380558595996487e-05,
      "loss": 2.3672,
      "step": 16713
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.3749268753575557e-05,
      "loss": 2.2148,
      "step": 16714
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.3692980221691664e-05,
      "loss": 2.2539,
      "step": 16715
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.363672036601907e-05,
      "loss": 2.1133,
      "step": 16716
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.3580489188262305e-05,
      "loss": 2.0664,
      "step": 16717
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.3524286690125766e-05,
      "loss": 2.3828,
      "step": 16718
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.34681128733121e-05,
      "loss": 2.3906,
      "step": 16719
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.341196773952372e-05,
      "loss": 2.2305,
      "step": 16720
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.3355851290462385e-05,
      "loss": 2.334,
      "step": 16721
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.3299763527828174e-05,
      "loss": 2.0605,
      "step": 16722
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.324370445332083e-05,
      "loss": 2.3438,
      "step": 16723
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.3187674068639004e-05,
      "loss": 2.2227,
      "step": 16724
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.3131672375481e-05,
      "loss": 2.332,
      "step": 16725
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.307569937554357e-05,
      "loss": 2.2188,
      "step": 16726
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.30197550705227e-05,
      "loss": 2.0254,
      "step": 16727
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.296383946211414e-05,
      "loss": 2.2754,
      "step": 16728
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.290795255201208e-05,
      "loss": 2.2227,
      "step": 16729
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.285209434190985e-05,
      "loss": 2.1406,
      "step": 16730
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.279626483350053e-05,
      "loss": 2.0684,
      "step": 16731
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.2740464028475766e-05,
      "loss": 2.3438,
      "step": 16732
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.268469192852643e-05,
      "loss": 2.4258,
      "step": 16733
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.262894853534283e-05,
      "loss": 2.293,
      "step": 16734
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.2573233850613854e-05,
      "loss": 2.1719,
      "step": 16735
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.251754787602814e-05,
      "loss": 2.0742,
      "step": 16736
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.2461890613272887e-05,
      "loss": 2.1543,
      "step": 16737
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.240626206403498e-05,
      "loss": 2.0293,
      "step": 16738
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.2350662229999846e-05,
      "loss": 2.1504,
      "step": 16739
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.229509111285258e-05,
      "loss": 2.3203,
      "step": 16740
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.223954871427716e-05,
      "loss": 2.252,
      "step": 16741
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.218403503595659e-05,
      "loss": 2.1738,
      "step": 16742
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.2128550079573064e-05,
      "loss": 2.4219,
      "step": 16743
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.207309384680803e-05,
      "loss": 2.1348,
      "step": 16744
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.201766633934213e-05,
      "loss": 2.3477,
      "step": 16745
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.196226755885469e-05,
      "loss": 2.1055,
      "step": 16746
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.190689750702482e-05,
      "loss": 2.2891,
      "step": 16747
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.185155618553028e-05,
      "loss": 2.2227,
      "step": 16748
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.179624359604807e-05,
      "loss": 2.0703,
      "step": 16749
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.174095974025417e-05,
      "loss": 2.1465,
      "step": 16750
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.168570461982425e-05,
      "loss": 2.3672,
      "step": 16751
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.163047823643252e-05,
      "loss": 2.1699,
      "step": 16752
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.1575280591752314e-05,
      "loss": 2.332,
      "step": 16753
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.152011168745663e-05,
      "loss": 2.1992,
      "step": 16754
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.146497152521723e-05,
      "loss": 2.2188,
      "step": 16755
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.1409860106704895e-05,
      "loss": 2.0234,
      "step": 16756
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.135477743358963e-05,
      "loss": 2.0605,
      "step": 16757
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.1299723507540755e-05,
      "loss": 2.2539,
      "step": 16758
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.1244698330226605e-05,
      "loss": 2.1309,
      "step": 16759
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.118970190331451e-05,
      "loss": 2.1484,
      "step": 16760
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.113473422847126e-05,
      "loss": 2.1426,
      "step": 16761
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.107979530736229e-05,
      "loss": 2.123,
      "step": 16762
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.102488514165249e-05,
      "loss": 2.3359,
      "step": 16763
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.097000373300598e-05,
      "loss": 2.0703,
      "step": 16764
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.0915151083085756e-05,
      "loss": 2.2656,
      "step": 16765
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.086032719355393e-05,
      "loss": 2.3789,
      "step": 16766
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.0805532066071966e-05,
      "loss": 2.125,
      "step": 16767
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.0750765702300305e-05,
      "loss": 2.2598,
      "step": 16768
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.0696028103898505e-05,
      "loss": 2.2812,
      "step": 16769
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.0641319272525354e-05,
      "loss": 2.1445,
      "step": 16770
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.0586639209838746e-05,
      "loss": 2.3203,
      "step": 16771
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.0531987917495695e-05,
      "loss": 2.1328,
      "step": 16772
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.047736539715209e-05,
      "loss": 2.041,
      "step": 16773
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.042277165046327e-05,
      "loss": 2.1934,
      "step": 16774
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.036820667908382e-05,
      "loss": 2.0566,
      "step": 16775
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.031367048466684e-05,
      "loss": 2.332,
      "step": 16776
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.0259163068865466e-05,
      "loss": 2.2031,
      "step": 16777
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.020468443333093e-05,
      "loss": 2.0723,
      "step": 16778
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.015023457971446e-05,
      "loss": 2.3555,
      "step": 16779
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.0095813509665855e-05,
      "loss": 2.1738,
      "step": 16780
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.004142122483457e-05,
      "loss": 2.1523,
      "step": 16781
    },
    {
      "epoch": 1.8,
      "learning_rate": 4.99870577268684e-05,
      "loss": 2.2031,
      "step": 16782
    },
    {
      "epoch": 1.8,
      "learning_rate": 4.993272301741514e-05,
      "loss": 2.2949,
      "step": 16783
    },
    {
      "epoch": 1.8,
      "learning_rate": 4.987841709812113e-05,
      "loss": 2.3594,
      "step": 16784
    },
    {
      "epoch": 1.8,
      "learning_rate": 4.9824139970632066e-05,
      "loss": 2.3164,
      "step": 16785
    },
    {
      "epoch": 1.8,
      "learning_rate": 4.976989163659262e-05,
      "loss": 2.1562,
      "step": 16786
    },
    {
      "epoch": 1.8,
      "learning_rate": 4.971567209764693e-05,
      "loss": 2.252,
      "step": 16787
    },
    {
      "epoch": 1.8,
      "learning_rate": 4.966148135543791e-05,
      "loss": 2.1621,
      "step": 16788
    },
    {
      "epoch": 1.8,
      "learning_rate": 4.9607319411607455e-05,
      "loss": 2.2969,
      "step": 16789
    },
    {
      "epoch": 1.8,
      "learning_rate": 4.9553186267797144e-05,
      "loss": 2.2383,
      "step": 16790
    },
    {
      "epoch": 1.8,
      "learning_rate": 4.949908192564756e-05,
      "loss": 2.4648,
      "step": 16791
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.944500638679783e-05,
      "loss": 2.3203,
      "step": 16792
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.939095965288665e-05,
      "loss": 2.0859,
      "step": 16793
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.933694172555225e-05,
      "loss": 2.2031,
      "step": 16794
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.928295260643112e-05,
      "loss": 2.2148,
      "step": 16795
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.922899229715949e-05,
      "loss": 2.3242,
      "step": 16796
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.9175060799372396e-05,
      "loss": 2.2129,
      "step": 16797
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.9121158114704414e-05,
      "loss": 2.2734,
      "step": 16798
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.906728424478857e-05,
      "loss": 2.1602,
      "step": 16799
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.901343919125789e-05,
      "loss": 2.3125,
      "step": 16800
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.8959622955743634e-05,
      "loss": 2.1816,
      "step": 16801
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.890583553987693e-05,
      "loss": 2.2188,
      "step": 16802
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.8852076945287374e-05,
      "loss": 2.0586,
      "step": 16803
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.879834717360443e-05,
      "loss": 2.2773,
      "step": 16804
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.874464622645591e-05,
      "loss": 2.1934,
      "step": 16805
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.869097410546941e-05,
      "loss": 2.375,
      "step": 16806
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.863733081227128e-05,
      "loss": 2.0254,
      "step": 16807
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.8583716348487126e-05,
      "loss": 2.2656,
      "step": 16808
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.853013071574142e-05,
      "loss": 2.2461,
      "step": 16809
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.847657391565818e-05,
      "loss": 2.2031,
      "step": 16810
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.842304594986047e-05,
      "loss": 2.1719,
      "step": 16811
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.836954681997008e-05,
      "loss": 2.2344,
      "step": 16812
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.8316076527608275e-05,
      "loss": 2.1426,
      "step": 16813
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.826263507439565e-05,
      "loss": 2.0234,
      "step": 16814
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.8209222461951474e-05,
      "loss": 2.3125,
      "step": 16815
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.815583869189411e-05,
      "loss": 2.1641,
      "step": 16816
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.8102483765841474e-05,
      "loss": 2.0996,
      "step": 16817
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.804915768541052e-05,
      "loss": 1.8906,
      "step": 16818
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.799586045221704e-05,
      "loss": 2.3828,
      "step": 16819
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.794259206787599e-05,
      "loss": 2.4219,
      "step": 16820
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.788935253400195e-05,
      "loss": 2.1738,
      "step": 16821
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.783614185220797e-05,
      "loss": 2.2344,
      "step": 16822
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.7782960024106534e-05,
      "loss": 2.1523,
      "step": 16823
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.772980705130914e-05,
      "loss": 2.2539,
      "step": 16824
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.767668293542682e-05,
      "loss": 2.0742,
      "step": 16825
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.762358767806907e-05,
      "loss": 2.2188,
      "step": 16826
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.757052128084505e-05,
      "loss": 2.0137,
      "step": 16827
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.75174837453628e-05,
      "loss": 2.2266,
      "step": 16828
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.746447507322938e-05,
      "loss": 2.1641,
      "step": 16829
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.741149526605149e-05,
      "loss": 2.2734,
      "step": 16830
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.735854432543429e-05,
      "loss": 2.2695,
      "step": 16831
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.73056222529823e-05,
      "loss": 2.1973,
      "step": 16832
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.725272905029943e-05,
      "loss": 2.1406,
      "step": 16833
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.719986471898863e-05,
      "loss": 2.5078,
      "step": 16834
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.714702926065162e-05,
      "loss": 2.1445,
      "step": 16835
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.7094222676889345e-05,
      "loss": 2.2773,
      "step": 16836
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.704144496930251e-05,
      "loss": 1.9531,
      "step": 16837
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.6988696139490086e-05,
      "loss": 2.3379,
      "step": 16838
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.6935976189050544e-05,
      "loss": 2.3438,
      "step": 16839
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.688328511958162e-05,
      "loss": 2.168,
      "step": 16840
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.683062293268003e-05,
      "loss": 2.2695,
      "step": 16841
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.677798962994151e-05,
      "loss": 2.1836,
      "step": 16842
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.67253852129611e-05,
      "loss": 2.1055,
      "step": 16843
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.667280968333265e-05,
      "loss": 2.2148,
      "step": 16844
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.662026304264988e-05,
      "loss": 2.2363,
      "step": 16845
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.656774529250451e-05,
      "loss": 2.3125,
      "step": 16846
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.651525643448851e-05,
      "loss": 2.1758,
      "step": 16847
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.646279647019214e-05,
      "loss": 2.3594,
      "step": 16848
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.6410365401205134e-05,
      "loss": 2.3262,
      "step": 16849
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.635796322911667e-05,
      "loss": 2.418,
      "step": 16850
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.630558995551437e-05,
      "loss": 2.2148,
      "step": 16851
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.625324558198518e-05,
      "loss": 2.2305,
      "step": 16852
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.620093011011572e-05,
      "loss": 2.4609,
      "step": 16853
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.614864354149117e-05,
      "loss": 2.1191,
      "step": 16854
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.6096385877695825e-05,
      "loss": 2.3828,
      "step": 16855
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.6044157120313405e-05,
      "loss": 2.1543,
      "step": 16856
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.5991957270926644e-05,
      "loss": 2.2109,
      "step": 16857
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.5939786331117395e-05,
      "loss": 2.3555,
      "step": 16858
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.5887644302466166e-05,
      "loss": 2.0781,
      "step": 16859
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.5835531186553704e-05,
      "loss": 2.3652,
      "step": 16860
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.578344698495895e-05,
      "loss": 2.3047,
      "step": 16861
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.5731391699259995e-05,
      "loss": 2.1738,
      "step": 16862
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.567936533103445e-05,
      "loss": 2.2188,
      "step": 16863
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.562736788185906e-05,
      "loss": 2.332,
      "step": 16864
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.557539935330912e-05,
      "loss": 2.0996,
      "step": 16865
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.552345974695993e-05,
      "loss": 2.5195,
      "step": 16866
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.5471549064385e-05,
      "loss": 2.2773,
      "step": 16867
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.541966730715774e-05,
      "loss": 2.4297,
      "step": 16868
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.536781447685001e-05,
      "loss": 2.2656,
      "step": 16869
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.531599057503344e-05,
      "loss": 2.4883,
      "step": 16870
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.5264195603278216e-05,
      "loss": 2.332,
      "step": 16871
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.521242956315397e-05,
      "loss": 2.0059,
      "step": 16872
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.516069245622945e-05,
      "loss": 2.1172,
      "step": 16873
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.510898428407251e-05,
      "loss": 2.3203,
      "step": 16874
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.505730504824979e-05,
      "loss": 2.1953,
      "step": 16875
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.5005654750327585e-05,
      "loss": 2.2012,
      "step": 16876
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.49540333918711e-05,
      "loss": 2.1309,
      "step": 16877
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.4902440974444404e-05,
      "loss": 2.1465,
      "step": 16878
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.485087749961114e-05,
      "loss": 2.0098,
      "step": 16879
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.479934296893384e-05,
      "loss": 2.3086,
      "step": 16880
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.474783738397414e-05,
      "loss": 2.2344,
      "step": 16881
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.469636074629257e-05,
      "loss": 2.3789,
      "step": 16882
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.464491305744933e-05,
      "loss": 2.0977,
      "step": 16883
    },
    {
      "epoch": 1.81,
      "learning_rate": 4.4593494319003615e-05,
      "loss": 2.0762,
      "step": 16884
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.454210453251306e-05,
      "loss": 2.2539,
      "step": 16885
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.449074369953543e-05,
      "loss": 2.3906,
      "step": 16886
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.443941182162681e-05,
      "loss": 2.3594,
      "step": 16887
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.438810890034295e-05,
      "loss": 2.1602,
      "step": 16888
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.433683493723828e-05,
      "loss": 2.1758,
      "step": 16889
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.428558993386678e-05,
      "loss": 2.2422,
      "step": 16890
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.4234373891781085e-05,
      "loss": 2.25,
      "step": 16891
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.418318681253353e-05,
      "loss": 2.1719,
      "step": 16892
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.413202869767507e-05,
      "loss": 2.1152,
      "step": 16893
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.4080899548756045e-05,
      "loss": 2.2109,
      "step": 16894
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.4029799367325426e-05,
      "loss": 2.1328,
      "step": 16895
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.3978728154932426e-05,
      "loss": 2.3203,
      "step": 16896
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.392768591312435e-05,
      "loss": 2.2617,
      "step": 16897
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.387667264344763e-05,
      "loss": 2.3086,
      "step": 16898
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.382568834744849e-05,
      "loss": 2.2266,
      "step": 16899
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.377473302667201e-05,
      "loss": 2.3984,
      "step": 16900
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.372380668266207e-05,
      "loss": 2.4688,
      "step": 16901
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.367290931696177e-05,
      "loss": 2.0723,
      "step": 16902
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.362204093111388e-05,
      "loss": 2.2227,
      "step": 16903
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.357120152665972e-05,
      "loss": 2.3359,
      "step": 16904
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.3520391105139726e-05,
      "loss": 2.1816,
      "step": 16905
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.346960966809366e-05,
      "loss": 2.1328,
      "step": 16906
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.3418857217060623e-05,
      "loss": 2.2578,
      "step": 16907
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.336813375357829e-05,
      "loss": 2.127,
      "step": 16908
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.331743927918397e-05,
      "loss": 2.375,
      "step": 16909
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.326677379541355e-05,
      "loss": 1.9902,
      "step": 16910
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.32161373038028e-05,
      "loss": 2.3242,
      "step": 16911
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.316552980588573e-05,
      "loss": 2.2617,
      "step": 16912
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.311495130319631e-05,
      "loss": 2.043,
      "step": 16913
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.306440179726689e-05,
      "loss": 2.375,
      "step": 16914
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.3013881289629465e-05,
      "loss": 2.1035,
      "step": 16915
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.296338978181513e-05,
      "loss": 2.3164,
      "step": 16916
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.2912927275353675e-05,
      "loss": 2.2344,
      "step": 16917
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.286249377177431e-05,
      "loss": 2.2012,
      "step": 16918
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.2812089272605383e-05,
      "loss": 2.2891,
      "step": 16919
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.276171377937443e-05,
      "loss": 2.2188,
      "step": 16920
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.2711367293607805e-05,
      "loss": 2.2031,
      "step": 16921
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.2661049816831274e-05,
      "loss": 2.1055,
      "step": 16922
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.261076135056974e-05,
      "loss": 2.1699,
      "step": 16923
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.256050189634697e-05,
      "loss": 2.1758,
      "step": 16924
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.251027145568587e-05,
      "loss": 2.3086,
      "step": 16925
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.2460070030108655e-05,
      "loss": 2.2793,
      "step": 16926
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.240989762113678e-05,
      "loss": 2.3281,
      "step": 16927
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.235975423029048e-05,
      "loss": 2.1406,
      "step": 16928
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.230963985908931e-05,
      "loss": 2.1074,
      "step": 16929
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.225955450905183e-05,
      "loss": 2.2148,
      "step": 16930
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.220949818169595e-05,
      "loss": 2.0898,
      "step": 16931
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.215947087853833e-05,
      "loss": 2.2422,
      "step": 16932
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.21094726010951e-05,
      "loss": 2.2617,
      "step": 16933
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.205950335088138e-05,
      "loss": 2.1953,
      "step": 16934
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.200956312941129e-05,
      "loss": 2.1875,
      "step": 16935
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.195965193819829e-05,
      "loss": 2.1074,
      "step": 16936
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.1909769778754826e-05,
      "loss": 2.2852,
      "step": 16937
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.1859916652592366e-05,
      "loss": 2.2969,
      "step": 16938
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.1810092561221926e-05,
      "loss": 2.1191,
      "step": 16939
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.1760297506153176e-05,
      "loss": 2.0898,
      "step": 16940
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.171053148889481e-05,
      "loss": 2.125,
      "step": 16941
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.166079451095528e-05,
      "loss": 2.125,
      "step": 16942
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.1611086573841715e-05,
      "loss": 2.1895,
      "step": 16943
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.156140767906014e-05,
      "loss": 2.209,
      "step": 16944
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.151175782811634e-05,
      "loss": 2.1133,
      "step": 16945
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.146213702251478e-05,
      "loss": 2.1035,
      "step": 16946
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.141254526375904e-05,
      "loss": 2.293,
      "step": 16947
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.1362982553351914e-05,
      "loss": 2.4062,
      "step": 16948
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.131344889279531e-05,
      "loss": 2.3438,
      "step": 16949
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.126394428359037e-05,
      "loss": 2.125,
      "step": 16950
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.121446872723711e-05,
      "loss": 2.2109,
      "step": 16951
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.1165022225235104e-05,
      "loss": 2.2676,
      "step": 16952
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.111560477908227e-05,
      "loss": 2.4648,
      "step": 16953
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.106621639027652e-05,
      "loss": 2.0918,
      "step": 16954
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.1016857060314214e-05,
      "loss": 2.2383,
      "step": 16955
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.096752679069138e-05,
      "loss": 2.168,
      "step": 16956
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.091822558290248e-05,
      "loss": 2.2344,
      "step": 16957
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.086895343844188e-05,
      "loss": 2.0625,
      "step": 16958
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.0819710358802606e-05,
      "loss": 2.3125,
      "step": 16959
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.07704963454768e-05,
      "loss": 2.1523,
      "step": 16960
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.0721311399955604e-05,
      "loss": 2.2773,
      "step": 16961
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.067215552373005e-05,
      "loss": 2.3008,
      "step": 16962
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.062302871828938e-05,
      "loss": 2.1426,
      "step": 16963
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.0573930985122076e-05,
      "loss": 2.0352,
      "step": 16964
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.0524862325716286e-05,
      "loss": 2.3828,
      "step": 16965
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.047582274155903e-05,
      "loss": 2.123,
      "step": 16966
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.042681223413613e-05,
      "loss": 2.0137,
      "step": 16967
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.0377830804932733e-05,
      "loss": 2.3906,
      "step": 16968
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.03288784554332e-05,
      "loss": 2.166,
      "step": 16969
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.027995518712113e-05,
      "loss": 2.2676,
      "step": 16970
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.023106100147877e-05,
      "loss": 2.4492,
      "step": 16971
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.018219589998795e-05,
      "loss": 2.1465,
      "step": 16972
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.013335988412958e-05,
      "loss": 2.1934,
      "step": 16973
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.008455295538316e-05,
      "loss": 2.125,
      "step": 16974
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.003577511522816e-05,
      "loss": 2.1172,
      "step": 16975
    },
    {
      "epoch": 1.82,
      "learning_rate": 3.998702636514229e-05,
      "loss": 2.2109,
      "step": 16976
    },
    {
      "epoch": 1.82,
      "learning_rate": 3.9938306706603036e-05,
      "loss": 2.0605,
      "step": 16977
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.988961614108666e-05,
      "loss": 2.0742,
      "step": 16978
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.9840954670068873e-05,
      "loss": 2.1836,
      "step": 16979
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.979232229502383e-05,
      "loss": 2.4414,
      "step": 16980
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.9743719017425686e-05,
      "loss": 2.1133,
      "step": 16981
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.969514483874714e-05,
      "loss": 2.0938,
      "step": 16982
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.964659976046015e-05,
      "loss": 2.1504,
      "step": 16983
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.959808378403562e-05,
      "loss": 2.248,
      "step": 16984
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.9549596910943955e-05,
      "loss": 2.3086,
      "step": 16985
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.950113914265441e-05,
      "loss": 2.1562,
      "step": 16986
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.9452710480635364e-05,
      "loss": 2.3379,
      "step": 16987
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.940431092635444e-05,
      "loss": 2.1816,
      "step": 16988
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.935594048127833e-05,
      "loss": 2.1016,
      "step": 16989
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.930759914687276e-05,
      "loss": 2.1367,
      "step": 16990
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.9259286924602456e-05,
      "loss": 2.2207,
      "step": 16991
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.9211003815931676e-05,
      "loss": 2.1719,
      "step": 16992
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.91627498223236e-05,
      "loss": 2.3945,
      "step": 16993
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.9114524945240256e-05,
      "loss": 2.1211,
      "step": 16994
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.906632918614328e-05,
      "loss": 2.2871,
      "step": 16995
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.901816254649282e-05,
      "loss": 2.2852,
      "step": 16996
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.897002502774882e-05,
      "loss": 2.1719,
      "step": 16997
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.892191663136979e-05,
      "loss": 2.1855,
      "step": 16998
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.887383735881367e-05,
      "loss": 2.3867,
      "step": 16999
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.88257872115374e-05,
      "loss": 2.168,
      "step": 17000
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.877776619099693e-05,
      "loss": 2.2695,
      "step": 17001
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.872977429864777e-05,
      "loss": 2.2461,
      "step": 17002
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.868181153594408e-05,
      "loss": 2.5625,
      "step": 17003
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.863387790433892e-05,
      "loss": 2.2051,
      "step": 17004
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.8585973405285356e-05,
      "loss": 2.1973,
      "step": 17005
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.8538098040235004e-05,
      "loss": 2.252,
      "step": 17006
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.849025181063826e-05,
      "loss": 2.2344,
      "step": 17007
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.844243471794539e-05,
      "loss": 2.1875,
      "step": 17008
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.839464676360527e-05,
      "loss": 2.2148,
      "step": 17009
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.834688794906616e-05,
      "loss": 2.3594,
      "step": 17010
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.8299158275774906e-05,
      "loss": 2.2598,
      "step": 17011
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.8251457745178354e-05,
      "loss": 2.332,
      "step": 17012
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.820378635872179e-05,
      "loss": 2.4766,
      "step": 17013
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.815614411784973e-05,
      "loss": 2.2266,
      "step": 17014
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.810853102400602e-05,
      "loss": 2.3047,
      "step": 17015
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.80609470786335e-05,
      "loss": 2.2656,
      "step": 17016
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.801339228317402e-05,
      "loss": 2.4336,
      "step": 17017
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.7965866639068756e-05,
      "loss": 2.1953,
      "step": 17018
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.7918370147757787e-05,
      "loss": 2.1953,
      "step": 17019
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.7870902810680505e-05,
      "loss": 2.2168,
      "step": 17020
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.782346462927522e-05,
      "loss": 2.1445,
      "step": 17021
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.777605560497954e-05,
      "loss": 2.2852,
      "step": 17022
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.772867573923011e-05,
      "loss": 2.1953,
      "step": 17023
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.7681325033462555e-05,
      "loss": 2.1055,
      "step": 17024
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.7634003489112054e-05,
      "loss": 2.3242,
      "step": 17025
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.758671110761247e-05,
      "loss": 2.2656,
      "step": 17026
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.753944789039665e-05,
      "loss": 2.0996,
      "step": 17027
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.7492213838897225e-05,
      "loss": 2.4766,
      "step": 17028
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.744500895454539e-05,
      "loss": 1.9824,
      "step": 17029
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.739783323877155e-05,
      "loss": 2.1914,
      "step": 17030
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.7350686693005233e-05,
      "loss": 2.1562,
      "step": 17031
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.73035693186754e-05,
      "loss": 2.375,
      "step": 17032
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.7256481117209695e-05,
      "loss": 2.4023,
      "step": 17033
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.720942209003497e-05,
      "loss": 2.3184,
      "step": 17034
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.716239223857731e-05,
      "loss": 2.1992,
      "step": 17035
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.711539156426191e-05,
      "loss": 2.3828,
      "step": 17036
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.7068420068513074e-05,
      "loss": 2.2695,
      "step": 17037
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.702147775275422e-05,
      "loss": 2.2578,
      "step": 17038
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.697456461840765e-05,
      "loss": 2.1113,
      "step": 17039
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.6927680666895115e-05,
      "loss": 2.332,
      "step": 17040
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.6880825899637484e-05,
      "loss": 2.082,
      "step": 17041
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.683400031805451e-05,
      "loss": 2.1426,
      "step": 17042
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.678720392356505e-05,
      "loss": 2.2852,
      "step": 17043
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.67404367175872e-05,
      "loss": 2.0078,
      "step": 17044
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.669369870153849e-05,
      "loss": 2.1797,
      "step": 17045
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.664698987683479e-05,
      "loss": 2.0039,
      "step": 17046
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.660031024489174e-05,
      "loss": 2.2969,
      "step": 17047
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.6553659807124e-05,
      "loss": 2.0332,
      "step": 17048
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.650703856494508e-05,
      "loss": 2.2383,
      "step": 17049
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.646044651976765e-05,
      "loss": 2.1738,
      "step": 17050
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.64138836730038e-05,
      "loss": 2.1133,
      "step": 17051
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.636735002606451e-05,
      "loss": 2.2773,
      "step": 17052
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.632084558035986e-05,
      "loss": 2.2148,
      "step": 17053
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.6274370337298966e-05,
      "loss": 2.5547,
      "step": 17054
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.622792429829047e-05,
      "loss": 2.3457,
      "step": 17055
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.6181507464741694e-05,
      "loss": 2.2754,
      "step": 17056
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.613511983805906e-05,
      "loss": 2.3125,
      "step": 17057
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.608876141964845e-05,
      "loss": 2.25,
      "step": 17058
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.604243221091474e-05,
      "loss": 2.3066,
      "step": 17059
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.599613221326159e-05,
      "loss": 2.0723,
      "step": 17060
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.5949861428092314e-05,
      "loss": 2.168,
      "step": 17061
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.59036198568089e-05,
      "loss": 2.1719,
      "step": 17062
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.585740750081279e-05,
      "loss": 2.5195,
      "step": 17063
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.581122436150408e-05,
      "loss": 2.2656,
      "step": 17064
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.5765070440282656e-05,
      "loss": 1.957,
      "step": 17065
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.571894573854673e-05,
      "loss": 2.3086,
      "step": 17066
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.567285025769429e-05,
      "loss": 2.2266,
      "step": 17067
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.5626783999122113e-05,
      "loss": 2.1562,
      "step": 17068
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.558074696422631e-05,
      "loss": 2.2695,
      "step": 17069
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.553473915440153e-05,
      "loss": 2.1387,
      "step": 17070
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.548876057104244e-05,
      "loss": 2.1055,
      "step": 17071
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.544281121554216e-05,
      "loss": 2.3008,
      "step": 17072
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.5396891089293e-05,
      "loss": 2.1484,
      "step": 17073
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.535100019368653e-05,
      "loss": 2.2031,
      "step": 17074
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.530513853011352e-05,
      "loss": 2.168,
      "step": 17075
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.525930609996375e-05,
      "loss": 2.4141,
      "step": 17076
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.521350290462577e-05,
      "loss": 2.1152,
      "step": 17077
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.516772894548792e-05,
      "loss": 2.3164,
      "step": 17078
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.51219842239372e-05,
      "loss": 2.2656,
      "step": 17079
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.507626874135972e-05,
      "loss": 2.3164,
      "step": 17080
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.5030582499140816e-05,
      "loss": 2.3555,
      "step": 17081
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.498492549866528e-05,
      "loss": 2.1777,
      "step": 17082
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.49392977413161e-05,
      "loss": 2.2031,
      "step": 17083
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.48936992284764e-05,
      "loss": 2.1484,
      "step": 17084
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.4848129961527755e-05,
      "loss": 2.1562,
      "step": 17085
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.480258994185126e-05,
      "loss": 2.25,
      "step": 17086
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.475707917082649e-05,
      "loss": 2.2227,
      "step": 17087
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.471159764983311e-05,
      "loss": 2.2129,
      "step": 17088
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.4666145380249034e-05,
      "loss": 2.0312,
      "step": 17089
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.46207223634516e-05,
      "loss": 2.3477,
      "step": 17090
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.457532860081747e-05,
      "loss": 2.3398,
      "step": 17091
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.452996409372211e-05,
      "loss": 2.3242,
      "step": 17092
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.44846288435402e-05,
      "loss": 2.1445,
      "step": 17093
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.4439322851645524e-05,
      "loss": 2.1426,
      "step": 17094
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.43940461194111e-05,
      "loss": 2.3359,
      "step": 17095
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.4348798648208944e-05,
      "loss": 2.2148,
      "step": 17096
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.4303580439410064e-05,
      "loss": 2.2539,
      "step": 17097
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.425839149438492e-05,
      "loss": 2.3828,
      "step": 17098
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.421323181450287e-05,
      "loss": 2.1621,
      "step": 17099
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.4168101401132136e-05,
      "loss": 2.3633,
      "step": 17100
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.4123000255640525e-05,
      "loss": 2.1875,
      "step": 17101
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.407792837939483e-05,
      "loss": 2.4766,
      "step": 17102
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.403288577376074e-05,
      "loss": 2.1523,
      "step": 17103
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.398787244010326e-05,
      "loss": 2.4531,
      "step": 17104
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.394288837978632e-05,
      "loss": 2.2227,
      "step": 17105
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.3897933594173145e-05,
      "loss": 2.0996,
      "step": 17106
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.385300808462621e-05,
      "loss": 2.3359,
      "step": 17107
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.380811185250676e-05,
      "loss": 2.2227,
      "step": 17108
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.376324489917504e-05,
      "loss": 2.1328,
      "step": 17109
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.3718407225991065e-05,
      "loss": 2.2578,
      "step": 17110
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.367359883431342e-05,
      "loss": 2.3477,
      "step": 17111
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.362881972549991e-05,
      "loss": 2.2637,
      "step": 17112
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.3584069900907344e-05,
      "loss": 2.25,
      "step": 17113
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.353934936189218e-05,
      "loss": 2.168,
      "step": 17114
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.349465810980934e-05,
      "loss": 2.2246,
      "step": 17115
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.3449996146012965e-05,
      "loss": 2.0859,
      "step": 17116
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.340536347185674e-05,
      "loss": 2.3711,
      "step": 17117
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.336076008869316e-05,
      "loss": 2.3574,
      "step": 17118
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.331618599787367e-05,
      "loss": 2.3945,
      "step": 17119
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.3271641200749106e-05,
      "loss": 2.1211,
      "step": 17120
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.322712569866948e-05,
      "loss": 2.1113,
      "step": 17121
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.31826394929835e-05,
      "loss": 2.25,
      "step": 17122
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.313818258503931e-05,
      "loss": 2.4141,
      "step": 17123
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.3093754976184166e-05,
      "loss": 2.0605,
      "step": 17124
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.304935666776443e-05,
      "loss": 2.1426,
      "step": 17125
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.300498766112536e-05,
      "loss": 2.3867,
      "step": 17126
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.296064795761167e-05,
      "loss": 2.1094,
      "step": 17127
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.291633755856682e-05,
      "loss": 2.2617,
      "step": 17128
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.287205646533364e-05,
      "loss": 2.1953,
      "step": 17129
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.282780467925395e-05,
      "loss": 2.2891,
      "step": 17130
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.278358220166877e-05,
      "loss": 2.1504,
      "step": 17131
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.273938903391816e-05,
      "loss": 2.2344,
      "step": 17132
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.269522517734125e-05,
      "loss": 2.0898,
      "step": 17133
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.2651090633276535e-05,
      "loss": 2.125,
      "step": 17134
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.2606985403061394e-05,
      "loss": 2.2695,
      "step": 17135
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.256290948803209e-05,
      "loss": 2.3633,
      "step": 17136
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.251886288952466e-05,
      "loss": 2.3125,
      "step": 17137
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.2474845608873594e-05,
      "loss": 2.2383,
      "step": 17138
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.2430857647412825e-05,
      "loss": 2.2617,
      "step": 17139
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.23868990064754e-05,
      "loss": 2.2305,
      "step": 17140
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.2342969687393366e-05,
      "loss": 2.3711,
      "step": 17141
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.2299069691497985e-05,
      "loss": 1.9512,
      "step": 17142
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.225519902011931e-05,
      "loss": 2.3672,
      "step": 17143
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.221135767458705e-05,
      "loss": 2.3711,
      "step": 17144
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.21675456562297e-05,
      "loss": 2.2539,
      "step": 17145
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.212376296637476e-05,
      "loss": 2.4062,
      "step": 17146
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.208000960634927e-05,
      "loss": 2.1426,
      "step": 17147
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.203628557747873e-05,
      "loss": 2.4062,
      "step": 17148
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.199259088108841e-05,
      "loss": 2.3281,
      "step": 17149
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.194892551850237e-05,
      "loss": 2.1641,
      "step": 17150
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.190528949104377e-05,
      "loss": 2.3184,
      "step": 17151
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.1861682800034766e-05,
      "loss": 2.4023,
      "step": 17152
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.181810544679686e-05,
      "loss": 2.1953,
      "step": 17153
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.1774557432650783e-05,
      "loss": 2.0215,
      "step": 17154
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.173103875891603e-05,
      "loss": 2.2422,
      "step": 17155
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.168754942691132e-05,
      "loss": 2.3633,
      "step": 17156
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.164408943795471e-05,
      "loss": 2.0879,
      "step": 17157
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.1600658793363045e-05,
      "loss": 2.1523,
      "step": 17158
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.155725749445237e-05,
      "loss": 2.168,
      "step": 17159
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.1513885542537866e-05,
      "loss": 2.127,
      "step": 17160
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.147054293893414e-05,
      "loss": 2.2227,
      "step": 17161
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.142722968495415e-05,
      "loss": 2.1602,
      "step": 17162
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.138394578191073e-05,
      "loss": 2.1738,
      "step": 17163
    },
    {
      "epoch": 1.84,
      "learning_rate": 3.13406912311156e-05,
      "loss": 2.2734,
      "step": 17164
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.12974660338794e-05,
      "loss": 2.2305,
      "step": 17165
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.125427019151183e-05,
      "loss": 2.2266,
      "step": 17166
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.12111037053221e-05,
      "loss": 2.3516,
      "step": 17167
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.1167966576618245e-05,
      "loss": 2.1992,
      "step": 17168
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.1124858806707344e-05,
      "loss": 2.2852,
      "step": 17169
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.108178039689591e-05,
      "loss": 2.1406,
      "step": 17170
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.103873134848911e-05,
      "loss": 2.1094,
      "step": 17171
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.099571166279169e-05,
      "loss": 2.2852,
      "step": 17172
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.095272134110716e-05,
      "loss": 1.998,
      "step": 17173
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.090976038473836e-05,
      "loss": 2.2578,
      "step": 17174
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.086682879498703e-05,
      "loss": 2.3516,
      "step": 17175
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.082392657315414e-05,
      "loss": 2.3867,
      "step": 17176
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.0781053720540076e-05,
      "loss": 2.2812,
      "step": 17177
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.0738210238443695e-05,
      "loss": 2.3477,
      "step": 17178
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.069539612816308e-05,
      "loss": 2.4023,
      "step": 17179
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.0652611390996285e-05,
      "loss": 2.2578,
      "step": 17180
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.0609856028239515e-05,
      "loss": 2.4414,
      "step": 17181
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.0567130041188166e-05,
      "loss": 2.127,
      "step": 17182
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.05244334311372e-05,
      "loss": 2.3398,
      "step": 17183
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.048176619938059e-05,
      "loss": 2.0703,
      "step": 17184
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.0439128347211075e-05,
      "loss": 2.2852,
      "step": 17185
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.0396519875920736e-05,
      "loss": 2.4219,
      "step": 17186
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.035394078680076e-05,
      "loss": 2.0527,
      "step": 17187
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.031139108114167e-05,
      "loss": 2.3242,
      "step": 17188
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.0268870760232547e-05,
      "loss": 2.1094,
      "step": 17189
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.022637982536214e-05,
      "loss": 2.2969,
      "step": 17190
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.0183918277817747e-05,
      "loss": 2.4141,
      "step": 17191
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.014148611888634e-05,
      "loss": 2.5,
      "step": 17192
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.0099083349853896e-05,
      "loss": 2.3477,
      "step": 17193
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.0056709972004935e-05,
      "loss": 2.3438,
      "step": 17194
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.001436598662388e-05,
      "loss": 2.2012,
      "step": 17195
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.9972051394993706e-05,
      "loss": 2.1855,
      "step": 17196
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.9929766198396824e-05,
      "loss": 2.4062,
      "step": 17197
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.9887510398114327e-05,
      "loss": 2.373,
      "step": 17198
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.9845283995426964e-05,
      "loss": 2.1484,
      "step": 17199
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.980308699161438e-05,
      "loss": 2.1328,
      "step": 17200
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.9760919387955222e-05,
      "loss": 2.3359,
      "step": 17201
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.9718781185727016e-05,
      "loss": 2.2656,
      "step": 17202
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.967667238620708e-05,
      "loss": 2.1074,
      "step": 17203
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.9634592990671284e-05,
      "loss": 2.3047,
      "step": 17204
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.959254300039482e-05,
      "loss": 2.2344,
      "step": 17205
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.955052241665179e-05,
      "loss": 2.1367,
      "step": 17206
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.950853124071573e-05,
      "loss": 2.041,
      "step": 17207
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.9466569473859174e-05,
      "loss": 2.1953,
      "step": 17208
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.9424637117353437e-05,
      "loss": 2.1875,
      "step": 17209
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.9382734172469395e-05,
      "loss": 2.1484,
      "step": 17210
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.9340860640476807e-05,
      "loss": 2.2188,
      "step": 17211
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.9299016522644552e-05,
      "loss": 2.0273,
      "step": 17212
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.925720182024072e-05,
      "loss": 2.1836,
      "step": 17213
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.9215416534532303e-05,
      "loss": 2.1914,
      "step": 17214
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.9173660666785507e-05,
      "loss": 2.1836,
      "step": 17215
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.913193421826599e-05,
      "loss": 2.3125,
      "step": 17216
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.9090237190237955e-05,
      "loss": 2.3086,
      "step": 17217
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.9048569583964846e-05,
      "loss": 2.1816,
      "step": 17218
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.9006931400709535e-05,
      "loss": 2.3027,
      "step": 17219
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8965322641733793e-05,
      "loss": 2.3164,
      "step": 17220
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8923743308298502e-05,
      "loss": 2.2012,
      "step": 17221
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8882193401663315e-05,
      "loss": 2.1953,
      "step": 17222
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8840672923087785e-05,
      "loss": 2.3789,
      "step": 17223
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8799181873830015e-05,
      "loss": 2.2402,
      "step": 17224
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8757720255147112e-05,
      "loss": 2.2422,
      "step": 17225
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8716288068295625e-05,
      "loss": 2.293,
      "step": 17226
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8674885314531107e-05,
      "loss": 2.1582,
      "step": 17227
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8633511995108218e-05,
      "loss": 2.2969,
      "step": 17228
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8592168111280735e-05,
      "loss": 2.3359,
      "step": 17229
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8550853664301323e-05,
      "loss": 2.2852,
      "step": 17230
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8509568655422204e-05,
      "loss": 2.1484,
      "step": 17231
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8468313085894147e-05,
      "loss": 2.2812,
      "step": 17232
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8427086956967496e-05,
      "loss": 2.2695,
      "step": 17233
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8385890269891688e-05,
      "loss": 2.3086,
      "step": 17234
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8344723025914952e-05,
      "loss": 2.2227,
      "step": 17235
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8303585226284845e-05,
      "loss": 2.2656,
      "step": 17236
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.826247687224781e-05,
      "loss": 2.2109,
      "step": 17237
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8221397965049857e-05,
      "loss": 2.2949,
      "step": 17238
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8180348505935425e-05,
      "loss": 2.3086,
      "step": 17239
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8139328496148864e-05,
      "loss": 2.3633,
      "step": 17240
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8098337936932948e-05,
      "loss": 2.2461,
      "step": 17241
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8057376829529914e-05,
      "loss": 2.3203,
      "step": 17242
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.8016445175181092e-05,
      "loss": 2.0273,
      "step": 17243
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.7975542975126723e-05,
      "loss": 2.0293,
      "step": 17244
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.793467023060614e-05,
      "loss": 2.123,
      "step": 17245
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.789382694285836e-05,
      "loss": 2.3398,
      "step": 17246
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.7853013113120716e-05,
      "loss": 2.3164,
      "step": 17247
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.781222874263001e-05,
      "loss": 2.3398,
      "step": 17248
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.777147383262224e-05,
      "loss": 2.0918,
      "step": 17249
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.773074838433254e-05,
      "loss": 2.2637,
      "step": 17250
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.7690052398994802e-05,
      "loss": 2.3008,
      "step": 17251
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.764938587784227e-05,
      "loss": 2.3008,
      "step": 17252
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.76087488221074e-05,
      "loss": 2.2207,
      "step": 17253
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.756814123302154e-05,
      "loss": 2.166,
      "step": 17254
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.7527563111815257e-05,
      "loss": 1.9668,
      "step": 17255
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.748701445971824e-05,
      "loss": 2.2617,
      "step": 17256
    },
    {
      "epoch": 1.85,
      "learning_rate": 2.744649527795906e-05,
      "loss": 2.127,
      "step": 17257
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.7406005567765848e-05,
      "loss": 2.002,
      "step": 17258
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.7365545330365395e-05,
      "loss": 2.2441,
      "step": 17259
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.7325114566983945e-05,
      "loss": 2.1953,
      "step": 17260
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.7284713278846518e-05,
      "loss": 2.2695,
      "step": 17261
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.7244341467177358e-05,
      "loss": 2.0059,
      "step": 17262
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.7203999133200152e-05,
      "loss": 2.3008,
      "step": 17263
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.7163686278137147e-05,
      "loss": 2.2852,
      "step": 17264
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.7123402903209915e-05,
      "loss": 2.2305,
      "step": 17265
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.7083149009639373e-05,
      "loss": 2.3164,
      "step": 17266
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.7042924598645323e-05,
      "loss": 2.4102,
      "step": 17267
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.700272967144657e-05,
      "loss": 2.3281,
      "step": 17268
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.6962564229261244e-05,
      "loss": 2.1875,
      "step": 17269
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.6922428273306488e-05,
      "loss": 2.375,
      "step": 17270
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.6882321804798437e-05,
      "loss": 2.2383,
      "step": 17271
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.6842244824952566e-05,
      "loss": 2.0176,
      "step": 17272
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.680219733498346e-05,
      "loss": 2.4336,
      "step": 17273
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.6762179336104475e-05,
      "loss": 2.2539,
      "step": 17274
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.6722190829528316e-05,
      "loss": 1.8477,
      "step": 17275
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.6682231816466674e-05,
      "loss": 2.2578,
      "step": 17276
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.6642302298130806e-05,
      "loss": 2.2266,
      "step": 17277
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.66024022757303e-05,
      "loss": 1.9961,
      "step": 17278
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.6562531750474627e-05,
      "loss": 2.2773,
      "step": 17279
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.652269072357161e-05,
      "loss": 2.1055,
      "step": 17280
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.6482879196228714e-05,
      "loss": 2.0781,
      "step": 17281
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.6443097169652652e-05,
      "loss": 2.2148,
      "step": 17282
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.6403344645048565e-05,
      "loss": 2.3633,
      "step": 17283
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.636362162362116e-05,
      "loss": 2.1953,
      "step": 17284
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.6323928106574245e-05,
      "loss": 2.0977,
      "step": 17285
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.6284264095110643e-05,
      "loss": 2.1445,
      "step": 17286
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.624462959043239e-05,
      "loss": 2.0977,
      "step": 17287
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.62050245937403e-05,
      "loss": 2.0449,
      "step": 17288
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.616544910623486e-05,
      "loss": 2.25,
      "step": 17289
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.6125903129115226e-05,
      "loss": 2.3398,
      "step": 17290
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.6086386663579543e-05,
      "loss": 2.4141,
      "step": 17291
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.6046899710825523e-05,
      "loss": 2.1738,
      "step": 17292
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.600744227204965e-05,
      "loss": 2.2227,
      "step": 17293
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.5968014348447756e-05,
      "loss": 2.2539,
      "step": 17294
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.592861594121454e-05,
      "loss": 2.1973,
      "step": 17295
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.5889247051543718e-05,
      "loss": 2.1758,
      "step": 17296
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.584990768062867e-05,
      "loss": 2.1172,
      "step": 17297
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.581059782966122e-05,
      "loss": 2.1973,
      "step": 17298
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.577131749983286e-05,
      "loss": 2.123,
      "step": 17299
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.5732066692333524e-05,
      "loss": 2.3203,
      "step": 17300
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.5692845408352817e-05,
      "loss": 2.2148,
      "step": 17301
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.5653653649079456e-05,
      "loss": 2.2227,
      "step": 17302
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.5614491415700937e-05,
      "loss": 2.3164,
      "step": 17303
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.5575358709403972e-05,
      "loss": 2.4492,
      "step": 17304
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.5536255531374398e-05,
      "loss": 2.3496,
      "step": 17305
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.549718188279726e-05,
      "loss": 2.332,
      "step": 17306
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.5458137764856505e-05,
      "loss": 2.207,
      "step": 17307
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.5419123178735294e-05,
      "loss": 2.1738,
      "step": 17308
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.5380138125616126e-05,
      "loss": 2.1621,
      "step": 17309
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.534118260668017e-05,
      "loss": 2.2383,
      "step": 17310
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.530225662310781e-05,
      "loss": 2.2383,
      "step": 17311
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.5263360176078888e-05,
      "loss": 2.0566,
      "step": 17312
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.522449326677212e-05,
      "loss": 2.2012,
      "step": 17313
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.51856558963649e-05,
      "loss": 2.168,
      "step": 17314
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.514684806603451e-05,
      "loss": 2.0977,
      "step": 17315
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.5108069776956898e-05,
      "loss": 2.2441,
      "step": 17316
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.5069321030307013e-05,
      "loss": 2.1602,
      "step": 17317
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.5030601827259136e-05,
      "loss": 2.1445,
      "step": 17318
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.4991912168986664e-05,
      "loss": 2.127,
      "step": 17319
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.495325205666199e-05,
      "loss": 2.2031,
      "step": 17320
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.4914621491456513e-05,
      "loss": 2.2734,
      "step": 17321
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.4876020474541073e-05,
      "loss": 1.9766,
      "step": 17322
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.483744900708529e-05,
      "loss": 2.207,
      "step": 17323
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.4798907090258004e-05,
      "loss": 2.3398,
      "step": 17324
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.4760394725227286e-05,
      "loss": 1.9805,
      "step": 17325
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.4721911913159977e-05,
      "loss": 2.127,
      "step": 17326
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.4683458655222367e-05,
      "loss": 2.0996,
      "step": 17327
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.4645034952579637e-05,
      "loss": 2.2246,
      "step": 17328
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.4606640806396296e-05,
      "loss": 2.4414,
      "step": 17329
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.456827621783575e-05,
      "loss": 1.9824,
      "step": 17330
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.452994118806029e-05,
      "loss": 2.3008,
      "step": 17331
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.4491635718232098e-05,
      "loss": 2.1562,
      "step": 17332
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.4453359809511688e-05,
      "loss": 2.2773,
      "step": 17333
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.4415113463058802e-05,
      "loss": 2.1836,
      "step": 17334
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.4376896680032734e-05,
      "loss": 2.127,
      "step": 17335
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.4338709461591447e-05,
      "loss": 2.0469,
      "step": 17336
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.4300551808892014e-05,
      "loss": 2.1992,
      "step": 17337
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.4262423723090952e-05,
      "loss": 2.3633,
      "step": 17338
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.4224325205343456e-05,
      "loss": 2.25,
      "step": 17339
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.418625625680426e-05,
      "loss": 1.9297,
      "step": 17340
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.414821687862667e-05,
      "loss": 2.2852,
      "step": 17341
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.4110207071963764e-05,
      "loss": 2.2852,
      "step": 17342
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.407222683796717e-05,
      "loss": 2.1797,
      "step": 17343
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.403427617778775e-05,
      "loss": 2.2773,
      "step": 17344
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.3996355092575805e-05,
      "loss": 2.3203,
      "step": 17345
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.3958463583480082e-05,
      "loss": 2.207,
      "step": 17346
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.392060165164922e-05,
      "loss": 2.1094,
      "step": 17347
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.388276929823019e-05,
      "loss": 2.1367,
      "step": 17348
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.384496652436974e-05,
      "loss": 2.2578,
      "step": 17349
    },
    {
      "epoch": 1.86,
      "learning_rate": 2.380719333121317e-05,
      "loss": 2.1367,
      "step": 17350
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.3769449719905357e-05,
      "loss": 2.1797,
      "step": 17351
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.3731735691589927e-05,
      "loss": 2.2656,
      "step": 17352
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.3694051247409752e-05,
      "loss": 2.2422,
      "step": 17353
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.3656396388506696e-05,
      "loss": 2.2891,
      "step": 17354
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.3618771116022066e-05,
      "loss": 2.1934,
      "step": 17355
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.3581175431095947e-05,
      "loss": 2.2852,
      "step": 17356
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.3543609334867432e-05,
      "loss": 2.3359,
      "step": 17357
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.3506072828474945e-05,
      "loss": 1.9609,
      "step": 17358
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.346856591305624e-05,
      "loss": 2.1602,
      "step": 17359
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.343108858974763e-05,
      "loss": 2.1504,
      "step": 17360
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.3393640859684982e-05,
      "loss": 2.1875,
      "step": 17361
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.335622272400284e-05,
      "loss": 2.2812,
      "step": 17362
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.331883418383529e-05,
      "loss": 2.1445,
      "step": 17363
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.328147524031521e-05,
      "loss": 2.3105,
      "step": 17364
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.3244145894574907e-05,
      "loss": 2.3594,
      "step": 17365
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.3206846147745374e-05,
      "loss": 2.4375,
      "step": 17366
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.3169576000956927e-05,
      "loss": 2.1367,
      "step": 17367
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.3132335455339103e-05,
      "loss": 2.2148,
      "step": 17368
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.3095124512020338e-05,
      "loss": 2.5938,
      "step": 17369
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.305794317212817e-05,
      "loss": 2.4336,
      "step": 17370
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.302079143678937e-05,
      "loss": 2.2773,
      "step": 17371
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.298366930712992e-05,
      "loss": 2.2109,
      "step": 17372
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2946576784274476e-05,
      "loss": 2.375,
      "step": 17373
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2909513869347255e-05,
      "loss": 2.2188,
      "step": 17374
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2872480563471355e-05,
      "loss": 2.084,
      "step": 17375
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.283547686776899e-05,
      "loss": 2.2168,
      "step": 17376
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2798502783361373e-05,
      "loss": 2.2266,
      "step": 17377
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2761558311368946e-05,
      "loss": 2.0977,
      "step": 17378
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2724643452911587e-05,
      "loss": 2.2617,
      "step": 17379
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2687758209107513e-05,
      "loss": 2.1543,
      "step": 17380
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2650902581074718e-05,
      "loss": 2.1992,
      "step": 17381
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2614076569929976e-05,
      "loss": 2.25,
      "step": 17382
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2577280176789393e-05,
      "loss": 2.0742,
      "step": 17383
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2540513402767637e-05,
      "loss": 2.3281,
      "step": 17384
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2503776248979145e-05,
      "loss": 2.2402,
      "step": 17385
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2467068716537252e-05,
      "loss": 2.2891,
      "step": 17386
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2430390806553958e-05,
      "loss": 2.1562,
      "step": 17387
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2393742520141148e-05,
      "loss": 2.3906,
      "step": 17388
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2357123858409155e-05,
      "loss": 2.2578,
      "step": 17389
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2320534822467542e-05,
      "loss": 2.0859,
      "step": 17390
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2283975413425418e-05,
      "loss": 2.1328,
      "step": 17391
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.224744563239045e-05,
      "loss": 2.3066,
      "step": 17392
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2210945480469425e-05,
      "loss": 2.3047,
      "step": 17393
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2174474958768677e-05,
      "loss": 2.1113,
      "step": 17394
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.213803406839343e-05,
      "loss": 2.2266,
      "step": 17395
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2101622810447807e-05,
      "loss": 2.1074,
      "step": 17396
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2065241186034923e-05,
      "loss": 2.2109,
      "step": 17397
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.2028889196257895e-05,
      "loss": 2.2109,
      "step": 17398
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.1992566842217955e-05,
      "loss": 2.1602,
      "step": 17399
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.1956274125015664e-05,
      "loss": 2.3672,
      "step": 17400
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.192001104575092e-05,
      "loss": 2.3242,
      "step": 17401
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.1883777605522847e-05,
      "loss": 2.0586,
      "step": 17402
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.1847573805429122e-05,
      "loss": 2.2734,
      "step": 17403
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.1811399646566977e-05,
      "loss": 2.4766,
      "step": 17404
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.1775255130032536e-05,
      "loss": 2.2539,
      "step": 17405
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.1739140256921254e-05,
      "loss": 2.2148,
      "step": 17406
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.1703055028327258e-05,
      "loss": 2.1934,
      "step": 17407
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.166699944534445e-05,
      "loss": 2.3066,
      "step": 17408
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.1630973509064954e-05,
      "loss": 2.3691,
      "step": 17409
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.1594977220580793e-05,
      "loss": 2.1562,
      "step": 17410
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.1559010580982753e-05,
      "loss": 2.1426,
      "step": 17411
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.152307359136074e-05,
      "loss": 2.4141,
      "step": 17412
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.148716625280356e-05,
      "loss": 2.2422,
      "step": 17413
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.145128856639955e-05,
      "loss": 2.3789,
      "step": 17414
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.1415440533235854e-05,
      "loss": 2.3516,
      "step": 17415
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.1379622154398705e-05,
      "loss": 2.123,
      "step": 17416
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.134383343097357e-05,
      "loss": 2.1484,
      "step": 17417
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.1308074364045137e-05,
      "loss": 2.2969,
      "step": 17418
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.1272344954696764e-05,
      "loss": 2.293,
      "step": 17419
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.123664520401114e-05,
      "loss": 2.3066,
      "step": 17420
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.12009751130704e-05,
      "loss": 2.2871,
      "step": 17421
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.116533468295534e-05,
      "loss": 2.1953,
      "step": 17422
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.112972391474577e-05,
      "loss": 2.2148,
      "step": 17423
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.1094142809520935e-05,
      "loss": 2.3203,
      "step": 17424
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.1058591368359305e-05,
      "loss": 2.0703,
      "step": 17425
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.1023069592337906e-05,
      "loss": 2.2402,
      "step": 17426
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.0987577482533104e-05,
      "loss": 2.2227,
      "step": 17427
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.0952115040020704e-05,
      "loss": 2.1797,
      "step": 17428
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.0916682265875175e-05,
      "loss": 2.4531,
      "step": 17429
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.088127916117033e-05,
      "loss": 2.3711,
      "step": 17430
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.0845905726978865e-05,
      "loss": 2.2539,
      "step": 17431
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.0810561964372808e-05,
      "loss": 2.3203,
      "step": 17432
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.0775247874423197e-05,
      "loss": 2.2852,
      "step": 17433
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.0739963458200172e-05,
      "loss": 2.1348,
      "step": 17434
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.070470871677288e-05,
      "loss": 2.2695,
      "step": 17435
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.0669483651209687e-05,
      "loss": 2.3164,
      "step": 17436
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.0634288262578073e-05,
      "loss": 2.2891,
      "step": 17437
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.0599122551944626e-05,
      "loss": 2.2422,
      "step": 17438
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.0563986520374833e-05,
      "loss": 2.1445,
      "step": 17439
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.0528880168933506e-05,
      "loss": 2.1406,
      "step": 17440
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.049380349868457e-05,
      "loss": 2.252,
      "step": 17441
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.0458756510690957e-05,
      "loss": 2.0898,
      "step": 17442
    },
    {
      "epoch": 1.87,
      "learning_rate": 2.042373920601437e-05,
      "loss": 2.4336,
      "step": 17443
    },
    {
      "epoch": 1.88,
      "learning_rate": 2.03887515857164e-05,
      "loss": 2.0703,
      "step": 17444
    },
    {
      "epoch": 1.88,
      "learning_rate": 2.035379365085699e-05,
      "loss": 2.5078,
      "step": 17445
    },
    {
      "epoch": 1.88,
      "learning_rate": 2.0318865402495613e-05,
      "loss": 2.4336,
      "step": 17446
    },
    {
      "epoch": 1.88,
      "learning_rate": 2.028396684169076e-05,
      "loss": 2.1484,
      "step": 17447
    },
    {
      "epoch": 1.88,
      "learning_rate": 2.0249097969499807e-05,
      "loss": 2.1816,
      "step": 17448
    },
    {
      "epoch": 1.88,
      "learning_rate": 2.0214258786979577e-05,
      "loss": 2.3359,
      "step": 17449
    },
    {
      "epoch": 1.88,
      "learning_rate": 2.017944929518556e-05,
      "loss": 2.2656,
      "step": 17450
    },
    {
      "epoch": 1.88,
      "learning_rate": 2.014466949517291e-05,
      "loss": 2.3398,
      "step": 17451
    },
    {
      "epoch": 1.88,
      "learning_rate": 2.0109919387995223e-05,
      "loss": 2.1367,
      "step": 17452
    },
    {
      "epoch": 1.88,
      "learning_rate": 2.0075198974705778e-05,
      "loss": 2.3359,
      "step": 17453
    },
    {
      "epoch": 1.88,
      "learning_rate": 2.0040508256356836e-05,
      "loss": 2.3379,
      "step": 17454
    },
    {
      "epoch": 1.88,
      "learning_rate": 2.0005847233999343e-05,
      "loss": 2.127,
      "step": 17455
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9971215908683783e-05,
      "loss": 2.0996,
      "step": 17456
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9936614281459653e-05,
      "loss": 2.3398,
      "step": 17457
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.990204235337545e-05,
      "loss": 2.0781,
      "step": 17458
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9867500125478667e-05,
      "loss": 2.3828,
      "step": 17459
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9832987598816243e-05,
      "loss": 2.3164,
      "step": 17460
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9798504774434012e-05,
      "loss": 2.0859,
      "step": 17461
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9764051653376803e-05,
      "loss": 2.1797,
      "step": 17462
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9729628236688668e-05,
      "loss": 2.1055,
      "step": 17463
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9695234525412888e-05,
      "loss": 2.2598,
      "step": 17464
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.966087052059162e-05,
      "loss": 2.332,
      "step": 17465
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9626536223266156e-05,
      "loss": 2.2422,
      "step": 17466
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9592231634476877e-05,
      "loss": 2.2617,
      "step": 17467
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9557956755263617e-05,
      "loss": 2.3867,
      "step": 17468
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.952371158666477e-05,
      "loss": 2.1348,
      "step": 17469
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9489496129718176e-05,
      "loss": 2.0938,
      "step": 17470
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9455310385460558e-05,
      "loss": 2.4023,
      "step": 17471
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.942115435492797e-05,
      "loss": 2.1953,
      "step": 17472
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9387028039155486e-05,
      "loss": 2.2578,
      "step": 17473
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9352931439177158e-05,
      "loss": 2.2109,
      "step": 17474
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9318864556026163e-05,
      "loss": 2.2305,
      "step": 17475
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9284827390734895e-05,
      "loss": 2.2344,
      "step": 17476
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9250819944334973e-05,
      "loss": 2.1875,
      "step": 17477
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9216842217856688e-05,
      "loss": 2.332,
      "step": 17478
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.918289421232977e-05,
      "loss": 2.2461,
      "step": 17479
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9148975928782954e-05,
      "loss": 2.2148,
      "step": 17480
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.911508736824419e-05,
      "loss": 2.1328,
      "step": 17481
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.90812285317401e-05,
      "loss": 2.1621,
      "step": 17482
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9047399420296983e-05,
      "loss": 2.2539,
      "step": 17483
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.9013600034940015e-05,
      "loss": 2.2109,
      "step": 17484
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8979830376693264e-05,
      "loss": 2.2812,
      "step": 17485
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8946090446580135e-05,
      "loss": 2.375,
      "step": 17486
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8912380245622916e-05,
      "loss": 2.209,
      "step": 17487
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8878699774843355e-05,
      "loss": 2.1367,
      "step": 17488
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8845049035261962e-05,
      "loss": 2.4805,
      "step": 17489
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.881142802789848e-05,
      "loss": 2.25,
      "step": 17490
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8777836753771872e-05,
      "loss": 2.2129,
      "step": 17491
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8744275213899876e-05,
      "loss": 2.4062,
      "step": 17492
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8710743409299457e-05,
      "loss": 2.1699,
      "step": 17493
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8677241340986916e-05,
      "loss": 2.1211,
      "step": 17494
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.864376900997755e-05,
      "loss": 2.1289,
      "step": 17495
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.861032641728544e-05,
      "loss": 2.1719,
      "step": 17496
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8576913563924213e-05,
      "loss": 2.1094,
      "step": 17497
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8543530450906177e-05,
      "loss": 2.1855,
      "step": 17498
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8510177079243075e-05,
      "loss": 2.6016,
      "step": 17499
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.847685344994565e-05,
      "loss": 2.2109,
      "step": 17500
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.844355956402366e-05,
      "loss": 2.2422,
      "step": 17501
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8410295422486067e-05,
      "loss": 2.3711,
      "step": 17502
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8377061026340848e-05,
      "loss": 2.3516,
      "step": 17503
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.834385637659519e-05,
      "loss": 2.1758,
      "step": 17504
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8310681474255186e-05,
      "loss": 2.1191,
      "step": 17505
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.827753632032603e-05,
      "loss": 2.2695,
      "step": 17506
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8244420915812465e-05,
      "loss": 2.3105,
      "step": 17507
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.821133526171792e-05,
      "loss": 2.2344,
      "step": 17508
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8178279359044704e-05,
      "loss": 2.2168,
      "step": 17509
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.814525320879479e-05,
      "loss": 2.1367,
      "step": 17510
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.811225681196904e-05,
      "loss": 2.2754,
      "step": 17511
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8079290169566998e-05,
      "loss": 2.1113,
      "step": 17512
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.804635328258808e-05,
      "loss": 2.0879,
      "step": 17513
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8013446152030042e-05,
      "loss": 2.1074,
      "step": 17514
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.798056877889043e-05,
      "loss": 2.2695,
      "step": 17515
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.7947721164165097e-05,
      "loss": 2.207,
      "step": 17516
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.7914903308849817e-05,
      "loss": 2.1211,
      "step": 17517
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.7882115213938788e-05,
      "loss": 2.1855,
      "step": 17518
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.784935688042588e-05,
      "loss": 2.1328,
      "step": 17519
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.781662830930364e-05,
      "loss": 1.9961,
      "step": 17520
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.778392950156382e-05,
      "loss": 2.3438,
      "step": 17521
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.7751260458197195e-05,
      "loss": 2.2402,
      "step": 17522
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.771862118019396e-05,
      "loss": 2.4727,
      "step": 17523
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.7686011668543224e-05,
      "loss": 2.2617,
      "step": 17524
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.7653431924232856e-05,
      "loss": 2.0469,
      "step": 17525
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.76208819482504e-05,
      "loss": 2.2363,
      "step": 17526
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.758836174158229e-05,
      "loss": 2.3379,
      "step": 17527
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.7555871305213743e-05,
      "loss": 2.1348,
      "step": 17528
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.75234106401293e-05,
      "loss": 2.2227,
      "step": 17529
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.7490979747312953e-05,
      "loss": 2.3984,
      "step": 17530
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.7458578627747246e-05,
      "loss": 2.1152,
      "step": 17531
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.7426207282414065e-05,
      "loss": 2.0059,
      "step": 17532
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.739386571229429e-05,
      "loss": 2.0918,
      "step": 17533
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.7361553918368132e-05,
      "loss": 2.0527,
      "step": 17534
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.7329271901614596e-05,
      "loss": 2.3086,
      "step": 17535
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.7297019663012115e-05,
      "loss": 2.1895,
      "step": 17536
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.7264797203537907e-05,
      "loss": 2.0742,
      "step": 17537
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.7232604524168415e-05,
      "loss": 2.2754,
      "step": 17538
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.720044162587919e-05,
      "loss": 2.2383,
      "step": 17539
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.7168308509644903e-05,
      "loss": 2.1602,
      "step": 17540
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.7136205176439322e-05,
      "loss": 2.3594,
      "step": 17541
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.710413162723512e-05,
      "loss": 2.207,
      "step": 17542
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.7072087863004516e-05,
      "loss": 2.1738,
      "step": 17543
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.7040073884718398e-05,
      "loss": 2.0645,
      "step": 17544
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.7008089693346775e-05,
      "loss": 2.2578,
      "step": 17545
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6976135289858863e-05,
      "loss": 2.0293,
      "step": 17546
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6944210675223336e-05,
      "loss": 2.2422,
      "step": 17547
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.69123158504072e-05,
      "loss": 2.2891,
      "step": 17548
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6880450816377234e-05,
      "loss": 2.1797,
      "step": 17549
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6848615574099004e-05,
      "loss": 2.4062,
      "step": 17550
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6816810124537173e-05,
      "loss": 2.0312,
      "step": 17551
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6785034468655424e-05,
      "loss": 2.418,
      "step": 17552
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6753288607416872e-05,
      "loss": 2.2109,
      "step": 17553
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6721572541783635e-05,
      "loss": 2.2461,
      "step": 17554
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6689886272716392e-05,
      "loss": 2.2734,
      "step": 17555
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6658229801175707e-05,
      "loss": 2.0781,
      "step": 17556
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.66266031281207e-05,
      "loss": 2.2207,
      "step": 17557
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6595006254509937e-05,
      "loss": 2.1816,
      "step": 17558
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6563439181300655e-05,
      "loss": 2.2383,
      "step": 17559
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.653190190944953e-05,
      "loss": 2.2578,
      "step": 17560
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6500394439912357e-05,
      "loss": 2.3164,
      "step": 17561
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6468916773643815e-05,
      "loss": 2.1602,
      "step": 17562
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.643746891159781e-05,
      "loss": 2.1836,
      "step": 17563
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.640605085472746e-05,
      "loss": 2.1172,
      "step": 17564
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6374662603984348e-05,
      "loss": 2.3008,
      "step": 17565
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.634330416032026e-05,
      "loss": 2.1719,
      "step": 17566
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6311975524685107e-05,
      "loss": 2.2402,
      "step": 17567
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.628067669802835e-05,
      "loss": 2.418,
      "step": 17568
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6249407681298344e-05,
      "loss": 2.1348,
      "step": 17569
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6218168475442774e-05,
      "loss": 2.1836,
      "step": 17570
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6186959081408327e-05,
      "loss": 2.3828,
      "step": 17571
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6155779500140464e-05,
      "loss": 2.25,
      "step": 17572
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.612462973258433e-05,
      "loss": 2.1406,
      "step": 17573
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6093509779683825e-05,
      "loss": 2.1094,
      "step": 17574
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6062419642381753e-05,
      "loss": 2.0332,
      "step": 17575
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6031359321620475e-05,
      "loss": 2.4766,
      "step": 17576
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.6000328818341237e-05,
      "loss": 2.2969,
      "step": 17577
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5969328133484173e-05,
      "loss": 2.1992,
      "step": 17578
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.593835726798898e-05,
      "loss": 2.1289,
      "step": 17579
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5907416222793904e-05,
      "loss": 2.1582,
      "step": 17580
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5876504998836637e-05,
      "loss": 2.2949,
      "step": 17581
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5845623597053994e-05,
      "loss": 2.2656,
      "step": 17582
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5814772018381774e-05,
      "loss": 2.0664,
      "step": 17583
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5783950263754676e-05,
      "loss": 2.2793,
      "step": 17584
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5753158334106842e-05,
      "loss": 2.127,
      "step": 17585
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5722396230371528e-05,
      "loss": 2.0645,
      "step": 17586
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.569166395348076e-05,
      "loss": 2.0801,
      "step": 17587
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.566096150436569e-05,
      "loss": 2.2754,
      "step": 17588
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.563028888395701e-05,
      "loss": 2.377,
      "step": 17589
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5599646093183983e-05,
      "loss": 2.2754,
      "step": 17590
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5569033132975197e-05,
      "loss": 2.2695,
      "step": 17591
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5538450004258353e-05,
      "loss": 2.2734,
      "step": 17592
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.550789670796038e-05,
      "loss": 2.2188,
      "step": 17593
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5477373245006975e-05,
      "loss": 2.0879,
      "step": 17594
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5446879616323072e-05,
      "loss": 2.2773,
      "step": 17595
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.541641582283271e-05,
      "loss": 2.2812,
      "step": 17596
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5385981865459254e-05,
      "loss": 2.1641,
      "step": 17597
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.535557774512475e-05,
      "loss": 2.2617,
      "step": 17598
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5325203462750682e-05,
      "loss": 2.1914,
      "step": 17599
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5294859019257314e-05,
      "loss": 2.1953,
      "step": 17600
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5264544415564352e-05,
      "loss": 2.6055,
      "step": 17601
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5234259652590399e-05,
      "loss": 2.1777,
      "step": 17602
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5204004731253052e-05,
      "loss": 2.1621,
      "step": 17603
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5173779652469355e-05,
      "loss": 2.1074,
      "step": 17604
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.514358441715491e-05,
      "loss": 2.2754,
      "step": 17605
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5113419026225094e-05,
      "loss": 2.0156,
      "step": 17606
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5083283480593735e-05,
      "loss": 2.0781,
      "step": 17607
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.505317778117421e-05,
      "loss": 2.1172,
      "step": 17608
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.5023101928878791e-05,
      "loss": 2.3203,
      "step": 17609
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.4993055924618859e-05,
      "loss": 2.1504,
      "step": 17610
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.4963039769304798e-05,
      "loss": 2.0469,
      "step": 17611
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.4933053463846324e-05,
      "loss": 2.2363,
      "step": 17612
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.4903097009152155e-05,
      "loss": 2.3711,
      "step": 17613
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.4873170406129899e-05,
      "loss": 2.2227,
      "step": 17614
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.4843273655686495e-05,
      "loss": 2.1465,
      "step": 17615
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.481340675872811e-05,
      "loss": 2.4922,
      "step": 17616
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.4783569716159573e-05,
      "loss": 2.3867,
      "step": 17617
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.4753762528885162e-05,
      "loss": 2.0293,
      "step": 17618
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.4723985197808044e-05,
      "loss": 2.2656,
      "step": 17619
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.4694237723830606e-05,
      "loss": 2.332,
      "step": 17620
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.4664520107854351e-05,
      "loss": 2.2578,
      "step": 17621
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.4634832350779781e-05,
      "loss": 2.293,
      "step": 17622
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.460517445350651e-05,
      "loss": 2.0957,
      "step": 17623
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.4575546416933261e-05,
      "loss": 2.0449,
      "step": 17624
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.4545948241957874e-05,
      "loss": 2.2734,
      "step": 17625
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.4516379929477408e-05,
      "loss": 2.1367,
      "step": 17626
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.4486841480387591e-05,
      "loss": 2.293,
      "step": 17627
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.4457332895583707e-05,
      "loss": 2.1211,
      "step": 17628
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.4427854175960153e-05,
      "loss": 2.166,
      "step": 17629
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.439840532240988e-05,
      "loss": 2.2969,
      "step": 17630
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.4368986335825396e-05,
      "loss": 2.2715,
      "step": 17631
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.4339597217098321e-05,
      "loss": 1.9512,
      "step": 17632
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.4310237967119167e-05,
      "loss": 2.1387,
      "step": 17633
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.4280908586777552e-05,
      "loss": 2.2305,
      "step": 17634
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.4251609076962324e-05,
      "loss": 2.0898,
      "step": 17635
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.4222339438561438e-05,
      "loss": 2.1641,
      "step": 17636
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.4193099672461629e-05,
      "loss": 2.3477,
      "step": 17637
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.4163889779549077e-05,
      "loss": 2.2344,
      "step": 17638
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.4134709760709075e-05,
      "loss": 2.0625,
      "step": 17639
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.4105559616825691e-05,
      "loss": 2.1523,
      "step": 17640
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.4076439348782221e-05,
      "loss": 2.3125,
      "step": 17641
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.4047348957461293e-05,
      "loss": 2.1719,
      "step": 17642
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.401828844374442e-05,
      "loss": 2.1719,
      "step": 17643
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3989257808512012e-05,
      "loss": 2.0879,
      "step": 17644
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3960257052644143e-05,
      "loss": 2.2773,
      "step": 17645
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3931286177019332e-05,
      "loss": 2.3711,
      "step": 17646
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3902345182515653e-05,
      "loss": 2.25,
      "step": 17647
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.387343407000996e-05,
      "loss": 2.1992,
      "step": 17648
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3844552840378555e-05,
      "loss": 2.2617,
      "step": 17649
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3815701494496401e-05,
      "loss": 2.3438,
      "step": 17650
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3786880033238026e-05,
      "loss": 2.1895,
      "step": 17651
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3758088457476725e-05,
      "loss": 2.0938,
      "step": 17652
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3729326768084915e-05,
      "loss": 2.2852,
      "step": 17653
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3700594965934232e-05,
      "loss": 2.0352,
      "step": 17654
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3671893051895201e-05,
      "loss": 2.2188,
      "step": 17655
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3643221026837904e-05,
      "loss": 2.166,
      "step": 17656
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3614578891630868e-05,
      "loss": 2.252,
      "step": 17657
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.358596664714229e-05,
      "loss": 2.3906,
      "step": 17658
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3557384294239028e-05,
      "loss": 2.1465,
      "step": 17659
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3528831833787391e-05,
      "loss": 2.2617,
      "step": 17660
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3500309266652355e-05,
      "loss": 2.4336,
      "step": 17661
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.347181659369856e-05,
      "loss": 2.1504,
      "step": 17662
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3443353815789206e-05,
      "loss": 2.002,
      "step": 17663
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3414920933786933e-05,
      "loss": 2.2461,
      "step": 17664
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3386517948553278e-05,
      "loss": 2.248,
      "step": 17665
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3358144860948884e-05,
      "loss": 2.2617,
      "step": 17666
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3329801671833842e-05,
      "loss": 2.293,
      "step": 17667
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3301488382066573e-05,
      "loss": 2.2012,
      "step": 17668
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3273204992505506e-05,
      "loss": 2.2168,
      "step": 17669
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3244951504007508e-05,
      "loss": 2.1367,
      "step": 17670
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3216727917428672e-05,
      "loss": 2.3984,
      "step": 17671
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3188534233624539e-05,
      "loss": 2.2051,
      "step": 17672
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.31603704534492e-05,
      "loss": 2.1309,
      "step": 17673
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3132236577756196e-05,
      "loss": 2.1504,
      "step": 17674
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3104132607398178e-05,
      "loss": 2.0254,
      "step": 17675
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3076058543226688e-05,
      "loss": 2.3164,
      "step": 17676
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3048014386092377e-05,
      "loss": 2.2422,
      "step": 17677
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.3020000136845234e-05,
      "loss": 2.3105,
      "step": 17678
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2992015796334244e-05,
      "loss": 2.1484,
      "step": 17679
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2964061365407288e-05,
      "loss": 2.1543,
      "step": 17680
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.293613684491135e-05,
      "loss": 2.2461,
      "step": 17681
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2908242235692868e-05,
      "loss": 2.1953,
      "step": 17682
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2880377538597055e-05,
      "loss": 2.2383,
      "step": 17683
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2852542754468344e-05,
      "loss": 2.1934,
      "step": 17684
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2824737884150062e-05,
      "loss": 2.4414,
      "step": 17685
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2796962928484978e-05,
      "loss": 2.25,
      "step": 17686
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2769217888314644e-05,
      "loss": 2.1738,
      "step": 17687
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2741502764480051e-05,
      "loss": 2.2617,
      "step": 17688
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2713817557820639e-05,
      "loss": 2.3711,
      "step": 17689
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2686162269175739e-05,
      "loss": 2.4688,
      "step": 17690
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2658536899383233e-05,
      "loss": 1.9199,
      "step": 17691
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2630941449280343e-05,
      "loss": 2.0762,
      "step": 17692
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2603375919703175e-05,
      "loss": 2.1602,
      "step": 17693
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2575840311487063e-05,
      "loss": 2.3906,
      "step": 17694
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2548334625466673e-05,
      "loss": 2.2402,
      "step": 17695
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2520858862475226e-05,
      "loss": 2.1504,
      "step": 17696
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.249341302334539e-05,
      "loss": 2.1094,
      "step": 17697
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2465997108908944e-05,
      "loss": 2.375,
      "step": 17698
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2438611119996779e-05,
      "loss": 2.168,
      "step": 17699
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2411255057438454e-05,
      "loss": 2.3594,
      "step": 17700
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2383928922063192e-05,
      "loss": 2.0938,
      "step": 17701
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2356632714699112e-05,
      "loss": 2.3984,
      "step": 17702
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2329366436173217e-05,
      "loss": 2.209,
      "step": 17703
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2302130087311847e-05,
      "loss": 2.5195,
      "step": 17704
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.227492366894023e-05,
      "loss": 2.2148,
      "step": 17705
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.224774718188304e-05,
      "loss": 2.043,
      "step": 17706
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2220600626963618e-05,
      "loss": 2.1211,
      "step": 17707
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.219348400500475e-05,
      "loss": 2.1562,
      "step": 17708
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2166397316828004e-05,
      "loss": 2.3359,
      "step": 17709
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2139340563254276e-05,
      "loss": 2.2012,
      "step": 17710
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2112313745103465e-05,
      "loss": 2.2617,
      "step": 17711
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2085316863194585e-05,
      "loss": 2.0664,
      "step": 17712
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2058349918345646e-05,
      "loss": 2.2695,
      "step": 17713
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2031412911373996e-05,
      "loss": 2.3164,
      "step": 17714
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.2004505843095759e-05,
      "loss": 2.3203,
      "step": 17715
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.1977628714326393e-05,
      "loss": 2.3828,
      "step": 17716
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.195078152588036e-05,
      "loss": 2.002,
      "step": 17717
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.1923964278571231e-05,
      "loss": 2.2109,
      "step": 17718
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.1897176973211576e-05,
      "loss": 2.084,
      "step": 17719
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.1870419610613193e-05,
      "loss": 2.3047,
      "step": 17720
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.1843692191586875e-05,
      "loss": 2.1289,
      "step": 17721
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.1816994716942641e-05,
      "loss": 2.1016,
      "step": 17722
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1790327187489403e-05,
      "loss": 2.3203,
      "step": 17723
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1763689604035399e-05,
      "loss": 2.1953,
      "step": 17724
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1737081967387763e-05,
      "loss": 1.9258,
      "step": 17725
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1710504278352851e-05,
      "loss": 2.2695,
      "step": 17726
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1683956537735907e-05,
      "loss": 2.2539,
      "step": 17727
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.165743874634151e-05,
      "loss": 2.248,
      "step": 17728
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1630950904973236e-05,
      "loss": 2.209,
      "step": 17729
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1604493014433782e-05,
      "loss": 2.3086,
      "step": 17730
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1578065075524947e-05,
      "loss": 2.1836,
      "step": 17731
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1551667089047425e-05,
      "loss": 2.3672,
      "step": 17732
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1525299055801353e-05,
      "loss": 2.3828,
      "step": 17733
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1498960976585537e-05,
      "loss": 2.2324,
      "step": 17734
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.147265285219834e-05,
      "loss": 2.375,
      "step": 17735
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1446374683436789e-05,
      "loss": 2.1484,
      "step": 17736
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1420126471097359e-05,
      "loss": 2.3555,
      "step": 17737
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1393908215975412e-05,
      "loss": 2.4336,
      "step": 17738
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1367719918865427e-05,
      "loss": 2.084,
      "step": 17739
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1341561580560878e-05,
      "loss": 2.4805,
      "step": 17740
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1315433201854686e-05,
      "loss": 2.2852,
      "step": 17741
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1289334783538551e-05,
      "loss": 2.0938,
      "step": 17742
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1263266326403177e-05,
      "loss": 2.3477,
      "step": 17743
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1237227831238705e-05,
      "loss": 2.3086,
      "step": 17744
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1211219298834175e-05,
      "loss": 2.2969,
      "step": 17745
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1185240729977619e-05,
      "loss": 2.2734,
      "step": 17746
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1159292125456411e-05,
      "loss": 2.1484,
      "step": 17747
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1133373486056698e-05,
      "loss": 2.0449,
      "step": 17748
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1107484812564073e-05,
      "loss": 2.2188,
      "step": 17749
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1081626105762909e-05,
      "loss": 2.0957,
      "step": 17750
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1055797366436916e-05,
      "loss": 2.3242,
      "step": 17751
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1029998595368795e-05,
      "loss": 2.0684,
      "step": 17752
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.1004229793340259e-05,
      "loss": 2.2617,
      "step": 17753
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0978490961132349e-05,
      "loss": 2.2891,
      "step": 17754
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0952782099524772e-05,
      "loss": 2.0586,
      "step": 17755
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0927103209296795e-05,
      "loss": 2.1953,
      "step": 17756
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0901454291226464e-05,
      "loss": 2.3164,
      "step": 17757
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0875835346091046e-05,
      "loss": 2.2461,
      "step": 17758
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0850246374666917e-05,
      "loss": 2.166,
      "step": 17759
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0824687377729458e-05,
      "loss": 2.0859,
      "step": 17760
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0799158356053384e-05,
      "loss": 2.4922,
      "step": 17761
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0773659310412075e-05,
      "loss": 2.2578,
      "step": 17762
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0748190241578248e-05,
      "loss": 2.293,
      "step": 17763
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.072275115032373e-05,
      "loss": 2.3633,
      "step": 17764
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0697342037419566e-05,
      "loss": 2.1914,
      "step": 17765
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.067196290363548e-05,
      "loss": 2.1797,
      "step": 17766
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.064661374974063e-05,
      "loss": 2.1777,
      "step": 17767
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0621294576503404e-05,
      "loss": 2.25,
      "step": 17768
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0596005384690855e-05,
      "loss": 2.2188,
      "step": 17769
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0570746175069257e-05,
      "loss": 2.3984,
      "step": 17770
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.054551694840411e-05,
      "loss": 2.0762,
      "step": 17771
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0520317705460024e-05,
      "loss": 2.207,
      "step": 17772
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0495148447000503e-05,
      "loss": 2.2227,
      "step": 17773
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0470009173788487e-05,
      "loss": 2.1914,
      "step": 17774
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0444899886585479e-05,
      "loss": 2.1387,
      "step": 17775
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0419820586152428e-05,
      "loss": 2.2188,
      "step": 17776
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0394771273249615e-05,
      "loss": 2.3477,
      "step": 17777
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0369751948635763e-05,
      "loss": 2.3711,
      "step": 17778
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0344762613069158e-05,
      "loss": 2.3398,
      "step": 17779
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0319803267307082e-05,
      "loss": 2.168,
      "step": 17780
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0294873912105928e-05,
      "loss": 2.4883,
      "step": 17781
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0269974548221095e-05,
      "loss": 2.2266,
      "step": 17782
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0245105176406976e-05,
      "loss": 2.043,
      "step": 17783
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0220265797417417e-05,
      "loss": 2.2031,
      "step": 17784
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0195456412005144e-05,
      "loss": 1.9668,
      "step": 17785
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0170677020921671e-05,
      "loss": 2.127,
      "step": 17786
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0145927624918172e-05,
      "loss": 2.2227,
      "step": 17787
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0121208224744605e-05,
      "loss": 2.2852,
      "step": 17788
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0096518821149924e-05,
      "loss": 2.0117,
      "step": 17789
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0071859414882311e-05,
      "loss": 2.2734,
      "step": 17790
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0047230006689278e-05,
      "loss": 2.1504,
      "step": 17791
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.0022630597316896e-05,
      "loss": 2.3711,
      "step": 17792
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.998061187510565e-06,
      "loss": 2.293,
      "step": 17793
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.973521778015027e-06,
      "loss": 2.2969,
      "step": 17794
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.949012369573906e-06,
      "loss": 2.3203,
      "step": 17795
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.924532962929722e-06,
      "loss": 2.3281,
      "step": 17796
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.900083558824436e-06,
      "loss": 2.3359,
      "step": 17797
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.875664157998898e-06,
      "loss": 1.9492,
      "step": 17798
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.851274761193186e-06,
      "loss": 2.123,
      "step": 17799
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.82691536914626e-06,
      "loss": 2.207,
      "step": 17800
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.802585982596312e-06,
      "loss": 1.9707,
      "step": 17801
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.77828660228064e-06,
      "loss": 2.2617,
      "step": 17802
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.754017228935541e-06,
      "loss": 2.2285,
      "step": 17803
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.72977786329654e-06,
      "loss": 2.1465,
      "step": 17804
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.70556850609805e-06,
      "loss": 2.2227,
      "step": 17805
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.681389158073705e-06,
      "loss": 2.332,
      "step": 17806
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.657239819956477e-06,
      "loss": 2.2656,
      "step": 17807
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.633120492477887e-06,
      "loss": 2.1387,
      "step": 17808
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.6090311763688e-06,
      "loss": 2.1309,
      "step": 17809
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.584971872359405e-06,
      "loss": 2.2207,
      "step": 17810
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.560942581178677e-06,
      "loss": 2.2832,
      "step": 17811
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.536943303554812e-06,
      "loss": 2.3164,
      "step": 17812
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.512974040215006e-06,
      "loss": 2.0898,
      "step": 17813
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.489034791885676e-06,
      "loss": 2.3398,
      "step": 17814
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.465125559292242e-06,
      "loss": 2.2188,
      "step": 17815
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.441246343159238e-06,
      "loss": 2.1797,
      "step": 17816
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.417397144210194e-06,
      "loss": 2.1641,
      "step": 17817
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.393577963167976e-06,
      "loss": 2.2812,
      "step": 17818
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.369788800754232e-06,
      "loss": 2.1328,
      "step": 17819
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.346029657689936e-06,
      "loss": 2.2305,
      "step": 17820
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.322300534695071e-06,
      "loss": 2.3047,
      "step": 17821
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.29860143248873e-06,
      "loss": 2.1348,
      "step": 17822
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.27493235178889e-06,
      "loss": 2.0898,
      "step": 17823
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.25129329331309e-06,
      "loss": 2.1328,
      "step": 17824
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.227684257777424e-06,
      "loss": 2.1152,
      "step": 17825
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.204105245897431e-06,
      "loss": 2.3438,
      "step": 17826
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.180556258387763e-06,
      "loss": 2.3242,
      "step": 17827
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.157037295961735e-06,
      "loss": 2.1016,
      "step": 17828
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.133548359332223e-06,
      "loss": 2.0039,
      "step": 17829
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.1100894492111e-06,
      "loss": 2.2871,
      "step": 17830
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.086660566309135e-06,
      "loss": 2.3008,
      "step": 17831
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.0632617113362e-06,
      "loss": 2.2852,
      "step": 17832
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.03989288500151e-06,
      "loss": 2.1328,
      "step": 17833
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.016554088013273e-06,
      "loss": 2.1895,
      "step": 17834
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.993245321078591e-06,
      "loss": 2.1289,
      "step": 17835
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.969966584903788e-06,
      "loss": 2.0605,
      "step": 17836
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.946717880194411e-06,
      "loss": 2.2676,
      "step": 17837
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.923499207654895e-06,
      "loss": 2.2812,
      "step": 17838
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.900310567988789e-06,
      "loss": 1.9512,
      "step": 17839
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.877151961898976e-06,
      "loss": 2.2383,
      "step": 17840
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.854023390087007e-06,
      "loss": 2.0664,
      "step": 17841
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.830924853253875e-06,
      "loss": 2.2461,
      "step": 17842
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.807856352099576e-06,
      "loss": 2.0293,
      "step": 17843
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.784817887323104e-06,
      "loss": 2.1562,
      "step": 17844
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.76180945962246e-06,
      "loss": 2.3203,
      "step": 17845
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.738831069695085e-06,
      "loss": 2.248,
      "step": 17846
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.715882718237312e-06,
      "loss": 2.1191,
      "step": 17847
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.69296440594447e-06,
      "loss": 2.1504,
      "step": 17848
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.670076133510896e-06,
      "loss": 2.3164,
      "step": 17849
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.647217901630478e-06,
      "loss": 2.2422,
      "step": 17850
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.624389710995883e-06,
      "loss": 2.3594,
      "step": 17851
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.601591562298561e-06,
      "loss": 2.3945,
      "step": 17852
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.578823456229622e-06,
      "loss": 2.1895,
      "step": 17853
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.556085393478962e-06,
      "loss": 2.3281,
      "step": 17854
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.533377374735584e-06,
      "loss": 2.332,
      "step": 17855
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.510699400687716e-06,
      "loss": 2.6602,
      "step": 17856
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.488051472022473e-06,
      "loss": 2.123,
      "step": 17857
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.465433589426308e-06,
      "loss": 2.2637,
      "step": 17858
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.442845753584339e-06,
      "loss": 2.1621,
      "step": 17859
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.42028796518135e-06,
      "loss": 2.2305,
      "step": 17860
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.397760224900685e-06,
      "loss": 2.293,
      "step": 17861
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.375262533425131e-06,
      "loss": 2.2656,
      "step": 17862
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.352794891436477e-06,
      "loss": 2.2773,
      "step": 17863
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.33035729961551e-06,
      "loss": 2.2598,
      "step": 17864
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.30794975864213e-06,
      "loss": 2.2578,
      "step": 17865
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.285572269195352e-06,
      "loss": 2.1387,
      "step": 17866
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.26322483195341e-06,
      "loss": 2.3633,
      "step": 17867
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.240907447593426e-06,
      "loss": 2.0254,
      "step": 17868
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.218620116791531e-06,
      "loss": 2.332,
      "step": 17869
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.196362840223403e-06,
      "loss": 2.1992,
      "step": 17870
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.174135618563393e-06,
      "loss": 2.3242,
      "step": 17871
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.151938452484964e-06,
      "loss": 2.2891,
      "step": 17872
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.129771342660796e-06,
      "loss": 2.25,
      "step": 17873
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.1076342897628e-06,
      "loss": 2.1934,
      "step": 17874
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.085527294461547e-06,
      "loss": 2.3438,
      "step": 17875
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.06345035742706e-06,
      "loss": 2.1191,
      "step": 17876
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.041403479328358e-06,
      "loss": 2.2949,
      "step": 17877
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.019386660833572e-06,
      "loss": 2.3359,
      "step": 17878
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.997399902609836e-06,
      "loss": 2.4219,
      "step": 17879
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.975443205323396e-06,
      "loss": 2.1035,
      "step": 17880
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.953516569639608e-06,
      "loss": 2.123,
      "step": 17881
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.931619996222938e-06,
      "loss": 2.1094,
      "step": 17882
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.909753485737081e-06,
      "loss": 2.375,
      "step": 17883
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.887917038844395e-06,
      "loss": 2.4336,
      "step": 17884
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.866110656206682e-06,
      "loss": 2.4844,
      "step": 17885
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.84433433848497e-06,
      "loss": 2.2461,
      "step": 17886
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.822588086338845e-06,
      "loss": 2.2402,
      "step": 17887
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.800871900427442e-06,
      "loss": 2.1797,
      "step": 17888
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.779185781408792e-06,
      "loss": 2.2676,
      "step": 17889
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.757529729940038e-06,
      "loss": 2.2734,
      "step": 17890
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.735903746677542e-06,
      "loss": 2.3398,
      "step": 17891
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.714307832276447e-06,
      "loss": 2.1934,
      "step": 17892
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.692741987391339e-06,
      "loss": 2.2812,
      "step": 17893
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.671206212675807e-06,
      "loss": 2.2461,
      "step": 17894
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.649700508782221e-06,
      "loss": 2.0664,
      "step": 17895
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.628224876362389e-06,
      "loss": 2.2891,
      "step": 17896
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.606779316067125e-06,
      "loss": 2.4336,
      "step": 17897
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.585363828546243e-06,
      "loss": 2.2969,
      "step": 17898
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.56397841444878e-06,
      "loss": 2.3945,
      "step": 17899
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.542623074422661e-06,
      "loss": 2.1016,
      "step": 17900
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.521297809115146e-06,
      "loss": 2.2754,
      "step": 17901
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.500002619172386e-06,
      "loss": 2.4023,
      "step": 17902
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.478737505239752e-06,
      "loss": 2.0605,
      "step": 17903
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.457502467961619e-06,
      "loss": 2.2969,
      "step": 17904
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.436297507981471e-06,
      "loss": 2.2773,
      "step": 17905
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.4151226259419055e-06,
      "loss": 2.0176,
      "step": 17906
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.393977822484521e-06,
      "loss": 2.0762,
      "step": 17907
    },
    {
      "epoch": 1.92,
      "learning_rate": 7.372863098250138e-06,
      "loss": 2.293,
      "step": 17908
    },
    {
      "epoch": 1.93,
      "learning_rate": 7.351778453878577e-06,
      "loss": 2.1172,
      "step": 17909
    },
    {
      "epoch": 1.93,
      "learning_rate": 7.330723890008884e-06,
      "loss": 2.1543,
      "step": 17910
    },
    {
      "epoch": 1.93,
      "learning_rate": 7.30969940727888e-06,
      "loss": 2.2305,
      "step": 17911
    },
    {
      "epoch": 1.93,
      "learning_rate": 7.288705006325836e-06,
      "loss": 2.3125,
      "step": 17912
    },
    {
      "epoch": 1.93,
      "learning_rate": 7.267740687785907e-06,
      "loss": 2.2988,
      "step": 17913
    },
    {
      "epoch": 1.93,
      "learning_rate": 7.246806452294363e-06,
      "loss": 2.2656,
      "step": 17914
    },
    {
      "epoch": 1.93,
      "learning_rate": 7.225902300485476e-06,
      "loss": 2.2285,
      "step": 17915
    },
    {
      "epoch": 1.93,
      "learning_rate": 7.205028232993072e-06,
      "loss": 2.1582,
      "step": 17916
    },
    {
      "epoch": 1.93,
      "learning_rate": 7.18418425044931e-06,
      "loss": 2.3672,
      "step": 17917
    },
    {
      "epoch": 1.93,
      "learning_rate": 7.16337035348591e-06,
      "loss": 2.2031,
      "step": 17918
    },
    {
      "epoch": 1.93,
      "learning_rate": 7.142586542733698e-06,
      "loss": 2.0879,
      "step": 17919
    },
    {
      "epoch": 1.93,
      "learning_rate": 7.121832818822616e-06,
      "loss": 2.2266,
      "step": 17920
    },
    {
      "epoch": 1.93,
      "learning_rate": 7.101109182381271e-06,
      "loss": 2.1777,
      "step": 17921
    },
    {
      "epoch": 1.93,
      "learning_rate": 7.080415634037829e-06,
      "loss": 2.084,
      "step": 17922
    },
    {
      "epoch": 1.93,
      "learning_rate": 7.059752174419342e-06,
      "loss": 2.1309,
      "step": 17923
    },
    {
      "epoch": 1.93,
      "learning_rate": 7.039118804151978e-06,
      "loss": 2.3516,
      "step": 17924
    },
    {
      "epoch": 1.93,
      "learning_rate": 7.0185155238610135e-06,
      "loss": 2.3047,
      "step": 17925
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.997942334170837e-06,
      "loss": 2.1348,
      "step": 17926
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.977399235704729e-06,
      "loss": 2.1504,
      "step": 17927
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.9568862290853015e-06,
      "loss": 2.1035,
      "step": 17928
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.936403314934281e-06,
      "loss": 2.3359,
      "step": 17929
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.915950493872281e-06,
      "loss": 2.4648,
      "step": 17930
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.8955277665190275e-06,
      "loss": 2.3789,
      "step": 17931
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.87513513349336e-06,
      "loss": 2.0996,
      "step": 17932
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.85477259541345e-06,
      "loss": 2.0566,
      "step": 17933
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.834440152896137e-06,
      "loss": 2.3164,
      "step": 17934
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.8141378065575965e-06,
      "loss": 1.9023,
      "step": 17935
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.793865557013224e-06,
      "loss": 2.2148,
      "step": 17936
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.773623404877194e-06,
      "loss": 2.125,
      "step": 17937
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.753411350762906e-06,
      "loss": 2.0859,
      "step": 17938
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.733229395282869e-06,
      "loss": 2.1426,
      "step": 17939
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.713077539048817e-06,
      "loss": 2.2695,
      "step": 17940
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.69295578267104e-06,
      "loss": 2.3242,
      "step": 17941
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.672864126759715e-06,
      "loss": 2.377,
      "step": 17942
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.652802571923355e-06,
      "loss": 2.1172,
      "step": 17943
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.6327711187701426e-06,
      "loss": 2.248,
      "step": 17944
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.612769767906923e-06,
      "loss": 2.0371,
      "step": 17945
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.59279851993988e-06,
      "loss": 2.1719,
      "step": 17946
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.572857375474306e-06,
      "loss": 2.0527,
      "step": 17947
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.552946335114274e-06,
      "loss": 2.2891,
      "step": 17948
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.5330653994631895e-06,
      "loss": 2.2227,
      "step": 17949
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.5132145691236825e-06,
      "loss": 2.2344,
      "step": 17950
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.4933938446970485e-06,
      "loss": 2.1348,
      "step": 17951
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.473603226784252e-06,
      "loss": 2.2695,
      "step": 17952
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.453842715984704e-06,
      "loss": 2.3086,
      "step": 17953
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.434112312897367e-06,
      "loss": 2.209,
      "step": 17954
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.414412018120097e-06,
      "loss": 2.1523,
      "step": 17955
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.394741832249862e-06,
      "loss": 2.1016,
      "step": 17956
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.3751017558828504e-06,
      "loss": 2.0879,
      "step": 17957
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.355491789613921e-06,
      "loss": 2.0664,
      "step": 17958
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.335911934037708e-06,
      "loss": 2.0371,
      "step": 17959
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.316362189747293e-06,
      "loss": 2.4297,
      "step": 17960
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.296842557335203e-06,
      "loss": 2.3281,
      "step": 17961
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.277353037392852e-06,
      "loss": 2.2773,
      "step": 17962
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.25789363051088e-06,
      "loss": 2.125,
      "step": 17963
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.238464337279037e-06,
      "loss": 2.1875,
      "step": 17964
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.219065158286075e-06,
      "loss": 2.1719,
      "step": 17965
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.199696094119745e-06,
      "loss": 2.2109,
      "step": 17966
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.180357145367133e-06,
      "loss": 2.5,
      "step": 17967
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.161048312614104e-06,
      "loss": 2.2383,
      "step": 17968
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.1417695964459675e-06,
      "loss": 2.1602,
      "step": 17969
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.1225209974468125e-06,
      "loss": 2.3047,
      "step": 17970
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.103302516199949e-06,
      "loss": 2.2031,
      "step": 17971
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.0841141532878005e-06,
      "loss": 2.0684,
      "step": 17972
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.064955909291902e-06,
      "loss": 2.3555,
      "step": 17973
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.045827784792679e-06,
      "loss": 2.2305,
      "step": 17974
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.026729780369778e-06,
      "loss": 2.166,
      "step": 17975
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.007661896601957e-06,
      "loss": 2.4492,
      "step": 17976
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.988624134067089e-06,
      "loss": 2.2461,
      "step": 17977
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.969616493342045e-06,
      "loss": 1.9727,
      "step": 17978
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.95063897500292e-06,
      "loss": 2.0879,
      "step": 17979
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.931691579624587e-06,
      "loss": 2.1934,
      "step": 17980
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.9127743077813655e-06,
      "loss": 2.1152,
      "step": 17981
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.893887160046463e-06,
      "loss": 2.2363,
      "step": 17982
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.875030136992199e-06,
      "loss": 2.3984,
      "step": 17983
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.856203239190006e-06,
      "loss": 2.0664,
      "step": 17984
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.837406467210538e-06,
      "loss": 2.3242,
      "step": 17985
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.818639821623228e-06,
      "loss": 2.2695,
      "step": 17986
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.799903302996845e-06,
      "loss": 2.2578,
      "step": 17987
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.781196911899156e-06,
      "loss": 2.2832,
      "step": 17988
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.76252064889693e-06,
      "loss": 2.0469,
      "step": 17989
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.743874514556268e-06,
      "loss": 2.2422,
      "step": 17990
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.725258509442166e-06,
      "loss": 2.1465,
      "step": 17991
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.706672634118726e-06,
      "loss": 2.3105,
      "step": 17992
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.688116889149164e-06,
      "loss": 2.1777,
      "step": 17993
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.669591275095809e-06,
      "loss": 2.3242,
      "step": 17994
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.651095792519989e-06,
      "loss": 2.2461,
      "step": 17995
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.632630441982256e-06,
      "loss": 2.4883,
      "step": 17996
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.614195224042162e-06,
      "loss": 2.2969,
      "step": 17997
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.595790139258261e-06,
      "loss": 2.041,
      "step": 17998
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.577415188188328e-06,
      "loss": 2.2266,
      "step": 17999
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.559070371389252e-06,
      "loss": 2.2734,
      "step": 18000
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.54075568941681e-06,
      "loss": 2.2715,
      "step": 18001
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.5224711428261136e-06,
      "loss": 2.418,
      "step": 18002
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.504216732171274e-06,
      "loss": 2.0664,
      "step": 18003
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.485992458005407e-06,
      "loss": 2.2656,
      "step": 18004
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.467798320880624e-06,
      "loss": 2.2578,
      "step": 18005
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.449634321348484e-06,
      "loss": 2.2051,
      "step": 18006
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.431500459959326e-06,
      "loss": 2.1113,
      "step": 18007
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.41339673726271e-06,
      "loss": 2.3945,
      "step": 18008
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.395323153807196e-06,
      "loss": 2.1602,
      "step": 18009
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.377279710140459e-06,
      "loss": 2.3359,
      "step": 18010
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.359266406809282e-06,
      "loss": 2.3086,
      "step": 18011
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.341283244359452e-06,
      "loss": 2.2988,
      "step": 18012
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.323330223336198e-06,
      "loss": 2.1719,
      "step": 18013
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.3054073442831974e-06,
      "loss": 2.0332,
      "step": 18014
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.287514607743793e-06,
      "loss": 2.207,
      "step": 18015
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.269652014260106e-06,
      "loss": 2.4102,
      "step": 18016
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.2518195643735946e-06,
      "loss": 2.0859,
      "step": 18017
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.234017258624379e-06,
      "loss": 2.2656,
      "step": 18018
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.2162450975521415e-06,
      "loss": 2.2227,
      "step": 18019
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.198503081695228e-06,
      "loss": 2.1836,
      "step": 18020
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.180791211591429e-06,
      "loss": 2.3867,
      "step": 18021
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.16310948777754e-06,
      "loss": 2.209,
      "step": 18022
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.145457910789242e-06,
      "loss": 2.3086,
      "step": 18023
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.127836481161441e-06,
      "loss": 2.1875,
      "step": 18024
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.110245199428265e-06,
      "loss": 2.2539,
      "step": 18025
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.0926840661226215e-06,
      "loss": 2.1973,
      "step": 18026
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.07515308177664e-06,
      "loss": 2.2461,
      "step": 18027
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.057652246921784e-06,
      "loss": 2.1836,
      "step": 18028
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.040181562088187e-06,
      "loss": 2.3457,
      "step": 18029
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.022741027805422e-06,
      "loss": 2.2227,
      "step": 18030
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.0053306446018465e-06,
      "loss": 2.4219,
      "step": 18031
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.987950413005149e-06,
      "loss": 2.1914,
      "step": 18032
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.9706003335420195e-06,
      "loss": 1.8691,
      "step": 18033
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.953280406738037e-06,
      "loss": 2.1387,
      "step": 18034
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.9359906331183365e-06,
      "loss": 2.2969,
      "step": 18035
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.918731013206723e-06,
      "loss": 2.1953,
      "step": 18036
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.90150154752611e-06,
      "loss": 2.2031,
      "step": 18037
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.884302236598748e-06,
      "loss": 2.1504,
      "step": 18038
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.867133080945884e-06,
      "loss": 2.2812,
      "step": 18039
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.8499940810875495e-06,
      "loss": 2.1934,
      "step": 18040
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.832885237543327e-06,
      "loss": 2.1855,
      "step": 18041
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.8158065508316914e-06,
      "loss": 2.3047,
      "step": 18042
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.7987580214700065e-06,
      "loss": 2.1719,
      "step": 18043
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.781739649975081e-06,
      "loss": 2.0996,
      "step": 18044
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.7647514368625024e-06,
      "loss": 1.9805,
      "step": 18045
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.747793382647192e-06,
      "loss": 2.3164,
      "step": 18046
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.73086548784285e-06,
      "loss": 2.168,
      "step": 18047
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.7139677529626225e-06,
      "loss": 2.1797,
      "step": 18048
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.697100178518543e-06,
      "loss": 2.0156,
      "step": 18049
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.680262765021537e-06,
      "loss": 2.0586,
      "step": 18050
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.663455512982085e-06,
      "loss": 2.002,
      "step": 18051
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.646678422909556e-06,
      "loss": 2.3633,
      "step": 18052
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.629931495312101e-06,
      "loss": 2.2305,
      "step": 18053
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.613214730697312e-06,
      "loss": 2.4492,
      "step": 18054
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.596528129571787e-06,
      "loss": 2.293,
      "step": 18055
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.579871692441118e-06,
      "loss": 2.25,
      "step": 18056
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.563245419810125e-06,
      "loss": 2.2422,
      "step": 18057
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.546649312182738e-06,
      "loss": 2.25,
      "step": 18058
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.530083370061666e-06,
      "loss": 2.0254,
      "step": 18059
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.513547593948952e-06,
      "loss": 2.2031,
      "step": 18060
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.497041984345751e-06,
      "loss": 2.2148,
      "step": 18061
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.480566541752218e-06,
      "loss": 2.3555,
      "step": 18062
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.46412126666762e-06,
      "loss": 2.3633,
      "step": 18063
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.447706159590337e-06,
      "loss": 2.2051,
      "step": 18064
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.431321221017748e-06,
      "loss": 2.1602,
      "step": 18065
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.414966451446345e-06,
      "loss": 2.2656,
      "step": 18066
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.398641851371732e-06,
      "loss": 2.2539,
      "step": 18067
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.382347421288735e-06,
      "loss": 2.0605,
      "step": 18068
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.366083161690959e-06,
      "loss": 2.2852,
      "step": 18069
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.349849073071344e-06,
      "loss": 2.207,
      "step": 18070
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.3336451559217174e-06,
      "loss": 2.123,
      "step": 18071
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.3174714107333535e-06,
      "loss": 2.1426,
      "step": 18072
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.301327837996194e-06,
      "loss": 2.2285,
      "step": 18073
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.285214438199514e-06,
      "loss": 2.4609,
      "step": 18074
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.269131211831478e-06,
      "loss": 2.1875,
      "step": 18075
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.253078159379698e-06,
      "loss": 2.3125,
      "step": 18076
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.237055281330337e-06,
      "loss": 2.1289,
      "step": 18077
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.221062578169233e-06,
      "loss": 2.3359,
      "step": 18078
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.205100050380772e-06,
      "loss": 2.3047,
      "step": 18079
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.189167698448793e-06,
      "loss": 2.1895,
      "step": 18080
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.173265522856018e-06,
      "loss": 2.4238,
      "step": 18081
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.157393524084508e-06,
      "loss": 2.3242,
      "step": 18082
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.141551702615098e-06,
      "loss": 2.123,
      "step": 18083
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.125740058927851e-06,
      "loss": 2.1992,
      "step": 18084
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.10995859350205e-06,
      "loss": 2.1523,
      "step": 18085
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.094207306815645e-06,
      "loss": 2.2266,
      "step": 18086
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.078486199346143e-06,
      "loss": 2.4141,
      "step": 18087
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.062795271570052e-06,
      "loss": 2.0527,
      "step": 18088
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.047134523962659e-06,
      "loss": 2.1094,
      "step": 18089
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.031503956998583e-06,
      "loss": 2.3711,
      "step": 18090
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.015903571151558e-06,
      "loss": 2.2227,
      "step": 18091
    },
    {
      "epoch": 1.94,
      "learning_rate": 4.000333366894204e-06,
      "loss": 2.418,
      "step": 18092
    },
    {
      "epoch": 1.94,
      "learning_rate": 3.9847933446984786e-06,
      "loss": 2.3633,
      "step": 18093
    },
    {
      "epoch": 1.94,
      "learning_rate": 3.969283505035115e-06,
      "loss": 2.2773,
      "step": 18094
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.953803848374404e-06,
      "loss": 2.2871,
      "step": 18095
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.938354375185193e-06,
      "loss": 2.1328,
      "step": 18096
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.922935085935664e-06,
      "loss": 2.4062,
      "step": 18097
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.907545981093108e-06,
      "loss": 2.0176,
      "step": 18098
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.892187061124041e-06,
      "loss": 2.1699,
      "step": 18099
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.876858326493537e-06,
      "loss": 2.1133,
      "step": 18100
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.861559777666446e-06,
      "loss": 2.2656,
      "step": 18101
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.846291415106174e-06,
      "loss": 2.0898,
      "step": 18102
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.831053239275351e-06,
      "loss": 2.3438,
      "step": 18103
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.815845250636052e-06,
      "loss": 2.332,
      "step": 18104
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.800667449648798e-06,
      "loss": 2.0098,
      "step": 18105
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.7855198367735545e-06,
      "loss": 2.293,
      "step": 18106
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.7704024124695093e-06,
      "loss": 2.0996,
      "step": 18107
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.7553151771947402e-06,
      "loss": 2.2109,
      "step": 18108
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.7402581314063266e-06,
      "loss": 2.0078,
      "step": 18109
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.725231275560681e-06,
      "loss": 2.2793,
      "step": 18110
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.7102346101131056e-06,
      "loss": 2.25,
      "step": 18111
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.695268135518015e-06,
      "loss": 2.25,
      "step": 18112
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.6803318522289353e-06,
      "loss": 2.2852,
      "step": 18113
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.6654257606985044e-06,
      "loss": 2.1367,
      "step": 18114
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.6505498613785826e-06,
      "loss": 2.4102,
      "step": 18115
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.635704154719699e-06,
      "loss": 2.2617,
      "step": 18116
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.6208886411718267e-06,
      "loss": 2.4258,
      "step": 18117
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.60610332118394e-06,
      "loss": 2.2695,
      "step": 18118
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.591348195204236e-06,
      "loss": 2.3906,
      "step": 18119
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.576623263679579e-06,
      "loss": 2.1504,
      "step": 18120
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.5619285270562794e-06,
      "loss": 2.293,
      "step": 18121
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.5472639857796473e-06,
      "loss": 2.3164,
      "step": 18122
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.532629640294105e-06,
      "loss": 2.2422,
      "step": 18123
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.5180254910431863e-06,
      "loss": 2.0566,
      "step": 18124
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.5034515384692043e-06,
      "loss": 2.0938,
      "step": 18125
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.4889077830140283e-06,
      "loss": 2.2695,
      "step": 18126
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.4743942251183045e-06,
      "loss": 2.1836,
      "step": 18127
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.4599108652217935e-06,
      "loss": 2.2227,
      "step": 18128
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.4454577037633663e-06,
      "loss": 2.1562,
      "step": 18129
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.431034741181116e-06,
      "loss": 2.0996,
      "step": 18130
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.416641977912138e-06,
      "loss": 2.0664,
      "step": 18131
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.4022794143924173e-06,
      "loss": 2.0859,
      "step": 18132
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.3879470510571606e-06,
      "loss": 2.1406,
      "step": 18133
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.37364488834091e-06,
      "loss": 2.4375,
      "step": 18134
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.3593729266769845e-06,
      "loss": 2.2891,
      "step": 18135
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.3451311664978167e-06,
      "loss": 2.1035,
      "step": 18136
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.33091960823495e-06,
      "loss": 2.1621,
      "step": 18137
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.3167382523190403e-06,
      "loss": 2.1855,
      "step": 18138
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.3025870991799655e-06,
      "loss": 2.1836,
      "step": 18139
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.288466149246383e-06,
      "loss": 2.2812,
      "step": 18140
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.2743754029463944e-06,
      "loss": 2.2266,
      "step": 18141
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.2603148607067703e-06,
      "loss": 2.3047,
      "step": 18142
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.246284522953835e-06,
      "loss": 2.2051,
      "step": 18143
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.2322843901124723e-06,
      "loss": 1.9902,
      "step": 18144
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.21831446260723e-06,
      "loss": 2.3711,
      "step": 18145
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.2043747408612157e-06,
      "loss": 2.0723,
      "step": 18146
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.190465225296868e-06,
      "loss": 2.2422,
      "step": 18147
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.17658591633585e-06,
      "loss": 2.2012,
      "step": 18148
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.1627368143987147e-06,
      "loss": 2.25,
      "step": 18149
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.1489179199049034e-06,
      "loss": 2.4258,
      "step": 18150
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.135129233273526e-06,
      "loss": 2.2656,
      "step": 18151
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.121370754922137e-06,
      "loss": 2.2031,
      "step": 18152
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.1076424852677365e-06,
      "loss": 2.3164,
      "step": 18153
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.0939444247264357e-06,
      "loss": 2.0762,
      "step": 18154
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.0802765737132365e-06,
      "loss": 2.0059,
      "step": 18155
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.066638932642363e-06,
      "loss": 2.4219,
      "step": 18156
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.0530315019270395e-06,
      "loss": 2.5234,
      "step": 18157
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.0394542819797142e-06,
      "loss": 2.2383,
      "step": 18158
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.0259072732117253e-06,
      "loss": 2.4375,
      "step": 18159
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.012390476033522e-06,
      "loss": 2.1484,
      "step": 18160
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.998903890854887e-06,
      "loss": 2.3086,
      "step": 18161
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.985447518084383e-06,
      "loss": 2.1016,
      "step": 18162
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.972021358129906e-06,
      "loss": 2.1074,
      "step": 18163
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.9586254113981304e-06,
      "loss": 2.2891,
      "step": 18164
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.9452596782951758e-06,
      "loss": 2.2031,
      "step": 18165
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.9319241592259404e-06,
      "loss": 2.0312,
      "step": 18166
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.918618854594546e-06,
      "loss": 2.2676,
      "step": 18167
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.9053437648043356e-06,
      "loss": 2.3828,
      "step": 18168
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.892098890257322e-06,
      "loss": 2.25,
      "step": 18169
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.878884231355183e-06,
      "loss": 2.293,
      "step": 18170
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.865699788498155e-06,
      "loss": 2.1738,
      "step": 18171
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.8525455620856953e-06,
      "loss": 2.2031,
      "step": 18172
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.8394215525167076e-06,
      "loss": 2.0664,
      "step": 18173
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.826327760188652e-06,
      "loss": 2.2285,
      "step": 18174
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.813264185498432e-06,
      "loss": 2.0977,
      "step": 18175
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.800230828841843e-06,
      "loss": 2.1367,
      "step": 18176
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.7872276906137915e-06,
      "loss": 2.084,
      "step": 18177
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.7742547712085177e-06,
      "loss": 2.3086,
      "step": 18178
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.7613120710190396e-06,
      "loss": 2.1465,
      "step": 18179
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.7483995904373784e-06,
      "loss": 2.2773,
      "step": 18180
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.7355173298552195e-06,
      "loss": 2.2363,
      "step": 18181
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.7226652896624738e-06,
      "loss": 2.2656,
      "step": 18182
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.7098434702490516e-06,
      "loss": 2.4141,
      "step": 18183
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.697051872003087e-06,
      "loss": 2.4219,
      "step": 18184
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.6842904953126024e-06,
      "loss": 2.3438,
      "step": 18185
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.671559340563956e-06,
      "loss": 2.2539,
      "step": 18186
    },
    {
      "epoch": 1.95,
      "learning_rate": 2.6588584081431723e-06,
      "loss": 2.3906,
      "step": 18187
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.646187698434943e-06,
      "loss": 2.1074,
      "step": 18188
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.633547211823406e-06,
      "loss": 2.3359,
      "step": 18189
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.620936948691588e-06,
      "loss": 2.1602,
      "step": 18190
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.6083569094216273e-06,
      "loss": 2.082,
      "step": 18191
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.5958070943945533e-06,
      "loss": 2.2812,
      "step": 18192
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.5832875039909498e-06,
      "loss": 2.127,
      "step": 18193
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.5707981385899583e-06,
      "loss": 2.1875,
      "step": 18194
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.5583389985701645e-06,
      "loss": 2.248,
      "step": 18195
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.5459100843091554e-06,
      "loss": 2.2578,
      "step": 18196
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.533511396183408e-06,
      "loss": 2.4336,
      "step": 18197
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.521142934568843e-06,
      "loss": 2.3008,
      "step": 18198
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.5088046998401616e-06,
      "loss": 2.375,
      "step": 18199
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.4964966923712863e-06,
      "loss": 2.3242,
      "step": 18200
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.4842189125351413e-06,
      "loss": 2.1797,
      "step": 18201
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.471971360703762e-06,
      "loss": 2.3008,
      "step": 18202
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.4597540372484074e-06,
      "loss": 2.1602,
      "step": 18203
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.4475669425392256e-06,
      "loss": 2.0645,
      "step": 18204
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.435410076945588e-06,
      "loss": 2.2656,
      "step": 18205
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.423283440835755e-06,
      "loss": 2.3086,
      "step": 18206
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.4111870345773225e-06,
      "loss": 2.2344,
      "step": 18207
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.399120858536774e-06,
      "loss": 2.2109,
      "step": 18208
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.387084913079818e-06,
      "loss": 2.0488,
      "step": 18209
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.3750791985711616e-06,
      "loss": 2.2949,
      "step": 18210
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.363103715374626e-06,
      "loss": 2.2422,
      "step": 18211
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.3511584638530315e-06,
      "loss": 2.1191,
      "step": 18212
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.339243444368533e-06,
      "loss": 2.2344,
      "step": 18213
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.327358657281953e-06,
      "loss": 2.0352,
      "step": 18214
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.3155041029536693e-06,
      "loss": 2.2461,
      "step": 18215
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.303679781742729e-06,
      "loss": 2.2812,
      "step": 18216
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.291885694007623e-06,
      "loss": 2.4609,
      "step": 18217
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.28012184010562e-06,
      "loss": 2.3008,
      "step": 18218
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.2683882203932137e-06,
      "loss": 2.2441,
      "step": 18219
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.2566848352261193e-06,
      "loss": 2.375,
      "step": 18220
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.245011684958831e-06,
      "loss": 2.3066,
      "step": 18221
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.2333687699450653e-06,
      "loss": 2.2852,
      "step": 18222
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.2217560905376523e-06,
      "loss": 2.1836,
      "step": 18223
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.2101736470886423e-06,
      "loss": 2.0605,
      "step": 18224
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.198621439948867e-06,
      "loss": 2.168,
      "step": 18225
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.18709946946849e-06,
      "loss": 2.2148,
      "step": 18226
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.1756077359965654e-06,
      "loss": 2.1582,
      "step": 18227
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.1641462398814816e-06,
      "loss": 2.2188,
      "step": 18228
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.152714981470405e-06,
      "loss": 2.1621,
      "step": 18229
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.1413139611098363e-06,
      "loss": 2.3555,
      "step": 18230
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.1299431791451664e-06,
      "loss": 2.1738,
      "step": 18231
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.1186026359210076e-06,
      "loss": 2.2617,
      "step": 18232
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.1072923317810855e-06,
      "loss": 2.2109,
      "step": 18233
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.096012267068126e-06,
      "loss": 2.1602,
      "step": 18234
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.0847624421238555e-06,
      "loss": 2.0137,
      "step": 18235
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.0735428572893347e-06,
      "loss": 2.2852,
      "step": 18236
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.0623535129045133e-06,
      "loss": 2.252,
      "step": 18237
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.0511944093082326e-06,
      "loss": 2.3203,
      "step": 18238
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.0400655468388874e-06,
      "loss": 2.1992,
      "step": 18239
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.028966925833764e-06,
      "loss": 2.1641,
      "step": 18240
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.017898546629038e-06,
      "loss": 2.3867,
      "step": 18241
    },
    {
      "epoch": 1.96,
      "learning_rate": 2.0068604095601074e-06,
      "loss": 2.2305,
      "step": 18242
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.9958525149615934e-06,
      "loss": 2.1934,
      "step": 18243
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.9848748631670076e-06,
      "loss": 2.2344,
      "step": 18244
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.9739274545089725e-06,
      "loss": 2.3457,
      "step": 18245
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.9630102893192226e-06,
      "loss": 2.1367,
      "step": 18246
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.9521233679287154e-06,
      "loss": 2.2422,
      "step": 18247
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.941266690667187e-06,
      "loss": 2.2578,
      "step": 18248
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.930440257863708e-06,
      "loss": 2.2617,
      "step": 18249
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.9196440698463493e-06,
      "loss": 2.2188,
      "step": 18250
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.908878126942404e-06,
      "loss": 2.3828,
      "step": 18251
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.8981424294778337e-06,
      "loss": 2.123,
      "step": 18252
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.8874369777782673e-06,
      "loss": 2.2383,
      "step": 18253
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.8767617721678898e-06,
      "loss": 2.1348,
      "step": 18254
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.86611681297022e-06,
      "loss": 2.1523,
      "step": 18255
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.8555021005079998e-06,
      "loss": 2.1035,
      "step": 18256
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.8449176351027498e-06,
      "loss": 2.3203,
      "step": 18257
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.8343634170752133e-06,
      "loss": 2.2539,
      "step": 18258
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.8238394467452458e-06,
      "loss": 2.2773,
      "step": 18259
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.8133457244317032e-06,
      "loss": 2.2383,
      "step": 18260
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.8028822504527752e-06,
      "loss": 2.3828,
      "step": 18261
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.79244902512532e-06,
      "loss": 2.1484,
      "step": 18262
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.7820460487656399e-06,
      "loss": 2.041,
      "step": 18263
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.7716733216888159e-06,
      "loss": 2.2656,
      "step": 18264
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.7613308442093745e-06,
      "loss": 2.3203,
      "step": 18265
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.7510186166406206e-06,
      "loss": 2.4297,
      "step": 18266
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.7407366392950819e-06,
      "loss": 2.293,
      "step": 18267
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.730484912484176e-06,
      "loss": 2.2852,
      "step": 18268
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.7202634365188763e-06,
      "loss": 2.3945,
      "step": 18269
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.7100722117087131e-06,
      "loss": 2.1719,
      "step": 18270
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.6999112383624394e-06,
      "loss": 2.3086,
      "step": 18271
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.6897805167881419e-06,
      "loss": 2.4531,
      "step": 18272
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.6796800472927976e-06,
      "loss": 2.0352,
      "step": 18273
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.6696098301824947e-06,
      "loss": 2.2461,
      "step": 18274
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.6595698657622115e-06,
      "loss": 2.4688,
      "step": 18275
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.6495601543363713e-06,
      "loss": 2.2461,
      "step": 18276
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.639580696208287e-06,
      "loss": 2.4648,
      "step": 18277
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.6296314916802723e-06,
      "loss": 2.2734,
      "step": 18278
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.6197125410538639e-06,
      "loss": 2.1914,
      "step": 18279
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.6098238446297098e-06,
      "loss": 2.0879,
      "step": 18280
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.5999654027073485e-06,
      "loss": 2.1309,
      "step": 18281
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.590137215585652e-06,
      "loss": 2.4258,
      "step": 18282
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.580339283562382e-06,
      "loss": 2.2793,
      "step": 18283
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.5705716069344122e-06,
      "loss": 2.0508,
      "step": 18284
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.5608341859978393e-06,
      "loss": 2.2383,
      "step": 18285
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.5511270210476491e-06,
      "loss": 2.2617,
      "step": 18286
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.5414501123780512e-06,
      "loss": 2.1719,
      "step": 18287
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.531803460282144e-06,
      "loss": 2.3047,
      "step": 18288
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.5221870650524716e-06,
      "loss": 2.2188,
      "step": 18289
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.5126009269803565e-06,
      "loss": 2.2617,
      "step": 18290
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.5030450463562328e-06,
      "loss": 2.2266,
      "step": 18291
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.493519423469647e-06,
      "loss": 2.1738,
      "step": 18292
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.484024058609368e-06,
      "loss": 2.0234,
      "step": 18293
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.4745589520631654e-06,
      "loss": 2.0547,
      "step": 18294
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.4651241041176988e-06,
      "loss": 2.2734,
      "step": 18295
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.455719515059073e-06,
      "loss": 2.3516,
      "step": 18296
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.446345185172171e-06,
      "loss": 2.2461,
      "step": 18297
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.4370011147409878e-06,
      "loss": 2.2617,
      "step": 18298
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.4276873040487415e-06,
      "loss": 2.1602,
      "step": 18299
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.4184037533777617e-06,
      "loss": 2.2773,
      "step": 18300
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.4091504630092678e-06,
      "loss": 2.2344,
      "step": 18301
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.3999274332237023e-06,
      "loss": 2.0469,
      "step": 18302
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.390734664300508e-06,
      "loss": 2.1914,
      "step": 18303
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.3815721565183514e-06,
      "loss": 2.2539,
      "step": 18304
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.372439910154788e-06,
      "loss": 2.3125,
      "step": 18305
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.3633379254867072e-06,
      "loss": 2.4727,
      "step": 18306
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.354266202789667e-06,
      "loss": 2.3438,
      "step": 18307
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.3452247423387797e-06,
      "loss": 2.1426,
      "step": 18308
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.3362135444080492e-06,
      "loss": 2.1973,
      "step": 18309
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.3272326092703678e-06,
      "loss": 2.3379,
      "step": 18310
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.3182819371979626e-06,
      "loss": 2.1602,
      "step": 18311
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.3093615284621718e-06,
      "loss": 2.2461,
      "step": 18312
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.3004713833332238e-06,
      "loss": 2.3438,
      "step": 18313
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.2916115020805696e-06,
      "loss": 2.2266,
      "step": 18314
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.2827818849725503e-06,
      "loss": 2.2891,
      "step": 18315
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.2739825322769516e-06,
      "loss": 2.4141,
      "step": 18316
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.265213444260227e-06,
      "loss": 2.2109,
      "step": 18317
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.2564746211881638e-06,
      "loss": 2.25,
      "step": 18318
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.2477660633256615e-06,
      "loss": 2.2383,
      "step": 18319
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.2390877709365089e-06,
      "loss": 2.1055,
      "step": 18320
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.230439744283829e-06,
      "loss": 2.1836,
      "step": 18321
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.221821983629523e-06,
      "loss": 2.168,
      "step": 18322
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.213234489234827e-06,
      "loss": 2.0449,
      "step": 18323
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.2046772613599766e-06,
      "loss": 2.3457,
      "step": 18324
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.1961503002642093e-06,
      "loss": 2.2148,
      "step": 18325
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.187653606205985e-06,
      "loss": 2.2539,
      "step": 18326
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.1791871794427645e-06,
      "loss": 2.248,
      "step": 18327
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.17075102023112e-06,
      "loss": 2.457,
      "step": 18328
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.162345128826625e-06,
      "loss": 2.1641,
      "step": 18329
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.153969505484076e-06,
      "loss": 2.1172,
      "step": 18330
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.1456241504573805e-06,
      "loss": 2.2852,
      "step": 18331
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.1373090639992256e-06,
      "loss": 2.0547,
      "step": 18332
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.1290242463616318e-06,
      "loss": 2.0977,
      "step": 18333
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.1207696977958425e-06,
      "loss": 2.332,
      "step": 18334
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.112545418551769e-06,
      "loss": 2.3281,
      "step": 18335
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.1043514088787676e-06,
      "loss": 2.2148,
      "step": 18336
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.0961876690250839e-06,
      "loss": 2.0586,
      "step": 18337
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.0880541992380755e-06,
      "loss": 2.041,
      "step": 18338
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.079950999764323e-06,
      "loss": 2.2266,
      "step": 18339
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.071878070849297e-06,
      "loss": 2.3828,
      "step": 18340
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.0638354127375794e-06,
      "loss": 2.3555,
      "step": 18341
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.0558230256730862e-06,
      "loss": 2.1953,
      "step": 18342
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.047840909898401e-06,
      "loss": 2.2598,
      "step": 18343
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.0398890656555527e-06,
      "loss": 2.207,
      "step": 18344
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.0319674931854595e-06,
      "loss": 2.1738,
      "step": 18345
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.0240761927281518e-06,
      "loss": 2.3086,
      "step": 18346
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.0162151645227712e-06,
      "loss": 2.1699,
      "step": 18347
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.0083844088075722e-06,
      "loss": 2.2539,
      "step": 18348
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.0005839258198091e-06,
      "loss": 2.1484,
      "step": 18349
    },
    {
      "epoch": 1.97,
      "learning_rate": 9.928137157959593e-07,
      "loss": 2.2539,
      "step": 18350
    },
    {
      "epoch": 1.97,
      "learning_rate": 9.850737789712794e-07,
      "loss": 2.2598,
      "step": 18351
    },
    {
      "epoch": 1.97,
      "learning_rate": 9.773641155804703e-07,
      "loss": 2.3398,
      "step": 18352
    },
    {
      "epoch": 1.97,
      "learning_rate": 9.69684725857234e-07,
      "loss": 2.3086,
      "step": 18353
    },
    {
      "epoch": 1.97,
      "learning_rate": 9.62035610034051e-07,
      "loss": 2.4414,
      "step": 18354
    },
    {
      "epoch": 1.97,
      "learning_rate": 9.544167683428474e-07,
      "loss": 2.25,
      "step": 18355
    },
    {
      "epoch": 1.97,
      "learning_rate": 9.468282010145491e-07,
      "loss": 2.3945,
      "step": 18356
    },
    {
      "epoch": 1.97,
      "learning_rate": 9.392699082789724e-07,
      "loss": 2.4062,
      "step": 18357
    },
    {
      "epoch": 1.97,
      "learning_rate": 9.317418903652674e-07,
      "loss": 2.332,
      "step": 18358
    },
    {
      "epoch": 1.97,
      "learning_rate": 9.24244147501585e-07,
      "loss": 2.3711,
      "step": 18359
    },
    {
      "epoch": 1.97,
      "learning_rate": 9.167766799150767e-07,
      "loss": 2.0566,
      "step": 18360
    },
    {
      "epoch": 1.97,
      "learning_rate": 9.093394878320061e-07,
      "loss": 2.1367,
      "step": 18361
    },
    {
      "epoch": 1.97,
      "learning_rate": 9.019325714777482e-07,
      "loss": 2.3398,
      "step": 18362
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.945559310767903e-07,
      "loss": 2.209,
      "step": 18363
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.872095668526203e-07,
      "loss": 2.2266,
      "step": 18364
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.7989347902806e-07,
      "loss": 2.2422,
      "step": 18365
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.726076678244877e-07,
      "loss": 2.2188,
      "step": 18366
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.653521334628378e-07,
      "loss": 2.1211,
      "step": 18367
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.581268761630457e-07,
      "loss": 2.2852,
      "step": 18368
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.509318961440471e-07,
      "loss": 2.25,
      "step": 18369
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.43767193623779e-07,
      "loss": 2.1348,
      "step": 18370
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.366327688194009e-07,
      "loss": 2.2383,
      "step": 18371
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.295286219470733e-07,
      "loss": 2.0723,
      "step": 18372
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.224547532221793e-07,
      "loss": 2.3867,
      "step": 18373
    },
    {
      "epoch": 1.98,
      "learning_rate": 8.154111628589922e-07,
      "loss": 1.9199,
      "step": 18374
    },
    {
      "epoch": 1.98,
      "learning_rate": 8.083978510708967e-07,
      "loss": 2.3398,
      "step": 18375
    },
    {
      "epoch": 1.98,
      "learning_rate": 8.014148180706116e-07,
      "loss": 2.3086,
      "step": 18376
    },
    {
      "epoch": 1.98,
      "learning_rate": 7.944620640696343e-07,
      "loss": 2.1406,
      "step": 18377
    },
    {
      "epoch": 1.98,
      "learning_rate": 7.875395892785741e-07,
      "loss": 2.2637,
      "step": 18378
    },
    {
      "epoch": 1.98,
      "learning_rate": 7.806473939073744e-07,
      "loss": 2.3633,
      "step": 18379
    },
    {
      "epoch": 1.98,
      "learning_rate": 7.737854781647569e-07,
      "loss": 2.0859,
      "step": 18380
    },
    {
      "epoch": 1.98,
      "learning_rate": 7.669538422586664e-07,
      "loss": 2.2422,
      "step": 18381
    },
    {
      "epoch": 1.98,
      "learning_rate": 7.601524863962706e-07,
      "loss": 2.3555,
      "step": 18382
    },
    {
      "epoch": 1.98,
      "learning_rate": 7.533814107834048e-07,
      "loss": 2.2031,
      "step": 18383
    },
    {
      "epoch": 1.98,
      "learning_rate": 7.466406156255711e-07,
      "loss": 2.4648,
      "step": 18384
    },
    {
      "epoch": 1.98,
      "learning_rate": 7.399301011268289e-07,
      "loss": 2.3086,
      "step": 18385
    },
    {
      "epoch": 1.98,
      "learning_rate": 7.332498674905708e-07,
      "loss": 2.2539,
      "step": 18386
    },
    {
      "epoch": 1.98,
      "learning_rate": 7.265999149193014e-07,
      "loss": 2.2891,
      "step": 18387
    },
    {
      "epoch": 1.98,
      "learning_rate": 7.199802436144154e-07,
      "loss": 2.4277,
      "step": 18388
    },
    {
      "epoch": 1.98,
      "learning_rate": 7.133908537765299e-07,
      "loss": 2.0859,
      "step": 18389
    },
    {
      "epoch": 1.98,
      "learning_rate": 7.068317456054851e-07,
      "loss": 2.2227,
      "step": 18390
    },
    {
      "epoch": 1.98,
      "learning_rate": 7.00302919299789e-07,
      "loss": 2.1992,
      "step": 18391
    },
    {
      "epoch": 1.98,
      "learning_rate": 6.938043750576162e-07,
      "loss": 2.3086,
      "step": 18392
    },
    {
      "epoch": 1.98,
      "learning_rate": 6.873361130754762e-07,
      "loss": 2.2383,
      "step": 18393
    },
    {
      "epoch": 1.98,
      "learning_rate": 6.808981335497677e-07,
      "loss": 1.9434,
      "step": 18394
    },
    {
      "epoch": 1.98,
      "learning_rate": 6.744904366753346e-07,
      "loss": 2.1992,
      "step": 18395
    },
    {
      "epoch": 1.98,
      "learning_rate": 6.68113022646466e-07,
      "loss": 2.168,
      "step": 18396
    },
    {
      "epoch": 1.98,
      "learning_rate": 6.617658916564517e-07,
      "loss": 2.2129,
      "step": 18397
    },
    {
      "epoch": 1.98,
      "learning_rate": 6.554490438974714e-07,
      "loss": 2.2578,
      "step": 18398
    },
    {
      "epoch": 1.98,
      "learning_rate": 6.491624795610384e-07,
      "loss": 2.2852,
      "step": 18399
    },
    {
      "epoch": 1.98,
      "learning_rate": 6.429061988377782e-07,
      "loss": 2.168,
      "step": 18400
    },
    {
      "epoch": 1.98,
      "learning_rate": 6.366802019170948e-07,
      "loss": 2.1211,
      "step": 18401
    },
    {
      "epoch": 1.98,
      "learning_rate": 6.304844889876149e-07,
      "loss": 2.2539,
      "step": 18402
    },
    {
      "epoch": 1.98,
      "learning_rate": 6.243190602372995e-07,
      "loss": 2.3555,
      "step": 18403
    },
    {
      "epoch": 1.98,
      "learning_rate": 6.181839158528879e-07,
      "loss": 2.041,
      "step": 18404
    },
    {
      "epoch": 1.98,
      "learning_rate": 6.120790560202316e-07,
      "loss": 2.2891,
      "step": 18405
    },
    {
      "epoch": 1.98,
      "learning_rate": 6.060044809244047e-07,
      "loss": 2.3867,
      "step": 18406
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.999601907494823e-07,
      "loss": 2.1484,
      "step": 18407
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.9394618567854e-07,
      "loss": 2.3594,
      "step": 18408
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.879624658938764e-07,
      "loss": 2.207,
      "step": 18409
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.820090315769022e-07,
      "loss": 2.0273,
      "step": 18410
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.760858829079174e-07,
      "loss": 2.2539,
      "step": 18411
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.701930200664451e-07,
      "loss": 1.9219,
      "step": 18412
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.643304432311203e-07,
      "loss": 1.9961,
      "step": 18413
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.584981525794674e-07,
      "loss": 2.1738,
      "step": 18414
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.526961482883453e-07,
      "loss": 2.1016,
      "step": 18415
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.469244305335019e-07,
      "loss": 2.2734,
      "step": 18416
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.411829994897977e-07,
      "loss": 2.2266,
      "step": 18417
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.354718553313154e-07,
      "loss": 2.0762,
      "step": 18418
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.297909982311388e-07,
      "loss": 2.2734,
      "step": 18419
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.241404283613527e-07,
      "loss": 2.3984,
      "step": 18420
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.185201458931533e-07,
      "loss": 2.166,
      "step": 18421
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.129301509969597e-07,
      "loss": 2.2695,
      "step": 18422
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.073704438420812e-07,
      "loss": 2.1055,
      "step": 18423
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.018410245970496e-07,
      "loss": 2.3984,
      "step": 18424
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.963418934292863e-07,
      "loss": 1.9785,
      "step": 18425
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.90873050505658e-07,
      "loss": 2.1289,
      "step": 18426
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.85434495991699e-07,
      "loss": 2.0469,
      "step": 18427
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.800262300523883e-07,
      "loss": 2.1621,
      "step": 18428
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.7464825285148394e-07,
      "loss": 2.3164,
      "step": 18429
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.6930056455185555e-07,
      "loss": 2.0039,
      "step": 18430
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.6398316531581777e-07,
      "loss": 2.2969,
      "step": 18431
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.586960553043529e-07,
      "loss": 2.1211,
      "step": 18432
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.534392346776661e-07,
      "loss": 2.0957,
      "step": 18433
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.482127035951855e-07,
      "loss": 2.1035,
      "step": 18434
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.430164622151178e-07,
      "loss": 2.166,
      "step": 18435
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.378505106950037e-07,
      "loss": 2.0215,
      "step": 18436
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.327148491913846e-07,
      "loss": 2.3047,
      "step": 18437
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.276094778599138e-07,
      "loss": 1.9941,
      "step": 18438
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.2253439685535634e-07,
      "loss": 2.2188,
      "step": 18439
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.1748960633136714e-07,
      "loss": 2.0586,
      "step": 18440
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.124751064408239e-07,
      "loss": 2.3398,
      "step": 18441
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.074908973358271e-07,
      "loss": 2.3477,
      "step": 18442
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.025369791672562e-07,
      "loss": 2.1992,
      "step": 18443
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.9761335208532423e-07,
      "loss": 2.3047,
      "step": 18444
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.9272001623924524e-07,
      "loss": 2.2578,
      "step": 18445
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.87856971777234e-07,
      "loss": 2.3125,
      "step": 18446
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.830242188466171e-07,
      "loss": 2.1914,
      "step": 18447
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.78221757594055e-07,
      "loss": 2.3359,
      "step": 18448
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.7344958816487585e-07,
      "loss": 2.2617,
      "step": 18449
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.6870771070374174e-07,
      "loss": 2.2812,
      "step": 18450
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.639961253544266e-07,
      "loss": 2.2344,
      "step": 18451
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.5931483225959406e-07,
      "loss": 2.3398,
      "step": 18452
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.546638315611306e-07,
      "loss": 2.2832,
      "step": 18453
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.500431234000345e-07,
      "loss": 2.2578,
      "step": 18454
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.4545270791630503e-07,
      "loss": 2.2129,
      "step": 18455
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.40892585249053e-07,
      "loss": 2.2773,
      "step": 18456
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.363627555363902e-07,
      "loss": 2.3125,
      "step": 18457
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.318632189156512e-07,
      "loss": 2.0352,
      "step": 18458
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.273939755231714e-07,
      "loss": 2.1191,
      "step": 18459
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.22955025494398e-07,
      "loss": 2.1777,
      "step": 18460
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.185463689637791e-07,
      "loss": 2.3535,
      "step": 18461
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.141680060650964e-07,
      "loss": 2.0859,
      "step": 18462
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.0981993693079967e-07,
      "loss": 2.4727,
      "step": 18463
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.0550216169278336e-07,
      "loss": 2.1797,
      "step": 18464
    },
    {
      "epoch": 1.98,
      "learning_rate": 3.0121468048183164e-07,
      "loss": 2.2031,
      "step": 18465
    },
    {
      "epoch": 1.98,
      "learning_rate": 2.9695749342795174e-07,
      "loss": 2.0742,
      "step": 18466
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.9273060066004053e-07,
      "loss": 2.084,
      "step": 18467
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.885340023062177e-07,
      "loss": 2.0332,
      "step": 18468
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.8436769849382594e-07,
      "loss": 1.9316,
      "step": 18469
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.8023168934876444e-07,
      "loss": 2.209,
      "step": 18470
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.761259749967104e-07,
      "loss": 2.1602,
      "step": 18471
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.7205055556189795e-07,
      "loss": 2.2617,
      "step": 18472
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.6800543116789477e-07,
      "loss": 2.0586,
      "step": 18473
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.639906019372695e-07,
      "loss": 2.1445,
      "step": 18474
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.6000606799159165e-07,
      "loss": 2.1836,
      "step": 18475
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.560518294517644e-07,
      "loss": 2.207,
      "step": 18476
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.521278864374699e-07,
      "loss": 2.4531,
      "step": 18477
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.482342390677239e-07,
      "loss": 2.2461,
      "step": 18478
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.4437088746043223e-07,
      "loss": 2.2285,
      "step": 18479
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.405378317327234e-07,
      "loss": 2.0879,
      "step": 18480
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.3673507200083767e-07,
      "loss": 2.2871,
      "step": 18481
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.3296260837979422e-07,
      "loss": 2.1875,
      "step": 18482
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.2922044098405704e-07,
      "loss": 2.2539,
      "step": 18483
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.2550856992697987e-07,
      "loss": 2.2695,
      "step": 18484
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.2182699532113936e-07,
      "loss": 2.1797,
      "step": 18485
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.1817571727789088e-07,
      "loss": 2.2188,
      "step": 18486
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.1455473590814568e-07,
      "loss": 2.332,
      "step": 18487
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.1096405132137175e-07,
      "loss": 2.0938,
      "step": 18488
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.07403663626593e-07,
      "loss": 2.2188,
      "step": 18489
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.0387357293161212e-07,
      "loss": 2.5469,
      "step": 18490
    },
    {
      "epoch": 1.99,
      "learning_rate": 2.0037377934334355e-07,
      "loss": 2.2969,
      "step": 18491
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.9690428296792463e-07,
      "loss": 2.168,
      "step": 18492
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.9346508391049345e-07,
      "loss": 2.3867,
      "step": 18493
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.9005618227529996e-07,
      "loss": 2.0723,
      "step": 18494
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.8667757816548393e-07,
      "loss": 2.1602,
      "step": 18495
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.8332927168351887e-07,
      "loss": 2.2383,
      "step": 18496
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.8001126293099025e-07,
      "loss": 2.127,
      "step": 18497
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.7672355200826218e-07,
      "loss": 2.2109,
      "step": 18498
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.7346613901503272e-07,
      "loss": 2.2129,
      "step": 18499
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.7023902405011171e-07,
      "loss": 2.2383,
      "step": 18500
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.6704220721108776e-07,
      "loss": 2.1484,
      "step": 18501
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.6387568859499436e-07,
      "loss": 2.0762,
      "step": 18502
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.6073946829775476e-07,
      "loss": 2.1738,
      "step": 18503
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.5763354641440408e-07,
      "loss": 2.3789,
      "step": 18504
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.545579230389782e-07,
      "loss": 2.3711,
      "step": 18505
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.5151259826484686e-07,
      "loss": 2.1699,
      "step": 18506
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.4849757218415861e-07,
      "loss": 2.125,
      "step": 18507
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.4551284488828475e-07,
      "loss": 1.9629,
      "step": 18508
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.425584164677085e-07,
      "loss": 2.0293,
      "step": 18509
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.3963428701191384e-07,
      "loss": 2.1621,
      "step": 18510
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.3674045660960755e-07,
      "loss": 2.3086,
      "step": 18511
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.3387692534838626e-07,
      "loss": 2.1406,
      "step": 18512
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.3104369331506938e-07,
      "loss": 2.1758,
      "step": 18513
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.282407605955882e-07,
      "loss": 2.3516,
      "step": 18514
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.2546812727476376e-07,
      "loss": 2.2891,
      "step": 18515
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.2272579343663993e-07,
      "loss": 2.3086,
      "step": 18516
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.2001375916426137e-07,
      "loss": 2.2441,
      "step": 18517
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.173320245400067e-07,
      "loss": 2.1504,
      "step": 18518
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.1468058964492212e-07,
      "loss": 2.1172,
      "step": 18519
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.1205945455949884e-07,
      "loss": 2.1406,
      "step": 18520
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.094686193631178e-07,
      "loss": 2.3262,
      "step": 18521
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.0690808413416075e-07,
      "loss": 2.3477,
      "step": 18522
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.0437784895045432e-07,
      "loss": 2.4453,
      "step": 18523
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.018779138886039e-07,
      "loss": 2.1719,
      "step": 18524
    },
    {
      "epoch": 1.99,
      "learning_rate": 9.94082790243267e-08,
      "loss": 2.1055,
      "step": 18525
    },
    {
      "epoch": 1.99,
      "learning_rate": 9.696894443234073e-08,
      "loss": 2.2578,
      "step": 18526
    },
    {
      "epoch": 1.99,
      "learning_rate": 9.455991018680887e-08,
      "loss": 2.4961,
      "step": 18527
    },
    {
      "epoch": 1.99,
      "learning_rate": 9.218117636056178e-08,
      "loss": 2.4297,
      "step": 18528
    },
    {
      "epoch": 1.99,
      "learning_rate": 8.983274302576394e-08,
      "loss": 2.3203,
      "step": 18529
    },
    {
      "epoch": 1.99,
      "learning_rate": 8.751461025346963e-08,
      "loss": 2.3203,
      "step": 18530
    },
    {
      "epoch": 1.99,
      "learning_rate": 8.522677811406698e-08,
      "loss": 2.1953,
      "step": 18531
    },
    {
      "epoch": 1.99,
      "learning_rate": 8.296924667683392e-08,
      "loss": 2.1621,
      "step": 18532
    },
    {
      "epoch": 1.99,
      "learning_rate": 8.074201601016017e-08,
      "loss": 2.1465,
      "step": 18533
    },
    {
      "epoch": 1.99,
      "learning_rate": 7.854508618154732e-08,
      "loss": 2.1582,
      "step": 18534
    },
    {
      "epoch": 1.99,
      "learning_rate": 7.637845725760873e-08,
      "loss": 2.3867,
      "step": 18535
    },
    {
      "epoch": 1.99,
      "learning_rate": 7.424212930384756e-08,
      "loss": 2.2734,
      "step": 18536
    },
    {
      "epoch": 1.99,
      "learning_rate": 7.213610238521185e-08,
      "loss": 2.2578,
      "step": 18537
    },
    {
      "epoch": 1.99,
      "learning_rate": 7.006037656542841e-08,
      "loss": 2.1836,
      "step": 18538
    },
    {
      "epoch": 1.99,
      "learning_rate": 6.801495190733587e-08,
      "loss": 2.25,
      "step": 18539
    },
    {
      "epoch": 1.99,
      "learning_rate": 6.599982847299569e-08,
      "loss": 2.2285,
      "step": 18540
    },
    {
      "epoch": 1.99,
      "learning_rate": 6.401500632347012e-08,
      "loss": 2.0996,
      "step": 18541
    },
    {
      "epoch": 1.99,
      "learning_rate": 6.206048551882227e-08,
      "loss": 2.248,
      "step": 18542
    },
    {
      "epoch": 1.99,
      "learning_rate": 6.013626611844902e-08,
      "loss": 2.1172,
      "step": 18543
    },
    {
      "epoch": 1.99,
      "learning_rate": 5.824234818052609e-08,
      "loss": 2.3789,
      "step": 18544
    },
    {
      "epoch": 1.99,
      "learning_rate": 5.6378731762452004e-08,
      "loss": 2.1582,
      "step": 18545
    },
    {
      "epoch": 1.99,
      "learning_rate": 5.454541692073711e-08,
      "loss": 2.2852,
      "step": 18546
    },
    {
      "epoch": 1.99,
      "learning_rate": 5.274240371089256e-08,
      "loss": 2.1777,
      "step": 18547
    },
    {
      "epoch": 1.99,
      "learning_rate": 5.096969218765235e-08,
      "loss": 2.1348,
      "step": 18548
    },
    {
      "epoch": 1.99,
      "learning_rate": 4.922728240464025e-08,
      "loss": 2.3789,
      "step": 18549
    },
    {
      "epoch": 1.99,
      "learning_rate": 4.751517441470288e-08,
      "loss": 2.1152,
      "step": 18550
    },
    {
      "epoch": 1.99,
      "learning_rate": 4.583336826968765e-08,
      "loss": 2.4219,
      "step": 18551
    },
    {
      "epoch": 1.99,
      "learning_rate": 4.418186402066482e-08,
      "loss": 2.4102,
      "step": 18552
    },
    {
      "epoch": 1.99,
      "learning_rate": 4.256066171748341e-08,
      "loss": 2.252,
      "step": 18553
    },
    {
      "epoch": 1.99,
      "learning_rate": 4.096976140943731e-08,
      "loss": 2.3125,
      "step": 18554
    },
    {
      "epoch": 1.99,
      "learning_rate": 3.9409163144710214e-08,
      "loss": 2.166,
      "step": 18555
    },
    {
      "epoch": 1.99,
      "learning_rate": 3.787886697048659e-08,
      "loss": 2.2285,
      "step": 18556
    },
    {
      "epoch": 1.99,
      "learning_rate": 3.637887293328479e-08,
      "loss": 2.1465,
      "step": 18557
    },
    {
      "epoch": 1.99,
      "learning_rate": 3.4909181078401906e-08,
      "loss": 2.2559,
      "step": 18558
    },
    {
      "epoch": 1.99,
      "learning_rate": 3.3469791450579935e-08,
      "loss": 2.1426,
      "step": 18559
    },
    {
      "epoch": 2.0,
      "learning_rate": 3.2060704093228585e-08,
      "loss": 2.2734,
      "step": 18560
    },
    {
      "epoch": 2.0,
      "learning_rate": 3.0681919049202477e-08,
      "loss": 2.2734,
      "step": 18561
    },
    {
      "epoch": 2.0,
      "learning_rate": 2.933343636024599e-08,
      "loss": 2.3047,
      "step": 18562
    },
    {
      "epoch": 2.0,
      "learning_rate": 2.801525606710431e-08,
      "loss": 2.3691,
      "step": 18563
    },
    {
      "epoch": 2.0,
      "learning_rate": 2.6727378209967513e-08,
      "loss": 2.2578,
      "step": 18564
    },
    {
      "epoch": 2.0,
      "learning_rate": 2.5469802827582376e-08,
      "loss": 2.3789,
      "step": 18565
    },
    {
      "epoch": 2.0,
      "learning_rate": 2.4242529958251602e-08,
      "loss": 2.2812,
      "step": 18566
    },
    {
      "epoch": 2.0,
      "learning_rate": 2.3045559639056635e-08,
      "loss": 2.1777,
      "step": 18567
    },
    {
      "epoch": 2.0,
      "learning_rate": 2.1878891906301767e-08,
      "loss": 2.1504,
      "step": 18568
    },
    {
      "epoch": 2.0,
      "learning_rate": 2.0742526795403116e-08,
      "loss": 2.1367,
      "step": 18569
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.9636464340777594e-08,
      "loss": 2.3594,
      "step": 18570
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.8560704575842913e-08,
      "loss": 2.1367,
      "step": 18571
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.751524753323963e-08,
      "loss": 2.2188,
      "step": 18572
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.650009324483115e-08,
      "loss": 2.1328,
      "step": 18573
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.5515241741037578e-08,
      "loss": 2.1328,
      "step": 18574
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.4560693052056984e-08,
      "loss": 2.2812,
      "step": 18575
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.363644720653312e-08,
      "loss": 2.2891,
      "step": 18576
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.2742504232665653e-08,
      "loss": 2.2695,
      "step": 18577
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.1878864157433001e-08,
      "loss": 2.123,
      "step": 18578
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.1045527007036427e-08,
      "loss": 2.2461,
      "step": 18579
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.0242492806677994e-08,
      "loss": 2.2441,
      "step": 18580
    },
    {
      "epoch": 2.0,
      "learning_rate": 9.46976158078261e-09,
      "loss": 2.0566,
      "step": 18581
    },
    {
      "epoch": 2.0,
      "learning_rate": 8.727333352775979e-09,
      "loss": 2.3672,
      "step": 18582
    },
    {
      "epoch": 2.0,
      "learning_rate": 8.015208145084607e-09,
      "loss": 2.1406,
      "step": 18583
    },
    {
      "epoch": 2.0,
      "learning_rate": 7.333385979357843e-09,
      "loss": 2.3008,
      "step": 18584
    },
    {
      "epoch": 2.0,
      "learning_rate": 6.6818668761348124e-09,
      "loss": 2.2148,
      "step": 18585
    },
    {
      "epoch": 2.0,
      "learning_rate": 6.060650855288507e-09,
      "loss": 2.0215,
      "step": 18586
    },
    {
      "epoch": 2.0,
      "learning_rate": 5.469737935581698e-09,
      "loss": 2.2422,
      "step": 18587
    },
    {
      "epoch": 2.0,
      "learning_rate": 4.909128134999996e-09,
      "loss": 2.3906,
      "step": 18588
    },
    {
      "epoch": 2.0,
      "learning_rate": 4.37882147030777e-09,
      "loss": 2.1973,
      "step": 18589
    },
    {
      "epoch": 2.0,
      "learning_rate": 3.87881795793632e-09,
      "loss": 2.1465,
      "step": 18590
    },
    {
      "epoch": 2.0,
      "learning_rate": 3.4091176126516133e-09,
      "loss": 2.2852,
      "step": 18591
    },
    {
      "epoch": 2.0,
      "learning_rate": 2.9697204489975705e-09,
      "loss": 2.1152,
      "step": 18592
    },
    {
      "epoch": 2.0,
      "learning_rate": 2.5606264800748236e-09,
      "loss": 2.0938,
      "step": 18593
    },
    {
      "epoch": 2.0,
      "learning_rate": 2.1818357184288928e-09,
      "loss": 2.3945,
      "step": 18594
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.833348175384053e-09,
      "loss": 2.1992,
      "step": 18595
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.5151638617094676e-09,
      "loss": 2.2539,
      "step": 18596
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.2272827868420322e-09,
      "loss": 2.3281,
      "step": 18597
    },
    {
      "epoch": 2.0,
      "learning_rate": 9.69704959663531e-10,
      "loss": 2.209,
      "step": 18598
    },
    {
      "epoch": 2.0,
      "learning_rate": 7.424303878345029e-10,
      "loss": 2.1953,
      "step": 18599
    },
    {
      "epoch": 2.0,
      "learning_rate": 5.45459078349353e-10,
      "loss": 2.1055,
      "step": 18600
    },
    {
      "epoch": 2.0,
      "learning_rate": 3.7879103720328547e-10,
      "loss": 2.0664,
      "step": 18601
    },
    {
      "epoch": 2.0,
      "learning_rate": 2.4242626928128173e-10,
      "loss": 2.3594,
      "step": 18602
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.3636477891321165e-10,
      "loss": 2.0762,
      "step": 18603
    },
    {
      "epoch": 2.0,
      "learning_rate": 6.060656920769959e-11,
      "loss": 2.3555,
      "step": 18604
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.515164238519162e-11,
      "loss": 1.9844,
      "step": 18605
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0,
      "loss": 2.3516,
      "step": 18606
    },
    {
      "epoch": 2.0,
      "step": 18606,
      "total_flos": 1.615731709817389e+18,
      "train_loss": 2.3536201779667847,
      "train_runtime": 27305.3188,
      "train_samples_per_second": 43.609,
      "train_steps_per_second": 0.681
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 18606,
  "num_train_epochs": 2,
  "save_steps": 24000.0,
  "total_flos": 1.615731709817389e+18,
  "trial_name": null,
  "trial_params": null
}
